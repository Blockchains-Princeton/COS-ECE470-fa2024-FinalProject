[
    {
        "title": "Setting Forked Repo to Private",
        "question": "I'm having some trouble setting my forked repo to private. For the people able to do this successfully, how'd you do it? I wasn't able to figure out how to make the repository private when starting the forking process either.\n\n",
        "other_text": [
            "Thanks for pointing this out.\n\nTurns out GitHub does not allow making a private fork of a public repo.\nInstead, you can make a new private repository, and import https://github.com/Blockchains-Princeton/COS-ECE470-fa2022.git to this repo, and start working on this.\n\n"
        ]
    },
    {
        "title": "Mac/Linux versus Windows",
        "question": "The course GitHub says that we should switch to Linux or Mac. Are there alternatives or should we get started on switching operating systems now?",
        "other_text": [
            "You can use Windows, but Linux or Mac is recommended.\n\nWe provide instructions for running the provided autograder on Windows too (see Part1).",
            "If you don't have mac/linux, there's always WSL (Windows subsystem for Linux) which more or less gives you the linux experience on your windows laptop"
        ]
    },
    {
        "title": "Task for Week 1",
        "question": "Hi all, \n\nThere is no submission due for this week. However, we encourage you to get started with Rust and Part1 of the Bitcoin client project.\n\nWe have provided starter code and instructions on Github : https://github.com/Blockchains-Princeton/COS-ECE470-fa2022\n\nYou will be working on a private Github repository for this project (required for submission).\n\nTasks for week 1:\n1. Make a new private repository e.g. hebbarashwin/COS-ECE470-fa2022 \n(Please do not change the name of the repo. Might face small issues in the autograder)\n2. Import code from https://github.com/Blockchains-Princeton/COS-ECE470-fa2022.git\n\nYou can now start working on Part1 of the project on your private repos. Please let us know if you face any issues.",
        "other_text": []
    },
    {
        "title": "0 passed, 0 failed Test Result",
        "question": "Hello,\n\nI just ran my code for assignment 1 in the the autograder_windows.bat and got the following result. I'm not sure if this means it worked or I did something wrong in the setup process for the grader since it doesn't seem like it ran any tests. Not sure what went wrong. Any suggestions?\n\n\n\nThanks\n\n",
        "other_text": [
            "Hi Vinay,\n\nDid you pass 3 tests when you ran cargo test in your repo?\n\nFor the autograding:\n1. Do you have add_test.py in the same folder as autograder_windows.bat?\n2. Your files should be in netid/COS-ECE470-fa22-main/  (since the path is hardcoded in the bash file)\n(From your path I think you've named your repo as ECE470-fa22. I think it's best to rename it as COS-ECE470-fa22)",
            "I did pass the 3 tests when I ran cargo test. I do have add_test.py in the same folder. I'll rename my repo and let you know what happens.\n\n",
            "I changed the repo name is COS-ECE470-fa22-main, but I get the same issue with the top error saying \"No such file or directory,\" followed by cmd output that seems to come from code I wrote, and finally \"0 tests passed, 0 tests failed\" as I showed above. Does anything look obviously wrong with the path?",
            "Sorry my bad for the typo.\n\nThe repo and folder should be named COS-ECE470-fa2022 and COS-ECE470-fa2022-main respectively (same name as our template repo).\n\nCheck if it works once you change this.\nMeanwhile I'll try to reproduce the issue on my windows computer and get back to you.\n\nYou do have python3 installed on cmd right?",
            "Yes, I have python3 installed",
            "We checked it on a windows machine, seems to work fine : 3 tests are run by the auto grader.\n\nIf it's still not working for you, we can try to fix it during office hours. "
        ]
    },
    {
        "title": "`cargo build` failed on Apple Silicon",
        "question": "Vanilla build failed due to some instruction set problem (I guess).\n\nFound a solution here: https://github.com/briansmith/ring/issues/1163 (change the version of ring to \"0.16.19\"). This fix solved the compilation issue on my M1machine. \n\nCould you update the dependency version in cargo.toml ?\n\nThank you very much!",
        "other_text": []
    },
    {
        "title": "Collaboration policies for assignments",
        "question": "Hello,\n\nI wasn't able to find any course policies for collaboration. Are we allowed to discuss the assignments with our classmates? Can we use the internet for debugging or to look for the implementation of the modules/libraries we're supposed to use?\n\nThanks!",
        "other_text": [
            "Collaboration policy can be found in the corresponding tab on Canvas :\n\nUnless otherwise noted, all assignments are solo assignments. You are encouraged to ask and answer questions on Ed, but do not post code on the class discussion group, either for the purpose of debugging or demonstrating a possible solution. Your assignment solutions must not be made publicly available online (you must use a private github repository).\n\nDo not under any circumstances, copy another person's code. This is a violation of academic regulations. This includes adapting solutions or partial solutions to assignments from any offering of this course. An exception to this rule is the starter code provided by the course staff.",
            "Adding to this, feel free to look up resources online to debug your code and learn more about rust. We encourage you to do so. "
        ]
    },
    {
        "title": "Rust version",
        "question": "Any particular version of Rust we should use (for accuracy with the grader, etc?) \n\nI have 1.59.0, whereas the newest version appears to be 1.63.0",
        "other_text": [
            "Both versions should work."
        ]
    },
    {
        "title": "Isolation Zoom/Links",
        "question": "Hello, \n\nI tested positive for COVID today and was wondering whether I could get live access to the lecture tomorrow. I see that there is a recording of lecture 1, but I was unsure whether it would only be recorded or also livestreamed. I was in class on Monday but was wearing a KN95 mask. I hope you all are doing well. \n\nWarmly, \n\nMiranda Wang ",
        "other_text": [
            "Hi Miranda, \n\nSorry to hear about this. Hope you recover soon!\n\nUnfortunately, we are unable to provide a livestream of the lecture. However, we will be recording every lecture and will be posting it to the course website and canvas (Panopto video) asap.\nHope this helps."
        ]
    },
    {
        "title": "What to sign/verify in sign/verify functions",
        "question": "For Assignment 1, in order to implement the sign() and verify() functions, do we need to sign/verify a (serialized) transaction or the hash of the transaction?\n\n",
        "other_text": [
            "You need to sign/verify a serialized transaction.",
            "Thank you."
        ]
    },
    {
        "title": "File size for part 1",
        "question": "On Canvas it says: \n\n\"Rename it to your netid as netid.zip. Upload the zip file here on canvas. Please check your file size and it should not be very large.\"\n\nWhat is the expected file size for this? I'm getting something in the 210 MB area and was wondering what exactly quantifies \"not very large.\"\n\n",
        "other_text": [
            "It shouldn't be more than 1-2MB. \n\nYou can use .gitignore to avoid pushing unnecessary files to your repo.",
            "In particular, you can ignore the \"target\" folder that rust creates since that takes up most of the space after compiling"
        ]
    },
    {
        "title": "Returning last 20 bytes",
        "question": "I'm new to Rust and having trouble with something I think is probably pretty simple... \n\nOnce I have a variable of type &[u8], how do I convert it to a certain size? \n\nNot looking for direct answers to the programming assignment, but should I expect to be calling functions here, potentially using things like unwrap()? \n\nIn Python for example, returning the last 20 chars would use simple operators like string[-20:], so I'm not sure if I'm missing something really simple. \n\n\n\n",
        "other_text": [
            "The type of &[u8] is slice and Address wants a [u8; 20] which is an array, so specifically what you want to figure out is how to convert a slice into an array. Also note that slices don't have a size known at compile time while arrays do (eg. 20 in this case), so that might clue you into whether or not you would need something like .unwrap() . Not sure how much we're allowed to say so sorry if this doesn't answer your question directly\n\n",
            ".unwrap() afaik takes a closure (i.e. a function that contains bound variables) and returns the bound variables. For example, if a fn test() -> Result<Vec<u8>>, test().unwrap() would return the Vec<u8> inside closure returned by test(). This is just the behavior I experienced while playing around with Rust, so I have no idea whether this is a good explanation, but I thought I'd chime in.\n\n"
        ]
    },
    {
        "title": "Understanding Rust code in address.rs",
        "question": "I'm trying to understand this function in address.rs:\n\nimpl std::fmt::Display for Address {\n   fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {\n     let start = if let Some(precision) = f.precision() {\n        if precision >= 40 {\n            0\n        } else {\n            20 - precision / 2\n     }\n     } else {\n        0\n     };\n     for byte_idx in start..20 {\n        write!(f, \"{:>02x}\", &self.0[byte_idx])?;\n     }\n     Ok(())\n   }\n}\n\n\nWhat does &self.0[] do? Specifically the .0 part",
        "other_text": [
            "Here self is of type Address so &self is a reference to an Address type. The Address struct is defined above in the same file: pub struct Address([u8; 20]); . This is a tuple struct and in Rust tuple elements can be accessed using the . notation (ie. .0 for first element). The [byte_idx] part just indexes into the array as you'd expect.\n\n"
        ]
    },
    {
        "title": "Office Hours now?",
        "question": "Are there office hours now in J323? I'm in J323 but Professor Viswanath isn't :(\n\n",
        "other_text": [
            "Apologies, Prof Viswanath had to go to a faculty luncheon today. \nHe'll get back to you and let you know another good time to to meet shortly. ",
            "Hi Theo. Very sorry about this -- I had to go to a \"welcome to class of 2025 department meeting\" at an overlapping time. I am back this afternoon -- my room B-308 should be open 3-5pm if you have time to stop by. \n\nPramod",
            "I won't be able to make it during this period but I'll be sure to swing by your office hours in future weeks! Thank you!"
        ]
    },
    {
        "title": "Potentially moving lectures from McCosh to Thomas",
        "question": "Hi Folks,\n\n  Several of you have complained about the stuffiness of McCosh (no AC, very humid) and inconvenient for interactions. I agree. The registrar's office has kindly offered us to move to Thomas 003. I write to seek a quick poll from you on whether you like the new location significantly over McCosh to justify us to move to the new location. Thomas is a bit further down on Washington than McCosh and 003 is in the basement and is a very nice/modern auditorium. Please share your comments on Ed by this weekend. \n\n   Pramod",
        "other_text": [
            "Upvote! I have another class using Thomas 003. Though the room is more compact compared to McCosh, we definitely can hear each other better. Plus it's ACed. \n\nThe only potential issue is the light in that room is dimmer than McCosh 46, so writings on the blackboards are a little bit hard to read, but if we are using slides, then this won't be a problem.\n\nThanks for arranging the new room!",
            "Yes, please! Air con would be great because it's hard to stay focused in McCosh when I'm feeling sweaty and gross \n\n"
        ]
    },
    {
        "title": "TA Office Hours",
        "question": "Where can we find the TA office hours times?",
        "other_text": [
            "Canvas main page"
        ]
    },
    {
        "title": "Are we allowed to use external crates?",
        "question": "Specifically, crates that are not mentioned in the assignment specs.\n\n",
        "other_text": [
            "You can use standard crates (such as std,rand,etc.). But do not use the ones that implement data structures such as merkle trees, etc. that you have been asked to implement by yourself."
        ]
    },
    {
        "title": "Lecture 3",
        "question": "Will the lecture 3 recording be posted soon? ",
        "other_text": [
            "We will post it soon. Sorry for the delay\n",
            "Lecture video has been posted."
        ]
    },
    {
        "title": "Debugging ptr",
        "question": "Hope you're doing well! I can't make office hours tonight but I'm a little confused as to what I should do next for Assn 1, since my code results in an addr that doesn't match the correct one. I think there's a pointer-related issue but I can't seem to figure it out. Could I have some guidance on where I might be going wrong? Thanks! I made this private to course staff in order to post the code, but if I need to take this down, please let me know!\n\n",
        "other_text": [
            "Your result array seems to be the reverse of what the correct answer should be. You can change that order in the for loop you have.",
            "Thank you so much!"
        ]
    },
    {
        "title": "Looking up things on StackOverflow",
        "question": "I am pretty new to Rust and the docs are kind of disorienting. So I am figuring out a lot of what I need to do by going through Stack Overflow. These are simple manipulations (nothing that guides the overall module construction), but I do end up viewing code pieces written by others. \n\nGiven how basic some of these operations are, I feel like certain lines of my code are necessarily going to be very similar. \n\nLower-level Princeton courses are extremely particular about this type of thing so I wanted to check if this is acceptable.",
        "other_text": [
            "It is completely fine to refer to code from stack overflow for the purposes you are describing."
        ]
    },
    {
        "title": "Type conversions and value-to-value conversions",
        "question": "In Rust, can someone explain the difference between type conversions and value-to-value conversions?\n\nSpecifically, where to use TryFrom vs From?\n\nWhat types of conversions can't fail? What types can?\n\n",
        "other_text": [
            "In Rust, can someone explain the difference between type conversions and value-to-value conversions?\n\nI think type conversions is just the general term and you can specify that further as a value-to-value conversion, reference-to-reference conversion, or mutable (reference) - to - mutable (reference) conversion.\n\n\n\nSpecifically, where to use TryFrom vs From? What types of conversions can't fail? What types can?\n\nSince Rust is type safe, a function signature that returns type T must always return a T and thus cannot fail (barring panicking). So, if you were implementing a function that converts from a U to a T that could potentially fail for some value of U, it would need to return a Result<T, T::Error> instead of just T to represent the potential error returned.\n\nIf you look at the docs for From you can see that it returns Self, so it can never fail and must always return a Self. The docs for TryFrom say it returns a Result<Self, Self::Error>, so basically TryFrom is the same as From but it can fail, so the return type of TryFrom is a Result.\n\nWhich one you use depends on what's implemented in the library since sometimes it makes sense that any value of the input type can be converted to the new type (From) and sometimes some input values wouldn't make sense to convert (TryFrom).\n\n"
        ]
    },
    {
        "title": "cargo test from_a_test_key - not working well",
        "question": "Every time I run cargo test from_a_test_key , it has to compile 151 other things (like libc, unicode, bitcoin, serde, etc.). I'm not sure if these are dependencies or something else, but it takes a lot time to test just my address.rs file.\n\nHas anyone else ran into this problem?",
        "other_text": [
            "this doesn't really help you but for the record this shouldn't happen. When you run cargo build or cargo test it should only recompile the stuff that needs to be recompiled (ie. modules that were changed and stuff that depends on the stuff that changed) so running cargo test from_a_test_key twice without changing anything should start executing right away the second time. Maybe try cargo clean (deletes all the cached artifacts) and then try again? shouldn't make a difference but might help if there's some weird cargo bug somewhere\n\n",
            "I got it to mostly work now, but it still recompiles the bitcoin module every time, which is the one I'm writing locally. I believe this is because a lot of the functions are unfinished, so I'm receiving \"unused variable\" warnings, and compilation never finishes.\n\nDid you put explicit #[allow(unused_imports)] in these files? I don't want to forget to remove it when I start working with them.",
            "yea having to recompile bitcoin every time sounds correct since you're changing stuff there. If you run the test command twice without editing your code in between it shouldnt recompile anything.\n\nThe warnings should be there but they shouldn't be affecting the compilation / preventing it from finishing (they're just warnings). It will show the warnings every time you run it regardless of if it has to recompile. I didn't put any #[allow(unused_imports)] anywhere - you can just ignore those warnings since we really haven't used those imports/variables yet. If it really bothers you, you can also add #![allow(unused)] as the first line of main.rs which will suppress all the unused warnings for the whole crate.\n\n"
        ]
    },
    {
        "title": "More information on requirements",
        "question": "Could we be given greater detail in what we are actually supposed to implement? For example, the readme says to \"Fill in the sign and verify function\" with no guidance on how to implement these functions. The lecture notes talk about these topics tangentially, but they also don't get into implementation details.\n\nI could probably look at the test cases and reverse engineer a solution, but then I'm not really learning much about blockchain.\n\nThank you for your response.",
        "other_text": [
            "All of the parts of the first assignment use the ring crate. The documentation page shows various modules for hashing (ring::digest), digital signature + verification (ring::signature).\n\nIn this course we use these cryptographic primitives as black boxes and learn how to use them as tools. For motivation on why we are using them, you can read further parts of the assignments on a high level to understand how all these come together. We would go through all of this in the lecture as well."
        ]
    },
    {
        "title": "Rust Analyzer Issues",
        "question": "I've been having some issues with the Rust Analyzer extension in VSCode (e.g. some functions show \"{unknown}\" when highlighted instead of the corresponding documentation, and the extension simply does not work on my transaction.rs file). \n\nDoes anyone know what some potential causes are for this issue? It's slowing down my workflow a lot and this is even happening in areas that compile and pass tests.\n\nThanks,",
        "other_text": [
            "only thing I can think of is are you opening the whole folder rather than just the file (File -> Open Folder -> /path/to/COS-ECE470-fa2022)? the extension won't be able to work properly if it can't see the whole project structure\n\n"
        ]
    },
    {
        "title": "Mismatch types",
        "question": "Hi! I'm not sure whether I'm generating the addresses properly or the randomization portion in Rust. I have the following code/errors, and I had chosen to randomly generate an u32 since I thought I could make it into a slice/the address.rs file used 32 b for the example test case (I could be wrong, feel free to correct). Rust seems to have pretty specific conventions for treating things as slices, arrays, and vectors, and I can't seem to figure out what I'm doing wrong. Any guidance would be super helpful! Thanks.\n\n\n\n",
        "other_text": [
            "The input to Address::from_public_key_bytes should be a slice of u8. \nSo rand1 and rand2 need to be Vec<u8>, and not u32. (Error says \"expected &[u8], found &u32\")\n\nThe error messages and warnings in Rust are typically very informative. Should be helpful for debugging! ",
            "For this case, you can use the to_be_bytes() function for the conversion.",
            "Thank you both!"
        ]
    },
    {
        "title": "Proof clarification",
        "question": "For proof(), the assignment directions state:\n\nproof() - given a merkle tree, and also given the index, this function returns the proof in the form of a vector of hashes.\n\nShould the vector of hashes include\n\njust the sibling hashes or\n\nthe leaf hash at given index + sibling hashes + root hash?\n\n",
        "other_text": [
            "Only the sibling hashes.\n\nIn the merkle tree example given in the lecture slides, \nproof(5) should return [h(6), h(7,8), h(1,2,3,4)]\n"
        ]
    },
    {
        "title": "Edge cases",
        "question": "Could you please clarify how to deal with some edge cases:\n\nQuestion 1.\n\nfn new(data: &[T])\n\nSuppose  data.len() = 0 . What are the expected merkle tree and merkle root?\n\nQuestion 2.\n\nfn new(data: &[T]) \n\n\nSuppose data.len() = 1 .  Do we need to duplicate the single element?\n\nConsider the example  data = vec![a]\n\nOption 1: \n\nmerkle_root = hash(hash(a) + hash(a)) where \"+\" denotes concatenation\n\nOption 2: \n\nmerkle_root = hash(a)\n\nI lean towards Option 1 because it is consistent with the following requirement, but I would like to get confirmation which option is correct:  \n\nWhenever a level of the tree has odd number of nodes, duplicate the last node to make the number even.\n\nQuestion 3.\n\nfn proof(&self, index: usize) \n\n\nSuppose the merkle tree is built from the input array of size n . Suppose that index >= n. Does the function need to panic in this case? \n\nConsider the example: data.len()=3\n\nDoes the function need to panic when index = 3? Although index=3 is out of bounds for the input array data, the merkle tree has a duplicate element with index=3 at the leaves level. \n\nDoes the function need to panic when index > 3?\n\n",
        "other_text": [
            "1. We won't be testing such edge cases. But if data.len() == 0, you could consider the merkle root to be all zeros for example.\n\n2. Option 2 makes more sense in this case. Again, this won't be tested.\n\n3. Yes, it should panic if index >= 3. (You can just store data length in your struct and panic if index >= data_len)",
            "Thank you very much Ashwin!",
            "Thank you again for answering my previous questions.\n\nJust a quick follow up on Question 2. I understand this case is not tested, but I would like to implement it correctly in case we have to process blocks containing single transactions in the future.\n\nSuppose data.len() = 1, data = vec![a] .\n\nfn new(data: &[T])  builds a Merkle tree that has a single element hash(a) (no duplication in case of a single element).\n\nmerkle_root = hash(a)\n\nThen fn proof(&self, index: usize) , where index=0, returns an empty vector as element  hash(a) is the root of the Merkle tree, and therefore, has no siblings.\n\nCould you please confirm that I understand this correctly? \n\nThank you.\n\n",
            "Yes, this is correct.\n\nproof(index) returns a list of hashes that are required to compute the merkle root. In this case, you can compute the root yourself without any other hashes. ",
            "Thank you!",
            "For Q3),\n\nInstead of letting the program panic/exit :\n\nYou can return an empty vector for proof if index is out of bounds.\nFor verification you should return false,\n\n(Again, this won't be tested)",
            "Thank you!"
        ]
    },
    {
        "title": "Unable to Run the Windows autograder",
        "question": "Whenever I do the windows autograder, it gives me the error: \n\nFileNotFoundError: [Errno 2] No such file or directory: 'gvchen\\COS-ECE470-fa2022-main\\src\\types\\address.rs'\n\nand then proceeds to run 0 tests. I'm not sure what's wrong, since the file path of the autograder is (Desktop)\\gvchen\\COS-ECE470-fa2022-main\\Project1. One thing I've noticed is that when unzipping the folder from github, the COS-ECE470-fa2022 part of the filepath had an extra hyphen. Not sure if that has anything to do with it, but any help for the autograder would be appreciated. ",
        "other_text": [
            "You should run the autograder outside the unzipped folder (in your case in the Desktop folder)."
        ]
    },
    {
        "title": "Making Address Fields Public",
        "question": "Hi, are we allowed to change the field in the Address struct to public or add a public function that allows us to access this field? I am wondering how else we would be able to incorporate this value into our signature. I was thinking we could maybe just turn the entire struct into bytes and then use that but I wasn't sure if the byte representation for an identical Transaction is necessarily the same.\n\nThanks!",
        "other_text": [
            "Yes, you can do either of the two options (make field public or add a public get function)."
        ]
    },
    {
        "title": "Autograder.sh",
        "question": "When I run bash autograder.sh in Project 1, I get:\n\nnetid/COS-ECE470-fa2022-main/src/types  Changed the test code\n\n\nHowever, I did not change the test code. I'm passing the 3 relevant tests when I run cargo test, and I added the .zip file from GitHub as required. Any thoughts on what could be wrong?`",
        "other_text": [
            "It is not an error you are getting - it is the file add_test.py that is adding new test cases to the test code in transaction.rs and address.rs. This file emits this output after successful execution.",
            "I see. So does that mean that the autograder is able to test my code? (I didn't receive any success message, so I wasn't sure). Thanks for clarifying.",
            "You should get a success/fail message for three autograder test cases. \n\nThe autograder adds the new test cases and runs cargo test again.",
            "It creates a log.txt file after running in the root directory. Should look something like this:\n\n\n\n"
        ]
    },
    {
        "title": "Moving from McCosh to Thomas 003 TODAY",
        "question": "Based on your feedback, we will be moving lectures to Thomas Lab 003 starting TODAY (Monday September 19).\n\nPlease make a note.",
        "other_text": []
    },
    {
        "title": "Confused about SignedTransaction?",
        "question": "I implemented sign, verify, and generate_random transaction. I'm passing the basic tests, but I didn't use the SignedTransaction at all, how does that play in?\n\n",
        "other_text": [
            "SignedTransaction will be used in future parts of the projects. We don't test it in Part 1.",
            "Thank you!"
        ]
    },
    {
        "title": "Constraint on Transaction amount?",
        "question": "Is there any upper bound for Transaction amount size?",
        "other_text": [
            "You could use u8 or u32 for now"
        ]
    },
    {
        "title": "Tip for Hashing Two Hashes",
        "question": "Hey,\n\nDuring office hours, we were working on hashing a combination two hashes for the construction of a Merkle tree. A general tip: instead of trying to concatenate the two hashes and rehashing the combination explicitly, try using the ring::context's methods update() and finish() from the Ring library. There's pretty good documentation online for using context. The into() method also can be used to implicitly convert types if necessary. \n\n\n\nBest\n\n",
        "other_text": []
    },
    {
        "title": "log.txt expected output",
        "question": "I'm getting the following output in log.txt\n\nstudent netid: xxx\n\n\nbut not getting any errors or ok's. Does this mean the autograder passed successfully?\n\n",
        "other_text": [
            "You should get ok/failed messages on your console as well on the test cases. You can check if you have any errors in the build_log.txt file that the autograder creates.",
            "I'm not getting any other lines in the output file. And mine is called log.txt not build_log.txt.",
            "There should be a file called build_log inside the COS-ECE470-fa2022-main folder."
        ]
    },
    {
        "title": "Extract array from Address",
        "question": "I'm trying to get at the [u8; 20] array inside the address struct but failing (accessing it as address.0 fails because it is a private field).\n\nThe into method also doesn't seem to work.\n\nHow do I get at the array contained in the struct so I can move forward with operating on it? Or is this a wrong track entirely?",
        "other_text": [
            "If you require it, you can make the field public or write a function to access it.\n\nHowever, I think you can implement without needing to access the array in the struct. "
        ]
    },
    {
        "title": "Assignment re-submission naming",
        "question": "Hello there!\n\nWhen I resubmitted my file as a \"New Attempt\" on canvas, I found that canvas appended a \"-1\" to the end (e.g. original name was netid.zip and it is now netid-1.zip). I was wondering if this would cause any issues with grading the assignment?\n\nThanks!\n\n",
        "other_text": [
            "Should be fine. "
        ]
    },
    {
        "title": "Using SignedTransaction struct?",
        "question": "Per instruction in A1, I filled out SignedTransaction struct with a Transation, public key and signature, but didn't end up using it anywhere else.\n\nIs this struct intended for later assignments or am I missing something?\n\nThank you.",
        "other_text": [
            "Yes this is intended for later assignments."
        ]
    },
    {
        "title": "Adding to Transaction and SignedTransaction",
        "question": "The Structs Transaction and Signed Transaction are not flagged with unimplemented, but also dont have anything in them.  Are we allowed/supposed to add to them even though they are not flagged unimplemented? ",
        "other_text": [
            "Yes you are supposed to add the appropriate fields. But we would be using those only in later assignments.",
            "Reading through these threads a bit late. I did not use SignedTransaction anywhere in my Assignment 1 code and thus did not add any fields to it. Will I be penalized for this?\n\n",
            "No you won't be penalized. It is fine, you can add the fields later"
        ]
    },
    {
        "title": "Viraj Nadkarni Office Hours",
        "question": "Does Viraj Nadkarni have office hours right now (4-5PM) as indicated on canvas? I have been in the zoom link for the past half hour but no one is here\n\nThanks!",
        "other_text": [
            "They were in-person in EQUAD J323.\n\nIf you have any unanswered questions you can post here on Ed"
        ]
    },
    {
        "title": "Turning a transaction into a signature",
        "question": "Hi,\n\nI am currently working on the sign() function and I noticed that the key.sign() function only accepts a slice, but we want to sign a struct rather than a string. Are we supposed to try to convert a struct to a string or is there some other way we should be signing it? Thanks for your help!",
        "other_text": [
            "You need to serialize the transaction to get a vector of bytes. serde, bincode have implementations for serialization "
        ]
    },
    {
        "title": "Converting ring verify as a boolean.",
        "question": "Hi course staff! \n\nAfter going to office hours, I learned the general strategy for converting types/results. \n\nHowever, my verify function asks for a bool return, and I can't figure out how to convert the result into a boolean. Any tips? And thank you for your help! \n\n",
        "other_text": [
            "You can try .is_ok().\n\nOr you could use the match statement"
        ]
    },
    {
        "title": "Late Days",
        "question": "Are there any late days for the assignment / what is the policy on late submissions?",
        "other_text": [
            "Unfortunately we will not be having any late days for the assignments.\n\nQuoting the professor's announcement on canvas regarding assignment deadlines : \n\nWe affirm that all deadlines are firm. The assignments have been released up front allowing for plenty of time to get a head start. In case of an emergency, contact the teaching staff (instructor/TAs) as soon as you are aware of it and we will discuss the matter on a one-on-one basis. "
        ]
    },
    {
        "title": "Ring Crate (Assignment 1)",
        "question": "Is there better documentation for using the Ring crate than this (https://docs.rs/ring/0.11.0/ring/signature/index.html) or actual examples of usage we can reference?\n\nI'm a bit confused on how to use things in the Ring crate for assignment 1? For example, in the \"sign\" function do we / how can we use ring::signature::{Signature}?",
        "other_text": [
            "The examples in the ring documentation should be a good reference:\n\nHashing using SHA256 : https://docs.rs/ring/0.16.20/ring/digest/fn.digest.html\nSigning and verifying with Ed25519 : https://docs.rs/ring/0.16.20/ring/signature/index.html"
        ]
    },
    {
        "title": "Error creating Address instance in generate_random_transaction()",
        "question": "Hi,\n\nI am having trouble creating Address objects in generate_random_transaction() because it says the fields are private and the constructor is not shown because of this. Any hint on how I can create Address objects in this function? Can we make Address array field public? Thanks!\n\n",
        "other_text": [
            "You can generate a random u8 vector/slice and use Address::from_public_key_bytes that you have implemented."
        ]
    },
    {
        "title": "Assignment 1 Grading Questions",
        "question": "Will style be a factor in our grading?\n\nShould our code include extensive error handling/checking? (in particular, will we be graded on how a function behaves if called with bad arguments?)\n\n",
        "other_text": [
            "Will style be a factor in our grading?\n\nNo, grades will be assigned based on the number of test cases passed on the autograder.\n\n(in particular, will we be graded on how a function behaves if called with bad arguments?)\n\nNo, we will not be testing corner cases and error handling with incorrect arguments. However, we encourage you to write your own test cases to ensure that the logic is sound, and conceptually important cases work correctly.",
            "Orthogonal but in terms of style, you may try cargo fmt which formats all rust code automatically."
        ]
    },
    {
        "title": "Issue with autograder",
        "question": "I forked the repo and didn't change the name, so my repo is called COS-ECE470-fa2022 ; however, when I try to run the autograder, I get an error, because it is looking for a directory named COS-ECE470-fa2022-main. Do I need to update my repo name?",
        "other_text": [
            "After you push your code to the main branch of your repo, download zip file from the repo.\n\nWhen you unzip this you should get a folder named \"COS-ECE470-fa2022-main\"\n\n"
        ]
    },
    {
        "title": "Rust learning resource",
        "question": "Found that educative has some pretty well written articles on different rust concepts, if you have difficulty understanding rust concepts, could be worth trying to google \"educative rust\" + the concept .\n\n\n\n",
        "other_text": []
    },
    {
        "title": "hex macro error in autograder.sh output",
        "question": "I am getting the following error in my autograder.sh output \n\nerror: cannot find macro hex in this scope\n\nThis is referring to the usage of hex in the method from_a_test_key() that we did not even edit.\n\nI have unsuccessfully tried some quick fixes but am wondering whether this could have to do with the way I've zipped my code files. (My code passes the 3 cargo tests that it is supposed to.)",
        "other_text": [
            "This issue had to do with the name of my zip file.",
            "You were able to fix the issue right? ",
            "yes I was thanks."
        ]
    },
    {
        "title": "Assignment 1",
        "question": "When I run the autograder script I get the error:\n\nChanged the test code. I also do net get a success message at all in the log file. I get:\n\nstudent netid: COS-ECE470-fa2022-main\nstudent netid: COS-ECE470-fa2022-main\nstudent netid: COS-ECE470-fa2022-main\n\nHowever when i run the tests individually without the autograder I get ok.\n\nThen I get a pop up: \n\nlibhex_literal-c1a4aaadac546f0f.dylib\u201d cannot be opened because the developer cannot be verified.\n\nHow do I fix this?\n\nI also wanted to ask about the significance of signTransaction struct. I was able to run the tests without the need to implement it. I do not know if this is correct.  From my understanding we needed to convert the sender address , reciever address and the value to an array of u8 (&u8) concat the array and then create a signature from this long array. I did this and it gave me okay on the test. Is this right? and if so what is the point of the signed Transaction struct?",
        "other_text": [
            "\"Changed the test code\" is not an error, the autograder is supposed to do that. The signed transaction struct will be used in later assignments, you can just fill in the fields in its definition - no need to worry about anything else right now.",
            "You can also check if you are getting any errors in the build_log.txt file that gets created in COS-ECE470-fa2022-main folder.",
            "Oh no worries I found it. I get alot of errors related to other files however. Like files I didnt edit. I found this inside the generated folder\n\n   Compiling bitcoin v0.1.0 (/Users/brianmaxtchouambe/PRINCETON/470/COS-ECE470-fa2022/test/COS-ECE470-fa2022-main/COS-ECE470-fa2022-main)\nerror: dlopen(/Users/brianmaxtchouambe/PRINCETON/470/COS-ECE470-fa2022/test/COS-ECE470-fa2022-main/COS-ECE470-fa2022-main/target/debug/deps/libhex_literal-c1a4aaadac546f0f.dylib, 5): no suitable image found.  Did find:\n           /Users/brianmaxtchouambe/PRINCETON/470/COS-ECE470-fa2022/test/COS-ECE470-fa2022-main/COS-ECE470-fa2022-main/target/debug/deps/libhex_literal-c1a4aaadac546f0f.dylib: code signature in (/Users/brianmaxtchouambe/PRINCETON/470/COS-ECE470-fa2022/test/COS-ECE470-fa2022-main/COS-ECE470-fa2022-main/target/debug/deps/libhex_literal-c1a4aaadac546f0f.dylib) not valid for use in process using Library Validation: library load disallowed by system policy\n --> src/main.rs:3:1\n  |\n3 | extern crate hex_literal;\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n --> src/network/peer.rs:2:5\n  |\n2 | use futures::{channel::mpsc, sink::SinkExt};\n  |     ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n --> src/network/server.rs:6:5\n  |\n6 | use futures::io::{AsyncReadExt, AsyncWriteExt};\n  |     ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n --> src/network/server.rs:7:5\n  |\n7 | use futures::io::{BufReader, BufWriter};\n  |     ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n --> src/network/server.rs:8:5\n  |\n8 | use futures::{channel::oneshot, stream::StreamExt};\n  |     ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/api/mod.rs:1:5\n  |\n1 | use serde::Serialize;\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/types/address.rs:1:5\n  |\n1 | use serde::{Serialize, Deserialize};\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/types/block.rs:1:5\n  |\n1 | use serde::{Serialize, Deserialize};\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/types/hash.rs:1:5\n  |\n1 | use serde::{Serialize, Deserialize};\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/types/transaction.rs:1:5\n  |\n1 | use serde::{Serialize,Deserialize};\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `ntest_test_cases` which `ntest` depends on\n   --> src/miner/mod.rs:152:9\n    |\n152 |     use ntest::timeout;\n    |         ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/network/message.rs:1:5\n  |\n1 | use serde::{Serialize, Deserialize};\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `ntest_test_cases` which `ntest` depends on\n   --> src/network/worker.rs:102:9\n    |\n102 |     use ntest::timeout;\n    |         ^^^^^ can't find crate\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:39:18\n   |\n39 |                 (hex!(\"0101010101010101010101010101010101010101010101010101010101010202\")).into(),\n   |                  ^^^\n...\n76 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:38:18\n   |\n38 |                 (hex!(\"0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d\")).into(),\n   |                  ^^^\n...\n76 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:68:25\n   |\n68 |                    vec![hex!(\"965b093a75a75895a351786dd7a188515173f6928a8af8c9baa4dcff268a4f0f\").into()]\n   |                         ^^^\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:39:18\n   |\n39 |                 (hex!(\"0101010101010101010101010101010101010101010101010101010101010202\")).into(),\n   |                  ^^^\n...\n64 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:38:18\n   |\n38 |                 (hex!(\"0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d\")).into(),\n   |                  ^^^\n...\n64 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:51:14\n   |\n51 |             (hex!(\"6b787718210e0b3b608814e04e61fde06d0df794319a12162f287412df3ec920\")).into()\n   |              ^^^\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:39:18\n   |\n39 |                 (hex!(\"0101010101010101010101010101010101010101010101010101010101010202\")).into(),\n   |                  ^^^\n...\n46 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:38:18\n   |\n38 |                 (hex!(\"0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d\")).into(),\n   |                  ^^^\n...\n46 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot determine resolution for the attribute macro `timeout`\n   --> src/network/worker.rs:137:7\n    |\n137 |     #[timeout(60000)]\n    |       ^^^^^^^\n    |\n    = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the attribute macro `timeout`\n   --> src/network/worker.rs:123:7\n    |\n123 |     #[timeout(60000)]\n    |       ^^^^^^^\n    |\n    = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the attribute macro `timeout`\n   --> src/network/worker.rs:110:7\n    |\n110 |     #[timeout(60000)]\n    |       ^^^^^^^\n    |\n    = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n --> src/network/message.rs:5:10\n  |\n5 | #[derive(Serialize, Deserialize, Debug, Clone)]\n  |          ^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n --> src/network/message.rs:5:21\n  |\n5 | #[derive(Serialize, Deserialize, Debug, Clone)]\n  |                     ^^^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the attribute macro `timeout`\n   --> src/miner/mod.rs:156:7\n    |\n156 |     #[timeout(60000)]\n    |       ^^^^^^^\n    |\n    = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n  --> src/types/transaction.rs:14:10\n   |\n14 | #[derive(Serialize, Deserialize, Debug, Default, Clone)]\n   |          ^^^^^^^^^\n   |\n   = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n  --> src/types/transaction.rs:14:21\n   |\n14 | #[derive(Serialize, Deserialize, Debug, Default, Clone)]\n   |                     ^^^^^^^^^^^\n   |\n   = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n --> src/types/transaction.rs:6:10\n  |\n6 | #[derive(Serialize, Deserialize, Debug, Default, Clone)]\n  |          ^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n --> src/types/transaction.rs:6:21\n  |\n6 | #[derive(Serialize, Deserialize, Debug, Default, Clone)]\n  |                     ^^^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n  --> src/types/hash.rs:13:25\n   |\n13 | #[derive(Eq, PartialEq, Serialize, Deserialize, Clone, Hash, Default, Copy)]\n   |                         ^^^^^^^^^\n   |\n   = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n  --> src/types/hash.rs:13:36\n   |\n13 | #[derive(Eq, PartialEq, Serialize, Deserialize, Clone, Hash, Default, Copy)]\n   |                                    ^^^^^^^^^^^\n   |\n   = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n --> src/types/block.rs:4:10\n  |\n4 | #[derive(Serialize, Deserialize, Debug, Clone)]\n  |          ^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n --> src/types/block.rs:4:21\n  |\n4 | #[derive(Serialize, Deserialize, Debug, Clone)]\n  |                     ^^^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/address.rs:72:37\n   |\n72 |         let correct_addr: Address = hex!(\"1851a0eae0060a132cf0f64a0ffaea248de6cba0\").into();\n   |                                     ^^^\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/address.rs:70:24\n   |\n70 |         let test_key = hex!(\"0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d\");\n   |                        ^^^\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n\nerror: cannot determine resolution for the derive macro `Serialize`\n --> src/types/address.rs:5:25\n  |\n5 | #[derive(Eq, PartialEq, Serialize, Deserialize, Clone, Hash, Default, Copy)]\n  |                         ^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n --> src/types/address.rs:5:36\n  |\n5 | #[derive(Eq, PartialEq, Serialize, Deserialize, Clone, Hash, Default, Copy)]\n  |                                    ^^^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n  --> src/api/mod.rs:23:10\n   |\n23 | #[derive(Serialize)]\n   |          ^^^^^^^^^\n   |\n   = note: import resolution is stuck, try simplifying macro imports\n\nerror[E0463]: can't find crate for `serde_derive` which `serde_json` depends on\n  --> src/api/mod.rs:36:42\n   |\n36 |         let resp = Response::from_string(serde_json::to_string_pretty(&payload).unwrap())\n   |                                          ^^^^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde_json` depends on\n  --> src/api/mod.rs:44:42\n   |\n44 |         let resp = Response::from_string(serde_json::to_string(&$message).unwrap())\n   |                                          ^^^^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde_json` depends on\n   --> src/api/mod.rs:134:33\n    |\n134 | ...                   serde_json::to_string_pretty(&payload).unwrap(),\n    |                       ^^^^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `bincode` depends on\n  --> src/network/peer.rs:37:22\n   |\n37 |         let buffer = bincode::serialize(&msg).unwrap();\n   |                      ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n  --> src/network/peer.rs:65:36\n   |\n65 |         let bytes = smol::block_on(futures::stream::StreamExt::next(&mut self.r)).unwrap();\n   |                                    ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `bincode` depends on\n  --> src/network/peer.rs:66:28\n   |\n66 |         let msg: Message = bincode::deserialize(&bytes).unwrap();\n   |                            ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n  --> src/network/server.rs:60:53\n   |\n60 |         thread::spawn(move || smol::block_on(ex.run(futures::future::pending::<()>())));\n   |                                                     ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `bincode` depends on\n  --> src/network/worker.rs:55:32\n   |\n55 |             let msg: Message = bincode::deserialize(&msg).unwrap();\n   |                                ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `bincode` depends on\n  --> src/network/worker.rs:82:21\n   |\n82 |         let bytes = bincode::serialize(&msg).unwrap();\n   |                     ^^^^^^^ can't find crate\n\nwarning: unused imports: `EdDSAParameters`, `KeyPair`\n --> src/types/transaction.rs:2:59\n  |\n2 | use ring::signature::{Ed25519KeyPair, ED25519, Signature, KeyPair, VerificationAlgorithm, EdDSAParameters, UnparsedPublicKey};\n  |                                                           ^^^^^^^                         ^^^^^^^^^^^^^^^\n  |\n  = note: `#[warn(unused_imports)]` on by default\n\nwarning: unused imports: `Sender`, `TryRecvError`, `unbounded`\n --> src/miner/worker.rs:1:26\n  |\n1 | use crossbeam::channel::{unbounded, Receiver, Sender, TryRecvError};\n  |                          ^^^^^^^^^            ^^^^^^  ^^^^^^^^^^^^\n\nwarning: unused import: `debug`\n --> src/miner/worker.rs:2:11\n  |\n2 | use log::{debug, info};\n  |           ^^^^^\n\nwarning: unused import: `VerificationAlgorithm`\n --> src/types/transaction.rs:2:68\n  |\n2 | use ring::signature::{Ed25519KeyPair, ED25519, Signature, KeyPair, VerificationAlgorithm, EdDSAParameters, UnparsedPublicKey};\n  |                                                                    ^^^^^^^^^^^^^^^^^^^^^\n\nFor more information about this error, try `rustc --explain E0463`.\nwarning: `bitcoin` (bin \"bitcoin\" test) generated 4 warnings\nerror: could not compile `bitcoin` due to 49 previous errors; 4 warnings emitted\n   Compiling bitcoin v0.1.0 (/Users/brianmaxtchouambe/PRINCETON/470/COS-ECE470-fa2022/test/COS-ECE470-fa2022-main/COS-ECE470-fa2022-main)\nerror: dlopen(/Users/brianmaxtchouambe/PRINCETON/470/COS-ECE470-fa2022/test/COS-ECE470-fa2022-main/COS-ECE470-fa2022-main/target/debug/deps/libhex_literal-c1a4aaadac546f0f.dylib, 5): no suitable image found.  Did find:\n           /Users/brianmaxtchouambe/PRINCETON/470/COS-ECE470-fa2022/test/COS-ECE470-fa2022-main/COS-ECE470-fa2022-main/target/debug/deps/libhex_literal-c1a4aaadac546f0f.dylib: code signature in (/Users/brianmaxtchouambe/PRINCETON/470/COS-ECE470-fa2022/test/COS-ECE470-fa2022-main/COS-ECE470-fa2022-main/target/debug/deps/libhex_literal-c1a4aaadac546f0f.dylib) not valid for use in process using Library Validation: library load disallowed by system policy\n --> src/main.rs:3:1\n  |\n3 | extern crate hex_literal;\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n --> src/network/peer.rs:2:5\n  |\n2 | use futures::{channel::mpsc, sink::SinkExt};\n  |     ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n --> src/network/server.rs:6:5\n  |\n6 | use futures::io::{AsyncReadExt, AsyncWriteExt};\n  |     ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n --> src/network/server.rs:7:5\n  |\n7 | use futures::io::{BufReader, BufWriter};\n  |     ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n --> src/network/server.rs:8:5\n  |\n8 | use futures::{channel::oneshot, stream::StreamExt};\n  |     ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/api/mod.rs:1:5\n  |\n1 | use serde::Serialize;\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/types/address.rs:1:5\n  |\n1 | use serde::{Serialize, Deserialize};\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/types/block.rs:1:5\n  |\n1 | use serde::{Serialize, Deserialize};\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/types/hash.rs:1:5\n  |\n1 | use serde::{Serialize, Deserialize};\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/types/transaction.rs:1:5\n  |\n1 | use serde::{Serialize,Deserialize};\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `ntest_test_cases` which `ntest` depends on\n   --> src/miner/mod.rs:152:9\n    |\n152 |     use ntest::timeout;\n    |         ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/network/message.rs:1:5\n  |\n1 | use serde::{Serialize, Deserialize};\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `ntest_test_cases` which `ntest` depends on\n   --> src/network/worker.rs:102:9\n    |\n102 |     use ntest::timeout;\n    |         ^^^^^ can't find crate\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:39:18\n   |\n39 |                 (hex!(\"0101010101010101010101010101010101010101010101010101010101010202\")).into(),\n   |                  ^^^\n...\n76 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:38:18\n   |\n38 |                 (hex!(\"0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d\")).into(),\n   |                  ^^^\n...\n76 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:68:25\n   |\n68 |                    vec![hex!(\"965b093a75a75895a351786dd7a188515173f6928a8af8c9baa4dcff268a4f0f\").into()]\n   |                         ^^^\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:39:18\n   |\n39 |                 (hex!(\"0101010101010101010101010101010101010101010101010101010101010202\")).into(),\n   |                  ^^^\n...\n64 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:38:18\n   |\n38 |                 (hex!(\"0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d\")).into(),\n   |                  ^^^\n...\n64 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:51:14\n   |\n51 |             (hex!(\"6b787718210e0b3b608814e04e61fde06d0df794319a12162f287412df3ec920\")).into()\n   |              ^^^\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:39:18\n   |\n39 |                 (hex!(\"0101010101010101010101010101010101010101010101010101010101010202\")).into(),\n   |                  ^^^\n...\n46 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:38:18\n   |\n38 |                 (hex!(\"0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d\")).into(),\n   |                  ^^^\n...\n46 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot determine resolution for the attribute macro `timeout`\n   --> src/network/worker.rs:137:7\n    |\n137 |     #[timeout(60000)]\n    |       ^^^^^^^\n    |\n    = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the attribute macro `timeout`\n   --> src/network/worker.rs:123:7\n    |\n123 |     #[timeout(60000)]\n    |       ^^^^^^^\n    |\n    = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the attribute macro `timeout`\n   --> src/network/worker.rs:110:7\n    |\n110 |     #[timeout(60000)]\n    |       ^^^^^^^\n    |\n    = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n --> src/network/message.rs:5:10\n  |\n5 | #[derive(Serialize, Deserialize, Debug, Clone)]\n  |          ^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n --> src/network/message.rs:5:21\n  |\n5 | #[derive(Serialize, Deserialize, Debug, Clone)]\n  |                     ^^^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the attribute macro `timeout`\n   --> src/miner/mod.rs:156:7\n    |\n156 |     #[timeout(60000)]\n    |       ^^^^^^^\n    |\n    = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n  --> src/types/transaction.rs:14:10\n   |\n14 | #[derive(Serialize, Deserialize, Debug, Default, Clone)]\n   |          ^^^^^^^^^\n   |\n   = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n  --> src/types/transaction.rs:14:21\n   |\n14 | #[derive(Serialize, Deserialize, Debug, Default, Clone)]\n   |                     ^^^^^^^^^^^\n   |\n   = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n --> src/types/transaction.rs:6:10\n  |\n6 | #[derive(Serialize, Deserialize, Debug, Default, Clone)]\n  |          ^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n --> src/types/transaction.rs:6:21\n  |\n6 | #[derive(Serialize, Deserialize, Debug, Default, Clone)]\n  |                     ^^^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n  --> src/types/hash.rs:13:25\n   |\n13 | #[derive(Eq, PartialEq, Serialize, Deserialize, Clone, Hash, Default, Copy)]\n   |                         ^^^^^^^^^\n   |\n   = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n  --> src/types/hash.rs:13:36\n   |\n13 | #[derive(Eq, PartialEq, Serialize, Deserialize, Clone, Hash, Default, Copy)]\n   |                                    ^^^^^^^^^^^\n   |\n   = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n --> src/types/block.rs:4:10\n  |\n4 | #[derive(Serialize, Deserialize, Debug, Clone)]\n  |          ^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n --> src/types/block.rs:4:21\n  |\n4 | #[derive(Serialize, Deserialize, Debug, Clone)]\n  |                     ^^^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/address.rs:72:37\n   |\n72 |         let correct_addr: Address = hex!(\"1851a0eae0060a132cf0f64a0ffaea248de6cba0\").into();\n   |                                     ^^^\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/address.rs:70:24\n   |\n70 |         let test_key = hex!(\"0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d\");\n   |                        ^^^\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n\nerror: cannot determine resolution for the derive macro `Serialize`\n --> src/types/address.rs:5:25\n  |\n5 | #[derive(Eq, PartialEq, Serialize, Deserialize, Clone, Hash, Default, Copy)]\n  |                         ^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n --> src/types/address.rs:5:36\n  |\n5 | #[derive(Eq, PartialEq, Serialize, Deserialize, Clone, Hash, Default, Copy)]\n  |                                    ^^^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n  --> src/api/mod.rs:23:10\n   |\n23 | #[derive(Serialize)]\n   |          ^^^^^^^^^\n   |\n   = note: import resolution is stuck, try simplifying macro imports\n\nerror[E0463]: can't find crate for `serde_derive` which `serde_json` depends on\n  --> src/api/mod.rs:36:42\n   |\n36 |         let resp = Response::from_string(serde_json::to_string_pretty(&payload).unwrap())\n   |                                          ^^^^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde_json` depends on\n  --> src/api/mod.rs:44:42\n   |\n44 |         let resp = Response::from_string(serde_json::to_string(&$message).unwrap())\n   |                                          ^^^^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde_json` depends on\n   --> src/api/mod.rs:134:33\n    |\n134 | ...                   serde_json::to_string_pretty(&payload).unwrap(),\n    |                       ^^^^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `bincode` depends on\n  --> src/network/peer.rs:37:22\n   |\n37 |         let buffer = bincode::serialize(&msg).unwrap();\n   |                      ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n  --> src/network/peer.rs:65:36\n   |\n65 |         let bytes = smol::block_on(futures::stream::StreamExt::next(&mut self.r)).unwrap();\n   |                                    ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `bincode` depends on\n  --> src/network/peer.rs:66:28\n   |\n66 |         let msg: Message = bincode::deserialize(&bytes).unwrap();\n   |                            ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n  --> src/network/server.rs:60:53\n   |\n60 |         thread::spawn(move || smol::block_on(ex.run(futures::future::pending::<()>())));\n   |                                                     ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `bincode` depends on\n  --> src/network/worker.rs:55:32\n   |\n55 |             let msg: Message = bincode::deserialize(&msg).unwrap();\n   |                                ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `bincode` depends on\n  --> src/network/worker.rs:82:21\n   |\n82 |         let bytes = bincode::serialize(&msg).unwrap();\n   |                     ^^^^^^^ can't find crate\n\nwarning: unused imports: `EdDSAParameters`, `KeyPair`\n --> src/types/transaction.rs:2:59\n  |\n2 | use ring::signature::{Ed25519KeyPair, ED25519, Signature, KeyPair, VerificationAlgorithm, EdDSAParameters, UnparsedPublicKey};\n  |                                                           ^^^^^^^                         ^^^^^^^^^^^^^^^\n  |\n  = note: `#[warn(unused_imports)]` on by default\n\nwarning: unused imports: `Sender`, `TryRecvError`, `unbounded`\n --> src/miner/worker.rs:1:26\n  |\n1 | use crossbeam::channel::{unbounded, Receiver, Sender, TryRecvError};\n  |                          ^^^^^^^^^            ^^^^^^  ^^^^^^^^^^^^\n\nwarning: unused import: `debug`\n --> src/miner/worker.rs:2:11\n  |\n2 | use log::{debug, info};\n  |           ^^^^^\n\nwarning: unused import: `VerificationAlgorithm`\n --> src/types/transaction.rs:2:68\n  |\n2 | use ring::signature::{Ed25519KeyPair, ED25519, Signature, KeyPair, VerificationAlgorithm, EdDSAParameters, UnparsedPublicKey};\n  |                                                                    ^^^^^^^^^^^^^^^^^^^^^\n\nFor more information about this error, try `rustc --explain E0463`.\nwarning: `bitcoin` (bin \"bitcoin\" test) generated 4 warnings\nerror: could not compile `bitcoin` due to 49 previous errors; 4 warnings emitted\n   Compiling bitcoin v0.1.0 (/Users/brianmaxtchouambe/PRINCETON/470/COS-ECE470-fa2022/test/COS-ECE470-fa2022-main/COS-ECE470-fa2022-main)\nerror: dlopen(/Users/brianmaxtchouambe/PRINCETON/470/COS-ECE470-fa2022/test/COS-ECE470-fa2022-main/COS-ECE470-fa2022-main/target/debug/deps/libhex_literal-c1a4aaadac546f0f.dylib, 5): no suitable image found.  Did find:\n           /Users/brianmaxtchouambe/PRINCETON/470/COS-ECE470-fa2022/test/COS-ECE470-fa2022-main/COS-ECE470-fa2022-main/target/debug/deps/libhex_literal-c1a4aaadac546f0f.dylib: code signature in (/Users/brianmaxtchouambe/PRINCETON/470/COS-ECE470-fa2022/test/COS-ECE470-fa2022-main/COS-ECE470-fa2022-main/target/debug/deps/libhex_literal-c1a4aaadac546f0f.dylib) not valid for use in process using Library Validation: library load disallowed by system policy\n --> src/main.rs:3:1\n  |\n3 | extern crate hex_literal;\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n --> src/network/peer.rs:2:5\n  |\n2 | use futures::{channel::mpsc, sink::SinkExt};\n  |     ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n --> src/network/server.rs:6:5\n  |\n6 | use futures::io::{AsyncReadExt, AsyncWriteExt};\n  |     ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n --> src/network/server.rs:7:5\n  |\n7 | use futures::io::{BufReader, BufWriter};\n  |     ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n --> src/network/server.rs:8:5\n  |\n8 | use futures::{channel::oneshot, stream::StreamExt};\n  |     ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/api/mod.rs:1:5\n  |\n1 | use serde::Serialize;\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/types/address.rs:1:5\n  |\n1 | use serde::{Serialize, Deserialize};\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/types/block.rs:1:5\n  |\n1 | use serde::{Serialize, Deserialize};\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/types/hash.rs:1:5\n  |\n1 | use serde::{Serialize, Deserialize};\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/types/transaction.rs:1:5\n  |\n1 | use serde::{Serialize,Deserialize};\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `ntest_test_cases` which `ntest` depends on\n   --> src/miner/mod.rs:152:9\n    |\n152 |     use ntest::timeout;\n    |         ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde` depends on\n --> src/network/message.rs:1:5\n  |\n1 | use serde::{Serialize, Deserialize};\n  |     ^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `ntest_test_cases` which `ntest` depends on\n   --> src/network/worker.rs:102:9\n    |\n102 |     use ntest::timeout;\n    |         ^^^^^ can't find crate\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:39:18\n   |\n39 |                 (hex!(\"0101010101010101010101010101010101010101010101010101010101010202\")).into(),\n   |                  ^^^\n...\n76 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:38:18\n   |\n38 |                 (hex!(\"0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d\")).into(),\n   |                  ^^^\n...\n76 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:68:25\n   |\n68 |                    vec![hex!(\"965b093a75a75895a351786dd7a188515173f6928a8af8c9baa4dcff268a4f0f\").into()]\n   |                         ^^^\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:39:18\n   |\n39 |                 (hex!(\"0101010101010101010101010101010101010101010101010101010101010202\")).into(),\n   |                  ^^^\n...\n64 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:38:18\n   |\n38 |                 (hex!(\"0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d\")).into(),\n   |                  ^^^\n...\n64 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:51:14\n   |\n51 |             (hex!(\"6b787718210e0b3b608814e04e61fde06d0df794319a12162f287412df3ec920\")).into()\n   |              ^^^\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:39:18\n   |\n39 |                 (hex!(\"0101010101010101010101010101010101010101010101010101010101010202\")).into(),\n   |                  ^^^\n...\n46 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/merkle.rs:38:18\n   |\n38 |                 (hex!(\"0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d\")).into(),\n   |                  ^^^\n...\n46 |         let input_data: Vec<H256> = gen_merkle_tree_data!();\n   |                                     ----------------------- in this macro invocation\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n   = note: this error originates in the macro `gen_merkle_tree_data` (in Nightly builds, run with -Z macro-backtrace for more info)\n\nerror: cannot determine resolution for the attribute macro `timeout`\n   --> src/network/worker.rs:137:7\n    |\n137 |     #[timeout(60000)]\n    |       ^^^^^^^\n    |\n    = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the attribute macro `timeout`\n   --> src/network/worker.rs:123:7\n    |\n123 |     #[timeout(60000)]\n    |       ^^^^^^^\n    |\n    = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the attribute macro `timeout`\n   --> src/network/worker.rs:110:7\n    |\n110 |     #[timeout(60000)]\n    |       ^^^^^^^\n    |\n    = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n --> src/network/message.rs:5:10\n  |\n5 | #[derive(Serialize, Deserialize, Debug, Clone)]\n  |          ^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n --> src/network/message.rs:5:21\n  |\n5 | #[derive(Serialize, Deserialize, Debug, Clone)]\n  |                     ^^^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the attribute macro `timeout`\n   --> src/miner/mod.rs:156:7\n    |\n156 |     #[timeout(60000)]\n    |       ^^^^^^^\n    |\n    = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n  --> src/types/transaction.rs:14:10\n   |\n14 | #[derive(Serialize, Deserialize, Debug, Default, Clone)]\n   |          ^^^^^^^^^\n   |\n   = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n  --> src/types/transaction.rs:14:21\n   |\n14 | #[derive(Serialize, Deserialize, Debug, Default, Clone)]\n   |                     ^^^^^^^^^^^\n   |\n   = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n --> src/types/transaction.rs:6:10\n  |\n6 | #[derive(Serialize, Deserialize, Debug, Default, Clone)]\n  |          ^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n --> src/types/transaction.rs:6:21\n  |\n6 | #[derive(Serialize, Deserialize, Debug, Default, Clone)]\n  |                     ^^^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n  --> src/types/hash.rs:13:25\n   |\n13 | #[derive(Eq, PartialEq, Serialize, Deserialize, Clone, Hash, Default, Copy)]\n   |                         ^^^^^^^^^\n   |\n   = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n  --> src/types/hash.rs:13:36\n   |\n13 | #[derive(Eq, PartialEq, Serialize, Deserialize, Clone, Hash, Default, Copy)]\n   |                                    ^^^^^^^^^^^\n   |\n   = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n --> src/types/block.rs:4:10\n  |\n4 | #[derive(Serialize, Deserialize, Debug, Clone)]\n  |          ^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n --> src/types/block.rs:4:21\n  |\n4 | #[derive(Serialize, Deserialize, Debug, Clone)]\n  |                     ^^^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/address.rs:72:37\n   |\n72 |         let correct_addr: Address = hex!(\"1851a0eae0060a132cf0f64a0ffaea248de6cba0\").into();\n   |                                     ^^^\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n\nerror: cannot find macro `hex` in this scope\n  --> src/types/address.rs:70:24\n   |\n70 |         let test_key = hex!(\"0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d\");\n   |                        ^^^\n   |\n   = note: `hex` is in scope, but it is a crate, not a macro\n\nerror: cannot determine resolution for the derive macro `Serialize`\n --> src/types/address.rs:5:25\n  |\n5 | #[derive(Eq, PartialEq, Serialize, Deserialize, Clone, Hash, Default, Copy)]\n  |                         ^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Deserialize`\n --> src/types/address.rs:5:36\n  |\n5 | #[derive(Eq, PartialEq, Serialize, Deserialize, Clone, Hash, Default, Copy)]\n  |                                    ^^^^^^^^^^^\n  |\n  = note: import resolution is stuck, try simplifying macro imports\n\nerror: cannot determine resolution for the derive macro `Serialize`\n  --> src/api/mod.rs:23:10\n   |\n23 | #[derive(Serialize)]\n   |          ^^^^^^^^^\n   |\n   = note: import resolution is stuck, try simplifying macro imports\n\nerror[E0463]: can't find crate for `serde_derive` which `serde_json` depends on\n  --> src/api/mod.rs:36:42\n   |\n36 |         let resp = Response::from_string(serde_json::to_string_pretty(&payload).unwrap())\n   |                                          ^^^^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde_json` depends on\n  --> src/api/mod.rs:44:42\n   |\n44 |         let resp = Response::from_string(serde_json::to_string(&$message).unwrap())\n   |                                          ^^^^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `serde_json` depends on\n   --> src/api/mod.rs:134:33\n    |\n134 | ...                   serde_json::to_string_pretty(&payload).unwrap(),\n    |                       ^^^^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `bincode` depends on\n  --> src/network/peer.rs:37:22\n   |\n37 |         let buffer = bincode::serialize(&msg).unwrap();\n   |                      ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n  --> src/network/peer.rs:65:36\n   |\n65 |         let bytes = smol::block_on(futures::stream::StreamExt::next(&mut self.r)).unwrap();\n   |                                    ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `bincode` depends on\n  --> src/network/peer.rs:66:28\n   |\n66 |         let msg: Message = bincode::deserialize(&bytes).unwrap();\n   |                            ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `futures_macro` which `futures` depends on\n  --> src/network/server.rs:60:53\n   |\n60 |         thread::spawn(move || smol::block_on(ex.run(futures::future::pending::<()>())));\n   |                                                     ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `bincode` depends on\n  --> src/network/worker.rs:55:32\n   |\n55 |             let msg: Message = bincode::deserialize(&msg).unwrap();\n   |                                ^^^^^^^ can't find crate\n\nerror[E0463]: can't find crate for `serde_derive` which `bincode` depends on\n  --> src/network/worker.rs:82:21\n   |\n82 |         let bytes = bincode::serialize(&msg).unwrap();\n   |                     ^^^^^^^ can't find crate\n\nwarning: unused imports: `EdDSAParameters`, `KeyPair`\n --> src/types/transaction.rs:2:59\n  |\n2 | use ring::signature::{Ed25519KeyPair, ED25519, Signature, KeyPair, VerificationAlgorithm, EdDSAParameters, UnparsedPublicKey};\n  |                                                           ^^^^^^^                         ^^^^^^^^^^^^^^^\n  |\n  = note: `#[warn(unused_imports)]` on by default\n\nwarning: unused imports: `Sender`, `TryRecvError`, `unbounded`\n --> src/miner/worker.rs:1:26\n  |\n1 | use crossbeam::channel::{unbounded, Receiver, Sender, TryRecvError};\n  |                          ^^^^^^^^^            ^^^^^^  ^^^^^^^^^^^^\n\nwarning: unused import: `debug`\n --> src/miner/worker.rs:2:11\n  |\n2 | use log::{debug, info};\n  |           ^^^^^\n\nwarning: unused import: `VerificationAlgorithm`\n --> src/types/transaction.rs:2:68\n  |\n2 | use ring::signature::{Ed25519KeyPair, ED25519, Signature, KeyPair, VerificationAlgorithm, EdDSAParameters, UnparsedPublicKey};\n  |                                                                    ^^^^^^^^^^^^^^^^^^^^^\n\nFor more information about this error, try `rustc --explain E0463`.\nwarning: `bitcoin` (bin \"bitcoin\" test) generated 4 warnings\nerror: could not compile `bitcoin` due to 49 previous errors; 4 warnings emitted\n",
            "Have you listed all your dependencies correctly in the Cargo.toml file?\n\n",
            "No. I havent touched that file at all. How do I do this?",
            "Actually you arent supposed to get any errors from other files since the Cargo.toml is already setup appropriately. Since you mentioned cargo test is working then that shouldn't be an issue. All the test cases there are passing right? If so you can submit it for now.",
            "Thank you. How do I know if it worked them. I dont get a build_logs.txt file at all either"
        ]
    },
    {
        "title": "zip file size issues",
        "question": "I have not been able to reduce my netid.zip file size to below 3MB as I have been unsuccessfully trying to figure out how to use .gitignore properly. My zip file is 100MB sometimes and 200MB sometimes. \n\nWill points be deducted for having too large of a file size? I would like to go to office hours and resolve this there, but there are no office hours until after the Assignment 1 deadline (3pm today).",
        "other_text": [
            "Hi Arin, \n\nThe large file size is due to the \"target\" directory.\n\nThis is not required and you can add it to gitignore. Your submission will be within 2MB if you remove this directory from the repo.",
            "Thanks for your response. I sorted out the issue."
        ]
    },
    {
        "title": "Part 1 submission",
        "question": "I just submitted part 1 a few minutes ago, and am only now noticing that my .zip file is far too large. It seems that I forgot to .gitignore and therefore pushed all the files to my repo. Will this be an issue? Should I email somebody a .zip with no extraneous files?",
        "other_text": [
            "Should be okay. Please make sure you don't push \"target\" to your repo for future parts"
        ]
    },
    {
        "title": "Merkel Tree with Too Few Leaves",
        "question": "Hello,\n\nI'm assuming we have to support the case for when we are given a number of blocks which are not a power of two. In lecture, if I am remembering correctly, it was said that we should just hash  the unmatched blocks with themselves. Do we do that on each level of the tree? As in, if there are five blocks, the fifth leaf is hashed with itself, then that result will also be hashed with itself on the next level up the tree?",
        "other_text": [
            "Yes, this is correct - at each level of the tree which has an odd number of hashes, you need to hash the last one with itself to get its parent."
        ]
    },
    {
        "title": "Late Submissions",
        "question": "Can you give partial credit for late assignments? Most other COS classes have a 10% deduction for each day after the submission date. Also, will late assignments receive feedback?",
        "other_text": [
            "Hi Thomas, \n\nAs announced earlier, we will not accept late assignment submissions. (unless there is an emergency : please email the professor and TAs asap).\nThere will be no partial credit for late assignments \n\nSince it's early in the semester, we will make an exception for your first assignment submission. Please ensure that you submit on time henceforth. ",
            "Thank you so much! I really appreciate it. It will not happen again.",
            "?"
        ]
    },
    {
        "title": "Merkle Tree Hashing Process question",
        "question": "Maybe coding through Part 2 would help me clear this up, but I thought I'd ask anyway.\n\nAs part of the \"fault diagnosis\" process, the article/lecture noted that we request the two hashes below the root.\n\nGiven that the block header only contains the Merkle root, does requesting the two hashes below the root essentially mean computing and constructing the entire Merkle tree (i.e. in this example, first hashing blocks 1 through 8, then hashing their pairs, then hashing the pairs of pairs?).\n\nThen, if we had a large number of blocks (say 15,000 as the article notes) wouldn't this requesting process get pretty computationally expensive (we do O(n) hashing operations for n blocks)? Or is hashing fast enough that this is pretty negligible?\n\nI was confused because given this process it's clear that we do O(log(n)) compares, but don't we do O(n) hashes / isn't that meaningful?\n\n",
        "other_text": [
            "Given that the block header only contains the Merkle root, does requesting the two hashes below the root essentially mean computing and constructing the entire Merkle tree (i.e. in this example, first hashing blocks 1 through 8, then hashing their pairs, then hashing the pairs of pairs?).\n\nThen, if we had a large number of blocks (say 15,000 as the article notes) wouldn't this requesting process get pretty computationally expensive (we do O(n) hashing operations for n blocks)? Or is hashing fast enough that this is pretty negligible?\n\nIf you don't use the Merkle tree, then the sender would need to send all the 15000 hashes - O(n) to find the error.\n\nHowever, if we are using the Merkle tree: The sender sends you the data, and the merkle root. \nYou can construct the Merkle tree using received data in a small amount of time (hashing is computationally inexpensive). \nIf the merkle root does not match your computed merkle root, you only need to request O(log n) hashes from the sender.\n\nYou essentially reduced the number of hashes to be sent from O(n) to O(log n).\n\nHope I answered your question?"
        ]
    },
    {
        "title": "Merkle Tree use in bitcoin",
        "question": "Just realized I'm a bit confused at how Bitcoin uses Merkle Trees.\n\n\n\nIs a completely new Merkle Tree constructed every time a new block is added to the ledger? Or does bitcoin simply add a block to the existing tree somehow?",
        "other_text": [
            "In every block, you compute the Merkle tree of the data in the block, and store the Merkle root in the block.",
            "Think I figured it out, seems like from the readings that it is a new merkle tree for each block."
        ]
    },
    {
        "title": "merkle tree indices",
        "question": "How do indices work for the merkle trees?\n\n\n\nIs it just the index of the element in the last (largest length) level?",
        "other_text": [
            "Yes"
        ]
    },
    {
        "title": "What form should the Merkle Tree take",
        "question": "Should the Merkle Tree take the form of a linked list, an array, a hash tree, or anything above?\n\nIf it's anything above, how do we convert the Hashable datatype to this new data structure? Thanks so much!",
        "other_text": [
            "You can use any suitable data structure to implement the tree.\n\nIf it's anything above, how do we convert the Hashable datatype to this new data structure? Thanks so much!\n\nI didn't understand the question. The data for which the merkle tree has to be constructed is of a hashable type T.\n\n"
        ]
    },
    {
        "title": "MerkleTree new(), does data input come in blocks",
        "question": "I had a question regarding implementation and context around the new() function for the Merkle Tree. The method accepts slice array of type T, does this mean this array contains the data already divided into blocks, where index i in the array is the ith block. If not, do we have to divide the input data into a set of blocks first? ",
        "other_text": [
            "Yes index i in the input array is the ith block"
        ]
    },
    {
        "title": "Converting Hashable type T to Bytes",
        "question": "I'm confused on how to deal with generic types in Rust. Please let me know if there is anything wrong in my logic.\n\nWe know that type T is hashable, but the hash() function is only implemented for the type H256. So first we need to convert our data (for the new() Merkle function) from &[T] to any of &[u8; 32], [u8; 32], or ring::digest::Digest, so that it could be converted to H256 and then be hashed?\n\nAssuming everything above is correct, how do we actually go about converting &[T], some arbitrary type, to an array of bytes. Rust is very finnicky about lengths, and I haven't found anything to work yet.\n\nThank you!",
        "other_text": [
            ".hash() is implemented for any type T which has the Hashable trait.\n\nIt is given that type T has the Hashable trait implemented. So something like data[0].hash() should work fine (regardless of what type T is)",
            "it might help to better understand what traits are - I think the best way to understand traits is to know that generally speaking, inheritance in Rust follows a \"has a\" structure rather than a \"is a\" structure as you might be used to in oop languages like C++ or Java. Take Hashable as an example - the Hashable trait is defined at the top of hash.rs (pub trait Hashable {...) and specifies a single function hash(&self) -> H256 . What this means is any class that implements the Hashable trait must implement the functions defined as part of that trait, in this case just the hash() function.\n\nIn hash.rs we see that the H256 class implements the Hashable trait with  impl Hashable for H256 { ... , but note that there's nothing special about the implementing this trait for the H256 class specifically - any class you write can also implement the Hashable trait using that syntax (and this is actually part of assignment 3).\n\nIn merkle.rs, the where T: Hashable (called a where clause) after the function signature in MerkleTree::new<T>(data: &[T}) means that the function guarantees you that whatever type T is, you know for sure that T implements Hashable, meaning you must be able to call the hash(&self) -> H256 function on objects of type T.\n\nto answer your question directly, no you don't have to convert it to [u8] to hash it or anything like that, you can just call hash directly on any type T such as data[i].hash() and that will return an H256 .\n\nI think the rust book section on traits (linked above) is really good, would recommend giving that a read. feel free to follow up if anything i wrote wasnt clear or you have questions"
        ]
    },
    {
        "title": "Merkle Prof",
        "question": "Just want to confirm, is a merkle proof a vector of the sibling hashes you need to verify a given hash is a leaf? ",
        "other_text": [
            "Yes, this is correct"
        ]
    },
    {
        "title": "Scrambled inputs",
        "question": "Can we assume that incoming hashable data for a block will always come in the same order, or do we need to account for the possibility of the incoming data to be scrambled? i.e. do we need to re-order the input data so we produce the same Merkel tree every time?",
        "other_text": [
            "Yes, each valid block in a blockchain has a fixed order of transactions. You do not need to reorder data in this assignment, assume that the order of transaction is as per input. "
        ]
    },
    {
        "title": "Generic Type Causing Issues",
        "question": "Hey everyone, \n\nI am attempting to build a binary tree like the one in the article linked in the assignment. \n\nMy understanding is that the 'Blocks' at the bottom hold data of Generic Type T. When I try to implement this using a node schema, I am running into issues with the fact that my MerkleTree Struct can't handle my generic Node. Any tips? Attaching Code... You will see some commented out blocks that are relevent, But I for debugging purposes I wanted to isolate the generic type issue. \n\n",
        "other_text": [
            "I would recommend having a merkle tree struct with a vector of hashes instead of a vector of nodes with some parent-child structure between them. It simplifies things a lot since you can use appropriate indices to move on the tree. You can also use a vector of vector of hashes (ie, a vector of hashes for each level of the tree).\n\nHowever, if you still want to implement it this way then you can try the following. I am not sure how to do this with a generic Node though.\n\n#[derive(Debug, Default,Clone)]\npub struct Node {\n    value: H256,\n    child_l: Option<Box<Node>>,\n    child_r: Option<Box<Node>>,\n    parent: Option<Box<Node>>,\n    is_leaf: bool,\n}",
            "Im not sure I understand it correctly then. \n\nI was under the impression that the 'bottom' layer of the tree had blocks that held the data itself, not hashes. \n\nAlso, if the merkle tree struct is simply a vector of hashes, how do we construct the 'tree' portion? Wont we need pointers to compose the tree?\n\n",
            "The bottom layer of the tree (leaves) stores the hashes of the blocks. \n\nYou can store each level of the tree one after another in a vector as well. You would just need to work out what indices are on what level, and what index is the parent of what, etc. \n\nOr else each level of the tree can be separate vector, and the tree as a whole would be a vector of vectors. In this case it would be easier to see parent-child structure across levels.",
            "Got it. Thank you. So I would start with a vector of Data.len() or Data.len() + 1 depending on even or odd length... then work my way up? What is the distinction of a 'leaf' then if all the nodes are essentially the same? ",
            "Am I at least on the right path that we need to define an additional struct? Is it possible to do the assignment with just the Merkle Tree Struct?",
            "Yes I have explained how to do that in the comment below"
        ]
    },
    {
        "title": "Are the index and leaf size necessary for verification?",
        "question": "It seems that if you provide all the siblings in the proof then the verification can be done without using the index or leaf size. So far I have deduced that it can make a difference if a Merkle tree had an odd number of hashes at a level and we were not permitted to append the duplicate of the hash to the proof [possibly for security purposes?]. Is this the case or is there something else that I am missing?\n\n",
        "other_text": [
            "You need the index because at each step while going up the tree, you need to decide whether the sibling in the proof is to your left or right.",
            "I'm a bit confused on this - if the proof vector contains all the sibling hashes (#62) then why is it necessary to know whether the sibling is on the left or right within verify()? wouldn't it be sufficient to just use those sibling hashes with the datum hash to produce the root and check if it matches? Thank you!",
            "The value of the hash is affected by whether you left concatenate or right concatenate",
            "I see, thanks! Would it be acceptable (both for this assignment but also in general from a security perspective for a real blockchain) to use a commutative operation to combine hashes (say, XORing the two hashes together and then hashing that result) so that knowing which side the sibling is on doesn't matter?\n\n",
            "Definitely not acceptable for this assignment.\n\nIn general, this would mean that the order of the transactions is not \"locked in\" the block. This may not be desirable in most applications. You want all transactions to have a specific order in a ledger.",
            "Also wondering this, i didn't use index or leaf size either"
        ]
    },
    {
        "title": "clarification on verifying a proof",
        "question": "Hi,\n\nI am confused on how exactly to implement the verify() function. Some things that I wanted clarification on was: 1) if we have the root of the tree which is the final hash, if that doesn't match the last hash in the proof vector, then the proof is false right away? 2) How are we supposed to reconstruct the tree and recalculate the hashes if we don't actually have all the hashes of the leaves of the tree, as in the sibling hashes required to create the parent hashes (this is to compare each step of the proof). \n\nMaybe there is some conceptual error that I am making. Any hints or guidance will help a lot, thanks! ",
        "other_text": [
            "1) Proof only gives you an array of sibling hashes along the way to the root and not the root itself. We assume you have root already through other means.\n\n2)Using just the sibling hashes of the proof, you can work your way up the tree and verify if the root you calculated matches the one you already have. You do not need the rest of the tree for that.",
            "Oh ok so to clarify, we need to know the index of the root because hash(hash1hash2) has a different result than hash(hash2hash1) right? in terms of knowing if it was the left or right concatenation that you need?",
            "Yes exactly",
            "As a follow up, we are given the root and the proof by the same entity in this case. How do we know that a malicious actor has not just given us a fake root that always satisfies the given proof? Or is this simulating that we collect data from an existing block to verify that the contents of that block have not been tampered with? In other words, in real life, machines would run verify() on every datum hash to confirm that none of the data has changed?",
            "Since the root is included in the header of a block (on which PoW happens) and the hash of the header is present in its child, we can assume that the root is much more secure (since the malicious actor would have to provide a duplicate PoW valid block for each child block after that just for a small corruption in one block, meaning it would have to do PoW computation for every subsequent block just to convince you of the validity of that one fake transaction in one block).\n\nGiven that the root is much more secure, we verify whether a transaction is indeed present in the block by asking for a proof which can be tallied with this root. Since we are using the cryptographic hash function for the hashing, constructing a fake proof to match the root would also be computationally difficult for the malicious actor.",
            "I realized I might also not be understanding what a proof is exactly. Are there any resources that would help guide me in the right direction?",
            "https://nakamoto.com/merkle-trees/"
        ]
    },
    {
        "title": "Runtime of verify()",
        "question": "Is there a recommended time complexity for verify()? I was going to make it O(NlogN) where N is the number of transactions, because i thought it would be easy to implement it that way. Is it necessary to make it more efficient?",
        "other_text": [
            "You should be able to verify the proof of one transaction in O(logN) time."
        ]
    },
    {
        "title": "Copying code from rust docs",
        "question": "Is it allowed to copy code from Rust By Example? I am trying to use some of their code in my merkle tree implementation",
        "other_text": [
            "Yes you can do that. \n\nBut make sure you implement the merkle tree by yourself and do not use a rust crate that does that directly."
        ]
    },
    {
        "title": "merkle tree index",
        "question": "Does the merkle tree index for data inputs start at 0 or 1?\n\n",
        "other_text": [
            "Indexing starts from 0"
        ]
    },
    {
        "title": "Merkle Tree",
        "question": "When we save the input data inside Merkle Tree, it says if the number of nodes in a level is odd, duplicate the last node to make the node even. Should we save that duplicated node in Merkle Tree, or just use the duplicate node to make the hash value for its parent node, but no need to keep duplicated node in Merkle Tree?",
        "other_text": [
            "Either way works, but might be easier to implement the proof if you save it in the tree."
        ]
    },
    {
        "title": "leaf_size in verify()",
        "question": "Does the leaf_size include the duplicated leaf if the number of nodes on bottom level is odd? I'm confused about why we need the leaf_size for the proof.\n\n",
        "other_text": [
            "You don't need it directly, you can check if index is valid by checking it is less than leaf_size."
        ]
    },
    {
        "title": "Finding a path In an binary tree (array implementation)",
        "question": "If we implemented our binary tree to have a Vec represent each layer of the tree, does anyone have any tips to find a proof path from the root given the index of a leaf? ",
        "other_text": [
            "You should find the proof path from the leaf to the root, not the other way round. \n\nIn this case simply dividing an index by 2 should give you the index of the parent."
        ]
    },
    {
        "title": "hashes in test cases",
        "question": "I am trying to write extra test cases, but am confused about how the example hashes are generated. When I put 0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d0a0b0c0d0e0f0e0d into a SHA256 hash generator (https://xorbin.com/tools/sha256-hash-calculator), I get b34e350bc1bb3eac0939905f83057dd23dd0507042e1d86b7ce7ecd0c195deb8 which does not match b6956... . Could someone clarify how I can validate the hashes?",
        "other_text": [
            "The tool you are using takes your input as a string and not as a hex value\nYou can use the ring digest function itself to test it out ",
            "You can also use this: SHA256 Online (emn178.github.io). It accepts hex inputs."
        ]
    },
    {
        "title": "Design question for merkle tree",
        "question": "Hi, I am currently debating two different ways to construct my Merkle tree and I was hoping to get some guidance:\n\nOption 1 is recursion. I have an idea of how my algorithm would work, but the only thing that's holding me back is that I read recursion is not recommended in rust (link: https://stackoverflow.com/questions/65948553/why-is-recursion-not-suggested-in-rust#:~:text=Recursion%20is%20possible%20in%20Rust,iteration%2C%20also%20known%20as%20looping)\n\nOption 2 is to iterate (i.e. bottom up approach). I also have an idea of how to do this, but it would likely be messier than recursion. \n\nI am hoping to get some guidance on which option, esp. given that we are using rust, may be better. Specifically, do you guys also recommend against recursion in rust? Thank you",
        "other_text": [
            "Yes, we would recommend using iteration than recursion.\n\nIf you have used recursion in rust before and are familiar with it at an advanced level, you can go ahead."
        ]
    },
    {
        "title": "Grading of Previous assignments",
        "question": "Just wondering around how many days/weeks after submission dates we can expect our assignments to be graded? ",
        "other_text": [
            "We would grade all assignments within a week usually. Might be a slight delay of a few days for the first assignment though."
        ]
    },
    {
        "title": "Leaf_Size and Index in Merkle Trees for Verify",
        "question": "Is the leaf_size of a Merkle Tree the total number of leaves in the Merkle Tree. Ie, if you create a Merkle Tree from a vector of length 8, does this end up having 15 total leaves?\n\n1 (root) +  2 + 4 + 8 = 15?\n\nOr does it have 8 leaves and the leaves are just the bottom?\n\n\n\nRegarding index, do we always assume the index is starting from the bottom leaves? Meaning in the example above, because index starts at 0, the highest valid index would be 7?\n\n\n\n\n\n",
        "other_text": [
            "Yes, leaves are the nodes at the bottom. \n\nIndex corresponds to the bottom leaves only as you said.",
            "Let's say I have an input vector of length 7, therefore while constructing a Merkle Tree I would need to duplicate item 7. Would a person calling verify call it with leaf_size 7 or 8? And if they would call the function with leaf_size 7, would they be able to use index 8 (the index of the duplicate)?\n\n",
            "1. They would call it with leaf_size 7\n\n2. Would not be able to access index 7 (indexing starts from 0 in Rust)",
            "So to clarify, if I call new() with size 5, we would need to duplicate the 5th element to make it 6. Thus should a client be able to call proof() or verify() with index = 5 (index of the duplicated item)?",
            "If you call index with size 5, the indices of the leaves will be {0,1,2,3,4}.\n\nSo a client should not be able to call proof() with index=5.\nFor handling invalid inputs, refer to #82 "
        ]
    },
    {
        "title": "Empty input data for create merkle tree",
        "question": "Hi,\n\nDo we need to handle the case for creating a Merkle tree with empty input data? By looking through the signature of verifying, it looks like we will not have the case with empty input data because we need to use an index of data. But I just want to confirm that.\n\n",
        "other_text": [
            "You do need to handle the empty input case (assignment 3 involves using root of an empty input merkle tree). I agree it is a bit weird though for verify() since it's unclear what index would be.",
            "Do we have any specific requirements like how to handle empty input cases? Like hash an empty slice or something? ",
            "Also a bit confused on what to put as the root for this case",
            "Should it just panic when asked to return the root of an empty tree?",
            "I think it should not panic for empty input since in a3 it says \n\nAs for content, you can simply let it be empty. So merkle_root should be the Merkle root of an empty input. \n\nno idea what the root should be though - I just hashed an empty array for now. I feel like it doesn't actually matter what the root is since it's kinda useless to get the root of an empty merkle tree. hope a TA can chime in here!\n\n",
            "good",
            "peer endorsed\n\n",
            "Yes, you need to handle the case where data.len() = 0. Your program should not panic.\n\nWe don't have any specifications for this.\nYou could return a (fake) root of value 0x000...00. \n\nverify() should return false in this case. (Or any case where index >= data.len() )",
            "What would the verify() method take as inputs to test this input? assert!(verify(&merkle_tree.root(), &input_data[0].hash(), &proof, 0, input_data.len())); from the test code doesn't work since input_data has a length of 0, so attempting to input_data[0] results in IndexOutOfBounds.",
            "It should return false irrespective of what your second argument is. "
        ]
    },
    {
        "title": "Request for A1 Grades Before A2 Due",
        "question": "Hello! As I had asked Professor Viswanath in class, many of my peers and I were hoping that we would receive feedback on our A1 before we have our A2 due. Many of us are using Rust for the first time, so we believe receiving feedback on our novel skills would be extremely helpful before we commit the same mistakes or faux pas for A2. If that is not possible, would the course staff be willing to extend the A2 deadline? Thank you so much!\n\n",
        "other_text": []
    },
    {
        "title": "Storing original unhashed data",
        "question": "Do our merkle trees need to store the original unhashed data?",
        "other_text": [
            "No. The leaves of the merkle tree are the hash of the data. You do not need to store the data itself"
        ]
    },
    {
        "title": "Assignment 1 grades posted",
        "question": "Assignment 1 grades have been posted under the Grades tab of Canvas. Please let us know if your grade is not visible to you.\n\nPlease remember to do the following before submitting the next assignments:\n\n1. Please ensure that the folder inside your submission zip file is named COS-ECE470-fa2022-main\n\n2. Please edit the version of ring in your Cargo.toml file to : ring = \"0.16.20\". \n\n3. Please make sure the zip file size is less than 2MB. You can delete the target folder from your repo since that takes up most of the space. ",
        "other_text": [
            "Thank you so much! Can the additional grading tests be revealed?\u00a0",
            "Sorry, we do not plan to release the private test cases.",
            "Just want to know how to check the folder name inside the submission zip file without zipping it. I remember Assignment 1's README.md suggest avoiding zipping the submission file because it may cause an error for auto-grading.",
            "It would be best if you submit the zip file you download from git. That would automatically have COS-ECE470-fa2022-main as the name of the folder inside.",
            "And dont forget to rename it with your netid. Canvas might append a -1, -2 to your submission and that is okay."
        ]
    },
    {
        "title": "Out of Bounds Inputs",
        "question": "Should we handle the case where an index to proof() or verify() is out of bounds for the given Merkle Tree? Or is this not needed for the assignment.\n\n",
        "other_text": [
            "We will not be testing these corner cases.\n\nHowever, it's better to not allow the program to panic. \n\nFor proof, you can return an empty vector. \nFor verify, you must return false"
        ]
    },
    {
        "title": "verify(): leaf_size is less than total number of elements in the original data",
        "question": "I am creating various test cases for this assignment, and I am facing the problem I really do not know how to solve. Could you please give me some directions?\n\nConsider the merkle tree example from the  lecture slides:\n\nSuppose we have a valid proof for the element 1:\n\nproof(1) = [h(2), h(3,4), h(5,6,7,8)]\n\n\nPlease note that in my example I am using the actual elements' numbers from the picture, not the indexes.\n\nSuppose we use this valid proof to verify the memberships of element 1:\n\nverify(h(1,2,3,4,5,6,7,8), h(1), proof(1), index_of_element_1, 8)\n\nThis function is returning true as expected.\n\nHowever, if I change the function parameters as following\n\nverify(h(1,2,3,4,5,6,7,8), h(1), proof(1), index_of_element_1, 7)\n\nthen my implementation of the function also returns true.\n\nIt seems that there is no way to verify if the  size of the original data was 7 or 8 due to the method we use while constructing the tree. Providing that the proof is valid, and therefore, the element h(5,6,7,8) is correct, it seems that there is no way to verify if this element was constructed from the elements 5,6,7 and 8, or from the elements 5,6,7 and duplicate(7). Thus, it seems that there is not enough information to determine if the  parameter leaf_size=7 of the function verify() does not match the actual data size of 8. Should we ignore verification of this parameter and only use it to check that index < leaf_size?\n\nCould you please point me out to the correct direction?\n\n\n\n\n\n\n\n\n\n",
        "other_text": [
            "You can just use it for checking index < leaf_size. \n\nNo need to worry about whether leaf_size is valid or not, for now.",
            "Thank you very much Viraj!"
        ]
    },
    {
        "title": "Test of A2",
        "question": "Hi,\n\nIf I write extra test cases in merkle.rs, when I submitted my assignment, should I remove all my test cases, comment out them, or it is okay to leave them inside the code file?\n\n",
        "other_text": [
            "Please comment them.",
            "I already submitted the assignment without commenting tests out. Should I resubmit it then?\n\n",
            "Yes you should",
            "After resubmitting the assignment, Canvas adds the number of submissions (e.g., netid-3.zip for the third submission), even though I named the file netid.zip. Would this be an issue for parsing the netid?",
            "Yes that is fine we would handle that on our end. Just make sure you have the netid."
        ]
    },
    {
        "title": "odd leafs + side of the proof",
        "question": "Hi! I'd like to clarify the case of an odd number of leaves in a Merkle tree by looking at an example. Say we have the following hashes for our leaves (just duplicating the first leaf in the example test case):\n\n1. b69566be6e1720872f73651d1851a0eae0060a132cf0f64a0ffaea248de6cba0\n\n2. b69566be6e1720872f73651d1851a0eae0060a132cf0f64a0ffaea248de6cba0\n\n3. 965b093a75a75895a351786dd7a188515173f6928a8af8c9baa4dcff268a4f0f\n\nAccording to Merkle tree properties, the parents of these leaves would be:\n\n1. 8c56ff4c190d4f6cd98b87661e77da02ce4c1436de294382278bfb915c30576c which is the hash of the concatenation of leaf 1 and leaf 2, where order matters. \n\n2. Would this hash be: 965b093a75a75895a351786dd7a188515173f6928a8af8c9baa4dcff268a4f0f or would it be the hash of the concatenation of leaf 3 with itself which is a009de28b2c7d64131c88719938cace7f900fd7c45ec138826347bdadb2dd3ad?\n\nIf it's the latter, when we consider the proof() function, say we are given an index of 2, would we also return the hash of leaf 3 (the implied leaf 4) in the proof because the fourth leaf is needed for the hash?\n\nAdditionally how do we know if the hash that is given in a proof in verify is a left or right child, since ordering of the hashes when concatenating would change the output? \n\nThanks!",
        "other_text": [
            "1. In the case of odd leaves, the parent of the last leaf is the hash of the leaf concatenated with itself.\n\n2. In the proof of leaf 2, you would send the leaf 1 and the parent of leaves 3 and 4. Neither leaf 3 nor 4 would be there in the proof. The proof is list of siblings you get as you go up the tree.\n\n3. Whether the index of the leaf is even or odd should tell you whether its the right or the left child.",
            "For the second question, I meant index 2, not leaf 2. In that case, I was talking about leaf 3 (the odd leaf out). Would the proof include the hash of leaf 3 since leaf 3's parent is the hash of the concatenation of the hash of leaf 3 with itself?",
            "Yes ",
            "As suggested in a previous post, it might be better to consider the duplicate of node 3 as another node. This will probably simplify the left/right calculation. "
        ]
    },
    {
        "title": "merkle proof counting",
        "question": "Should we assume that proof(1) refers to the first leaf, or the second leaf?  In other words should the counting system start from 0 or 1?",
        "other_text": [
            "The counting starts from index 0.",
            "thanks"
        ]
    },
    {
        "title": "merkle_proof test",
        "question": "Seems I misunderstand how the proof should work.\n\nFollowing the test merkle_proof(). It generates data, that gives the tree\n(got it from the test description):\n    \n    (0) 6b7877\n    /        \\\n(1) b6956    (2) 965b0\n-------------------\n0a0b0        01010\n ^            ^\ndata[0]     data[1]\n\n\nmerkle_proof(0) should return\n[b6956, 965b0, 6b7877]  (nodes 1, 2, 3).\n\nThough the test assert the proof is equal to [965b0].\n\nCould you please explain, where I do mistake?\nThanks.\n\n",
        "other_text": [
            "The proof must return a list of neighbour hashes of the index-specified data point, where there is a \"neighbour\" at each tree level (except the root). A \"neighbour\" is a hash with which the original data point's hash ends up being concatenated as we move up the tree levels towards the root.\n\nIn this example, merkle_proof(0) asks for the neighbours of the hashed \"0a0b0\" data point in the Merkle Tree. Since there are only two levels of the tree (first level and the root), the proof will only contain one entry, b6956's neighbour in the first level, which is 965b0, hence the answer.\n\nHere is a good explanation and diagram for what a proof looks like for a tree with more levels:\n\nhttps://medium.com/crypto-0-nite/merkle-proofs-explained-6dd429623dc5\n\n"
        ]
    },
    {
        "title": "Edge case: only 1 hash given",
        "question": "Sorry if asked before, but if there is only 1 hash given in new, in data, should that become the root or should it be hashed with itself and then that hash be the root?",
        "other_text": [
            "Not sure what you mean if the \"hash given in new\" but the Merkle Tree should keep track of the hashes of the input. ",
            "If there is only one datapoint given, then its hash becomes the root.",
            "What should the proof() method output in this case?",
            "You don't need a proof in this case, you can just output an empty vec",
            "And if we try to verify, what should we do?\n\n",
            "Just check if the given hash matches the root hash.",
            "This is the opposite of what I expected. It would be helpful to update the README.md with more detailed specifications for next year.",
            "You can follow both ways, as long as the proof and verify methods are consistent, it should be good.\n\nWe won't be testing such edge cases anyway.",
            "I see. So as long as we are consistent, our treatment of the n=1 input is inconsequential to our grade for this assignment?",
            "Yes"
        ]
    },
    {
        "title": "Messing with test cases",
        "question": "If we make test013 work in the autograder with variable size inputs (i.e. hacking the gen_merkle_tree_data macro to generate variable length input) and playing around with the index we're testing for, is that a robust enough test for Part 2?\n\nAny inputs/pointers appreciated!",
        "other_text": [
            "Yes, this should be enough.",
            "The tests are purely up to you. There are many articles online that describe different SWE testing methods.\n\nFor corner cases, it was most helpful for me to think of these two:\n\n1. The tree is empty.\n\n2. The tree was made with only one data point.\n\nIf it works on these two and larger trees of variable size input, you should be good."
        ]
    },
    {
        "title": "Header timestamp",
        "question": "Is there a recommended data type for the block's timestamp? I saw some options online (SystemTime, humantime::Timestamp) but was wondering if someone with more Rust experience could point out what's the best alternative.\n\n",
        "other_text": [
            "u128 (assignment 4 says to use smthg like SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_millis(), and that returns a u128)\n\n",
            "Thanks, Kevin!"
        ]
    },
    {
        "title": "Hash Header and Content or only Header?",
        "question": "For A3, should the hash of a block simply be the hash of its header? Or should we combine the hashes of the header and the content?",
        "other_text": [
            "Only the header.\n\nYou need to implement trait Hashable for Block. They way to hash a block is to hash Header rather than Content. So you can first implement Hashable for Header. When you hash a Block, you can directly call the hash function of Header.\n\n"
        ]
    },
    {
        "title": "Assignment 3 - genesis block",
        "question": "The assignment specification states that we need to define genesis block by ourselves.\n\nAre there any requirements to the genesis block?\n\nCan we set nonce and timestamp to some predefined values (for instance, nonce = 0 and timestamp = 0) ? In this case we can guarantee that the hash of the genesis block is always the same.\n\nAlso, in the specification to the Part 6, there is an example of block hashes in the longest chain: \n\n[\"0000000000000000000000000000000000000000000000000000000000000000\",\"93b6a5b271bf03019da96d49506660dcdcad2376c3119c4cb9c47cb0f27fbbf1\"] \n\nThat is, block 0 (genesis), followed by block 1, block 2, etc.\n\nIs it required that the hash of the genesis block to be always \"0000000000000000000000000000000000000000000000000000000000000000\"? Could you please advise how we can achieve that?\n\nThank you!\n\n",
        "other_text": [
            "Yes, you can construct the genesis block however you want for now.\n\nAlso, in the specification to the Part 6\n\nThis is just an example. The hash of the genesis can be any value.",
            "Thank you very much Ashwin!"
        ]
    },
    {
        "title": "Typo ReadMe Assignment 4",
        "question": "The readme for Assignment 4 has a typo in the description of Worker in point #2: \u201cgenearated\u201d",
        "other_text": []
    },
    {
        "title": "& in Rust",
        "question": "Still kinda confused about what & is in Rust, even after looking at docs a lot. In C & just means the memory address, but in rust i get that it has something to do with ownership. It's pretty confusing to me and right now I just plug in the & whenever a function requires it.\n\nI guess I just don't understand what ownership means in Rust? If anybody has any info that may be helpful about & I would really appreciate it :-)",
        "other_text": [
            "Ownership / borrowing checking is arguably the most unique and fundamental feature of Rust that separates it from other systems programming languages like C++ - it's what allows Rust to be memory safe at compile time without a garbage collector. IMO since it's so unique and really has no analogy in other languages it is hard to wrap your head around it but really is fundamental to understand.\n\nI would highly recommend reading the Rust book's section on ownership slowly and carefully (it really isn't that long and explains it very well).\n\nHere's the best way I'd describe the general idea of how memory management works in Rust: all heap-allocated objects have one and only one owner variable. For example, if I have let merkle = MerkleTree::new(...);, that merkle tree object is owned by the variable merkle. Whenever the owner goes out of scope, the memory it points to is automatically deallocated. This in itself pretty much already explains how Rust achieves memory safety - every object can only have one owner and the object is deallocated as soon as the owner goes out of scope (see how this way you can't have things like dangling pointers, double frees, memory leaks, etc.). Since objects can only have one owner, if you add another line like let merkle2 = merkle; , the object in merkle is moved to merkle2, meaning the original merkle variable is now dead and can no longer be used. The actual heap memory isn't copied or changed - it's the same as it was when merkle pointed to it.\n\nThe issue with this is that forcing all variables to only have one owner that can access it is incredibly restrictive and just unrealistic for almost all programs. That's where references come in - adding the & in front of a variable (ie. &merkle) gives you an immutable reference to that variable (aka you're borrowing that memory from the owner). Unlike for an owner, when a reference goes out of scope, the underlying memory is not freed, but instead is returned back to the original owner variable.\n\nThis is why you'll see many functions will take an immutable reference rather than the value itself (ie. fn example_function(merkle_tree_arg: &MerkleTree) { ...). Here, you would call this function like example_function(&merkle);. If it took a MerkleTree instead of a &MerkleTree, you would call it like example_function(merkle);. The merkle object would be moved into the argument of the function (which we called merkle_tree_arg) when called and consume the original variable (you can no longer use your merkle variable after this point). Since merkle_tree_arg is defined in the function's scope, the underlying memory for merkle_tree_arg (which used to belong to merkle) is freed at the end of the function and is gone forever. Hopefully you can see why moving the variable into the function doesn't really make sense in most cases. More likely than not you'll want to use a reference to an object rather than the object itself, unless you actually want to transfer ownership of the object to another variable.\n\nWhile this whole ownership / borrow checker stuff sounds really annoying and restrictive, by forcing the programmer to do this, Rust's borrow checker can determine at compile-time if your code will always be memory-safe (aka you can be certain that all references are always valid and you'll never have memory leaks) and won't let you compile unless it is, which is a really powerful paradigm (and a large reason why it's so popular for newer projects, especially in crypto where memory safety is extremely important).\n\nAgain, I'd highly recommend reading the section on it in the book as it explains it thoroughly and better than I ever could, but definitely feel free to post follow-ups if you have any specific questions.",
            "That makes a lot of sense, thanks Kevin!!",
            "Do you know what happens when you dereference in rust, i.e. in a function you passed a reference too, with * ? Is a copy of the object made, or is it then passed into the function and consumed?",
            "If the type of the reference you are trying to dereference implements the Copy trait, then a copy will be made. If it doesn't, then a move occurs. aka, if you have\n\nlet a : T = ...;\nlet b : &T = &a;\nlet c : T = *b;\n\n\nif T implements the Copy trait then c will have a copy of a. If T does not implement Copy, then the value will be moved into c and a will be consumed.\n\nThe Copy trait is implemented using #[derive(Copy, Clone)]\n\n"
        ]
    },
    {
        "title": "Null parent pointer in genesis block",
        "question": "For the assignment, since the genesis block has a \"null\" value for the parent pointer, should we set the parent's datatype to Option<H256> in the Header struct instead of H256 to support the idea of a parent pointer being equal to \"None\" in the genesis block? Also just as a follow up question, I'm assuming that the genesis block has empty/random information for nonce, difficulty, timestamp, merkle_root, and content right if I'm understanding genesis blocks correctly?\n\n",
        "other_text": [
            "Yes you can use Option<H256>. You can also set the parent hash as \"0x00..00\" or any fixed number. The nonce,etc. can be random for now.",
            "Follow up question here: does this mean that I can also make the return type of the get_parent function Option<H256>?",
            "Yes"
        ]
    },
    {
        "title": "inserting invalid blocks",
        "question": "Since we are not required to return Result, will the course staff be testing our code by inserting invalid blocks? Could I instead use .expect(\"error message\") to handle invalid blocks?\n\ninsert() - insert a block into the blockchain. You can (but not required) make it return struct Result since if you insert an invalid block, you need to handle the error.",
        "other_text": [
            "You will be checking validity of blocks in a later part. \nWe won't be testing invalid block handling in Part 3"
        ]
    },
    {
        "title": "Github Copilot",
        "question": "I recently found out about Github Copilot and was trying it out recently.\n\nIt seems like a marvelous tool, but I wanted to check if using it would be kosher with course policies.",
        "other_text": [
            "It would not be appropriate to use Copilot for the assignments\n\n"
        ]
    },
    {
        "title": "Ed Questions Regarding Assignment 3",
        "question": "There is no subcategory \"A3\" (or A4, A5, ..., A8 for that matter) under the \"Assignments\" category which is why all questions related to Assignment 3 are marked under the \"General\" category. If someone on the course staff could make subcategories for all the assignments it would be a lot easier to filter and view the questions. Thank you!\n\n",
        "other_text": [
            "Done, thanks"
        ]
    },
    {
        "title": "Canvas upload problems",
        "question": "Hello,\n\nI got an email a few days ago because my format for A2 was wrong. I just uploaded A3 following the instructions to fix it and i believe everything is correct now, however when i upload my zip file, szatz.zip, to canvas, it displays on canvas that i uploaded szatz-3.zip \n\n\n\nIs this anything to worry about on my end? Just want to make sure I don't get deducted any points",
        "other_text": [
            "No, you don't need to worry about the -1,-2,etc. appended by Canvas. Just the three things mentioned in the pinned assignment 1 post."
        ]
    },
    {
        "title": "Way to hash Header",
        "question": "Does the exact way we hash our header not matter as long as we do it consistently, or is there some preferred way based on later assignments?",
        "other_text": [
            "According to Office Hours, it seemed like the preferred way to hash the header was to serialize it and hash the serial. I'm not sure if it would cause an issue if you did it differently.",
            "Is there a way to serialize the entire struct at once? Or should I concat the serializations of each field individually\n\n",
            "You can use the same method you used to serialize the transaction struct in Part1"
        ]
    },
    {
        "title": "Submitting to Canvas",
        "question": "Currently, whenever I submit to canvas using the file gvchen.zip, canvas automatically renames it to gvchen-3.zip  (the number changes). I think this is because previous submissions to other assignments (like assignment 1) have the same file name, so canvas is automatically differentiating them. Is there any way around this?",
        "other_text": [
            "This is fine. We'll take care of this on our end. "
        ]
    },
    {
        "title": "Nonce/Difficulty enforcement in Blockchain insert (Part 3)",
        "question": "In Part 3, while writing the insert block code, do we need to handle the rules around nonce / check that the cryptographic challenge has been completed?\n\nOr is that deferred to later parts?",
        "other_text": [
            "It is deferred to a later part."
        ]
    },
    {
        "title": "Block ownership in Blockchain",
        "question": "Blockchain.insert takes a reference to a block as an argument.\n\nDo we clone that block and add it to our blockchain?\n\nI assume this is the case to enforce immutability but wasn't sure.\n\n",
        "other_text": [
            "Yes, you should clone the block"
        ]
    },
    {
        "title": "Parent ownership in generate_random_block",
        "question": "generate_random_block takes a reference to the hash of the parent as an argument.\n\nDo we clone that hash and add it to our random block?\n\nI assume this is the case to enforce immutability but wasn't sure.",
        "other_text": [
            "You can dereference the hash (*parent) and use it in your block."
        ]
    },
    {
        "title": "Add extra fields in Block struct",
        "question": "Hi,\n\nI am wondering if could we add extra fields in the Block struct besides parent, nonce, difficulty, content, etc.? For example, in the blockchain part, it said \"Since we are following the longest chain rule, you may also store the length/height of each block.\" Could we have a field called length in the block struct? If so, do we need to update generate_random_block to include length?\n\n",
        "other_text": [
            "Yes you can do that.\n\nYou would have to update the generate_random_block too to be consistent."
        ]
    },
    {
        "title": "Insert duplicated block",
        "question": "Hi,\n\nIf we are inserting a duplicated block (meaning it has the same hash value), it should be considered as an invalid block, is that right?\n\n",
        "other_text": [
            "Yes, you are right. But in future assignments we would check if we already have a block before calling insert() so we might not run into this issue anyway.",
            "Is this the only way a block can be invalid? What other checks can we do to check whether the block is valid?\n\n",
            "You will be implementing the checks in the subsequent assignments. They include things such as whether transaction signatures are valid, whether the nonce passes the PoW check, whether there are any double spending txns, etc."
        ]
    },
    {
        "title": "Trouble Hashing nonce",
        "question": "Hi, \n\nIf I understand correctly, we want to hash the 0 padded u32 nonce field in order to do the comparison. \n\nBelow is a screenshot of my code. I am super confused and have tried converting the 'difficulty' variable to all sorts of slices and arrays. Can I not hash a u32 by itself? What is .hash() expecting to receive as data? I looked back through merkle tree but I never ran into this issue there. \n\n\n\n",
        "other_text": [
            "convert [u8;32] to H256 and then try .hash().\n\nThe function expects a H256 as input",
            "How do I convert? I tried using from but I get an error that from is not implemented for [u8; 32] ",
            "have you imported the correct modules? \n\nIf you see hash.py in types folder, it implements a from method to convert [u8;32] to H256",
            "Yes, I have tried this",
            "Or If I try this I get a slightly different error... \n\n\n\n",
            "I see the from implemented though... Am i messing up syntax? \n\n\n\n",
            "Although I am not sure why you are taking the hash of the difficulty",
            "Thank you that worked.\n\n\n\nAnd In order to use it in the compare function I thought I should hash it... Should I just leave it as the 0 padded H256? ",
            "when from is implemented, the actual syntax is .into() not .from().\n\nSo add a line after line 36:\n\nlet difficulty_h256 : H256 = difficulty.into()\n\n\n\nThen you can write\n\nlet difficulty_hash: H256 = difficulty_h256.hash() \n\n",
            "Like this:\n\nuse crate::types::hash::{H256, Hashable}",
            "I have that in my imports \n\n",
            "One more thing I have a question on... My content is type Vec<SignedTransaction>... I implemented Hashable for SignedTransaction, but would you mind explaining a bit on what the merkle root of the signed transaction is? \n\nDo i need to create a tree of Signed Transactions as the blocks and then pull the root? ",
            "See #103 on how to hash the header."
        ]
    },
    {
        "title": "Hashmap and DAG",
        "question": "I'm a little confused about the relations between Hashmap and DAG. To my understanding, hashmap stores a sequence of blocks in the longest chain, but DAG stores the entire tree including both the longest and other chains. Is this accurate?\n\nIf this is right, in the actual implementation, how do we implement DAG in the Blockchain struct? And how do we put hashmap into the DAG?\n\nThanks!",
        "other_text": [
            "For this project, we are only concerned with the longest chain.\n\nBut you can efficiently access other chains by making minor modifications [not required for project]:\nFor instance, HashMap(Block_hash) could store both the Block and a list of children block hashes",
            "When you mean the children block hashes, do you actually mean the parent block? Because I think we only have the path from the latest block to the oldest block, not the other directions.",
            "Yes you only need to have a path from the tip to genesis (block to parent of block).\n\nYou can ignore the above comment. That would be a solution if you wanted a path from genesis to all chains in the blockchain."
        ]
    },
    {
        "title": "Finding the longest chain",
        "question": "The assignment specs say:\n\nYou need to update tip to hash(B2) if and only if the length of chain B2 is strictly greater than that of B1.\n\nDo we have to do this check in this assignment? Since we're implementing this functionality in the next assignments, should we be doing anything differently in this assignment apart from just updating the tip with the newest added block?\n\n",
        "other_text": [
            "Yes, this check must be done in this part. You will need this to identify the longest chain: this will be checked in the test cases.\n\n",
            "I was confused because #111 says that for this project we're not implementing forks and have one singular chain which is the longest chain. In what cases will the newly inserted block not be on the longest chain?\n\nOr do we need to implement the list of children approach for this assignment?",
            "In #111 I meant that we would only need to access the longest chain (This can be done by following the parent hash from the tip block). - With this implementation we cannot access other chains efficiently.\nHowever, there can be forks due to miners not mining on the tip due to various reasons. You need to account for this.\n\n(You don't need to implement the children approach)"
        ]
    },
    {
        "title": "Requesting Part 4 Due Date Change",
        "question": "Assignment 4 is due Wednesday, October 12, which is right in the middle of midterm week for most people.\n\nGiven that the assignment after that (Assignment 5) is not due till October 26, is there any chance the deadline for Assignment 4 can be pushed back a few days, to Friday or possibly Sunday? \n\nIf others in the class feel similarly, please upvote this.",
        "other_text": [
            "Sure. We will move the deadline to Sunday night.\nGood luck for your midterms!",
            "Thank you so much!"
        ]
    },
    {
        "title": "Trouble Understanding Difficulty",
        "question": "Can anyone help explain difficulty to me and how we are supposed to assign it? In A3, the readme states that this can be 'whatever we want'. In lecture however it seems to follow a specific formula and it is a 256 bit number that's 0 padded for the first 32 digits. \n\nI sort of understand that you try to hash with different 'nonce' values until it is less than the difficulty at which point you successfully mine the coin (Right?), but how do we determine the initial difficulty? \n\nAdditionally, is 'nonce' simply a random 32bit number? Any help would be appreciated! I hope my point of confusion makes sense!",
        "other_text": [
            "From the assignment 4's specs:\n\nYou can set it [difficulty] to be the largest hash 0xffff....ffff. In code, you can use [255u8; 32].into().\n\nnonce - generate a random nonce (use rand crate) in every iteration, or increment nonce (say, increment by 1) in every iteration. P.S. do you think there is any difference in terms of the probability of solving the puzzle?"
        ]
    },
    {
        "title": "cargo run -- -v error",
        "question": "Running cargo run -- -v leads to this error. Cargo test runs properly and I'm passing the blockchain test. The rust extension isn't detecting an error either. Any ideas on how to fix this?",
        "other_text": [
            "generate_random_block() is defined as a test function (denoted by the #[cfg(any(test, test_utilities))]) before the function declaration. This conditional compilation means that function is only compiled when testing, and doesn't exist otherwise, so it won't work for cargo run. You'll want to move that use statement directly into the mod tests { ... section of that file instead.\n\n",
            "Thanks!"
        ]
    },
    {
        "title": "Blockchain Struct Implimentation",
        "question": "Hi I am hoping that someone could help sanity check me here and let me know if There is anything that is glaringly wrong with this implementation.  \n\nThe thing I am struggling with is that the genesis block technically shouldn't have a parent although that is not an optional argument in the block struct. \n\nAm i correct that All the blockchain needs is the hash map because it's blocks and their parents will construct the DAG? ",
        "other_text": [
            "Yes, you could set the parent of genesis to an arbitrary (but deterministic) value.\n\nGiven the tip, we will be able to access the longest chain by following the parent hash and using the hashmap."
        ]
    },
    {
        "title": "Trouble with borrowed values",
        "question": "Hi all, \n\nI am having trouble with a stubborn part of the code that does not like the block reference in the insert function. \n\nSee below... Any tips? \n\n\n\n",
        "other_text": [
            "Is it acceptable to use .clone()?",
            "Yes, you should use clone",
            "I implemented clone but it seems the test 'addone' is not making it past creating a new blockchain...\n\n",
            "Try to debug this using print statements?",
            "It looks like an issue with my merkle root. When I omit this field It is fine. ",
            "It ended up being the fact that the program panicked at root: Option<H256> on the merkle tree because it found a 'None' Value when the content of the block was an empty vector....\n\n\n\nNot sure how to get around this, I just set the root of an empty tree to be H256 of all 0's. \n\nSeems hacky for now but if you think its ok ill go with it. ",
            "Yes, this is totally fine.\n\nOnce you've implemented the mempool, this case won't occur."
        ]
    },
    {
        "title": "What counts as Invalid Block?",
        "question": "What exactly counts as an invalid block? A block with a null value as parent hash? If so, we run the if block.get_parent() == None and have to set get_parent () return type to Option<H256> which will mess up the test case. \n\n",
        "other_text": [
            "You don't need to worry about invalid blocks in Part3.\n\n(See discussion in #109 )"
        ]
    },
    {
        "title": "Deadline extension for Assignment 4",
        "question": "Considering that many of you have midterms next week:\nAssignment 4 will be due 10PM on Sunday, October 16.\n\n(Assignment 3 is still due 3PM Wednesday).\n\nBest,\nAshwin\n\n",
        "other_text": []
    },
    {
        "title": "issue with derive",
        "question": "I keep getting this error when I run cargo test associated with this line (which was given to us): \n\n#[derive(Serialize, Deserialize, Debug, Clone)]\n\nCurrently my block has a header and content field which those traits are not derived on. Should I be adding that line to those structs? When I do that, the issue propagates down to my merkle tree. Should I just add this line everywhere? Also the issue happens with clone and deserialize.",
        "other_text": [
            "Yes, you should derive Clone for all structs."
        ]
    },
    {
        "title": "expectation for autograder log.txt file",
        "question": "Hi, \n\nI couldn't run the autograder on my computer bc of some python3 permission denied issues.\n\nI decided to run it on Princeton's courselab and got this output for the log.txt\n\n\n\nNot sure if it even ran the tests, what would the output look like?",
        "other_text": [
            "log.txt will have the autograder test results (ok or failed).\n\nInside COS-ECE470-... folder you would get build_log.txt that has a log of errors and/or warnings."
        ]
    },
    {
        "title": "Public Fields of Block",
        "question": "Hi,\n\nAre we allowed to make the Header/Content structs public as well as all fields contained in both of them? It seems like we're exposing a lot through this but on the other hand I am unsure how else we would be able to create the genesis block?\n\nOr should we simply make a create_genesis_block() in block.rs, similar to the get_parent() and get_difficulty() in order not to need to make all fields public?\n\nThanks!\n\n",
        "other_text": [
            "You can make the fields public."
        ]
    },
    {
        "title": "Public struct fields",
        "question": "When I try to create a block in the mining loop, I get an error saying that the fields of the Block struct are private. A solution I found online is to set each field as public using the pub keyword. Is this a good solution? Are there any drawbacks to making the fields of a struct public?",
        "other_text": [
            "You can make the fields public",
            "Is a 'new' function for the Block struct the more optimal solution?"
        ]
    },
    {
        "title": "merkle tree overflow",
        "question": "When I tried to run insert_one test, the error message said \"thread 'blockchain::tests::insert_one' panicked at 'attempt to subtract with overflow', src\\types\\merkle.rs\", even though I passed the tests on my previous assignment. Did anyone else come across this? What could be the possible reason - some edge cases that we didn't consider last time needed to be fixed for this time?\n\n",
        "other_text": [
            "Are you trying to get a Merkle tree of an empty vector? If so you would need to account for this in your merkle implementation.\n\n(if you\u2019re still stuck you can make a private post with your error/code)"
        ]
    },
    {
        "title": "How to return 0 as H256 in Rust?",
        "question": "Bouncing off ideas in #97, the staff recommended \"You can also set the parent hash as \"0x00..00\" or any fixed number. The nonce,etc. can be random for now.\" \n\nHow can we convert the string/int type to a H256 one to do this?",
        "other_text": [
            "You can use the hex_literal crate for this.\n\nOr you can make a [u8;32] array of zeros and convert it to H256 using .into()."
        ]
    },
    {
        "title": "Do miner workers check the validity of a block before insertion?",
        "question": "I saw that we could ignore this use case in Assignment 3 but do we still not check for the validity of a block before inserting it into the blockchain in Assignment 4?",
        "other_text": [
            "No, it is not required in Part 4.\n\nThe (honest) miner should ensure the validity of the block during creation.\n(correct difficulty, parent is tip of bc, PoW satisfied)\n\nYou'll implement the network modules in Part 5. In Part 6 you will be checking the validity of a block received from other nodes before insertion into your blockchain"
        ]
    },
    {
        "title": "Strange err message",
        "question": "I see that test fail on string in file src/blockchain/mod.rs (that I did not touch) at \n\n    /// Get the last block's hash of the longest chain\n    pub fn tip(&self) -> H256 {\n        unimplemented!()\n    }\n\nThe only guess I could come up is that in my mod.rs I did not implemented all_blocks_in_longest_chain, put some stuff that the function would return smth:\n\n 55     pub fn all_blocks_in_longest_chain(&self) -> Vec<hash::H256> {\n 56         // unimplemented!();\n 57         let mut all_blocks: Vec::<hash::H256> = vec![];\n 58         all_blocks.push(self.tip.clone());\n 59         all_blocks\n 60\n 61     }\n\nThe rest of  my code should work.\n\nMy tip function should be ok:\n\n 51     pub fn tip(&self) -> hash::H256 {\n 52         self.tip\n 53     }\n\n\n\nWhy do I get this error?",
        "other_text": [
            "How have you implemented the insert() function? There must be a problem there since that is what this test checks",
            "    This is the code for insert function. The code compiles. Is any reason\n    why the message tells \"not implemented\"?\n    The description tells that a returning value is not mandatory.\n    \n    pub fn insert(&mut self, mut new_block: block::Block) {\n        let parent = new_block.get_parent();\n\n        if let Some(parent) = self.storage.get(&parent) {\n            // parent exist\n            new_block.order = parent.order + 1;\n        } else {\n        // else we insert the genesis, storage is empty\n            self.tip = new_block.hash();\n        }\n        \n        // insert the new block into blockchain\n        self.storage.insert(new_block.hash(), new_block.clone());\n\n        // check if we are in the longest chain\n        if let Some(tip) = self.storage.get(&self.tip) {\n            if new_block.order > tip.order {\n                self.tip = new_block.hash();\n            };\n        };\n\n",
            "What is your code at line 20 in blockchain/mod.rs?\n\nAnd just to be sure: the genesis should be implemented in the new() function, not insert",
            "\n\nHere you can see line 20.  genesis is at new(). \n\n",
            "Try \n\ndifficulty: H256 = empty_dif.into()\n\nThe program is panicking at this line.\nAlso for hashing, you can just use, for eg. genesis_hash : H256 = genesis.hash()",
            "difficulty: H256 = empty_dif.into()\n\nThat does not work(\n\nbut I am in the file src/types/mod.rs;\n\nand the err is in line 20 of src /blockchain/mod.rs\n\nthat contains unimplemented in line 20\n\n    pub fn tip(&self) -> H256 {\n        unimplemented!()\n    }",
            "You need to implement your code in src/blockchain/mod.rs\n\nIf I'm not wrong types/mod.rs only has declarations of the implemented modules",
            "Thanks! It was a great idea and a very funny mistake=)",
            "Is any opportunity to discuss it before the 3pm? I understand that it may not be the case, but it would be great if possible",
            "I can meet briefly on the office hours zoom link"
        ]
    },
    {
        "title": "Typo A5 ReadMe",
        "question": "In \u201cGrading\u201d section, \u201cand\u201d is misspelled. Thought you might want it pointed out since they can be hard to find alone. Please let me know if you\u2019d prefer I put this somewhere else. Thanks for everything!",
        "other_text": [
            "Noted, thanks!",
            "Thanks Vinay. I never got to read the READMEs earlier myself and we are working to fix several of the other grammatical errors too. "
        ]
    },
    {
        "title": "Open Invite to Dinner with Professor Pramod on Thursday, Oct 6",
        "question": "Hi all,\n\nProfessor Pramod is inviting anyone who is interested to join for dinner at Mathey College. Swipes are open to all, including juniors and seniors not on the dining hall plan. We will meet at Blair Arch at 5:30 PM, then proceed to the Mathey Dining Hall. A chocolate fountain will be featured.\u00a0\n\nHope to see you tomorrow!\n\u00a0",
        "other_text": []
    },
    {
        "title": "0 on Assignment",
        "question": "Hello,\n\nsaw on canvas that I got a 0 on my assignment. I believe this is wrong because it passed all of the tests and i followed the upload formatting guidelines sent to me last week.\n\nCan you please fix this? \n\nThanks!",
        "other_text": [
            "Hi Sean, sorry to hear that. Can you please meet Ashwin or Viraj at a mutually convenient time asap to go over your code and find out the errors and we work together to fix the code? We don't want you to lose all your grade for this assignment -- we will work together to help you understand the assignment fully, fix the code, and get you to resubmit the code. \n\nPramod",
            "Cool will do, thanks!"
        ]
    },
    {
        "title": "Failing assertion in miner_three_block",
        "question": "Hello,\n\nI've implemented Part 4 fully but am failing the test. I cannot figure out why. \n\nThis is my code in the miner loop for creating a block:\n\nAnd for sending it when the correct hash is found:\n\nAnd finally, this is my worker loop:\n\nI tried printing the blockchain at different points to see what the problem was and it seems like the block isn't being inserted. I'm using arc mutex as well as Arc::clone(blockchain) in the new methods. And in the test_new() method I'm creating a new blockchain and passing it into the new() function.\n\nI'm not sure where the bug is or how to go about debugging this problem. Any advice will be helpful. I will try to attend office hours tomorrow but was hoping to finish this part soon.\n\nThank you for your time!",
        "other_text": [
            "You need to insert the mined block into the blockchain even in the miner loop.\n\nThis issue is happening because Worker and Context have different copies of the blockchain. Inserting a block in the Worker blockchain instance will not reflect in the blockchain instance owned by the miner context.",
            "Thank you! It wasn't clear from the assignment specs that we had to do that. I assumed that the worker was handling the insertion and since we're using mutex the other copy would be updated as well.",
            "You would be doing an Arc::clone() right? \nSo they would be different instances"
        ]
    },
    {
        "title": "Ways to improve in the class",
        "question": "Hi,\n\nI was just looking at my assignment 3 grades and even though I spent a lot of time on it, I didn't pass any of the test cases and it was pretty much as if I never turned in the assignment.  I thought I did exactly as the assignment wanted, and I passed the cargo test, but none of the hidden tests. (I am very scared now because I just lost a massive chunk of my course grade)\n\n I wanted to ask on some strategies I can use to better understand the assignment and what I can do to see if my program is working correctly/improve my grade before it is too late. \n\nThanks!",
        "other_text": [
            "Hi Pranav, sorry to hear that. Can you please meet Ashwin or Viraj at a mutually convenient time asap to go over your code and find out the errors and we work together to fix the code? We don't want you to lose all your grade for this assignment -- we will work together to help you understand the assignment fully, fix the code, and get you to resubmit the code. \n\nPramod",
            "Thank you for this opportunity! Will attend next scheduled office hours.",
            "Update: I resubmitted the code today after working together with Tianle. He also showed me how to write my own tests for future assignments. Thank you for this opportunity to resubmit!",
            "Glad it was useful. We would like to give students every opportunity to learn and improve. "
        ]
    },
    {
        "title": "Mentioning a blockchain/entrepreneurial event to the class",
        "question": "Hello there!\n\nI was wondering if it would be appropriate to post about blockchain events/opportunities for our class under a category like Social. The reason I am asking is because there is an event next Tuesday where a VC fund is coming on campus to talk about innovation and their web3 builders program (event details here https://par.tf/zEYU). I think some students in this class may be interested in the entrepreneurial side of blockchain, but first wanted to confirm with staff if it would be alright to announce this.\n\nThanks!",
        "other_text": [
            "Sure, go ahead!"
        ]
    },
    {
        "title": "Mid-term & final info",
        "question": "Where can we find info on the midterm & final? I looked on the course sites but couldn't find anything. ",
        "other_text": [
            "There will not be a midterm exam.\n\nAs announced on canvas:\n\n The grading is conducted via assignments in two forms: (a) a sequence of 8 programming assignments -- covering 80% of the grade; (b) a final take home exam -- covering 20% of the grade. \n\nYou will roughly have 2-3 weeks to work on the final take home exam.",
            "Will the final take-home be in the form of a coding assignment or a traditional exam based on the material?\n\n",
            "Traditional take-home exam based on lecture material. The take home exam will be based on some exercises we will release with the updated lecture notes. "
        ]
    },
    {
        "title": "Theory HW",
        "question": "Hi,\n\nWhere can I find theory HW? I couldn't find it on Canvas.\n\nThank you.",
        "other_text": [
            "Homework assignments will be released for lectures 1-8 tomorrow (Sunday). They are not all \n\"theory\", some may involve  (minimal) programming. "
        ]
    },
    {
        "title": "$100M Binance Hack due to a Bug in Merkle Proof?",
        "question": "As lot of you might have know, yesterday Binance Smart Chain suffered a $100M bridge hack due to the critical bug in its merkle proof implementation. Attackers essentially forged proofs that convinced the Binance Bridge to send them $1M BNBm, out of thin hair, which caused the entire chain to halt. The best place to dig into the details: https://twitter.com/samczsun/status/1578167198203289600?s=46&t=pMjE4bFaljbOsfSgZcSTEA.\n\nSo, do your merkle proof function right, anons. \n\nIt could worth several hundred million dollars :)\n\n\n\n",
        "other_text": [
            "Thanks Bofan for the announcement. Merkle proofs are so basic and used everywhere in blockchains. It is odd to see a bug at this stage and natural to wonder what exactly happened.  One of the advantages of learning the \"principles\" of blockchains is that we can dig deep into the exact mechanics (i.e., way deeper than Twitter summaries). This particular bug was in a \"bridge\", an important blockchain component allowing interoperability of blockchains, which is the focus of Lecture 18 where we discuss the core principles of bootstrapping and bridging blockchains. In fact, bridges are so new and being built so haphazardly, it is no surprise many recent hacks trace back to bridges -- the amounts have gotten so big that even a mainstream forum such as NY Times  ended up covering the hacks ($2B in recent months). Catch up on such news, follow the detective thrill of whodunit and hold on to this thread and we will do a (voluntary) homework exercise when we get to lecture 18. "
        ]
    },
    {
        "title": "If we are only supposed to get blockchain.tip() when ControlSignal::Update is received, how do we start mining?",
        "question": "Step 1 under \"Main Mining Loop\" reads\n\n1. parent - use blockchain.tip(). You can have a variable to store it, and only call blockchain.tip() when ControlSignal::Update is received.\n\nIt seems to me that this implies that we should call blockchain.tip() ONLY when we receive this signal. Before we have called blockchain.tip() (or done something equivalent, like directly getting the genesis block) though, we cannot begin mining. The test provided is then impossible to pass, as it never sends the ControlSignal::Update signal, so we can never begin mining.\n\nTo work around this, I called blockchain.tip() when miner_loop() starts. Is this allowed?\n\n",
        "other_text": [
            "Yes, you can get the tip when the miner_loop() starts.",
            "I'm also confused on what this test is trying to accomplish. Since it's asserting that the previously mined block is that of the parent of the most recently mined block, that would imply that we want to create a blockchain with three blocks on different levels, right? I'm just confused how this is supposed to work if the tests don't rely on a worker to insert the block into the blockchain: wouldn't blockchain.tip() always return the genesis block in that case? Can we just mine on the most recently mined block for this part, or am I missing something?\n\n",
            "You can make a variable called tip_hash which gets updated to blockchain.tip() whenever the miner gets a ControlSignal::Update.\n\nThe main miner loop can just use this tip_hash and update it to the latest mined block, like you said. This should be sufficient for passing the test. \n\nOutside the test, however, when you send the broadcast message the worker should update the blockchain."
        ]
    },
    {
        "title": "Lecture notes #8 - wrong file posted",
        "question": "Hi, you accidentally posted Lecture 7 twice (for lectures 7 and 8) on the course website. Thanks!",
        "other_text": [
            "Thanks for pointing this out. We'll update this",
            "Posted updated notes for lecture 8\n\n"
        ]
    },
    {
        "title": "Startup Funding Opportunity for Student Entrepreneurs",
        "question": "Hey everyone, knowing there are lots of rising entrepreneurs and innovators in this class, I wanted to spread word about Prospect Student Ventures' (PSV) grant application for the Fall semester.\n\nPSV provides equity-free, no-strings-attached grants of $1K-10K to student-founders creating technology based startups. Our mission is to help kick-start the entrepreneurial journeys of student innovators by bridging the funding gap on campus. \n\nApply here by Oct 23, 2022 @ 11:59PM\u200d.\n\nBefore applying, check out our grant criteria (also in slides with FAQ)\n\nMore info about our grant process on our website.\n\nPlease do not hesitate to email Adam (akelch@princeton.edu) with any other questions.\n\n \n\n",
        "other_text": []
    },
    {
        "title": "System time before unix epoch",
        "question": "Can we assume system time is not before the UNIX_EPOCH when calculating timestamp?",
        "other_text": [
            "Yes you can"
        ]
    },
    {
        "title": "Updating parent",
        "question": "The assignment says \"If it is satisfied, the block is successfully generated. Congratulations! Just send the block to the channel finished_block_chan. And keep on mining for another block. Oh, do not forget to update the parent of the block being mined.\"\n\nDoes that mean we just make the new parent to be the block we just mined?\n\n",
        "other_text": [
            "You can set it to the tip of the blockchain.",
            "but isn't that the same tip that we used to construct the parent of the block's header?\n\n",
            "You will be inserting the block into the blockchain (either in the worker, or the miner itself).\nSo the tip will have been updated if it's in the longest chain"
        ]
    },
    {
        "title": "Worker new function",
        "question": "(for assignment 5)\n\nThe spec says \n\nFirst, you need to add a thread-safe wrapper of Blockchain into Worker struct in src/network/worker.rs.\n\nDo we also have to modify Worker::new() so it accepts a thread-safe wrapper of Blockchain parameter? Or should new() just always create a new Blockchain ?\n\nFor generate_test_worker_and_start() the assignment spec says\n\nYou need to finish the part that adds Blockchain inside Worker\n\nwhich I think implies that we do need to modify Worker::new() to accept the Blockchain wrapper, but in main.rs there is also a call to Worker::new() with the line let worker_ctx = network::worker::Worker::new( ... , so should we also change this line as well to pass in a Blockchain wrapper?\n\n",
        "other_text": [
            "Do we also have to modify Worker::new() so it accepts a thread-safe wrapper of Blockchain parameter? Or should new() just always create a new Blockchain ?\n\nYes it should accept a thread-safe wrapper of Blockchain.\n\nshould we also change this line as well to pass in a Blockchain wrapper?\n\nYes",
            "I am confused why the answer to the question \"in main.rs there is also a call to Worker::new() with the line let worker_ctx = network::worker::Worker::new( ... , so should we also change this line as well to pass in a Blockchain wrapper?\" is yes, since this new function is for network::worker::Worker. \n\nI thought we were only supposed to edit miner::worker::Worker, so I only passed the Blockchain wrapper to the one call to miner::worker::Worker::new. Would we change the args to network::worker::Worker::new() only if we are implementing \"us[ing] network server handle to broadcast the newly genereated blocks' hashes. (Not required in this part.)\"?",
            "this is for assignment 5, I think you're probably referring to assignment 4?",
            "Oh my mistake, you're right. Thank you"
        ]
    },
    {
        "title": "context control signal",
        "question": "I didn't fully understand the step of updating context in mod.rs, isn't the control channel already written for us? Thank you for your help!\n\n",
        "other_text": [
            "You only need to add a field to get the blockchain struct.",
            "I also realized the blockchain field that I have created has the wrong type and should be as described as Arc<Mutex<Blockchain>>? The \"Arc\" part allows for multiple thread access and the \"Mutex\" part implements \"locks\"?",
            "Yes it should be Arc<Mutex<Blockchain>>"
        ]
    },
    {
        "title": "test_new() function",
        "question": "I'm confused about the implementation of this function.\n\nIn the specs it says\n\n\"You need to write function fn test_new() -> (Context, Handle, Receiver<Block>) in src/miner/mod.rs which creates a miner context, a miner handle, and a receiver for testing purpose. This function is called inside the auto-grader and should has no input parameter\"\n\nBut we were told to update our new() function to take blockchain: &Arc<Mutex<Blockchain>> as an input parameter. Where is this variable created in test_new()? Should we create a new, empty blockchain?",
        "other_text": [
            "Yes you should create a new blockchain."
        ]
    },
    {
        "title": "Error on channel",
        "question": "I'm getting the following error:\n\nthread '<unnamed>' panicked at 'called `Result::unwrap()` on an `Err` value: RecvError', src/miner/mod.rs:229:57\n\n\nwhich is failing from the given test line \n\nlet block_next = finished_block_chan.recv().unwrap();\n\nCan you provide any insights on why my channel is receiving a faulty block? I'm sending the successfully mined block to the channel with the code given to us. And I'm pretty sure my block is valid. So where could the error be?\n\nself.finished_block_chan.send(block.clone()).expect(\"Send finished block error\");\n\n\n",
        "other_text": [
            "finished_block_chan is of the type Sender<Block> so you can't call .recv() on it.\n\nYou can only do this in worker.rs.",
            "This finished_block_chan is of type Receiver<Block>, so that is not the problem. The code is compiling fine.\n\nThe code that is failing is the unchanged code from the miner_three_block() test function.\n\n",
            "Don't worry about the error if you are passing the test case.\n\nThis error comes up because the receiving end of finished_block_chan gets disconnected after the test function exits, but the miner is still running in another thread and sending blocks on the same channel.",
            "I'm failing the test case because my code panics before the assert",
            "So your code isn't panicking on the .recv().unwrap() that is just before the for loop?",
            "Right. The block_prev is received fine. But the first block_next receive is the one that panics",
            "The documentation says this would happen only when the channel is empty and disconnected. \n\nIs your miner thread exiting/panicking because of some other previous error? ",
            "Can you try putting print statements in your mining loop to confirm that it keeps trying different nonces and sending blocks?",
            "I start passing the test when I input the following code blockchain.insert(&created_block); after a successful mine in the main loop.\n\nI don't get why this solves the error, and I also thought that this is the Worker's job. Is this what we're supposed to do?\n\n",
            "Yes you can insert a mined block in the miner loop itself. If you are doing it only in the worker loop, you should keep track of the last mined block's hash in a variable in the miner loop. ",
            "For the last mined block's hash, isnt this just the same as the parent block?",
            "Yes"
        ]
    },
    {
        "title": "Unsure how to unwrap Arc<Mutex<Blockchain>>",
        "question": "I want to generate the parent field by calling .tip() from the blockchain field\n\nbut I am unsure on how to unwrap the Arc<Mutex<Blockchain>> field to call this function. \n\nI have tried:\n\nand\n\n\n\nCan you please guide me in the right direction on how I would be able to access the Blockchain? Thank you for your help!",
        "other_text": [
            "Try .lock().unwrap() to get a Blockchain struct from Arc<Mutex<Blockchain>>",
            "Also slightly confused on how exactly to create a new instance of a Block if the only public function we can use is generate_random_block() from part 3? For now, I should make my own public function like generate_block(params)?",
            "Just initialize each of the fields (parent,nonce, timestamp,etc.) and create an instance of the Block struct. (make the Block struct and all its fields public)"
        ]
    },
    {
        "title": "Thread Panic With Successful Test Case",
        "question": "I am passing the given test case (miner_three_block) but I am also getting a thread 'miner' panicked at 'Send finished block error: \"SendError(..)\"'. Is this expected / normal behavior?",
        "other_text": [
            "Don't worry about the error if you are passing the test case.\n\nThis error comes up because the receiving end of finished_block_chan gets disconnected after the test function exits, but the miner is still running in another thread and sending blocks on the same channel. \n\n"
        ]
    },
    {
        "title": "Setting Mining Difficulty",
        "question": "Setting the difficulty to the largest hash 0xffff....ffff. In code, you can use [255u8; 32].into(), and checking whether the block.hash() <= difficulty means that a valid block is immediately found, irrespective of the nonce. Is this the behavior that is expected?\n\nAdditionally, to get the difficulty from the blockchain in the mod.rs file, one has to get the blocks from the blockchain, which is not possible without making the blocks hashmap public in the struct that defines what a blockchain is. Is this what we are supposed to do, or should we just set the difficulty that we are testing in the mining loop to the same static difficulty that we are using for blocks?",
        "other_text": [
            "Setting the difficulty to the largest hash 0xffff....ffff. In code, you can use [255u8; 32].into(), and checking whether the block.hash() <= difficulty means that a valid block is immediately found, irrespective of the nonce. Is this the behavior that is expected?\n\nYes, this is the behavior expected.\n\nIs this what we are supposed to do, or should we just set the difficulty that we are testing in the mining loop to the same static difficulty that we are using for blocks?\n\nYou can define a get function in the blockchain struct to obtain the parent block given its hash. From there you can get its difficulty."
        ]
    },
    {
        "title": "Office hours tomorrow",
        "question": "Hello everyone,\n\nWe would have an online office hours tomorrow (Sunday 10/16) instead of Monday.\n\nTime : 3 - 4 pm, Oct 16\n\nLink : https://princeton.zoom.us/j/8756915306\n\nThanks, \n\nViraj",
        "other_text": [
            "Are you still here? Several students have been waiting in the main room for ~30 minutes, and the meeting indicates there are some breakout rooms still open",
            "Apologies, I was in other breakout rooms. I would be on zoom till 530, you can join if you have questions."
        ]
    },
    {
        "title": "convert from Arc<Mutex<Blockchain>> to Blockchain",
        "question": "I still don't fully understand what Arc<Mutex> does, but it seems that when I called self.arc_mutex.lock().unwrap(), the resulting type MutexGuard<Blockchain> has the same functionality as a blockchain, i.e. I can call insert a block on this new type. Why is that?\n\n",
        "other_text": [
            "This is a good reference to learn more about Arc<Mutex< . >>\n\nIn short, a mutex allows only one thread to access a datum at any given time.\nSo to access the data you need to acquire the mutex's lock.\n\nThe Arc wrapper is used to share ownership of the mutex across multiple threads."
        ]
    },
    {
        "title": "Ashwin's OH tonight",
        "question": "I wanted to ask if Ashwin's office hours are still on Zoom tonight, since it is technically fall break? No worries if not.\n\nThanks",
        "other_text": [
            "Yes, we 'll hold office hours today and tomorrow"
        ]
    },
    {
        "title": "Can we use Blockchain object created in src/main.rs?",
        "question": "In the assignment specification, it is stated:\n\nAt last, you need to go to src/main.rs, and change the code related to new() functions. You need to first create a new Blockchain, then turn it into Arc<Mutex<Blockchain>>, then pass it into new() functions.\n\nIt seems that the task highlighted in bold above is already implemented in the lines 38 and 39 here.\n\nCould you please confirm if we can use created Blockchain and Arc<Mutex<Blockchain>> objects, and thus, we only need to modify new() functions?\n\nThank you.\n\n",
        "other_text": [
            "Could you please confirm if we can use created Blockchain and Arc<Mutex<Blockchain>> objects, and thus, we only need to modify new() functions?\n\nYes you can use the created blockchain object ",
            "Thank you Ashwin!"
        ]
    },
    {
        "title": "miner::Handle::update()",
        "question": "Do we need to use miner::Handle::update() function for this assignment?\n\n",
        "other_text": [
            "It's not needed for this assignment",
            "Thank you.\n\nHow often are we allowed to check if the tip of the blockchain is updated? Can we check it before every attempt to solve the proof-of-work hash puzzle?",
            "For Part4, you can update the parent to the tip when you mine a block.\n\nThis should work for future parts too. \nAlternatively (optional), the worker can send Control_Signal::Update when the tip changes after an insert. (You can check if this control signal is received in every iter of the mining loop)\n",
            "For Part4, you can update the parent to the tip when you mine a block.\n\nThis should work for future parts too. \n\nJust to double check if I understand this correctly --  we can update the parent to the tip in the middle of mining the block (before every iteration) not just before starting to mine the new block. If the difficulty is low, it can take a lot of attempts to solve the puzzle, meanwhile the tip of the block may change.",
            "Yes, you can. \nBut this may not be efficient: in later parts you can use ControlSignal::Update to notify the miner when the tip has changed.",
            "Thank you!",
            "Alternatively (optional), the worker can send Control_Signal::Update when the tip changes after an insert. (You can check if this control signal is received in every iter of the mining loop)\n\nI am trying to figure out how to implement this optional part. Could you please point me in the right direction? \n\nWhat exact worker (miner worker, network worker, etc.) has an access to the control_chan  as a sender and is able to send Control_Signal::Update ?\n\nThank you.\n\n",
            "The miner handle has field Sender<ControlSignal>, and can send on the control_chan.\n(For eg, in api we use it to start the miner).\n\nNot sure of a clean way to use it though. Maybe you could pass the handle to the network worker, who can send miner_handle.update() if the tip has changed?\n(Ensure grading test cases for part5 pass if you change this now).\n\nThis isn't required for the project- your client works well when updating tip only after mining block, when the block rate is slow (as required in tests)\n\n",
            "Thank you Ashwin.\n\n"
        ]
    },
    {
        "title": "Starting miner before tests",
        "question": "Do we need to start the miner before running the tests?",
        "other_text": [
            "no"
        ]
    },
    {
        "title": "Forking Issue",
        "question": "Anybody experience this issue with forking?\n\nINFO - P2P server listening at 127.0.0.1:6000\nINFO - Miner initialized into paused mode\nINFO - Miner initialized into paused mode\nINFO - API server listening at 127.0.0.1:7000\nINFO - Miner starting in continuous mode with lambda 1000000\nINFO -  Worker just inserted block with hash 4e442e15887c2f0bc4c31440c799f2ff535f7be2d77d7a6ea82eff8f06c7b490, parent-hash cae2050b33e82850635a183dccc20faa7da4afb2bd9d8f662d93abfa0d3a74cb\nINFO -  Worker just inserted block with hash f81f53a997a0154d4e559a7d8382f62e4bc00bf6273af1fe0d04fe2a07ee17e5, parent-hash cae2050b33e82850635a183dccc20faa7da4afb2bd9d8f662d93abfa0d3a74cb\nINFO -  Worker just inserted block with hash 7e192afc651ace531f966f1b358cc114ff9990942192c22980307bcf255a1ac4, parent-hash 4e442e15887c2f0bc4c31440c799f2ff535f7be2d77d7a6ea82eff8f06c7b490\nINFO -  Worker just inserted block with hash 81a22d44742390f3dd9a17629797e1b8a22df5499ce972b3b3f5134d2edf8031, parent-hash 4e442e15887c2f0bc4c31440c799f2ff535f7be2d77d7a6ea82eff8f06c7b490\nINFO -  Worker just inserted block with hash 4153389f3a847bcf44fa963be2b83ea11f78aa1870a49bc1aae9957950b519fc, parent-hash 7e192afc651ace531f966f1b358cc114ff9990942192c22980307bcf255a1ac4\nINFO -  Worker just inserted block with hash 884eae43e3616bbc81f881a0fa5f337d0d799c161b36fb87618c66e48fc579a1, parent-hash 7e192afc651ace531f966f1b358cc114ff9990942192c22980307bcf255a1ac4\n\n\n\nAs you can see from my outputs, it seems like I always get 2 blocks mined from the same parent. I'm not sure why this is the case and have been struggling on this for a while, anybody got any advice?",
        "other_text": [
            "Are you updating the parent to the tip of blockchain (previously mined block if you have only one miner) after successfully mining a block?",
            "Yeah, after successfully mining I do that by calling blockchain.tip() after acquiring a lock on the blockchain (I use scoping {} to lock and unlock the blockchain whenever i need to get the tip or get a block)\n\nI also tried by just directly using the hash of the block i just mined but this gave me errors as well.\n\nJust to be clear, isn't there only one miner and one worker thread working in the tests?",
            "Maybe try to use print statements to see if the tip is actually being updated to your newly mined block?\n\nYes, in this part we will be testing with a single miner\n\n",
            "I fixed it by inserting the block into the blockchain in the miner loop instead of the in the worker. Now it passes the test case. I believe it was due to a race condition between the worker and miner.\n\n\n\nIs it ok to leave it like this with the insertions taking place in the miner?",
            "Yes that works",
            "I was having a similar problem where my blockchain.tip() was not updating and it was because I referenced the blockchain.tip() of self.blockchain in the Context struct since &self was the only argument passed in to Context::miner_loop(). Initially was sending the block over to worker_loop() and inserting the block into the Worker struct's blockchain but then I wasn't passing the test because my blockchain.tip() in miner_loop() would never be updated. I only passed the test when I began inserting the block into the Context struct's blockchain as well.\n\nCould you explain how the Context and Worker structs should work? Do they each have separate blockchains that need to be updated simultaneously or should they be the same blockchain that only needs to be updated (have blocks inserted) in worker_loop()? If the latter is the case, I'm unsure what I was doing wrong because I was sending the block to the channel after creating it and when it was inserted in worker_loop() the blockchain in miner_loop() wouldn't reflect the updated blockchain.\n\nIn other words, should I be inserting the newly mined block into the self.blockchain in miner_loop() and worker_loop(), or just worker_loop()?",
            "It's all one blockchain. Please read the documentation for Arc to understand this better. The provided test does not start the worker, hence the blockchain never gets updated in this test if you do A4 precisely using the README spec (inserting in the worker).\n\nThe bottom line is that A4's implementation is incomplete, and the the provided test is contrived. That is, without a considerable amount of extra work, you cannot make (1) your tests pass, (2) the blockchain be accurate, and (3) your server-worker hosted sessions to work as expected.\n\nPick two. One of those should be the ability to pass the test."
        ]
    },
    {
        "title": "Trouble adding Arc Blockchain to new() Function arguments.",
        "question": "Hi, \n\nIn the code below you can see my //added crates and then my new() function. The compiler is not liking the way I have coded this. Do you know whats going on here? \n\nFurthermore, my code was compiling when I imported and used an 'unsafe' blockchain. But now I have more errors that find problems with the miner. \n\n",
        "other_text": [
            "You don't need to change the returned values of the new() function. \n\nSo you can remove the blockchain:... on line 45",
            "I am confused, we are not supposed to modify the arguments of new()?",
            "What you have modified are not the arguments but the output of the function.",
            "Thank you!"
        ]
    },
    {
        "title": "Question about Borrowing Error",
        "question": "Hello! In my implementation of the main mining loop, I'm getting two errors regarding borrowing self when I'm inserting the block into sender, and I was wondering if I can have some help fixing this. I attached my code and an image of the error to this post. Thank you!\n\n",
        "other_text": [
            "Can you try just using \"self.finished_block_chan.send(block.clone()).expect(\"Send finished block error\");\" instead  of spawning a thread on line 185?",
            "This worked -- thank you! I was running test case miner_three_blocks, and it seems like I'm failing the test because my mining is taking 60004 ms to run, which is 4 ms more than the max allowed. Do you have any suggestions for how I can shorten the mining time? I set the difficulty to be [255u8;32].into() as recommended. I also attached an updated version of my code to this post. Thank you!\n\n",
            "line 169 in miner/mod.rs is throwing an error saying you haven't implemented hashable for signed transaction struct when you are calling the merkle tree constructor. Can you fix this and try once? ",
            "My apologies, but I forgot to push the changes to transaction.rs before downloading the file. The test is still failing, and I attached the most recent version of my code to this post. Thank you for your patience! ",
            "The new() functions in Context/Worker should take the blockchain as an argument\n\ntest_new() does not seem to be implemented?",
            "Hello! I made the changes, but I'm still getting around 60004 ms -- can you please take a look again? Thank you so much!\n\n",
            "This timeout means that mining isn't being done / some error in testing function.  It normally shouldn't take so long.\n\nTry debugging using print statements to see if the mining is happening as expected.\n\n",
            "In miner/mod.rs, comment out line 180 and change line 181 to \n\nself.blockchain.lock().unwrap().insert(&new_block);\n\nThat seems to be working.",
            "That works! Thank you both so much for your help!"
        ]
    },
    {
        "title": "Test Failure - tip not updating?",
        "question": "Hi, I'm running the test provided for the assignment and my code is failing on the first time the assertion \"assert_eq!(block_prev.hash(), block_next.get_parent());\" is called in the for loop. I traced out what is happening with the hashes, as described below:\n\nBlockchain \u2014> tip (f70) \u2014> block_prev (24b) \u2014> block_next (960)\n\nBlock\u2019s parent that is being added: f70\nBlock being added: 24b\nBlock_prev.getParent is: f70\nBlock_next.hash - 960\nblock_prev.hash - 24b\nblock_next.parent - f70\n\nFrom this, I know that the parent of both block_prev and block_next point to the blockchain tip. I'm not sure where this is happening in my code. I included screenshots of mod.rs and worker.rs but was mindful of updating the blockchain tip. Any advice would be helpful!\n",
        "other_text": [
            "The expected behavior is that parent of block_next should be block_prev.\n\nCan you verify if the tip is updated after you mine block_prev?",
            "Thank you! I think I had played around with my blockchain.rs code and that messed with insert/updating the tip. "
        ]
    },
    {
        "title": "Where does block mining go?",
        "question": "Is the code we write in the miner loop for mining a new block supposed to go inside the code-block for  OperatingState::Run? The TO-DO comments are outside of that code-block so I was a bit confused\n\n",
        "other_text": [
            "Either way would work."
        ]
    },
    {
        "title": "miner_three_block() question",
        "question": "According to the assignment specification, \n\nAfter the miner successfully generates a block, it sends the block to a channel finished_block_chan. We provide a struct named Worker that listens to this channel. The worker does the following:\n\n- When a block is received from the channel, it needs to insert the block into blockchain.\n\nTherefore, in my implementation, the miner does not insert the block into the blockchain; the miner worker is responsible for inserting the block into the blockchain.\n\nIt seems that in the  miner_three_block() test, the miner worker is never started, and as a result, the blocks are being generated by the miner, but never inserted into the blockchain. \n\nSince I update the parent of the next block with the the hash of the previously mined block, my implementation passes  the  miner_three_block() test. I am still wondering if this is the expected behavior?",
        "other_text": [
            "Yes this is fine. You can also insert the blocks in the miner loop itself before sending to the worker.",
            "Thank you Viraj.\n\nIn this case, can we skip the step when the worker inserts the block to the blockchain to prevent locking the blockchain one extra time?\n\nP.S. From reading the assignment spec it seems that there is a clear separation between mining the block (miner) and inserting the block (miner worker). Otherwise miner worker does not need a blockchain to be added into the Worker structure.",
            "You can keep both steps as well. It won't make a big difference for us.",
            "Does the worker need to verify that the PoW and difficulty of the block received from the channel is correct ?",
            "No it doesn't. We do that in subsequent parts of the project ",
            "Thank you."
        ]
    },
    {
        "title": "Issue with continuing loop after mining a block",
        "question": "I have been running into a bug for a while now where after my program finds a valid block, it seems to get stuck there and doesn't try to mine the next one. I have attached screenshots of places where there might be an issue. \n\noutput when I run cargo miner_three_block\n\n",
        "other_text": [
            "Update: I have narrowed the issue down to the idea that the test channel is not able to pull the block after I send it in the channel after mining, so it gets stuck until it can pull something out\n\n",
            "Update 2: It works now, even on stress tests, but only because I am inserting the block into the same blockchain var in had unwrapped in the beginning of the loop. I am assuming this has something to do with locking the same Blockchain instance multiple times, not sure, wanted some clarification on this, thanks!\n\n\n\n"
        ]
    },
    {
        "title": "Mining speed",
        "question": "When I run my test cases for A4, I find that the miner is able to mine the blocks very fast, usually <0.02 seconds. Is this the performance that is expected or is this only because we have set the highest threshold for our difficulty in the genesis?",
        "other_text": [
            "Yes it is because we have set the threshold to be high, and is what is expected in this part of the project."
        ]
    },
    {
        "title": "Questions on Test Failure",
        "question": "Hi, \n\nI am running the test mine three and I am getting some panics that I don't understand. \n\n1) 'Send finished block error'\n\n\n\n3) 'Miner Control Channel Detached' (I produce this by removing the expect from my send() call. \n\n \n\n3) Left != Right (You can see above)... \n\nThe assignment says don't forget to set the parent of the current block being mined once you send a finished block. How would I go about doing that? ",
        "other_text": [
            "You should update the variable tip_hash with the hash of the block you just mined.",
            "What about the 'Miner Control Channel Detached'? What does that mean? ",
            "That is expected to happen because when we exit the test function, one of the ends of the control channel gets disconnected.\n\nDon't worry about that if you are passing the test cases."
        ]
    },
    {
        "title": "Channel Disconnected.",
        "question": "I think my problem is stemming from the channel disconnect that I discovered in my last private post. See below for thorough trace of what's happening. The log is saying that it can't find the block in the blockchain even though I verify that the hashes match. It must not be inserting...\n\n\n\nHere is my Worker Receiver... The block is never being inserted which confuses me. \n\n\n\n",
        "other_text": [
            "You can insert the block in the miner loop itself after successful mining. ",
            "Does that not defeat the purpose? \n\n",
            "Is there a reason it wouldn't be working the other way? I have passed the test now, but it feels wrong to do it in the miner loop. ",
            "The worker is not running when we are doing the test. Since you are setting the difficulty and tip in the miner loop itself, you would also have to insert the block into the blockchain."
        ]
    },
    {
        "title": "Zoom call",
        "question": "Would a TA be available to Zoom briefly to talk about assignment 4 before 9:30pm EST? I think I must be misunderstanding some of the assignment 4 specs because I feel like I'm over-complicating everything.",
        "other_text": [
            "You can join the link now :  https://princeton.zoom.us/j/8756915306"
        ]
    },
    {
        "title": "NewBlockHashes broadcast",
        "question": "For the following snippet: \n\n Also if the blocks are new to this node, you need to make a broadcast of a NewBlockHashes message\n\nI just wanted to make sure that \"new to this node\" means that the block is not in  the local copy of the blockchain. You could have a situation whereby the blockchain the worker starts with has the block in it, so we count those as \"seen\" by the node, right?\n\nThank you!",
        "other_text": [
            "Correct."
        ]
    },
    {
        "title": "Orphan chain GetBlock messages",
        "question": "When we have an orphan chain (if we have blocks {A,B,C,D} but the node does not receive A but does receive {B,C,D} in a Blocks message), does it matter if we send a message back to the peer for all {A,B,C} as {B,C,D} will all see their parents missing or is it required that only A is included in the GetBlocks message. Asking for all of them shouldn't cause any issues since we ignore blocks we've already seen right?\n\nThank you!",
        "other_text": [
            "Yes, either way should work.\nYou can choose not to send GetBlocks if the parent is present in the orphan buffer.\n\n"
        ]
    },
    {
        "title": "NewBlockHashes and GetBlocks",
        "question": "For both these functions do we do the operations (send a GetBlocks message for NewBlockHashes or send a Blocks message for GetBlocks) for each block in the input vectors?\n\nSo for example if the input vector for NewBlockHashes is [A, B, C, D] and we find that hashes A and C are in the blockchain, do we send the GetBlocks message with the vector [B, D]?\n\nRelated to this, in miner/worker.rs we're broadcasting the NewBlockHashes message with a vector of size 1. In what cases will these messages be sent with more than one hash?\n\nThank you!\n\n",
        "other_text": [
            "So for example if the input vector for NewBlockHashes is [A, B, C, D] and we find that hashes A and C are in the blockchain, do we send the GetBlocks message with the vector [B, D]?\n\nYes this is correct. Similar logic for Blocks message as well.\n\nRelated to this, in miner/worker.rs we're broadcasting the NewBlockHashes message with a vector of size 1. In what cases will these messages be sent with more than one hash?\n\nThe miner worker would only send messages of size 1 - i.e., when it has mined a new block."
        ]
    },
    {
        "title": "Transactions in overtaken longest chain",
        "question": "According to the assignment specs, we only take transactions out of the mempool when a block is processed which is not orphaned or stale. If I remember correctly, a block is considered stale only if it is not in the longest chain, right? For this part, do we need to concern ourselves with an overtaking chain (i.e. there's a fork and another chain overtakes the longest chain)? Cause if so, wouldn't we need to iterate over the entire blockchain in order to find all the transactions not included in the new longest chain but were in the old chain?\n\nThanks!",
        "other_text": [
            "You can choose to put this feature in your miner. But the onus is usually on the transaction senders to resend if the longest chain suddenly switches to a new branch which is substantially different from the previous branch, and their transactions are not included.",
            "So in other words, we can ignore this for this part since transactions are done through the generator which does not really care at the moment?",
            "Yes."
        ]
    },
    {
        "title": "Checking a block's transactions",
        "question": "When receiving and processing a block, also check transactions inside it.\n\nIf a transaction within a block is invalid, should we discard the entire block?\n\n",
        "other_text": [
            "Yes. An honest miner would not mine a block with an invalid transaction, so the whole block becomes invalid."
        ]
    },
    {
        "title": "Editing main.rs",
        "question": "After we modify the Worker struct to include an instance of mutex guarded blockchain, it is expected that we should update main.rs where the Worker constructor is called, correct?",
        "other_text": [
            "Yes",
            "Can we use the same blockchain passed to the miner? ",
            "Yes"
        ]
    },
    {
        "title": "OH",
        "question": "Are there office hours tonight?",
        "other_text": []
    },
    {
        "title": "Changing difficulty with transaction generator",
        "question": "I changed the difficulty to mine 50 blocks at minimum when there were no transactions; however, once I added in the transaction generator, the mining rate went down by a lot. Do I have to update the difficulty to reflect this, or is it okay since the grading says on the first transaction of the second blocks will be checked?",
        "other_text": [
            "Just make sure the difficulty is such that the rate of block production satisfies the four criteria mentioned in the grading section."
        ]
    },
    {
        "title": "A5 Optional Parts",
        "question": "A few parts are listed as \"optional.\"\n\nAre these optional for now, but they'll come up in later assignments?\n\nOr are they just for our own enrichment?\n\n\n\nThanks",
        "other_text": [
            "They will come up in later assignments."
        ]
    },
    {
        "title": "Hash of genesis block",
        "question": "Should we set the genesis block's hash to be 0000...0000 or instead set it to be the actual hash() output of the block with zeroed values (which for me is 12d0..5795)?\n\n",
        "other_text": [
            "Set it to the actual hash with zeroed values.",
            "Sorry, still a little confused about this - does the hash of the genesis block need to be 00...00,  hash(00...00), or just any consistent H256 value?\n\n",
            "The hash of the genesis block should be a consistent H256 value. That is, everytime you generate the genesis block independently, its hash should be the same.\n\nThe hash does not need to be 0x00..00."
        ]
    },
    {
        "title": "\"Combine with miner\" section of A5",
        "question": "The assignment specs say to do the following:\n\nCombine with miner\n\nWhen miner succesfully generates a new block, broadcast the message NewBlockHashes. Hint: in src/miner/worker.rs, self.server.broadcast() may be useful.\n\nHowever, I passed all the tests without yet doing this part. How do you recommend we test this implementation, without having any test cases?",
        "other_text": [
            "You can run two processes connected to each other and start the miner in one of them. Also print the number of blocks in the longest chain of each process.  \n\nIf your broadcast code for the miner is working correctly, you should see equal number of blocks in both of them at any given time (i.e. the blocks mined by one of them would be added to the other)."
        ]
    },
    {
        "title": "Peer.write vs self.broadcast",
        "question": "What does peer.write() do, and how does it differ from broadcasting?\n\n",
        "other_text": [
            "peer.write() replies to only the peer from whom a message was received. -> useful in replying to targeted messages such as NewBlockHashes or GetBlocks\n\nbroadcast() sends message to all peers. -> useful to let all peers know you have added new blocks such as after mining or receiving new blocks from some peer."
        ]
    },
    {
        "title": "Change VS Code Highlighting",
        "question": "Does anyone know how to make it so that VS Code does not highlight automatic type annotations? My VS Code started doing this like last week and it is a little annoying. \n\n",
        "other_text": [
            "Go to VS code settings (Code -> Preferences -> Settings or press \u2318 + ,/ Ctrl + , )\n\nSearch for @ext:rust-lang.rust-analyzer Inlay Hints\n\nDisable the ones you don't want (probably Parameter Hints and Type Hints)\n\n"
        ]
    },
    {
        "title": "Check if hashes are in the blockchain",
        "question": "Have several questions related to the Gossip Protocol:\n\n1) How do we decide if a hash is in blockchain? I use all_hashes = self.arc_mutex.lock().unwrap().all_blocks_in_longest_chain() to get a hash vector and use contains() to decide if a hash in the vector. Is this the right way?\n\n2) For NewBlockHashes, how do we dcide if hashes are or are not in blockchain? \"if the hashes are not already in blockchain, you need to ask for them by sending GetBlocks.\" Do we check every single hash in the input hash vector and call getBlocks if it is not in all_hashes (if so, how would this work since getblocks only accept a hash vector but not a hash as inpute) ? Or do we check if the entire hash vector is in all_hashes (If so, how would this work?)\n\n3) Simiarly for GetBlocks, while we get blocks for hashes that are in blockchain, what do we do with the subset of hashes that are not in blockchain?\n\n\n\nThanks so much!!\n\n",
        "other_text": [
            "1) How do we decide if a hash is in blockchain?\n\nYou should check if the block is present in the hashmap (not longest chain!) you implemented for the blockchain ( eg, using hashmap.contains_key( . . . ) )\n\n2) For NewBlockHashes, how do we decide if hashes are or are not in blockchain?\n\nYou can make a vector of hashes that are not already in the blockchain, and send GetBlocks for those hashes.\n\n3) Simiarly for GetBlocks, while we get blocks for hashes that are in blockchain, what do we do with the subset of hashes that are not in blockchain?\n\nYou only send the blocks available to you. Can ignore the other hashes"
        ]
    },
    {
        "title": "non-exhaustive message types",
        "question": "Here is the error message I received non-exhaustive patterns: `message::Message::NewTransactionHashes(_)`, `message::Message::GetTransactions(_)` and `message::Message::Transactions(_)` not covered\n\nIn the worker loop function, what should we do with the message types that we don't cover in this assignment?",
        "other_text": [
            "You could just use a _ to match all other types and add an unimplemented()to this case."
        ]
    },
    {
        "title": "checking that both longest chains are the same",
        "question": "I'm trying to check that A5 is working by testing it using the method described in this Ed Post: https://edstem.org/us/courses/28225/discussion/2005762\n\nHere's what I get on both of the nodes:\n\nFirst Node:\n\nSecond Node:\n\nThe genesis block seems to be working but then each block seems to be added to the blockchain twice and maybe that is preventing it from being sent over to the second node? Could you provide some advice as to how to fix this bug/where it might be located?\n\n",
        "other_text": [
            "As soon as a block is mined by the first node, it should get broadcasted to the network. Make sure you are doing the broadcast in miner/worker.rs via the NewBlockHashes message.\n\nAs for the double insertions, I think you should check where you are calling .insert() function after mining and whether you are doing it twice by mistake.",
            "Ok, I found a faulty if statement in the gossip protocol which was preventing me from both of the nodes looking the same. I still am running into the issue of double insertion and have checked all instances where I'm calling insert, pictured below:\nin network/worker.rs (step 3 of gossip protocol):\n\nin miner/worker.rs (from part 4):\n\nShould I not be calling insert in both places? If so, where is it appropriate?",
            "Maybe add a check inside the insert function that prevents blocks from being added if they are already there in the blockchain?",
            "I've added a check in the insert function but I'm still running into the issue of double printing. I've also checked my longest chain function and I'm not sure where the problem could be coming from.",
            "Printing the longest chain after every insert might help you debug\n\n"
        ]
    },
    {
        "title": "returning ordered vector of hashes of all blocks, generate_worker_and_start() method",
        "question": "I am somewhat confused on how we can confidently return an ordered vector of hashes of all blocks in the chain. This makes sense to me when there is not diverging forks, i.e when there is one main chain (which is by default the longest chain), as we can start at blockchain.tip() and traverse backward using parent hashes. \n\nHowever, since the tip() method returns the tip of the longest chain, I don't see how this would get all blocks, particularly I don't see how we can get blocks not on the longest chain. I am also a bit confused on how blocks on the longest chain would be ordered in the vector.\n\n\n\nLastly, does the expected ordered vector start with the genesis hash as the first element ([genesis_hash, ....., tip_hash]), or start with the tip hash ([tip_hash, ...., genesis_hash])?\n\nAnswers to these questions would clarify a lot. Thanks in advance!\n\n",
        "other_text": [
            "generate_test_worker_and_start() only requires you to output the longest chain. You don't need all the blocks for that.\n\nThe order should be [genesis,...,tip]."
        ]
    },
    {
        "title": "How to obtain vector of hashes of all blocks for the generate_worker_and_start method.",
        "question": "I am a little confused on how best to obtain the vector of hashes since the blockchain struct is owned by the worker struct and the worker struct cannot be accessed after calling the worker.start() method [worker.start takes ownership of self].\n\nSecondly, what is the expected order of the hashes in the vector to be returned? The comments above the function specify to return an \"ordered vector of hashes of all blocks in the blockchain\". Is it ordered by the H256 ordering or by the time it was added to the chain?\n\n",
        "other_text": [
            "1. You should be able to use all_blocks_in_longest_chain() once you create a new blockchain in generate_worker_and_start\n\n2. The order of hashes in the longest chain to be returned is [genesis, . . . , tip]\n\n"
        ]
    },
    {
        "title": "Shared Blockchain vs. Local Copy",
        "question": "If we are using a shared blockchain structure with Arc and Mutex, how is it possible that a particular worker's blockchain instance is not up to date with all the others? I am assuming that by making this new blockchain thread-safe and shared, we are allowing all the workers to modify the same blockchain at once? \n\nThank you for your help!",
        "other_text": [
            "When you instantiate multiple nodes, they do not access the same blockchain: each would have a local copy that they would need to keep updated using the gossip protocol.\n\nWithin any node, the miner worker and network worker modify the same blockchain, and we use Arc and Mutex to enable thread-safety",
            "Oh I see, I think I am not understanding the role of a miner/worker duo correctly. Let me try to explain what I understand and let me know if this is correct:\n\n In this blockchain, we have several miner/worker duos, each are trying to mine their own blocks, simulating private parties interested in earning the reward. Within this duo, the miner's only job is to keep creating new blocks off its own blockchain's tip and if it finds one, sends it into the channel. The worker then inserts the block into the blockchain, broadcasts it to other miner/worker duos and also updates its own blockchain using the gossip protocol. The blockchain must be thread safe because the miner and worker work somewhat independently, but we also know the miner's tip may change based on incoming changes from worker, so we need to make sure the blockchain is updated before the miner \"mines\". If we have 10 of these such duos, we have instantiated 10 separate blockchains, which we hope over time, if new blocks stop being added, become identical through gossip protocol. In A5 we implement this \"updating\" functionality. ",
            "Yes this is correct"
        ]
    },
    {
        "title": "Empty vectors in the response messages",
        "question": "Could you please confirm that the network worker does not send a reply message with an empty vector of hashes? For instance, \n\nFor NewBlockHashes, if the hashes are not already in blockchain, you need to ask for them by sending GetBlocks.\n\nSuppose all hashes are already in blockchain, then the network worker does not send a GetBlocks message with the empty vector of hashes. Is that assumption correct?\n\nThe same is for GetBlocks and Blocks.",
        "other_text": [
            "Yes, you should not send any message with an empty vector.",
            "Thank you Viraj."
        ]
    },
    {
        "title": "Transactions",
        "question": "Are we creating whole new transaction structures or are we simply reusing the old ones? Im very confused by the transaction models described  and wether we are recreating the transaction structure or not?",
        "other_text": [
            "You would need to modify the Transaction structure you created in Part1",
            "What is an account nonce?\n\nAnd what is the input and output",
            "Account-nonce is a transaction counter in each account. It prevents replay attacks where a transaction (eg. sending 10 coins from A to B) can be replayed by B over and over to continually drain A's balance.\n\n\n\nAnd what is the input and output\n\nInput and output of?",
            "How do we get this value as we haven't set up any accounts. And by input and output i mean the explanation for the UTXO model",
            "Account-based model:\nFor Part7, you can implement a random tx.\nYou will set up accounts in the ledger or State in Part8. The state will contain information of the accounts. You need to set up accounts in the ICO.\n\n\nUTXO model:\n\nInput contains the hash of the previous transaction and the index; output contains a recipient address and a value. It can support multiple inputs/outputs in a transaction.\n\n\nAn example : a transaction can be TX = (input1, output1, output2), where input1 = (hash of previous transaction, output index), output1 = (recipient1, value1) and output2 = (recipient2, value2).\n\nYou will be storing the UTXOs in State (in Part8) after executing TX: UTXO1 = ((hash(TX), 1), (recipient1, value1)) and UTXO2 = ((hash(TX), 2), (recipient2, value2))"
        ]
    },
    {
        "title": "How to kill a process?",
        "question": "Hi, \n\nAfter just testing out the two processes specified in A5, I was just wondering how to terminate a process so that I can use the address again? \n\n\n\n\n\n",
        "other_text": [
            "If you are running it in the background, you can run the following to find the Process IDs and kill them:\n\nps -ef | grep \"bitcoin\"\nkill -9 <whatever-pids-are-associated-with-./bitcoin>",
            "Is Ctrl+C not working?"
        ]
    },
    {
        "title": "Feel like I don't understand the assignment... Some clarifying questions.",
        "question": "I am very confused on this assignment. Tell me if my understanding is correct please...\n\n1. The entirety of this assignment is going to go into the worker_loop? We are only adding code to the loop{} level. Is that correct? \n\n2. The match msg{} is simply deciding which type of message it is? What is the difference between ping and pong, I was not able to produce the mentioned log that said it would clarify. \n\n3. Would you mind just explaining what the loop itself is doing right now. My understanding is that it receives a message of unknown type, Deserializes it, then checks it type, and the rest is up to us? \n\nIm sorry for so many questions. This is the first assignment that I have felt genuinely unable to start. Thanks in advance for all your help! \n\n\n\nAside From the Loop I did modify the struct denoted by //Added. Is this the correct way to go about it? Do I address multi thread safety here?\n\n",
        "other_text": [
            "1. The entirety of this assignment is going to go into the worker_loop? We are only adding code to the loop{} level. Is that correct? \n\nCorrect.\n\n2. The match msg{} is simply deciding which type of message it is? What is the difference between ping and pong, I was not able to produce the mentioned log that said it would clarify. \n\nThe match msg is deciding what actions to do depending on what message was received. e.g. when a ping is received you respond with a pong.\n\n3. Would you mind just explaining what the loop itself is doing right now. My understanding is that it receives a message of unknown type, Deserializes it, then checks it type, and the rest is up to us? \n\nYes you are right.\n\nIm sorry for so many questions. This is the first assignment that I have felt genuinely unable to start. Thanks in advance for all your help! \n\nHave a look at message.rs and implement what should happen in case the other messages mentioned there are received. \n\nAside From the Loop I did modify the struct denoted by //Added. Is this the correct way to go about it? Do I address multi thread safety here?\n\nYes you have modified it correctly.\n\nYou can come to the office hours today at 4pm if you have more questions.",
            "I have practice at 4pm, so the office hours don't work. Im sorry about that. Will we have zoom office hours tonight? "
        ]
    },
    {
        "title": "NewBlockHashes message for the blocks handled by Orphan buffer",
        "question": "For Blocks, insert the blocks into blockchain if not already in it. Also if the blocks are new to this node, you need to make a broadcast of a NewBlockHashes message. NewBlockHashes message should contain hashes of blocks newly received.\n\n1. Suppose the block is never seen by the node before (new to this node), and is placed into the Orphan buffer. Should it be included into the NewBlockHashes  message vector?\n\n2. Suppose the block does not exist in the blockchain but already exists in the Orphan buffer.  Should it be included into the NewBlockHashes  message vector?",
        "other_text": [
            "Any logical design should be okay..\n\n1. Yes you can. You could also choose to send NewBlockHashes only when a block is inserted into the blockchain.\n\n2. If you send NewBlockHashes before inserting into the orphan buffer, you need not send it now.\n\n",
            "Thank you Ashwin.\n\n"
        ]
    },
    {
        "title": "The Crypto Story",
        "question": "Matt Levine from Bloomberg published this giant piece on crypto today:\n\nhttps://www.bloomberg.com/features/2022-the-crypto-story/\n\nIMO this is one of the best written high-level overviews of the entire crypto/web3/blockchain space intended for a layman audience that I've ever seen. It touches upon almost all of crypto - everything from low-level Blockchain technology (this class's material) to the decentralized apps and services built on top of it, to crypto's relation with and impact on broader society and traditional finance. I know a lot of people in this class are curious about all the stuff above the infra layer that this class focusses on, and I've had a lot of discussions with ppl about how to get their feet wet in that stuff. I think this piece is a fantastic overview for anyone interested in the entire crypto space. super long read btw, would still highly recommend reading the whole thing but maybe start by skimming the parts that interest you\n\n",
        "other_text": []
    },
    {
        "title": "NewBlockHashes/GetBlocks for blocks existing in orphan buffer",
        "question": "1.\n\nFor NewBlockHashes, if the hashes are not already in blockchain, you need to ask for them by sending GetBlocks.\n\nSuppose the hash does not exist in blockchain but exists in the orphan buffer -- do we still need  to ask for this block by sending GetBlocks?\n\n2.\n\nFor GetBlocks, if the hashes are in blockchain, you can get these blocks and reply them by Blocks message.\n\nSuppose the hash does not exist in blockchain but exists in the orphan buffer -- can we include this block into the Blocks message?",
        "other_text": [
            "Suppose the hash does not exist in blockchain but exists in the orphan buffer -- do we still need to ask for this block by sending GetBlocks?\n\nNo you do not need to do this, but it should not matter even if you do. I assume you have blocks in your orphan buffer and not just their hashes.\n\nSuppose the hash does not exist in blockchain but exists in the orphan buffer -- can we include this block into the Blocks message? \n\nYes you can do this.",
            "Thank you Viraj."
        ]
    },
    {
        "title": "blockchain.lock().unwrap() going into infinite loop",
        "question": "For this assignment, I passed all test cases but when I run http://127.0.0.1:7000/blockchain/longest-chain after running http://127.0.0.1:7000/miner/start?lambda=1000000 to start the miner, the browser goes into a loop and waits for a response that doesn't come. I edited the code to only be the first line where you do blockchain.lock().unwrap() and then return a status ok but the status ok never returns back to the browser which tells me there is some issue with the blokchain.lock().unwrap() code which never allows the status ok to return. Does anyone know what might be happening here?",
        "other_text": [
            "Just checking: have you started a node using, for e.g.: ./bitcoin --p2p 127.0.0.1:6000 --api 127.0.0.1:7000?\n\nThere might be an issue with the mutex lock. The lock is not released until the blockchain.lock().unwrap() goes out of scope. Other threads will wait until the lock is ready to be acquired.\nTry using print statements before and after acquiring locks to find where the potential issue might be.\n(It's a good idea to acquire the lock within a scope, and return the required value (e.g. tip) outside the scope.)",
            "I did cargo run instead of ./bitcoin! Does that work? Just to clarify, I have two lines of code, one of which is the blockchain.lock().unwrap() and the other of which is the returning of the status code\u00a0",
            "Yes, cargo run should work too.\nWere you able to fix the issue?"
        ]
    },
    {
        "title": "reply_blocks test - not finishing",
        "question": "I keep failing the reply blocks test (I wait a long time and never finishes). Everything else works (including checking the longest chains on both ports) Any advice on how to fix this bug?",
        "other_text": [
            "1) Are you broadcasting Message::NewBlockHashes once you receive a Blocks message?\n\n2) Have you implemented generate_random_block() correctly? (Should be done in Part3)\n",
            "I am broadcasting the message \n\nand my generate_random_block() function is what is described in the assignment (it passed everything in part 3):\n\n\n\n",
            "NewBlockHashes must be broadcasted after insertion if it's a new block..\n(shouldn't be in the else)",
            "Ok thank you! That fixed it."
        ]
    },
    {
        "title": "Argument for NewBlockHashes",
        "question": "\n\nHi, \n\n1) NewBlockHashes is declared as NewBlockHashes(Vec<H256>)...\n\nBelow I am attempting to run the first step of my gossip protocol ie: check if the New Block Hashes contained in the message are already in the blockchain. What is the argument where i put '???'\n\n\n\n\n\n2) In match msg{}, what is the logic here? What is this code doing and where is nonce coming from? Why doesn't pong write anything? Are we implementing anything in this match block? ",
        "other_text": [
            "Documentation for match : https://doc.rust-lang.org/rust-by-example/flow_control/match.html\n\nnonce is an argument to the Pong message. When a node receives a Ping message from its peer, it sends back a Pong message with the same nonce.\n\nYou need to implement the required messages similar to Ping/Pong within the match statement.\n\nMessage::NewBlockHashes(hashes) => {\n<your impl>\n}\n",
            "So would it look like this? \n\n",
            "Yes.\n\nYou might want to keep the \"_ => unimplemented()\" to account for message types that you won't implement in this assignment"
        ]
    },
    {
        "title": "Where does mining code go",
        "question": "I put my mining code for part 4 where the red arrow is, directly under the comment, however I think it might be that it is supposed to go inside the if let that checks if the state is Run above the sleep code if statement where the blue arrow is. Is this correct?",
        "other_text": [
            "It goes where the red arrow is.\n\nThe block within the if statement controls the mining rate by letting it sleep for some time (controlled by parameter lambda)."
        ]
    },
    {
        "title": "Edge Case Testing in A5",
        "question": "Any advice for how to play with the test cases in A5? \n\nI pass the autograder but not too sure on how to modify it. \n\nShould we be looking to make changes inside the generate_test_worker_and_start() function?",
        "other_text": [
            "The private test cases are similar to the public ones.\n\nSome examples of other test cases you could write, and verify that it works as expected:\n1. Sending messages with more than one hash/block\n2. One of the blocks in Blocks message is already present in receiver's chain\n3. etc",
            "Also, please make sure you follow the grading instructions carefully. For eg, don't add arguments to generate_test_worker_and_start(): autograder will panic and you'll get 0 "
        ]
    },
    {
        "title": "Panic when running http://127.0.0.1:7000/blockchain/longest-chain",
        "question": "Hello,\n\nI'm trying to check if the integration with the miner is working by using the URL above but I get the following error:\n\nI tried following the error but it's a bit hard to trace the problem. Any advice on how to fix?\n\nThanks!",
        "other_text": [
            "Looks like the error originates from blockchain/mod.rs , line 65.\nDid you check your code here?\n\n-Maybe there's some error in your all_blocks_in_longest_chain()\n-Have you implemented the genesis block correctly? (it should be deterministic, so that all nodes start with the same genesis)",
            "Subsequent errors are PoisonError, which means that your code panicked when holding a lock. I'm guessing the error originates from the blockchain struct implementation",
            "\n\nThis is how I've implemented all_blocks_in_longest_chain and the creation of the genesis block. The error is originating when I try to get the height of the tip. I update the height of each block in the insert method by getting the height of the parent (the height of any new block is set to be 0 by default):\n\nI'm not sure why the height would be None.",
            "It's not a good idea to have the height as a field within the block. (The hash of the block will change if you modify it within insert, this will cause problems). You can store it as a hashmap in Blockchain, or even as a tuple <Block_hash, (Block, height)>\n\nYou have set difficulty, timestamp, etc randomly in the genesis. This will cause issues because different nodes will have different genesis blocks, This shouldn't happen - everything should be a fixed value.",
            "Is it possible to meet over Zoom? I made the fixes but I'm still getting a similar error.\n\n",
            "https://princeton.zoom.us/j/92002112501\n\nCan meet briefly now",
            "I'm passing the local tests in network/worker.rs as well as some additional tests where I inserted blocks into the blockchain before running similar tests."
        ]
    },
    {
        "title": "Extension for Assignment 5",
        "question": "Hello all, \n\nI hope that you had a nice Fall Break. I've been really enjoying our class and meeting everyone at LedgerFest.\n\nHappy Diwali to you and your family! I have been attempting to fully understand and synthesize the course material and finish the assignment due today during the break, as I knew that my religious and familial obligations would limit my ability to work this week. However, my fall break, as many others's, took a very distressing turn for many reasons, which has impacted my progress. I am just now this morning returning back to campus.\n\nI was hoping that I would be able to have a short extension on the assignment. All I have left is finishing the Blocks function and testing. With this accommodation, I believe that I can better represent my ideas and put my best foot forward. I would really appreciate your help and kind consideration.\n\nBest, Tejas\n\n(this was also sent via email)",
        "other_text": [
            "You can submit the assignment by tonight 12 am.",
            "Thanks so much. Will do!"
        ]
    },
    {
        "title": "Genesis blocks for different nodes",
        "question": "Can we assume that all nodes start from the identical predefined genesis block? \n\nIf not, what is the recommended way for the new nodes to join in the existing blockchain? Should they abandon their own genesis block and replace it with the genesis block from the blockchain they are joining in?\n\nThank you.\n\n",
        "other_text": [
            "Yes all nodes have to have the same genesis block. You should implement your blockchain::new() code such that you get the same genesis every time.",
            "Thank you."
        ]
    },
    {
        "title": "Testing with two processes",
        "question": "\"You can run two processes connected to each other and start the miner in one of them. Also print the number of blocks in the longest chain of each process. \" #182 \n\n\n\nCould you explain a bit more how we do this? Thank you for the help!",
        "other_text": [
            "You can follow instructions in Part6:\nFor eg, \n\n1) Start two processes connected to each other:\n\n./bitcoin --p2p 127.0.0.1:6000 --api 127.0.0.1:7000\n\n./bitcoin --p2p 127.0.0.1:6001 --api 127.0.0.1:7001 -c 127.0.0.1:6000\n\n2) Use miner api to start mining on the first node, with suitable value of lambda:\n\nhttp://127.0.0.1:7000/miner/start?lambda=1000000\n\n\n3) Use longest chain api to display the longest chain:\n(Or can print the longest chain)\n\nhttp://127.0.0.1:7000/blockchain/longest-chain\n\nhttp://127.0.0.1:7001/blockchain/longest-chain\n"
        ]
    },
    {
        "title": "Homework solutions",
        "question": "Will the solutions/simulation code for the homeworks be released?",
        "other_text": [
            "We don't plan to release any solution code for the project.\n\nWe will help you debug your implementation during office hours (or on an Ed private post); since previous parts would need to be implemented correctly for future parts.\n\nIf you have any issues/questions about the grading, please make a private post here on Ed.",
            "I was talking about the homeworks on the lecture notes, not the project.",
            "We will not be releasing the solutions. Some of these problems will be part of the final exam"
        ]
    },
    {
        "title": "/blockchain/longest-chain API issue",
        "question": "When I run my program and go to http://127.0.0.1:7000/blockchain/longest-chain on my browser, the page does not load. \n\nHow can I approach debugging his? I am not sure where to start. Thanks.\n\n",
        "other_text": [
            "Have you initialized the nodes and started mining? (see #207, instructions in Part6)\n\nIf yes, try adding print statements to check if the mining/network is functioning as expected\n\n",
            "Thanks for your response. I followed the instructions you linked to. When I complete step 2 (http://127.0.0.1:7000/miner/start?lambda=1000000) I get {\"success\": true, \"message\": \"ok\"}\n\nWhen I attempt step 3 (http://127.0.0.1:7000/blockchain/longest-chain), the webpage does not load.  \n\n",
            "The api just calls all_blocks_in_longest_chain() that you have implemented, and converts it to json.\nCheck (using printing if necessary) if this function has been implemented correctly.\n\nAlso, is the mining happening? (can check this by printing)",
            "so I've inserted a print statement inside all_blocks_in_longest_chain() but am not seeing its output. \n\nIs it possible that the function isn't being called? Perhaps, I am not running the program correctly?\n\n",
            "It would be called when you use the longest chain api.\n\nDid you try printing the longest chain in the miner context/worker after inserting each mined block? This is to ensure the mining is happening correctly"
        ]
    },
    {
        "title": "Broadcasting invalid blocks",
        "question": "Should we be broadcasting invalid blocks? For example, if a block fails block.hash() <= difficulty",
        "other_text": [
            "No",
            "Should we just ignore the blocks that fail the difficulty check?",
            "Yes"
        ]
    },
    {
        "title": "Delay between generating longest chains in Grader.",
        "question": "I have created a script to test my implementation. The script starts 3 nodes (processes) locally. It  connects node A to node B, and node B to node C.  For mining, it starts 3 nodes' miner with lambda=0. \n\nMy difficulty level is \"00007fffffffffffffffffffffffffffffffffffffffffffffffffffffffffff\" \n\nAfter running for 5 minutes, the script dumps the longest chains for each process into the corresponding  file. This part of the script is the following.\n\ncurl http://127.0.0.1:7000/blockchain/longest-chain > 7000.json\ncurl http://127.0.0.1:7001/blockchain/longest-chain > 7001.json\ncurl http://127.0.0.1:7002/blockchain/longest-chain > 7002.json\n\nI run lots of experiments on two different machines, and my script always generates the identical files. However, if I add one second's delay between the curl commands, the resulting longest chains are different. This is due to the fact that node A dumps its longest chain first, and nodes B and C continue inserting blocks for one and two more seconds correspondingly.\n\ncurl http://127.0.0.1:7000/blockchain/longest-chain > 7000.json\nsleep 1\ncurl http://127.0.0.1:7001/blockchain/longest-chain > 7001.json\nsleep 1\ncurl http://127.0.0.1:7002/blockchain/longest-chain > 7002.json\n\nThe difference between the three longest chains is still  <=3, but I do not have confidence to meet the third requirement in the case of delays.\n\nCould you please point me in the right direction how I should proceed? Can we assume that there is no delay between the commands when the Grader generates the longest chains for the three nodes? \n\nThank you.\n\n\n\n\n\n",
        "other_text": [
            "Yes the longest chain will be checked at the same time at all 3 nodes",
            "Thank you Ashwin!"
        ]
    },
    {
        "title": "Parent of blocks from orphan buffer fails validity check",
        "question": "If the \"parent\" block fails validity check, and its \"children\" blocks are in orphan blocks buffer, do we need to remove all its children from the buffer (iteratively)?\n\n",
        "other_text": [
            "Yes",
            "Thank you."
        ]
    },
    {
        "title": "orphan buffer storage",
        "question": "I'm working on creating the orphan buffer and I have saved a hashmap struct with the parent hashes as keys and the orphan blocks as values in my worker struct in src/network/worker.rs. Since the protocol asks me to store orphan blocks and remove them once the parent has been processed, I was planning on inserting and removing from the hashmap. In order to do that, I have to make the input to the worker loop a mut self instead of just self. Can I make that change or is there a better way to store the orphan buffer?\n\nAlso to be clear, if a block is an orphan should I still be broadcasting it's hash with the NewBlockHashes message or is it just the parent hash?",
        "other_text": [
            "You can define your mutable orphan blocks hashmap outside the loop{....} in the worker_loop function. That should work without the change to mut self.\n\nAlso to be clear, if a block is an orphan should I still be broadcasting it's hash with the NewBlockHashes message or is it just the parent hash?\n\nIf you have inserted a block into the orphan blocks hashmap, you should include its hash in your NewBlockHashes message.\n\n"
        ]
    },
    {
        "title": "Orphan block buffer and handler",
        "question": "What should the scope of the orphan block buffer be? I currently have it as a vector in the Blocks message handler. If the parent doesn't exist I add it to the buffer and send a GetBlocks message.\n\nBut in A6 we have to implement a handler if we find the parents of orphan blocks. Should the vector in this case be initialized before the \"match msg\" statement and the handling be done in the Blocks message handler?",
        "other_text": [
            "Yes, you can initialize it just before the loop{....} statement in worker_loop. Adding/removing orphan blocks from this buffer would be done inside Blocks message handler. ",
            "Does \"handling\" the orphan block mean sending a Block message with this new block? ",
            "When you insert an orphan block into your buffer you include it in your NewBlockHashes message that you are broadcasting.\n\nOther than that, you should use this buffer to do what has been specified in this section of the instructions.\n\n"
        ]
    },
    {
        "title": "Waiting for 5 minutes",
        "question": "When waiting for 5 minutes, will the grader use clock time or system time (e.g., using sleep 300)?\n\nMy tests use sleep 300 in a script but it sometimes takes longer than 5 minutes because of the different processes.\n\n",
        "other_text": [
            "We'll use system time"
        ]
    },
    {
        "title": "Testing Assignment 6",
        "question": "When we run the binary using cargo run, should we only be getting the genesis block, since nothing has been mined, or should it be a constantly increasing json array?\n\nAlso, in step 4 of the Double Check section, it says: \n\nstart mining by mining API, and let it run for 5 minutes.\n\nis there a command for this, or do we just wait for 5 minutes?\n\nFinally, what is a good difficulty to use for this case?",
        "other_text": [
            "-- If you're mining blocks, the longest chain should be increasing\n\n-- You can start mining using the api and suitable lambda, for eg:\n\nhttp://127.0.0.1:7000/miner/start?lambda=1000000\n\n\n-- You need to find a suitable difficulty to satisfy the grading criteria"
        ]
    },
    {
        "title": "where do we perform block checking?",
        "question": "When processing a new block in src/network/worker.rs, please add the following checks.\n\n\nThere are a number of cases where we process a new block in that file, like when we process getBlocks Message or Block Message. Do we add all the validity, parent, and orphan buffer checks whenever we encounter a block object in the file?\n\n\n\n\n\n",
        "other_text": [
            "You process a block when you receive a Blocks message (i.e., a node receives new blocks).\n\nDo we add all the validity, parent, and orphan buffer checks whenever we encounter a block object in the file?\n\nYes you need to add all these checks when you encounter an unseen block in the Blocks message",
            "so essentially looping over all the blocks given by the Vec<Block> and check everyone of them?  \n\nBut the last assignment requires us to insert block when the blockchain contains its hash, but this one requires us to insert block when the blockchain contains its parent hash. Do we do a separate loop for the same Vec<Block> then? thanks!",
            "In the last assignment you inserted a block into blockchain if it doesn't already contain it.\n\nNow you just need to add extra conditions in the same loop over Vec<Block>, like block validity, and parent check"
        ]
    },
    {
        "title": "Understanding Orphan Blocks",
        "question": "I am confused by two things, one the scenario in which an orphan block would occur and how we would efficiently add blocks to the chain in order\n\n1) My understanding is that an orphan block can occur if we had multiple getBlocks requests, but we haven't added the parent yet, so insert() will fail because we can't find its parent to check the block's length for longest chain protocol\n\n2) Here, there are two cases, there is a broken chain in which there are a series of blocks where the end parent is in the chain or there is a series whose end parent is not in the chain. \n\n2a) If it is in the chain, I am thinking of using a stack and going through the vector again and again and adding blocks to the stack till I get to the block where the parent exists. Then pop from the stack till it is empty\n\n2b) For this case, there is no parent, so at the end of my broken chain, if I discover there is no parent, do I just send a getBlocks and send the blocks message with the orphan buffer back to itself and keep repeating forever till the getBlocks message comes back with the parent?\n\nMy algorithm seems inefficient and confusing, not sure if I am thinking of this correctly.",
        "other_text": [
            "Due to network delays, a node may receive a child block before receiving the parent. Since you cannot insert the child into the blockchain without its (valid) parent present, you need to have an orphan buffer to store such orphan blocks.\nIf/when you receive the parent P, you can insert all blocks in the orphan buffer whose parent is P into the blockchain.\n\nYou can implement the orphan buffer as a vector of blocks, or a hashmap within the worker_loop",
            "Just to make sure, let's assume that A is B's parent and A's parent is in the blockchain. Let's say we get B in the Blocks message, we see A is not in the blockchain, then after we process all the rest of the Blocks message, we call getBlocks(A) since A is B's parent that we don't have. The next time, we get {A} in Blocks message, A's parent does exist in the blockchain, we insert A, then in this case, isn't B lost? We wont have B in the hashmap unless it receives another B broadcast from another node. \n\nIn other words, if we only call getBlocks on the parents of the orphans, don't we lose the orphans and our blockchain might not ultimately contain the orphans but rather only the orphans' parents?",
            "Make a new vector/hashmap called orphan buffer, and store B in this.\n\nSo when you receive A you can access B from the orphan buffer",
            "Oh I see, so not just a temporary hashmap for that function call, but a \"global\" one in the struct so we can keep track of orphans across multiple function calls?\n\nEdit: Let me know if my understanding is correct: A global hashmap in the struct is useful so that we can process the parents we receive in a getBlocks response and the orphans in a future function call of Blocks? And we can also keep a local function vector that accumulates hashes corresponding to parent hashes for blocks we process whose parent is not in the blockchain, and according to #173 it doesn't matter if we send a parent hash request even if the parent is already in the orphan map since our function ignores duplicates?",
            "Yup, correct\n",
            "To implement this, I had to change lines 48 and 56 to be mutable, I am assuming this is ok for autograder?",
            "No you don't need to do this.\nYou can create the buffer as a field of the Worker struct.\nOr you can just initialize it inside worker_loop before loop",
            "I see ok, I changed it to this and the syntax seems to be ok:\n\nPreviously, I had actually put it in the worker struct, but it had issues saying the reference passed in on 56 was not mutable and wanted me to change it to &mut, but this way seems to be better if the loop is always running"
        ]
    },
    {
        "title": "implement copy traits for orphanbuffer",
        "question": "when I'm calling OrphanBuffer::orphan_buffer.is_empty() / push(), etc. it requires me to implement copy trait for orphanbuffer while Vec<Block> (the type for orphan_buffer) doesn't implement copy? what's the best way to work around this?\n\n",
        "other_text": [
            "you can push block.clone() ?"
        ]
    },
    {
        "title": "checking the PoW validity of a block",
        "question": "Can we put the PoW block checks in the insert() function in blockchain/mod.rs instead of in src/network/worker.rs? ",
        "other_text": [
            "Yes"
        ]
    },
    {
        "title": "Difference between worker.rs in /miner and /network",
        "question": "So in the worker.rs in network is where we are handling A6's Block's handling, however, we also have a section in miner/worker.rs where we receive a finished block from the miner and insert it regardless: \n\nDo we have to do a similar parent check here as we do in network/worker.rs? ",
        "other_text": [
            "The miner/worker.rs inserts a block mined at the tip of its blockchain.\n=> parent is in the blockchain for sure"
        ]
    },
    {
        "title": "Mining A6 Question",
        "question": "When we run the commands for mining, do we run three commands, one for each process e.g.:\n\nhttp://127.0.0.1:7000/miner/start?lambda=1000000\n\nhttp://127.0.0.1:7001/miner/start?lambda=1000000\n\nhttp://127.0.0.1:7002/miner/start?lambda=1000000\n\nOr do we just run one of these commands, e.g:\n\nhttp://127.0.0.1:7000/miner/start?lambda=1000000\n\n",
        "other_text": [
            "You need to run all three commands if you want all nodes to mine blocks",
            "When I run cargo test after assignment 6, I get this error: \n\ntest network::worker::test::reply_new_block_hashes ... ok thread 'miner' panicked at 'Miner control channel detached', src\\miner\\mod.rs:146:56 note: run with RUST_BACKTRACE=1 environment variable to display a backtrace\n\nbut this only shows up when cargo test is ran with the no captures flag, as the test passes, do you know why this could occur and if this would affect the consensus of the blockchain?\n\n",
            "Don't worry about the error if you are passing the test case.\n\nThis error comes up because the receiving end of the miner control channel gets disconnected after the test function exits, but the miner is still running in another thread and sending blocks on the same channel. "
        ]
    },
    {
        "title": "orphan buffer",
        "question": "When I try to add an orphan buffer to the worker struct and use it using self. I get the error that self is a & reference, so the data it refers to cannot be borrowed as mutable\n\nInstead of creating an orphan buffer struct, can we declare a variable to store the information in worker_loop()? (this would be right before loop{ })\n\n",
        "other_text": [
            "Correct."
        ]
    },
    {
        "title": "Debugging longest chain",
        "question": "I tried the following to see if the longest_chain api was working\n\n1) Started the worker  ./bitcoin --p2p 127.0.0.1:6000 --api 127.0.0.1:7000\n\n2) Longest chain output: http://127.0.0.1:7000/blockchain/longest-chain \n\nHash of random genesis : \n\n3) Started the miner: 127.0.0.1:7000/miner/start?lambda=1000000\n\n4) Longest chain output after several loops: http://127.0.0.1:7000/blockchain/longest-chain\n\nNow there doesn't seem to be any output at all, this is with only 1 worker running, shouldn't we see an array of a lot of mined blocks? I know my all_blocks_in_longest_chain() method works. Not sure why I am not getting an output here. Thank you for your help!",
        "other_text": [
            "Did you try printing what all blocks in longest chain returns?\n\nThe longest chain api just calls this function and writes it in json",
            "Will reply with results shortly, taking a bit of time to keep unzip, cargo build, and rerun test",
            "Edit: Skip to comment after this reply, I fixed the error, but have follow up questions\n\nWhen printing from the API, I see:\n\nSo I know that vector is coming back empty\n\nAnd when I print from the main mining loop \n\nSimilar results occur",
            "Yes, my all_blocks_in_longest_chain() function doesn't seem to be working based on my own unit tests, output is always [] after a block is inserted into the blockchain, but the tip does update as it should. \n\nEdit: Was an error in reversing the vector, is it possible that my A5 tests were actually passing even if this function was wrong? I have fixed it now, but not sure if it maintains correctness for previous parts; my cargo tests from A5 still pass.\n\n",
            "I see.\n\nWe didn't explicitly check the correctness of all_blocks_in_longest_chain() so far. (in A5 I guess your test function just returned a bc with only genesis block)"
        ]
    },
    {
        "title": "Spurious network error Mac OS X with cargo build?",
        "question": "Particular issue is \"cc\" package. Have tried adding the config.toml file with different http settings (i.e. multiplexing = false), but not having any luck. MacOS Monterey 12.3.1. \n\nJust wondering if anyone else has run into this error?\n\n",
        "other_text": [
            "Haven't faced this on my machine (Monterey 12.5).\nWasn't your code working for the previous parts?",
            "All working now! I don't think I was calling cargo build from deep enough within the project. \n\n",
            "Could you explain your solution to this a bit more? I have run into this error and now my rust code won't compile. The linter hasn't flagged any errors and I was able to compile it on a linux machine, but even after updating my Mac (Montery 12.6), reinstalling xcode tools and rust muiltiple times, it won't work. I tried to troubleshoot via stackoverflow, but nothing helped, here's the error\n\nerror: linking with cc failed: exit status: 1 rust",
            "Do you face this on any general rust code?\n\nHaven't seen this before, sorry!",
            "The error was within my .zshrc file, it declared the sdk root using an old version of mac, All i needed to do was run xcrun -sdk macosx --show-sdk-path  to get the proper path, then set the SDKROOT to that in my zsh file. "
        ]
    },
    {
        "title": "Blocks Message never processing received vector",
        "question": "As context, I am running the test procedure outlined in #207 and am trying to get the longest chain to get updated on a second worker while only running the miner on the first.\n\nFor A5/A6, we have a loop in the Blocks message that processes the vector of blocks we receive. Accordingly, I have written print statements whenever a message is received and processed by a worker.\n\nHowever, I am noticing that the loop that analyzes the vector is never entered! This makes it so that the chains can never sync. Not sure the reason, seems like simple loop syntax. \n\n",
        "other_text": [
            "Maybe you're sending a Blocks message with an empty vector?",
            "Yes, you're right it seems like both my NewBlockHashes and GetBlocks functions send empty vectors, but the only reason this would happen is if NewBlockHashes was receiving an empty input? But this doesn't make sense since every time I mine a block, I am sending a broadcast through my miner/worker.rs\n\n\n\n\n\n",
            "You need to send the messages only if length is >0.\n\nAre you sending the block correctly in miner/worker.rs?",
            "Hmm, seems like the syntax mirrors that of network/worker.rs, so I am thinking it is right",
            "My cargo test in miner_three_block in miner/mod.rs passes, so I know the channel is receiving it correctly",
            "I see. \nYou should be able to debug it by adding print statements everywhere to find the bug.\nEg: Print lengths of hashes, requested_blocks, etc to find why you were sending empty messages. (also send message only if vector.len() > 0)",
            "The issue was my genesis was random every time!! So the blocks were never inserted even if they were received. This was probably because we used rng for some fields when generating a block, but forgot to change it to being constant when generating a genesis.",
            "\ud83d\udc4d\ud83d\udc4d"
        ]
    },
    {
        "title": "API longest chain hangs with lambda = 0?",
        "question": "With lambda=0 I understand that hashes are being calculated as fast as possible, but I have also reduced my difficulty substantially. I suppose it's happening too fast and causing the longest chain to hang.\n\nIs the only way to do it is an iterative approach for reducing difficulty? And by \"reduce\", I mean decrease the number.\n\n\n\n",
        "other_text": [
            "Yes, either increase lambda or decrease the difficulty number.",
            "Did you solve this? Also having trouble with my longest-chain api call hanging"
        ]
    },
    {
        "title": "Block size limit",
        "question": "For this project, do we measure block size limit in bytes or in the number of transactions? \n\n",
        "other_text": [
            "number of transactions",
            "Thank you Ashwin.\n\n"
        ]
    },
    {
        "title": "Difficulty Consistency",
        "question": "Is there a reason why the checking of the difficulty should be done after the parent check? Wouldn't we want to throw an invalid block away as soon as possible?\n\nThe only reason I could see is that there are potential parents of such a block that have valid difficulties that we want to include, even if we throw away the later part of the chain.\n\n",
        "other_text": [
            "The difficulty of the block is based on the difficulty of the parent (in this specific implementation we use the same difficulty).\nSo we check difficulty only if the (valid) parent exists in the blockchain"
        ]
    },
    {
        "title": "Lecture 14 - Rollups: Slides?",
        "question": "The slides linked to for Lecture 14 (Rollups) on the website are not the same as those being presented at lecture today. \n\nWhere on the course website can I find the correct slides? ",
        "other_text": []
    },
    {
        "title": "Changing difficulty",
        "question": "It was recommended that we change the difficulty value so that mining rate (and forking) is reduced . The requirement is that we still maintain >= 10 blocks/min. Is there a way we can mathematically determine what a good difficulty is to get 10-20 blocks/min, or do we just try out different values?",
        "other_text": [
            "It would be best to try out different values."
        ]
    },
    {
        "title": "Office hours today",
        "question": "Hello,\n\nIs there still OH today?",
        "other_text": [
            "Yes, in J323 (and on zoom at 8pm)",
            "Ah sorry, was on zoom. I'll show up at 8 then, thanks!\n\n"
        ]
    },
    {
        "title": "Part 5 Regrade",
        "question": "Hi All, \n\nAs you may have saw, my part 5 was almost entirely unimplemented and didn't pass any public tests. I had a medical emergency last week which also caused me to miss two midterms. \n\nI have sent the formal documentation to my dead (CK). I just submitted a working pt5. I was wondering if you all would consider regrading under the circumstances? If so, what documentation would you need, and would you need to hear from dean CK?\n\n\n\nLet me know. Thank you! \n\n\n\nBen\n\n",
        "other_text": [
            "Hi Ben,\n\nSorry to hear that. \nI have regraded your A5, and updated on canvas. Hope this helps. ",
            "I appreciate it thank you!"
        ]
    },
    {
        "title": "Checking validity of the Merkle root",
        "question": "When receiving a new block, does the network worker need to check validity of the Merkle root?",
        "other_text": [
            "It's not required for the assignment ",
            "Thank you Ashwin. \n\nIs it required for the A7 or A8?\n\n",
            "No",
            "Thank you."
        ]
    },
    {
        "title": "reply_blocks",
        "question": "My reply_blocks test started failing after adding my A6 code. Can't seem to narrow down the issue, has anybody had anything similar happen?",
        "other_text": [
            "Yeah, when I change the difficulty I'm having the reply_blocks test fail. Update, turns out this was an issue caused by the test incorrectly failing the PoW difficulty validity check. If you're trying to debug, I'd recommend loading up your code with println statements and figuring out where it is catching.\n\n",
            "Isn't the problem that this reply_blocks test randomly generates a valid block using your generate_random_block function from the block.rs file and sends that as a Blocks message, so if your randomly generated block does not pass the new PoW requirements with a low difficulty value set (that were both just added in this assignment) then it will never pass this test trying only 1 random block. What I am saying is that nothing is wrong with your code if this test fails, in fact it should fail almost all the time since it is only gossiping about (sending NewBlockHashes messages about) valid blocks now and random blocks are very unlikely to be valid with a low difficulty value set.   \n\n",
            "Might be due to the orphan block handling code.\n\nIt's alright if you fail test cases of previous assignments for A6"
        ]
    },
    {
        "title": "Running miner",
        "question": "Should we run the miner on all nodes when testing?",
        "other_text": [
            "Yes"
        ]
    },
    {
        "title": "/blockchain/longest-chain",
        "question": "I'm testing my code and the /blockchain/longest-chain endpoint always hangs and I never get an output, any advice on what might be causing this?",
        "other_text": [
            "-- Verify that your implementation of all_blocks_in_longest_chain() is correct.\n(And that miner/network modules are working : by printing logs)\n\n-- Maybe your difficulty is too high\n\n-- Some students faced a similar issue when their genesis block had some random fields. Make sure that the genesis block is deterministic (should be the same across nodes).",
            "Right now my genesis nonce is random and my genesis timestamp is based on the SystemTime of when the genesis block was created, should I change these fields to be constants then?\n\n",
            "Yes they should be constants.",
            "shouldn't the difficulty be the maximum difficulty [255u8;32]?",
            "I think for the genesis block, you want to adjust its difficulty in this assignment in order to change the mining rate"
        ]
    },
    {
        "title": "A6 Debugging",
        "question": "Hello,\n\nI am trying to write a script to test my code for A6.\n\n\n\nMy script is as follows:\n\n#!/bin/bash\n\nunzip -qq szatz.zip -d szatz\ncd szatz/COS-ECE470-fa2022-main\ncargo build\ncd target/debug\necho \"starting nodes\"\n./bitcoin --p2p 127.0.0.1:6000 --api 127.0.0.1:7000 &\nP1=$!\n./bitcoin --p2p 127.0.0.1:6001 --api 127.0.0.1:7001 -c 127.0.0.1:6000 &\nP2=$!\n./bitcoin --p2p 127.0.0.1:6002 --api 127.0.0.1:7002 -c 127.0.0.1:6001 &\nP3=$!\necho \"starting miners\"\ncurl --silent --output /dev/null --show-error --fail http://127.0.0.1:7000/miner/start?lambda=0 &\nP4=$!\necho \"miner 1 started\"\ncurl --silent --output /dev/null --show-error --fail http://127.0.0.1:7001/miner/start?lambda=0 &\nP5=$!\necho \"miner 2 started\"\ncurl --silent --output /dev/null --show-error --fail http://127.0.0.1:7002/miner/start?lambda=0 &\nP6=$!\necho \"miner 3 started\"\necho \"sleeping for 5 min\"\nsleep 300\necho \"finished sleeping\"\nlcA=$(curl http://127.0.0.1:7000/blockchain/longest-chain)\necho \"Node 1 output obtained\"\nlcB=$(curl http://127.0.0.1:7001/blockchain/longest-chain)\necho \"Node 2 output obtained\"\nlcC=$(curl http://127.0.0.1:7002/blockchain/longest-chain)\necho \"Node 3 output obtained\"\necho \"Longest chains:\"\necho $lcA\necho $lcB\necho $lcC\ncd ../../../..\nkill $P1 $P2 $P3 $P4 $P5 $P6\necho \"killed all bg processes\"\nrm -rf szatz\n\n\n\nWhenever I run it, I get the following output:\n\nstarting nodes\nstarting miners\nminer 1 started\nminer 2 started\nminer 3 started\nsleeping for 5 min\nccuucrlu:r l(:2 2()2r2 l)T:h  e(T 2hr2)e  rTeheq ureesqetuqeuedse stUteRedLd  U rUReLRtL ur rerneteturdnu reendre rdeor rre:ro rr5o:0r :5 0500\n0\n0\nthread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Os { code: 48, kind: AddrInUse, message: \"Address already in use\" }', src/main.rs:72:24thread '\nmainnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n' panicked at 'called `Result::unwrap()` on an `Err` value: Os { code: 48, kind: AddrInUse, message: \"Address already in use\" }', src/main.rs:72:24\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\nthread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Os { code: 48, kind: AddrInUse, message: \"Address already in use\" }', src/main.rs:72:24\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n\n\n\n\n\nThere are no other processes running on those addresses, and in the script you can see that the addresses I gave are different. It doesn't seem that the script actually waits 5 minutes after the sleeping for 5 min  output, as it prints the curl errors right after. Does there seem to be anything wrong with my script that might be causing this?",
        "other_text": [
            "The script seems correct.\nTried running this on my code, it works as expected.\n\nCheck if you're able to access http://127.0.0.1:7000/blockchain/longest-chain on your browser? Maybe there's some issue with the api implementation\n\n",
            "dynamic-oit-vapornet100-10-8-5-133:a6-autograder seanzatz$ sudo lsof -i -P -n | grep LISTEN\nremoted      99            root    4u  IPv6 0x70a2028dfcb82947      0t0    TCP [fe80:4::aede:48ff:fe00:1122]:49154 (LISTEN)\nremoted      99            root    5u  IPv6 0x70a2028dfcb83027      0t0    TCP [fe80:4::aede:48ff:fe00:1122]:49155 (LISTEN)\nremoted      99            root    6u  IPv6 0x70a2028dfcb83707      0t0    TCP [fe80:4::aede:48ff:fe00:1122]:49156 (LISTEN)\nremoted      99            root    7u  IPv6 0x70a2028dfcb83de7      0t0    TCP [fe80:4::aede:48ff:fe00:1122]:49157 (LISTEN)\nremoted      99            root    8u  IPv6 0x70a2028dfcb844c7      0t0    TCP [fe80:4::aede:48ff:fe00:1122]:49158 (LISTEN)\nremoted      99            root    9u  IPv6 0x70a2028dfcb84ba7      0t0    TCP [fe80:4::aede:48ff:fe00:1122]:49159 (LISTEN)\nremoted      99            root   10u  IPv6 0x70a2028dfcb85287      0t0    TCP [fe80:4::aede:48ff:fe00:1122]:49160 (LISTEN)\nremoted      99            root   11u  IPv6 0x70a2028dfcb85967      0t0    TCP [fe80:4::aede:48ff:fe00:1122]:49161 (LISTEN)\nControlCe   546        seanzatz   20u  IPv4 0x70a2028dfe02f4af      0t0    TCP *:7000 (LISTEN)\nControlCe   546        seanzatz   21u  IPv6 0x70a2028e004162a7      0t0    TCP *:7000 (LISTEN)\nControlCe   546        seanzatz   22u  IPv4 0x70a2028dfe02e9ff      0t0    TCP *:5000 (LISTEN)\nControlCe   546        seanzatz   23u  IPv6 0x70a2028e0040fb87      0t0    TCP *:5000 (LISTEN)\npostgres    774        seanzatz    7u  IPv6 0x70a2028e08a58267      0t0    TCP [::1]:5432 (LISTEN)\npostgres    774        seanzatz    8u  IPv4 0x70a2028e0a128f5f      0t0    TCP 127.0.0.1:5432 (LISTEN)\nSpotify   16990        seanzatz   26u  IPv4 0x70a2028e236094af      0t0    TCP *:62968 (LISTEN)\nSpotify   16990        seanzatz   49u  IPv4 0x70a2028e1e203a1f      0t0    TCP *:57621 (LISTEN)\nbitcoin   49590        seanzatz    3u  IPv4 0x70a2028e20ed14af      0t0    TCP 127.0.0.1:6000 (LISTEN)\nbitcoin   49590        seanzatz    8u  IPv4 0x70a2028e20ed09ff      0t0    TCP 127.0.0.1:7000 (LISTEN)\nbitcoin   49591        seanzatz    3u  IPv4 0x70a2028e1f5039ff      0t0    TCP 127.0.0.1:6001 (LISTEN)\nbitcoin   49591        seanzatz    8u  IPv4 0x70a2028e0a1279ff      0t0    TCP 127.0.0.1:7001 (LISTEN)\nbitcoin   49592        seanzatz    3u  IPv4 0x70a2028e1e202f6f      0t0    TCP 127.0.0.1:6002 (LISTEN)\nbitcoin   49592        seanzatz    8u  IPv4 0x70a2028e2360ca1f      0t0    TCP 127.0.0.1:7002 (LISTEN)\ndynamic-oit-vapornet100-10-8-5-133:a6-autograder seanzatz$ kill 49590 49591 49592 \ndynamic-oit-vapornet100-10-8-5-133:a6-autograder seanzatz$ sudo lsof -i -P -n | grep LISTEN\nremoted      99            root    4u  IPv6 0x70a2028dfcb82947      0t0    TCP [fe80:4::aede:48ff:fe00:1122]:49154 (LISTEN)\nremoted      99            root    5u  IPv6 0x70a2028dfcb83027      0t0    TCP [fe80:4::aede:48ff:fe00:1122]:49155 (LISTEN)\nremoted      99            root    6u  IPv6 0x70a2028dfcb83707      0t0    TCP [fe80:4::aede:48ff:fe00:1122]:49156 (LISTEN)\nremoted      99            root    7u  IPv6 0x70a2028dfcb83de7      0t0    TCP [fe80:4::aede:48ff:fe00:1122]:49157 (LISTEN)\nremoted      99            root    8u  IPv6 0x70a2028dfcb844c7      0t0    TCP [fe80:4::aede:48ff:fe00:1122]:49158 (LISTEN)\nremoted      99            root    9u  IPv6 0x70a2028dfcb84ba7      0t0    TCP [fe80:4::aede:48ff:fe00:1122]:49159 (LISTEN)\nremoted      99            root   10u  IPv6 0x70a2028dfcb85287      0t0    TCP [fe80:4::aede:48ff:fe00:1122]:49160 (LISTEN)\nremoted      99            root   11u  IPv6 0x70a2028dfcb85967      0t0    TCP [fe80:4::aede:48ff:fe00:1122]:49161 (LISTEN)\nControlCe   546        seanzatz   20u  IPv4 0x70a2028dfe02f4af      0t0    TCP *:7000 (LISTEN)\nControlCe   546        seanzatz   21u  IPv6 0x70a2028e004162a7      0t0    TCP *:7000 (LISTEN)\nControlCe   546        seanzatz   22u  IPv4 0x70a2028dfe02e9ff      0t0    TCP *:5000 (LISTEN)\nControlCe   546        seanzatz   23u  IPv6 0x70a2028e0040fb87      0t0    TCP *:5000 (LISTEN)\n\n\nSeems like there actually were some old processes running using those addresses. Any idea what the processes on port 99 are (the ones with 49154 (LISTEN) after them contain the process id's of my previous tests) ? Seems like they are related to the bitcoin program I ran earlier and I think they may be messing up my testing.\n\n\n\nEdit:\n\nForgot to mention, i get this error when trying to access the endpoint, which is weird because I was able to access it before",
            "Think I figured it out, had to wait a few seconds after starting the workers before sending requests to their apis. Solved by adding additional sleep statements between these steps"
        ]
    },
    {
        "title": "Difficulty",
        "question": "In the assignment it's stated that the code will be ran with lambda = 0. This means that blocks will be mined very quickly, and the chains will rapidly get larger, far outpacing the 10 blocks per minute that was set in the assignment. Should we tune a really low difficulty in order to make it easier to manage?",
        "other_text": [
            "Yes, you should set your difficulty accordingly.\nMight be a good idea to aim for something larger than 10 to be on the safer side ",
            "I'm getting chains that are much much quicker than 10 blocks per minute, even with difficulties of ~10, which I think should be really low difficulty. Is this the result of lambda = 0?\n\n",
            "It's alright as long as you're satisfying the grading requirements.\n(but I think you wouldn't get a very high mining rate with such a very low difficulty)"
        ]
    },
    {
        "title": "A6 Clarifying Questions",
        "question": "Hi, \n\nThank you all for being flexible with my A5 submission. I am now getting caught up on A6. \n\n1. For the PoW validity check, what do we do if it succeeds / fails? Should we add a bool field to the block struct that gets assigned valid/invalid based on this check? Also, I am confused why this check would go in the network worker vs the Miner worker. Isn't the miner the one that cares about difficulty? In general, would you mind explaining the PoW check? \n\n\n\n2. I am confused at what the orphan buffer is and why it is recommended that we use a struct. Wouldn't the orphan buffer simply be Vec<Block>? ",
        "other_text": [
            "1. The block received in the worker would be from another node. That is why you need to check if it is valid by doing the PoW check.\n\n2. It is best to use a hashmap as an orphan block struct, since it makes it easy to look up any block. In particular you can store the mapping parent hash -> block. ",
            "After reading through some ED posts I think it would make more sense to put the check in the insert function, but I am still confused on the behavior. If the blocks hash greater than the difficulty should we simply not insert? \n\n\n\n",
            "No you should not. Because the block is invalid in that case."
        ]
    },
    {
        "title": "Genesis Block hash",
        "question": "Is it required for our genesis block hash to be all zeros, or can it be anything as long as it isnt random?",
        "other_text": [
            "It won't be all zeros"
        ]
    },
    {
        "title": "Large amount of blocks created",
        "question": "Hello,\n\nI am running my code for A6 at lambda 0 and difficulty of  let difficulty: [u8; 32]= [1u8; 32].into(); which is then converted to an H256\n\n\nI think this means the number of blocks produced should be pretty low, but I seem to get around 13 thousand produced per minute and the longest chain is consistent among 3 nodes. \n\nFrom OH i thought that this difficulty value should be good enough to reach 10-20 blocks per minute, but i am still producing a huge number of blocks. \n\n\n\nShould I just lower the value further, or would this risk producing too few blocks on the testing machine for the autograder?",
        "other_text": [
            "Lower the value further to ensure there is less forking"
        ]
    },
    {
        "title": "A5 0/10 Resubmission",
        "question": "Hello, I just saw that I received 0/10 on A5 with the following comment: \"generate_test_worker_and_start() does not take any arguments; otherwise autograder will fail. Giving you a chance to resubmit. Please modify and resubmit asap.\"\n\nI realized this after I completed A6.\n\nShould I update my A6 submission to reflect this update, or will it not be tested in A6?\nAlso, should I revert my A6 code additions when resubmitting A5, or would it be okay to leave them in?\n\nThank you,\n\nAdam",
        "other_text": [
            "Should I update my A6 submission to reflect this update, or will it not be tested in A6?\n\nIt won't be tested in A6\n\nAlso, should I revert my A6 code additions when resubmitting A5, or would it be okay to leave them in?\n\nYes",
            "Could you clarify that 2nd answer? Yes, it would be okay to leave them in?",
            "Sorry, I meant you should revert your A6 additions.\n(to avoid your code failing A5 tests due to orphan handling, etc)",
            "Thanks, I resubmitted!"
        ]
    },
    {
        "title": "Large number of blocks even with low difficulty value",
        "question": "Anybody experience their blockchain generating ~10 thousand blocks per minute even with a really low threshold? I tried checking for duplicates and making sure I'm not inserting invalid blocks but I can't figure out why it is still generating so many",
        "other_text": [
            "Maybe double check that you're setting the difficulty correctly? Make sure you're setting it to the value you want and not mistakenly hashing that value instead.\n\n",
            "Right now I create a u8 array and then use H256:from(), which I don't think hashes it?",
            "yea it doesn't - maybe try to make it all 0s to make sure lowering the difficulty is working?\n\n",
            "I started from the [255u8;32] and went down to [0u8;32], on 0 it doesnt pass any blocks, but [1u8;32] or above and it produces 10 thousand plus blocks.\n\nI was considering altering it between  [0u8;32] and  [1u8;32] but they said that wasn't necessary in OH and I'm worried it might fail the autograder if I go that low. Might be some other issue I guess.\n\nThanks for trying to help me though! :-)\n\n",
            "Ah, this might be your issue. What [1u8;32] means is repeating 1 for each element, eg. [1,1,1,1, ..., 1,1,1]. Effectively, only the first digit matters in terms of comparing hashes to this, so basically any hash has a 1/8 chance of being less than your difficulty, aka a lot of hashes will be valid. Not sure why they said you wouldn't want to alter less than [1u8;32], that doesn't make sense to me\n\n",
            "Ohhhhh omg ok that makes sense. Must have just been a miscommunication on my part, thanks so much for the help!",
            "np gl"
        ]
    },
    {
        "title": "http://127.0.0.1:7000/blockchain/longest-chain output",
        "question": "This behavior occurs after finishing the Programming section of the assignment and doing cargo build / cargo run.\n\nWhen I access the url above, it shows me one hash, likely the genesis block hash, but no other hash gets printed. I've tried different difficulties but not sure if this is happening because my difficulty is too easy (overwhelming forking) or too hard (not enough mining).\n\nIs there a way to get debug outputs to test what's going on?\n\nAlso, should I keep refreshing the url in my browser to see if new hashes get printed? or is that not a valid method?",
        "other_text": [
            "Did you turn the miner on? You have to start the miner and leave it on before checking this url. You can see instructions for that in A4\n\n\n\nSo do cargo run, then turn the miner on, then go to the url",
            "You can add print statements in your code to debug.\nSome things to check:\n\n-- Is the miner mining blocks?\n\n-- Is the genesis block consistent across nodes?\n\n-- If longest chains aren't matching, try printing and tracing the network messages\n\n-- Are your mutex locks being released?\n(Can check by adding a print before and after acquiring a lock)\n\nYou can either use scoping to ensure the lock goes out of scope. Eg:\n\nlet mut tip_hash = {\n\nlet bc = self.blockchain.lock().unwrap();\n\n bc.tip() };\n\n\nOr you can drop the blockchain to release the lock\n\ndrop(bc)\n\n\n"
        ]
    },
    {
        "title": "Longest Chain not matching up",
        "question": "I'm not sure why, but my longest chain for each miner diverges. Initially they will display some differences, but then re-align when blocks are communicated. But after the first 5-10 blocks, the longest chains never re-align. Any suggestions for how to debug?\n\n",
        "other_text": [
            "Might be due to how the nodes communicate, did you put logging statements for when each node sends/receives a certain block & inserts it? ",
            "Were you able to fix this?\n\nMaybe your network is getting jammed with too many messages.\n",
            "Like sending too many GetBlocks request or something like that?",
            "Yes. The discussion in #254 might be helpful."
        ]
    },
    {
        "title": "Sending GetBlock message for orphan blocks",
        "question": "Does it matter if we send GetBlock messages for each individual orphan block as we see it or do we need to send them all together after we're done seeing all the blocks that were input to the Blocks message?",
        "other_text": [
            "You can send it individually if that helps"
        ]
    },
    {
        "title": "Blockchain In Server Not Updating Tip",
        "question": "I've been struggling to debug an issue that I am getting where my \"/blockchain/longest-chain\" call always returns just a hash of the genesis block. However, I have put in print statements that show me that, for example, on a single miner, new blocks are successfully being mined and added to the tip of the chain. Whenever I mine a new block, the all_blocks_in_longest_chain function works properly and another hash is appended (which I have checked with print statements). This is when I call all_blocks_in_longest_chain on my blockchains in miner/mod.rs and miner/worker.rs. However, whenever, I make a call to \"/blockchain/longest-chain\", all I see is a vector of just one hash--the genesis hash. Where is the blockchain in the src/api/mod.rs file being initialized and how would you advise to debug this issue? Has anyone seen this happen?\n\n",
        "other_text": [
            "In main.rs make sure you are using the same blockchain object (aka you are making clones of the shared references to the same object). You are probably mistakenly making multiple blockchain objects so the api is calling longest chain it on a separate (empty) blockchain.\n\n",
            "Got it, that was the issue. Thanks for the help!\n\n",
            "me too",
            "U gotta check the main.rs file to make sure you are not accidentally instantiating extra Blockchains. In particular, check the top of the main.rs file.\n\n"
        ]
    },
    {
        "title": "Longest Chain API",
        "question": "Should the output order be [Genesis, Block1, Block2, Block3...] OR [...Block3, Block2, Block1, Genesis] \n\n\n\n(with hashes for each block)",
        "other_text": [
            "first one\n\nfrom the assignment spec:\n\nIt should output an array of strings in the hex format of block hashes in the longest chain. The order of block hashes should be number-ordered. That is, block 0 (genesis), followed by block 1, block 2, etc. The output should be in JSON format, and here is an example of JSON format:\n\n[\"0000000000000000000000000000000000000000000000000000000000000000\",\"93b6a5b271bf03019da96d49506660dcdcad2376c3119c4cb9c47cb0f27fbbf1\"]"
        ]
    },
    {
        "title": "Length difference",
        "question": "The length difference between my nodes is pretty high. I'm running them right now and the length of the longest chains are 28, 16, 13. \n\nHow do I fix this? I'm not sure which part is problematic.",
        "other_text": [
            "Could be that the hash rate is too high, even if they are consistent before that, if you are mining too fast then naturally the latency between checking the longest chain in one block vs another (ex: just the time it takes you to type out and send the different api requests) could result in that kind of difference\n\n",
            "The hash rate is pretty slow. Around 10-13 blocks/minute.",
            "Might be a locking issue (see #245).\n\nTry to print logs (eg block hashes) after a block is mined, Newblockhashes, getblocks, blocks, etc. and track if other nodes are receiving the mined blocks in time and are inserting correctly.\n\nEnsure it works for simpler settings (eg: one node is mining, two other nodes connected but do not mine/ mine very slowly)"
        ]
    },
    {
        "title": "2 Questions about part 6",
        "question": "Is there some way we are supposed to pause or stop the mining after the 5 mins is up? I just get the longest chain when the IRL timer is up and then ctrl+c the Nodes right now\n\nShould Message types NewBlockHashes and GetBlocks also check for validity of PoW like at least check that the hashes are <= constant_difficulty? I did not modify the NewBlockHashes and GetBlocks Message types at all in this assignment, only Blocks\n\n",
        "other_text": [
            "For 1, I think you are just supposed to get the longest chain while the miners are running.\n\nFor 2, I don't believe you have to do checks in the others, just in Blocks should be fine",
            "You can set a very high lambda to pause the mining"
        ]
    },
    {
        "title": "Precisely adjusting difficulty",
        "question": "Since for grading, it seems that the lambda will be 0, I am just adjusting the difficulty parameter to try to meet the grading requirements because it seems that when lambda is able to be greater than 0, my code is working fine. However, I want to be more precise than having a 32-sized array of u8's. \n\nI was wondering if one could have more precision with the first bytes of Rust to adjust the difficulty at a more detailed level? ",
        "other_text": [
            "You can set different values for different portions of the 32-sized array to precisely control the difficulty. ",
            "Is it possible to go into the first byte and adjust the value at the bit-level?",
            "I'm not sure. But you don't have to. Just setting different values for the u8 ints in the array worked for me.\n\n",
            "You can do hex!(\"ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff\").into()\n\nfor example to adjust it at the bit-level. Make sure to use hex_literal::hex;",
            "Thanks! For some reason here I'm encountering a \n\nproc macro not expanded: Cannot create expander ... (mach-o file, but is an incompatible architecture (have \\'x86_64\\', need \\'arm64e\\')), \\'/usr/local/lib/libhex_literal-c1a4aaadac546f0f.dylib\\' (no such file), \\'/usr/lib/libhex_literal-c1a4aaadac546f0f.dylib\\' (no such file)\" } })\n\nerror. Do you know why this might be happening?",
            "hmm, are you getting this error just in vscode or also when you're compiling? Im guessing you have a m1/m2 mac and theres some mistmatch in the rust and vscode architecture. If not then I have no idea\n\n"
        ]
    },
    {
        "title": "3 miner issue",
        "question": "When I try this out with 2 miners, it seems the code is working; however, adding the 3rd miner causes an issue. Is there any suspicion as to why this might be the case?",
        "other_text": [
            "What issue are you facing?",
            "The first and second miner have similar hashes in the longest chain output, but the third one is completely different (other than the genesis block)",
            "After a while, however, the first and second diverge as well",
            "Are the nodes receiving network messages in time? (print logs and check)\n\nDoes it work when you have 3 miners and only one of them is mining? (set lambda=very high value for other two)\n\nPossibly some bug in longest_chain or insert functions?",
            "How does one go about printing logs?",
            "println statements should work",
            "I believe they are, however, sometimes the arguments are empty. Is this a cause for concern?\n\nWith 3 miners and only one mining, things seem to be working -- the prefix of the first miner is the same as the prefix of the other 2, with the first one being the longest",
            "Yes empty messages can jam your network.\n\nAdd conditions to send messages only when non-empty",
            "Having this same exact issue. Ive adjusted my messages to send non empty messages and checked both insert and tip functions. And logically if I passed previous tests why would the code just stop working?",
            "Network delays/jamming can be caused by multiple reasons, maybe you're setting the difficulty too easy?\n\nThe third node is receiving the blocks mined by the other two, yes? ",
            "Yes",
            "Are you starting the third node after some delay?\nCould be possible that it would take some time to get all the longest chain blocks through your orphan handling.\n\nHow many blocks/min are you mining? "
        ]
    },
    {
        "title": "Forking and length difference even with low mining rate",
        "question": "My mining rate is ~10 blocks/minute. \n\nHowever, I'm seeing a lot of forking and length differences. At the end of the 5 minutes, my chains were around 50, 30, and 20 and had different blocks after the first 10-15 blocks.\n\nAny advice?",
        "other_text": [
            "Are the other nodes receiving the blocks/messages and correctly inserting them? \nYou could try #247 if it speeds things up\n\nDoes it work when only one node is mining? (If not some issue in the network worker insertion)",
            "It works slowly when it's just one node. But the blocks are transmitted and inserted.",
            "Around ~5 minutes I have 14, 16, and 14 blocks (mining on node 2). The longest chain is identical across the nodes.",
            "One potential issue - are you sending NewBlockHashes only after a new block is actually inserted into your blockchain? If node A sends it after receiving a block that ends up in its orphan buffer, then a peer will request that block from node A with a GetBlocks message that node A will ignore, since that block does not yet exist in its chain, causing the chains to diverge.\n\n",
            "I first insert all the blocks in the Blocks message in my chain. Then for each block, I recursively check for orphans that can now be added to the chain and insert them. I maintain a list of the blocks I inserted and at the end send the NewBlocksMessage.",
            "The problem was empty NewBlockHashes messages.",
            "\ud83d\udc4d\ud83d\udc4d"
        ]
    },
    {
        "title": "Zoom?",
        "question": "Is there a TA who can Zoom briefly?\n\n",
        "other_text": [
            "I can meet briefly now: https://princeton.zoom.us/j/92002112501",
            "I ran my code with \"cargo run...\" and there is no output from my println statements. Thoughts?",
            "Should be able to print. Not sure\n\nTry passing -vv flag?",
            "OK I'm seeing them now. Lambda was too big I think."
        ]
    },
    {
        "title": "Extension for Assignment 6",
        "question": "Hi all, \n\nI was hoping to get a short extension on this week assignment just until the end of the day. I ran into some personal difficulties. I would really appreciate your kindness in this matter.\n\nBest,\n\nTejas",
        "other_text": [
            "You can submit by 11:59pm today."
        ]
    },
    {
        "title": "Issue viewing longest chain for first miner",
        "question": "When trying to check the longest chain at http://127.0.0.1:7000/blockchain/longest-chain, it says \"Access to 127.0.0.1 was denied\" even though my terminal says \"INFO - API server listening at 127.0.0.1:7000\", so I am confused why it is saying access is denied. Did anyone run into this issue?\n\n",
        "other_text": [
            "Yeah, I ran into this. Just open it in another browser like Safari\n\n",
            "I'm not sure. Tried googling this? There are some fixes suggested"
        ]
    },
    {
        "title": "GetTransactions(Vec) Message",
        "question": "For GetTransactions(Vec) Message, does a network worker have to return transactions if they are already included into the blockchain? \n\nDoes a network worker have to return transactions if they are already included into one of the orphan blocks? \n\nIf yes, would this increase the number of duplicate transactions in the blockchain?",
        "other_text": [
            "For GetTransactions(Vec) Message, does a network worker have to return transactions if they are already included into the blockchain? \n\nDoes a network worker have to return transactions if they are already included into one of the orphan blocks?\n\nThis is not necessary. You can implement returning transactions only when they are present in mempool.",
            "Thank you very much Viraj.\n\n"
        ]
    },
    {
        "title": "Additional Extension Due to Hospitalization",
        "question": "Hi, sorry, but I was injured playing squash and am in the hospital. I have finished the assignment but am not in front of my computer to submit it. I was hoping I could submit it tomorrow. Apologies for the request. - Tejas",
        "other_text": [
            "Sure."
        ]
    },
    {
        "title": "NewTransactionHashes,GetTransactions,Transactions",
        "question": "The assignment guidelines say the implementation is similar to the block-related messages, but I am unclear about where we should be checking the transactions. We are given a vector of hashes, so are we looping through the transactions in every block in the blockchain to detect if the hash exists?\n\nAlso, in Transactions(), are we adding the signed transaction into the mempool?",
        "other_text": [
            "We are given a vector of hashes, so are we looping through the transactions in every block in the blockchain to detect if the hash exists?\n\nNo, only checking the mempool is enough.\n\nAlso, in Transactions(), are we adding the signed transaction into the mempool?\n\nYes",
            "wait I thought Message::Blocks gives us a vector of blocks which contains a vector of transactions, so we need to loop through every transaction within each block to validate all transactions are valid? \n\nAlso, do we need to add the transactions of the orphan blocks to the mempool since they are valid transactions and also not included in the blockchain yet?\n\n",
            "wait I thought Message::Blocks gives us a vector of blocks which contains a vector of transactions, so we need to loop through every transaction within each block to validate all transactions are valid? \n\nYes you do need to do this to check the validity of a block. I was talking about when you get NewTransactionHashes message.\n\nAlso, do we need to add the transactions of the orphan blocks to the mempool since they are valid transactions and also not included in the blockchain yet?\n\nYou can choose to do that, but we are not making it compulsory in our project."
        ]
    },
    {
        "title": "Mempool structure",
        "question": "Where should the Mempool structure exist in the network worker.rs file? If it is in the Worker struct, then does that mean that every node maintains its own Mempool struct? Do we also need to add it to the Miner struct then? Finally, would this mean that we instantiate a new instance of the Mempool struct in the main.rs file, and pass it to the Worker and Miner like we do with Blockchain?",
        "other_text": [
            "Yes, Mempool should be handled exactly like the Blockchain struct. That is, instantiate one mempool in main.rs and then pass it using Arc and Mutex to worker and miner. You can either define your mempool struct in blockchain's mod.rs file, or you can instantiate it directly as a new hashmap in main.rs.",
            "When you say worker and miner, does this mean the miner struct and the worker struct defined in miner/worker.rs, or do you just mean the network worker and the miner struct?\n\nI would think it is the second interpretation since it seems that no transaction logic should be handled in the miner/worker.rs case.",
            "I mean the network worker and the miner struct.\n\n"
        ]
    },
    {
        "title": "Transactions order in the block",
        "question": "In my implementation of the block content I use a Vec of SignedTransaction as recommended in the A3 specification. Hence, the order of transactions is preserved inside of the block content. \n\nIs it required to sort transactions by the transaction timestamp before adding them to the vector?\n\n",
        "other_text": [
            "No, its not required. You can insert them in the order in which you received.",
            "Thank you.\n\n"
        ]
    },
    {
        "title": "UTXO",
        "question": "How does UTXO prevent double spending? Like how do you check for it.",
        "other_text": [
            "In A8 you will store the UTXOs (unspent transaction outputs) in the State. When you execute any block, for all txs in the block you will remove all the tx inputs from State, and add tx outputs.\n\nWhen validating a transaction, you need to check if the inputs to the tx are not spent yet: that is, the inputs to the tx are present in the State.\nIf they aren't present in State, it means that UTXO has already been spent"
        ]
    },
    {
        "title": "Additional tests",
        "question": "Are we allowed to keep additional tests uncommented in our code from now on?",
        "other_text": [
            "Sure"
        ]
    },
    {
        "title": "Transaction generator",
        "question": "In which file are we creating the transaction generator? Also, how do we start new threads? Is there something in the assignment that is similar to how we should be doing it?\n\nThanks\n\n",
        "other_text": [
            "You can see miner/mod.rs and miner/worker.rs to see how new threads are started to generate blocks (you just have to do something similar for generating transactions instead of blocks). \n\nAlso see the \"/miner/start\" code in api/mod.rs to see how to start this generator (again, you just have to do something similar for \"/tx-generator/start\").",
            "In the api/mod.rs, instead of calling miner.start (theta), should we create a new handle in miner/mod for sending signal to the transaction generator thread, or should we use the same handle that sends signal to the miner thread?\n\n",
            "Yes you should create a new handle for the generator",
            "Just to clarify: are we reimplementing the Handle struct in miner/mod.rs for transactions or are we reusing the same Handle and importing it as a TransactionHandle (use crate::miner::Handle as TransactionHandle) and then adding the transaction generator of that type to the Server?",
            "You can use the same Handle structure for the tx generator too. I meant you cannot use the same handle instance for both miner and tx generator",
            "Since both the miner and the transaction generator use the Handle struct, does that mean transactions are generated in the miner_loop? Confused on where we should be creating these transactions.",
            "No. You need to make a new instance of handle for the tx generator..\n\n\n(The tx generator will be a separate struct. One way to implement it is to make txgen/mod.rs and/or txgen/worker.rs and implement this similar to miner)"
        ]
    },
    {
        "title": "Verify method from transactions",
        "question": "Can we use the verify method we wrote in types/transactions to check for the signature validity? Currently, it's not implemented for the SignedTransaction struct so wanted to make sure nothing will break if I move it.",
        "other_text": [
            "Yes you can use the verify method. If you think something might break, you can reimplement it for SignedTransaction separately."
        ]
    },
    {
        "title": "order of transactions",
        "question": "Mempool will also be used by miner to include transactions in the blocks being mined. The miner will add transactions in the mempool to the block till it reaches the block size limit (upper limit).\n\nDoes the order in which transactions are pulled from the mempool matter?",
        "other_text": [
            "No. Any order is fine."
        ]
    },
    {
        "title": "Broadcasting new transaction hashes by Transaction generator",
        "question": "After Transaction generator generates a new transaction, it broadcasts the hash to the network.\n\nWould it be ok if transactions are broadcasted in small batches (a vector of 10-20 transactions) at a time, instead of one-by-one?\n\n",
        "other_text": [
            "Should be fine",
            "Thank you!"
        ]
    },
    {
        "title": "account nonce in Account-based model",
        "question": "the Transaction structure we used in previous assignment contains sender, receiver, and value. But the account-based structure contains receiver, value, and account-nonce?\n\naccount-nonce means the number of transactions sent through the sender's address right? if so, why aren't we including the sender's address?\n\n",
        "other_text": [
            "You can obtain the sender's address from the public key in SignedTransaction",
            "gotcha. what about the meaning of account nonce?",
            "Yes account nonce is a transaction counter in each account. It prevents replay attacks where a transaction (eg. sending 10 coins from A to B) can be replayed by B over and over to continually drain A's balance."
        ]
    },
    {
        "title": "transaction thread",
        "question": "I am confused about the steps for the transaction generator and what parts of generating a block we should copy and modify. Should the transaction generator be implemented within the impl Context but in a separate function from the miner loop in mod.rs?",
        "other_text": [
            "The transaction generator will be a different object, separate from the miner.\n\nYou can implement it similar to the miner, but generate transactions instead of blocks; insert into mempool; and broadcast NewTransactionHashes when a new tx is generated.",
            "broadcasting seems to take either server (as in network/worker) or network (as in api/mod) to broadcast the msg. but we don't seem to have either in miner/mod - I tried to use control chain to broadcast but it doesn't seem to work.... this's my code below:\n\nself.control_chan.send(Message::NewTransactionHashes(vec![signed_transaction.hash()])).unwrap();\n\n",
            "Yes you would need to use the ServerHandle (like in miner/worker.rs). You can use this as an argument to your tx generator and do server.broadcast",
            "Do we need to make any changes to the pub fn new(blockchain: &Arc<Mutex<Blockchain>>, mempool: &Arc<Mutex<Mempool>>) -> (Context, Handle, Receiver<Block>) function in miner/mod.rs? I am confused about how to initialize the transaction generator within that file. Are we allowed to add to the returns?",
            "No you shouldn't modify the miner structure. You need to implement a similar structure for tx generator. ( #268 )\n",
            "This seems incorrect. The miner should be able to pull transactions out of the mempool to insert into blocks. Thus when creating the miner, we need to pass it the mempool.",
            "That's right.\nAnon is already passing the mempool to their new function ",
            "Ok, sounds good. Just wanted to make sure."
        ]
    },
    {
        "title": "get from transaction hashes to transaction",
        "question": "For Message::NewTransactionHashes, we are given some transaction hashes and are asked to check the validity of transactions right?\n\nIf we are given block hashes we can just use the hash map to get the block. But we never created a hash map for transaction hashes but instead have a bunch of blocks which contains a vector of signedtransactions as their contents.\n\nI'm confused as to how we can get from transaction_hashes to Transactions? Thanks!\n\n",
        "other_text": [
            "For Message::NewTransactionHashes, we are given some transaction hashes and are asked to check the validity of transactions right?\n\nNo, Message::NewTransactionHashes should be implemented similar to Message::NewBlockHashes : If tx does not exist in the mempool, you need to ask for it using GetTransactions.\n\nIf we are given block hashes we can just use the hash map to get the block. But we never created a hash map for transaction hashes\n\nYou need to implement a Mempool, similar to the Blockchain struct to store the tx hashes and the SignedTransactions.",
            "got it, the mempool should also be included in the worker struct right since the miner needs to work with it in other functions as well?\n\n",
            "Correct, it should be passed to the miner as well as the network worker."
        ]
    },
    {
        "title": "Transaction generator - theta",
        "question": "For the miner, parameter lambda represents an interval between block generation in microseconds.\n\nI am wondering if theta=100  also means that an interval between transaction generation is equal to 100 microseconds. Can we apply a multiplier to reduce the speed of the transaction generations? For instance, let interval = time::Duration::from_micros(theta *1000) ?\n\n\n\n",
        "other_text": [
            "I am wondering if theta=100 also means that an interval between transaction generation is equal to 100 microseconds.\n\nNo we haven't defined what theta should be\n\nCan we apply a multiplier to reduce the speed of the transaction generations? For instance, let interval = time::Duration::from_micros(theta *1000) ?\n\nYes, as long as your transaction throughput satisfies the grading criteria",
            "Great, thank you Ashwin."
        ]
    },
    {
        "title": "type conversion for public key",
        "question": "Should the signer's public key be the data type of Address ([u8;20]) or [u8]?\n\n\n\nIf it's Address, I'm wondering how we can convert address to [u8]. I tried try_into().unwrap() but doesn't seem to work.",
        "other_text": [
            "Public key will be of type Vec<u8> (as implemented in Part1).\nYou can get the sender's address using Address::from_public_key_bytes"
        ]
    },
    {
        "title": "Double spend checks for account-based model",
        "question": "The only way to check balance and current nonce I can think of is to add these two things into the Address struct so we always get the update, but this requires us to change the Address struct.... is this is fine, or is there some easier way to do this?",
        "other_text": [
            "You don't need to implement double spend checks in A7.\n\n(You will implement this in A8, when you implement State - See A8 instructions for more details)"
        ]
    },
    {
        "title": "Diverge longest chain",
        "question": "Hi,\n\nWhen I finished Assignment 6, my longest chain are exactly the same every time when I run 3 nodes and mine. However, after I implement Assignment 7 with mempool, my longest chain start to diverge. I believe I did not change anything with the previous code, except add extra conditions for transactions. Do you have any idea what could cause this divergence to happen?\n\nOne more thing: if I change the difficulty to be slightly easy, then this diverge will not come, even though its longest chain length varies a lot, like 59, 48, 44.",
        "other_text": [
            "You can put print statements within the new code you added to see if a node is getting stuck somewhere (maybe waiting for a blockchain.lock() to be released or something).\n\nAlso start with just two nodes and one of them mining, would help you better in debugging.",
            "I see. Does it mean we shouldn't have a node getting stuck (like waiting for a blockchain.lock() to be released?). It looks like when one of my nodes mined a new block, it get some time to receive and inserted in the blockchain in other nodes, which caused the divergence because the other node might be mined and inserted their block before receiving the blocks from other nodes. ",
            "Yes ideally you shouldn't have a node stuck waiting to acquire a lock.\nThe discussion in #245 might be useful.\n\nThe delay could also be because you are sending too many messages, and the network is getting jammed"
        ]
    },
    {
        "title": "My NewTransactionHashes Logic",
        "question": "This is my newtransactionhashes, w 2 questions:\n\n1) the following error message occured after I moved mempool from a struct in worker to a struct in blockchain mod.rs. Not sure why I can't have a temproary value in this case, and also how to fix it.\n\ntemporary value dropped while borrowed\nconsider using a `let` binding to create a longer lived value.\n\n2) I'm confused about the logic of this implementation since we retrieve the corresponding transaction of the hashes from the mempool first (assuming hashes are in the mempool already), and then we check if they are in the mempool, and if not add them to the mempool. seems a little chaotic....\n\nappreciate some insights!!\n\n\n\n",
        "other_text": [
            "2) NewTransactionHashes is similar to NewBlockhashes -- the network worker receives a hash of tx from another node; If this hash is not present in mempool, you ask for it using GetTransactions.\nOtherwise, you can ignore the tx.\n\nwe retrieve the corresponding transaction of the hashes from the mempool first (assuming hashes are in the mempool already)\n\nYou don't need to retrieve the tx when you receive this message. The tx signature/address checks would be done when you receive the transaction: i.e, in the Transactions message.\n\n1) Where are you facing this error?\nYou are passing the mempool as an argument in new() right?\n",
            "still the same problem after I moved it to the Transactions message. \n\nI mean I implemented new() separately for mempool instead of passing the mempool as an argument to the blockchain.new() function. Does it matter? Thanks!\n\n",
            "btw I'm facing the error on the line that is red",
            "Sorry I meant that Arc<Mutex<Mempool>> should be passed to new functions of network worker and miner context.\n\n\n\n"
        ]
    },
    {
        "title": "Clarifications on Mempool and Network Messages",
        "question": "I wanted to clarify some concepts regarding A7\n\n1)  The mempool is similar to the Blockchain struct as in every node's miner/worker will have access to it (miner's mod.rs and worker.rs and network's worker.rs), or can be included in blockchain struct? This mempool will be populated concurrently with generating new blocks in miner/mod.rs in its own loop?\n\n2) We know if a SignedTransaction is valid by calling our verify() function by passing in the transaction, public key, and signature as params?\n\n3) NewTransactionHashes is to check if a node's mempool has a transaction, then to request if it doesn't? GetTransactions returns the hashes from its own mempool hashmap? Transactions adds to its own hashmap if the signature is valid? But we don't have to worry about orphan signatures or anything in this case because there is no \"parent/child\" concept?\n\n4) We have to edit our miner loop for blocks to include transactions and edit our Message::Blocks from last week to check each block transaction?\n\nThank you for your help!",
        "other_text": [
            "1) Yes, mempool can be implemented similar to Blockchain.\nThe mempool will be populated by txs generated by a tx generator (which you can implement similar to the miner loop), or by the network worker.\n\n2) Correct\n\n3) Correct\n\n4) Correct\n\n"
        ]
    },
    {
        "title": "Message::Transactions Logic",
        "question": "Since Message::Transactions is similar to Message::Blocks,\n\nin Message::Blocks, we add the block and its children in the orphan buffer to the blockchain if the blockchain does not contain the block, and add the block to the orphan buffer if the blockchain contains the block.\n\nSince there is no orphan buffer structure required for Message::Transactions, the logic here would be to add the transaction to the mempool if the mempool doesn't contain the transaction, and disgard the transaction if the mempool already contains the transaction?\n\nIs this correct? something feels wrong here hmmm\n\n",
        "other_text": [
            "Correct.\n\nYou would also need to add the necessary checks before adding to the mempool"
        ]
    },
    {
        "title": "Account check",
        "question": "The assignment says:\n\n\"In account based model, check if the public key matches the owner's address of the withdrawing account\"\n\nBit confused what we are checking here, I know that we can get the sender address using the public key, but I am not sure what to compare it against?\n\nWe are only given the one public key and no other information on the sender so far, so I can't figure out how to check the validity of the public key or the address we can derive from it.\n\nIs this just for the next assignment?",
        "other_text": [
            "Yes, you can implement this check once you have the accounts in State in A8.\n\nIn A7, you can use random transactions since you haven't implemented the State (ledger) yet.\n\n"
        ]
    },
    {
        "title": "Confusion with public and private key",
        "question": "I'm a bit confused about how the public and private key works. My understanding is that each node has it's own private key and all the nodes share a public key. For this reason, I statically define a public key and randomly generate a private key \"seed\" in the main method. Then I create a Ed25519KeyPair using from_seed_and_public_key. Unfortunately this doesn't work since the result returns and error. Is this way of doing it correct? if not, what about this logic is wrong?\n\nAlso, I just randomly defined a public key...is this correct or is the program given a standard public key?\n\n",
        "other_text": [
            "Each node has a set of (private_key, public_key)s under its control.\nThe sender can sign an object using their private key; and other nodes can verify the signature using the sender's public key (which is known publicly).\n\nYou can use key = key_pair::random() to generate the key pairs. \nkey.public_key() would give you the public key."
        ]
    },
    {
        "title": "UTXO",
        "question": "Hey wanted to know what was meant by are transactions signed correctly in 7. Because logically I was thinking how is it effective to use the public key in the signed transaction struct as an attacker could just use their own key pairs to sign transactions to themselves. So know im thinking before that in assignment 8 you need to check if the public key used in assignment struct is equal to the public key used for the input (previously an output).\n\n\n\nAm i right? Can the link be explained?",
        "other_text": [
            "So know im thinking before that in assignment 8 you need to check if the public key used in assignment struct is equal to the public key used for the input (previously an output).\n\nCorrect. \n\nYou should check that the recipient address in input UTXO matches the public key of the signer. And also that the signature was produced by the same public key holder"
        ]
    },
    {
        "title": "Debugging A6 Grader Output",
        "question": "I think for A6 I got a couple points off because of \"longest chain does not have common prefix\" but got the other two criteria correct, and was trying to debug it on my own, but wasn't running into this issue whenever I ran the miner. What is a possible place/cause where I can look to debug this? Not sure why it happened with the grader but not on my personal test runs. \n\nIf I don't fix this, will it affect my A7 grade as well since I didn't realize my implementation for last week wasn't working until now. \n\nThank you for your help!",
        "other_text": [
            "Can you attend mine or Viraj's office hours?\nWe can show you the autograder output for your code, and we can try to fix the issue.\n\nI think this may not affect A7, since the grading criteria is different but it's better to fix it to avoid losing points on A7 too.",
            "Not sure if this was a common mistake for students, but I think we found that the issue was because we had set the difficulty to be the easiest, continuing from previous assignments and not changed it. Given that it isn't a logic error, is it possible we can get points back for this if we resubmit with the correct difficulty? It's ok if not because the assignment had mentioned to select a harder difficulty.",
            "Sorry we won't be able to increase the grade. Setting a reasonable difficulty to get it working was one of the main tasks of the assignment. "
        ]
    },
    {
        "title": "mempool in api",
        "question": "Similar to Blockchain, you need the thread-safe wrapper Arc<Mutex<>> (The mempool will be used by the api, miner, and network worker).\n\nWhere in api/mod.rs should we need to use the mempool? From my understanding /blockchain/longest-chain-tx takes the transactions from the blocks in the blockchain.\n\n",
        "other_text": [
            "Yes you don't use it in the api. Sorry for the typo! "
        ]
    },
    {
        "title": "Broadcast via server or sending to the worker",
        "question": "I want to broadcast the hash to the network. If I pass serverhandle as an argument, how do I initialize it (as shown above)? also not sure if creating a new server in the start function is right.",
        "other_text": [
            "No you shouldn't create a new server in the start function.\n\nYou can implement similar to how the serverhandle was used in miner/worker.rs\n\n(You could also have a worker struct for tx gen that takes care of the server.broadcast, similar to the miner implementation)"
        ]
    },
    {
        "title": "Double check section",
        "question": "When I run my code by following the \"Double check\" section in the assignment specs, the blockchains diverge. However, if i test it directly on vs code using cargo run -- -vvv  for the 3 processes, the blockchain does not diverge. What could be a potential reason for this? \n\n\n\nFor example, instead of ./bitcoin --p2p 127.0.0.1:6000 --api 127.0.0.1:7000, I used cargo run -- -vvv --p2p 127.0.0.1:6000 --api 127.0.0.1:7000 (similarly for the other 2 commands)\n\n",
        "other_text": [
            "Did you run cargo build before you ran ./bitcoin ... ? ",
            "I did after I downloaded the .zip file ",
            "Not sure right now, if all parameters (like lambda, theta, etc.) are the same, you should get the same output."
        ]
    },
    {
        "title": "STATE",
        "question": "Hi I have a few questions concerning the state. Does the network worker need its own state as the only way to check if there is double spending when receiving a transaction message is to have a state that isn't connected to a block. SO when receiving transaction messages does that mean we don't check that it is in a state before adding it to the memPool.",
        "other_text": [
            "You do not have to check double spending on a transaction level but on a block level. Transactions are only valid when you add them to a block, so you just need to check if the transactions in the block you are currently mining are compatible with the parent block's state.",
            "Okay thanks. What about the check if the public key(s) matches the owner(s)'s address of these inputs. Is this transaction level or block level. Ive applied it transaction level\n\n",
            "This is transaction level.",
            "Thank you. One last question is where do I add to the state and remove from it",
            "You update the State map every time you insert a block into the blockchain. Not sure why you would need to remove anything.",
            "I guess they're talking about removing the inputs of txs from State in the UTXO model",
            "Yes. Is this in the miner loop too? And how do we account for orphan blocks that have been in the buffer.",
            "This would happen both in worker and miner when you are adding a block to the blockchain.",
            "When im updating the state do i get the previous state from the previous block? And do i add initial coin offering to the genesis block? Sorry for the amount of questions. IM just abit lost.\n\nAnd Just adding to that. WHen it says remove those inputs, does it mean remove the previous transaction and add the current transactions ?",
            "Yes, you get previous state from the previous block. ICO is added to the genesis block (it would be the state corresponding to genesis block).\n\nTo update the state, you would start with the parent block's state, and then remove the UTXO's whose (transaction hash, index) is getting used by a transaction in the current block. Then you would add the current transactions like you said."
        ]
    },
    {
        "title": "Adding mempool to block",
        "question": "On the assignment specs for part 7, it says \"Mempool will also be used by miner to include transactions in the blocks being mined. The miner will add transactions in the mempool to the block till it reaches the block size limit (upper limit).\"\n\n\n\nDoes this mean that when we insert SignedTransactions to the mempool, we need to insert it into our Blockchain representation/struct as well?\n\n",
        "other_text": [
            "You need to insert transactions from the mempool into the block you are mining in /miner/mod.rs. \n\nYou don't need to insert transactions directly into the blockchain in /network/worker.rs if that is what you are asking."
        ]
    },
    {
        "title": "Corner case with removing from mempool",
        "question": "Would we ever have to deal with the corner case that we are processing a block in Message::Blocks, have validated it, and are removing its transactions from our local mempool that the specific transaction doesn't exist in our mempool? Or worse, we only remove the ones that exists and we later get a message to add a tx to our mempool that has already been added into the blockchain by a previous block?",
        "other_text": [
            "With a sufficiently low mining rate you can assume that this won't occur"
        ]
    },
    {
        "title": "How Do We Handle Duplicate Transactions?",
        "question": "If we remove transactions from the mempool then how do we prevent duplicate transactions?",
        "other_text": [
            "The double spend checks (to be implemented with State in A8) will prevent it\n\n(In account based model, account nonce won't match; In UTXO model the inputs to the duplicate tx wouldn't be in the state anymore)\n\n",
            "I'm having trouble with duplicate transactions. Is it possible to implement double spend checks in A7? Or is there another way to limit the number of duplicate transactions since the assignment specs say that double spend checks won't be tested in A7.",
            "Are you removing txs from the mempool when you're inserting a block into the blockchain?\n\nDo you face similar issues when you have a low mining and tx generation rate?\n\n",
            "When receiving a block, could we simply drop the block if it contains tx hash(s) that are not in the tx pool?",
            "Please ignore previous answer.\n\nYou can include the block if it contains tx hash(s) that are not in the tx pool; as long as the transactions are valid.\n\n",
            "Thanks! I am also having this issue. Since the miner starts with lambda=0, it looks up the mempool (when mining) pretty frequently which might block the worker from removing transactions when inserting a new block.",
            "You are releasing the lock immediately after accessing the mempool right?\n\n(Either using scoping or by drop() : #245 )\n\nI don't know if this works, but maybe remove the txs from mempool before inserting the block?",
            "Solved the problem. Reducing critical sections worked. Thanks!"
        ]
    },
    {
        "title": "Difficulty and cargo tests",
        "question": "I think based on A6, we set our difficulty using something like hex!(\"00000effffffffffffffffffffffffffffffffffffffffffffffffffffffffff\").into();\n\nBut this makes it so the cargo test times out at 60 seconds. I am assuming based on this:\n\n\n\nthis is ok? The tests still pass at easiest difficulty.\n\n",
        "other_text": [
            "Yes you don't need to pass previous tests.",
            "With the easiest difficulty, I think I mined ~10,000 blocks and transactions are successfully passing to other nodes with gossip protocol, but with this new difficulty, my miner can't seem to mine a single block even after 2-3 minutes, what could be the issue? \n\nGenesis: \n\nMiner loop difficulty check:\n\n",
            "You can increase the difficulty (make it easier) so that it mines 10-20 blocks per minute on your machine (mining rate depends on your machine) \nThis was just an example of a reasonable difficulty that passed our tests on our machine. \n\n(you should be fine if it isn't mining thousands of blocks, txs - then high chance your network may get jammed) "
        ]
    },
    {
        "title": "Checking block transactions",
        "question": "Hello!\n\nThe assignment specs say \"When receiving and processing a block, also check transactions inside it.\"\n\n\nI was wondering where this check would be? I am a bit confused because in #262 it appears that we checking just the mempool is enough (I suppose in Message::Transactions?) but in #176 we are checking the transaction within an entire block?",
        "other_text": [
            "When the network worker receives a block (in Message::Blocks), for all transactions in the block you need to check that the signature is valid, else ignore the block\n\n(#262 was about inserting a tx_hash into the mempool. You don't need to check if this tx is present in a block in the blockchain. Checking the mempool is enough)",
            "Why don't we need to check if transactions are  in the blockchain as well as the mempool for Message::NewTransactionHashes? Isn't there otherwise risk of inserting redundant transactions into our blockchains?",
            "This would actually be solved by the State/ledger you will implement in A8.\n\nA redundant transaction would be incompatible with the current State of the blockchain\n\n",
            "For GetTransactions and Transactions do we also only need to check the mempool? Wouldn't it make sense to see if we have the transaction somewhere in our blockchain when we receive a GetTransactions message? ",
            "For GetTransactions and Transactions do we also only need to check the mempool?\n\nYes.\n\nIf the tx is already in the blockchain, the peer may receive the block with the tx from you. (If a tx in a received block is valid but not in the mempool, you can still add the block to the blockchain)\n\n"
        ]
    },
    {
        "title": "Checking state in miner",
        "question": "Ive updated state in the miner using the parent blocks states. Why do we need to do this in the miner/worker as it is the same block that is passed, or even in the network/worker? And also what is the ICO? Do I add it to the genesis block directly?",
        "other_text": [
            "Ive updated state in the miner using the parent blocks states. Why do we need to do this in the miner/worker\n\nDidn't fully understand your question. But in the miner you check the validity of transactions based on the parent's current state. The state is then updated whenever you insert a block into the blockchain.\n\nAnd also what is the ICO? Do I add it to the genesis block directly?\n\nICO - initial coin offering sets up the initial state (state of the genesis block). \nYes you can add this in the genesis block. (Make sure that all nodes start with the same initial state)",
            "Thanks. I was just asking if any other updates are needed in miner/worker or network/worker since it is the same block being broadcast.",
            "Yes, once you have updated the state you need to update the mempool so that all txs are valid wrt the new state\n\nTransaction Mempool update\n\nAfter implementing the state transition, ensure that the transactions in the mempool are valid with respect to the new state; this is necessary since some transactions may classify as double-spends after the state update, and you may need to remove those transactions",
            "Thank you soo much. One last question? How do we generate an address for each account/node.",
            "You can set up accounts in the genesis.\nTo make them deterministic, you can use for eg: Ed25519KeyPair::from_seed_unchecked(&[seed; 32]).unwrap() with a fixed seed, or Ed25519KeyPair::from_pkcs8 with some pre-stored bytes.\n\nTo use these in the tx generator, one idea is to assign these deterministic private keys according to the IP port in main.rs (we will be using 127.0.0.1:6000, 127.0.0.1:6001, 127.0.0.1:6002 in the grading).\n\n\n\nYou can also generate new key pairs within the tx gen (and add it to the list of keys controlled by the tx gen). When this new public key receives an amount, it should be added to the State\n\n",
            "Wouldn't it make more sense for the server to hold the key. That way it is deterministically chosen by  the sockets? And when new people join we can get their keys.",
            "Yeah you can do this too. But make sure that in the genesis state (ICO), one of the accounts has a positive balance; and this account must be controlled by one of the nodes.\n\nYou also might need to add more network messages to broadcast new keys in this case? (PS: For the project, we will only be testing using three nodes which use the given ports)",
            "I'm assuming this question is related to A8",
            "Yes"
        ]
    },
    {
        "title": "\"/blockchain/longest-chain-tx\" timing out",
        "question": "Whenever I call this api method (after the miner has already been started), this call always times out. Do you know what could be a possible cause for this issue?",
        "other_text": [
            "Another thing that I have found can cause issues is if your difficulty is too low! I had an issue where my blocks would generate fine without the transactions, but with the transactions they'd take really long time. I found that by increasing the difficulty number (making it easier to mine blocks) I was able to resolve the issue. \n\n",
            "Does it time out by showing some output or does it just hang?",
            "It just hangs",
            "It may be because the locks are being blocked. I had this problem because I was trying to remove values from the mempool while it was locked. Try to add print statements to your transaction generator and miner to see where it's getting stuck. Also, see #245.",
            "Once you found your issue, how did you fix it? Shouldn't the locks automatically pause the thread until the resource is freed up?",
            "For my issue, I just stored the values as a vector before iterating through them. So the for-loop wasn't locking the mempool in case I tried to remove something from it."
        ]
    },
    {
        "title": "longest-chain-tx results not the same for 3 nodes",
        "question": "When testing my code for the \"longest-chain-tx\" api call, the 3 nodes do not have the same transactions, but they DO have the same longest chain and the same block hashes. I don't understand how this could be the case, since my longest-chain-tx's are retrieved in the same exact way as my longest-chain of blocks. Has anyone else had this problem?",
        "other_text": [
            "If the block hashes are the same, the transactions in the blocks would be the same too.\n\nI'm guessing it's a bug in your api implementation"
        ]
    },
    {
        "title": "longest chain is stuck",
        "question": "Hi, I'm running into an issue where my longest chain keeps getting stuck. The first node seems to be adding more blocks and transactions while the second two nodes lag pretty far behind. When I increase the difficulty (making it easier to mine), I get errors in identifying blocks and parents in my blockchain resulting in errors of unwrapping None values. I know in both posts (#279 and #245) we're told to check that the mutexes are locking and releasing properly. Could you provide more context on how to check that? \n\nAdditionally, could you clarify when should we be inserting to mempool and blockchain hashmaps? I'm worried I'm inserting in places that might cause the longest chain to be stuck. So do I insert just in network/worker.rs inside each of the Message clauses? Should we also be doing that in transactions/mod.rs and transactions/worker.rs (if we implemented parallel version of miner/mod.rs and miner/worker.rs for txs)? And is it possible that having a transactions/worker.rs would jam up the network? If so, how can I import server directly to be able to broadcast?\n\nLast, there are a lot of duplicate keys in my transactions. Where should I be removing from the mempool? Or is there something else I should be checking?",
        "other_text": [
            "Try making it harder to mine, would be easier to debug. It might be a locking issue, or you may be jamming the network with too many messages. Reducing the mining and tx gen rate might solve the issue / help you find any errors.\n\nI get errors in identifying blocks and parents in my blockchain\n\nYour orphan block handling should take care of this?\n\nwe're told to check that the mutexes are locking and releasing properly. Could you provide more context on how to check that?\n\nA straightforward way is to add printn statements before and after acquiring the lock:\n\nprintln(1)\nx.lock().unwrap()\nprintln(2)\n\nIf 1 is printed and 2 isn't, then the thread is waiting to acquire the mutex lock.\n(Try to implement the suggestion in #245 anyway, it's a good practice)\n\nAdditionally, could you clarify when should we be inserting to mempool and blockchain hashmaps?\n\nYou should insert into the blockchain once you mine a block, and when you receive a Blocks message / during orphan handling. Similarly, you insert in the mempool once you make a new transaction in txgen, and when you receive a Transactions message and it passes all checks\n\nLast, there are a lot of duplicate keys in my transactions. Where should I be removing from the mempool? Or is there something else I should be checking?\n\nWhen you insert a block (both in miner and network), you need to remove all the txs within the block from the mempool.",
            "And to clarify that last statement, we should be inserting a block/removing all txs within block from mempool in miner/mod.rs or miner/worker.rs or both?",
            "You can do it in either file",
            "I'm currently inserting the new block into the blockchain both in miner/mod.rs and miner/worker.rs. I remember I was told to do this in an earlier assignment. Is that okay to have or should I have it only in one file?",
            "It wouldn't make a difference since insert() would essentially ignore the block if it is already in the hashmap. That said, you could have it in one of the files to reduce redundancy..\n\n(I'm guessing in the previous assignment it was a locking issue which caused problems inserting in miner/worker.rs -- you have fixed them by now I think)"
        ]
    },
    {
        "title": "Reciever in Transaction Struct",
        "question": "In the earlier part where we implemented transaction and signed transaction we had both sender and reciever addresses in the Transaction struct.  Is the sender address nolonger required if using the account  based model?\n\n",
        "other_text": [
            "Sender address is still required because that is how we are keeping track of state (which address has how much balance). One of the checks we are doing here is verifying whether the sender address and the public key signing the transaction are consistent.\n\n"
        ]
    },
    {
        "title": "checking transactions in block",
        "question": "For the block transactions check of a block that the miner receives, do we have to make sure that all the transactions are already in the current mempool? Or do we only need to check that the signature is valid?",
        "other_text": [
            "The network/worker is the one who receives blocks via Message::Blocks. You just need to check if the transactions inside the block are valid."
        ]
    },
    {
        "title": "bitcoin exe compilation error",
        "question": "When doing cargo run, I am getting the following error. it worked multiple times just now, not sure why this stopped working. \n\nI have submitted my assignment to A7 already after checking it several times, was just doing a just-in-case check and got this error, not sure if my submission is correct anymore",
        "other_text": [
            "I think I fixed it by deleting the target folder and recompiling\n\n"
        ]
    },
    {
        "title": "/blockchain/longest-chain-tx-count",
        "question": "Should we be implementing /blockchain/longest-chain-tx-count  in the API for this assignment?",
        "other_text": [
            "No it's optional"
        ]
    },
    {
        "title": "Blocks without transactions",
        "question": "Is it ok if the first few blocks that are sent don't include any transactions since there is a delay between start of the mining and the transaction creation?\n\nWould this mess up the grading that compares the transactions of the second block?\n\n",
        "other_text": [
            "To avoid this you can start the transaction generation before starting the miner"
        ]
    },
    {
        "title": "Setting up Addresses",
        "question": "I don't understand how to set up addresses for each node. If we use a fixed seed wont all nodes have the same address. Also what do you mean by set it up in the genesis?\n\nAlso is the state a part of mempool or can we implement it as an extension of each block i.e changing the block struct and not using a hash map?\n\nThe instructions aren't very clear on how to set p the ICO and does that also mean the pool needs to have an initial transaction if we have an initial state object.",
        "other_text": [
            "You can derive the addresses from the public key. So if each node has different public keys, it would also have different addresses",
            "I understand that much. Im more so curious about how to get a different public key for each node as the code may use the same seed. I also wanted to know where to store this public key or all public keys and if to generate an initial one for the genesis transaction.",
            "You can use three different hardcoded seeds in the genesis to generate a keypair for each node.  (eg using Ed25519KeyPair::from_seed_unchecked(&[seed; 32]).unwrap())\nYou can store the public keys in the genesis state.\n\nWhen you start a node, you can use the p2p address of the node to retrieve its secret key (using the same seed used in genesis)",
            "Within the tx_gen you can create more key pairs; once these public keys receive some amount, they need to be added to State",
            "Thank you. This makes sense. I was wondering if there was a way to get the number of servers a server is connected to in order to dynamically use these other servers i.e incase more servers show up and i can add their public keys too. I looked at the broadcast code and its confusing",
            "Maybe you would need to add more network messages to broadcast keys.\n\nFor the purposes of the project, we will only be testing using three nodes",
            "I'm confused about the initial 3 key_pairs vs the additional key pairs you talk about in your reply.\n\nAre you suggesting creating only 3 key_pairs (corresponding to the 3 ports) or are you suggesting to creating many key_pairs? And is the number of key_pairs dynamic (more key_pairs are added as the transaction generator runs) or set at the beginning, prior to any loops?\n\nAn example question I have related to this is: should the transaction generator from port 6000 only be able to create transactions with a sender associated with port 6000's key_pair public key? \n\n",
            "Initially you can hardcode one keypair to each node.\n\nLater you can dynamically create more keypairs in the tx generation loop ; and store all the keys that the node controls in some vector.\n\nshould the transaction generator from port 6000 only be able to create transactions with a sender associated with port 6000's key_pair public key?\n\nYes it should access to the private key of only those key_pairs"
        ]
    },
    {
        "title": "sender address",
        "question": "Could you please confirm if the sender address should be included into the Transaction structure if using the account based model? There are two threads (#302 and #272) discussing this but I am still confused. Thank you very much!\n\n",
        "other_text": [
            "You can include sender address",
            "Thank you.",
            "Thank you very much for answering this question. I really appreciate that. Could you please answer few follow up questions?\n\nShould Transaction generator create a sender address from the signing public key of the transaction? \n\nShould Network worker verify that the sender address and the signing public key match upon transaction validation (for A7)?\n\nCan a random key pair be used for every new signed transaction, or should Transaction generator use pre-defined set of keys pairs?",
            "Yes if you're including the sender address it should match with the signer's public key.\n\nYes\n\nIt should store the set of (pre-defined) key pairs under its control. \n(For A8 - ) But it can also create new random key pairs and add to the set; when it receives some amount, this new public key should be updated in the State",
            "Thank you very much Ashwin.\n\nIt should store the set of (pre-defined) key pairs under its control.\n\nHow would you recommend to implement this part for A7? ",
            "Maybe pass/initialize them in the new function\n\n",
            "Thank you.",
            "The assignment A7 specification states:\n\nYou are free to choose the sender and recipient.\n\nWe have already determined that the sender can be selected from the list of senders that are under control of the miner node. For this assignment,  this list is populated upon the node start up. I hope I understand this correctly.\n\nWhat is the recipient of the transaction? Are there any rules regarding the recipient's address? Can the recipient be a random address for A7? Do we need to keep track of recipients for A7?\n\n",
            "For A7 you don't have access to receipients: you can create a random transaction\n\n",
            "Thank you."
        ]
    },
    {
        "title": "connecting between miner/worker and network/worker",
        "question": "In my part 7, the two of these aren't connecting properly just in terms of mining the blocks. My longest chain on the first node mines and then only the first block appears on the second. Thus the transactions have the same issue. This didn't happen in part 6, is there anything I could have done to create this issue in terms of networks? ",
        "other_text": [
            "Maybe you are generating too many transactions (and NewTransactionHash messages) which is causing the network to get jammed?\n\nYou can control tx generation rate by setting the sleep parameter to theta * x\n\n"
        ]
    },
    {
        "title": "Panic with 2 nodes",
        "question": "I'm getting the following error with theta=10 and lambda=0:\n\nThe code at src/network/worker.rs:204:83: \n\nI'm not sure what the problem is. Any advice on how to fix it?\n\nThank you!",
        "other_text": [
            "Which line is 204?\n\nLooks like your code panicked while holding the mempool lock",
            "It's the transacs.push(...) statement. ",
            "All the other Poison Error statements also point to places where I use the mempool lock.",
            "Not fully sure. Have you implemented get and contains_key correctly for the mempool struct?\n\nget(&hash) would return None only if the hash isn't present in the hashmap right?\n\n",
            "I haven't implemented a mempool struct. I'm using a HashMap directly.\n\nnetwork/worker.rs\n\nmain.rs\n\nminer (and similarly in transaction generator):\n\n",
            "Ok.\n\nMaybe ensure that the lock isn't being released between the two statements?\n\nEg: \n\n{m = mempool.lock().unwrap()\nif m.contains_key(){\n... = m.get()\n}\n}",
            "This fixed the issue. Thanks!",
            "\ud83d\udc4d\ud83d\udc4d"
        ]
    },
    {
        "title": "Part 6 AutoGrader",
        "question": "Would you all be able to let me know if my part 6 passes the auto grader? \n\nI just resubmitted. If any partial credit is possible for a late assignment that would be appreciated. If not, It would still really help just to know if its good to go. ",
        "other_text": [
            "Hi Ben, \n\nYour current submission doesn't pass the autograder.\n\nOne issue I noticed is that the genesis blocks on different nodes' longest chains are different.\nI think the genesis block has some random values in it? You should change it such that all nodes start with the same block.\n\nAlso, you would need to set the difficulty such that 10-20 blocks are mined in a minute. If the value is too high (mining is easy), there will be a lot of network messages sent which leads to the network getting jammed - as a result the longest chains on different nodes would not be synced up.",
            "Thursday/Friday/Saturday office hours generally have fewer people.\nFeel free to attend those if you need help catching up!",
            "I was not able to make any of those times due to athletic committments, but I will be in office hours today for both sessions. Hopefully I can make some headway. ",
            "Ok, I fixed the genesis block piece. My order was reversed for some reason meaning the last block in the chain was actually the genesis block.\n\nIn terms of difficulty, this should be an easy fix. \n\nThe problem is that I am now struggling with A7 and won't be able to submit my fix for A6 until I can create code that compiles for A7. \n\nCan I submit A6 again with my A7 submission for any partial credit? No worries if not. ",
            "Would recommend you fix A6 before A7.\nAny errors would carry over, and it's not easy to debug.\n\nIf you have committed your code for A6, you can work from that commit on a new branch..\n\n(eg using : git branch branch_name <commit-hash>) ",
            "Ok I will try this.",
            "Ashwin, \n\nMy Code is working. The problem was 100% the genesis block. Would you mind passing it through autograder? ",
            "I will Submit now",
            "Wait shoot, I forgot to lower my difficulty for Lamda. Will Resubmit as bdc3_9.zip\n\n",
            "Yes your A6 code passes the autograder now."
        ]
    },
    {
        "title": "Block rate",
        "question": "Just to be clear,\n\nthe number of blocks in the longest chain doesnt necessarily matter for this assignment, correct?",
        "other_text": [
            "Yes "
        ]
    },
    {
        "title": "Lag in longest chain syncing with transaction generator running",
        "question": "When I am mining without the trx generator running, the longest chains sync fine, but when I start it, the nodes' longest chains are very out of sync. I put in some print statements and started two nodes. The first is mining/generating transactions and the other is just listening. I saw the following output (reflecting block generation and messages received by the first node)\n\nInserted block [0035..5ad2] with 20 transactions!\nInserted block [002b..3776] with 20 transactions!\nInserted block [001f..f855] with 20 transactions!\nInserted block [001a..d933] with 20 transactions!\nInserted block [000c..a804] with 20 transactions!\nStart GET BLOCKS with hashes: [0035..5ad2], time: 1667952712552\nInserted block [0008..0d72] with 20 transactions!\nInserted block [0027..f260] with 20 transactions!\nInserted block [0025..36e7] with 20 transactions!\nInserted block [000f..a281] with 20 transactions!\nEnd GET BLOCKS with hashes: [0035..5ad2], time: 1667952730392\nStart GET BLOCKS with hashes: [002b..3776], time: 1667952730392\nStart NEW BLOCK HASHES message: [0035..5ad2], time: 1667952730397\nEnd NEW BLOCK HASHES message: [0035..5ad2], time: 1667952774375\nEnd GET BLOCKS with hashes: [002b..3776], time: 1667952774376\nStart GET BLOCKS with hashes: [001f..f855], time: 1667952774376\nStart NEW BLOCK HASHES message: [002b..3776], time: 1667952774381\nInserted block [0007..2d99] with 20 transactions!\nEnd NEW BLOCK HASHES message: [002b..3776], time: 1667952784376\nEnd GET BLOCKS with hashes: [001f..f855], time: 1667952784376\nStart GET BLOCKS with hashes: [001a..d933], time: 1667952784377\nStart NEW BLOCK HASHES message: [001f..f855], time: 1667952784382\nEnd NEW BLOCK HASHES message: [001f..f855], time: 1667952785728\nEnd GET BLOCKS with hashes: [001a..d933], time: 1667952785728\nStart GET BLOCKS with hashes: [000c..a804], time: 1667952785728\nStart NEW BLOCK HASHES message: [001a..d933], time: 1667952785733\nInserted block [000b..175d] with 20 transactions!\nInserted block [0017..2c54] with 20 transactions!\nInserted block [0029..eb59] with 20 transactions!\nInserted block [0025..806a] with 20 transactions!\nEnd NEW BLOCK HASHES message: [001a..d933], time: 1667952822208\nEnd GET BLOCKS with hashes: [000c..a804], time: 1667952822209\n\n\nI notice that NewBlockHashes, GetBlocks, and block generation often interleave --> Should I change this somehow so that new blocks are not being generated in the middle of sending new hashes or getting blocks?",
        "other_text": [
            "Maybe your transaction generation is very fast?\n(so a lot of NewTransactionHashes messages are being sent)",
            "The transaction generation is just based on theta (100), right? Is there any way to slow down the transaction generation beyond changing theta?",
            "Yes we will be testing with theta=100. theta is used to set the sleeping interval in thread::sleep(interval);\n\nYou can set the interval to be theta*x to change your txgen rate",
            "Sounds good! And the processes interleaving isn't something to be concerned about, then?",
            "The miner loop is running independent of the network worker. So I guess it's expected that block generation and the transaction messages happen concurrently?\n\n",
            "Not sure if it makes a difference, but these are the outputs from the other node:\n\nStart NEW BLOCK HASHES message: [0035..5ad2], time: 1667952712552\nEnd NEW BLOCK HASHES message: [0035..5ad2], time: 1667952712552\nStart NEW BLOCK HASHES message: [002b..3776], time: 1667952730392\nEnd NEW BLOCK HASHES message: [002b..3776], time: 1667952730392\nStart BLOCK message: [0035..5ad2], time: 1667952730392\nEnd BLOCK message: [0035..5ad2], time: 1667952730397\nStart NEW BLOCK HASHES message: [001f..f855], time: 1667952774376\nEnd NEW BLOCK HASHES message: [001f..f855], time: 1667952774376\nStart BLOCK message: [002b..3776], time: 1667952774376\nEnd BLOCK message: [002b..3776], time: 1667952774381\nStart NEW BLOCK HASHES message: [001a..d933], time: 1667952784377\nEnd NEW BLOCK HASHES message: [001a..d933], time: 1667952784377\nStart BLOCK message: [001f..f855], time: 1667952784377\nEnd BLOCK message: [001f..f855], time: 1667952784382\nStart NEW BLOCK HASHES message: [000c..a804], time: 1667952785728\nEnd NEW BLOCK HASHES message: [000c..a804], time: 1667952785728\nStart BLOCK message: [001a..d933], time: 1667952785728\nEnd BLOCK message: [001a..d933], time: 1667952785733\nStart NEW BLOCK HASHES message: [0008..0d72], time: 1667952822209\nEnd NEW BLOCK HASHES message: [0008..0d72], time: 1667952822209\nStart BLOCK message: [000c..a804], time: 1667952822209\nEnd BLOCK message: [000c..a804], time: 1667952822214\nStart BLOCK message: [0008..0d72], time: 1667952896439\nEnd BLOCK message: [0008..0d72], time: 1667952896443\nStart NEW BLOCK HASHES message: [0027..f260], time: 1667952896454\nEnd NEW BLOCK HASHES message: [0027..f260], time: 1667952896454\n"
        ]
    },
    {
        "title": "1-day extension",
        "question": "Dear Instructors,\n\nI have been spending double the amount of hours on this assignment, and despite my steady progress, this assignment has presented a much larger burden than the past ones. I have spoken to a few of my classmates who feel similarly (despite attending office hours, answering and posting Ed questions, etc.). I am not aware of many who have finished the assignment. I am prepared to work on this assignment until completed, but would it be possible for the sake of comprehension and completion to have the deadline extended by one day?\n\n",
        "other_text": [
            "Yes, we will extend the deadline (tentatively we are thinking Sunday evening).\nWe'll push Part8 to November 23.\n\nWill announce officially in a bit \n\n"
        ]
    },
    {
        "title": "Transaction Generator using Miner::Worker and Miner::mod",
        "question": "Would a reasonable design to implement the transaction generator be to mimic the two-file structure of miner::mod.rs and miner::worker.rs? Specifically, we would have a generator loop in our transaction::mod.rs file that would mimic miner::mod.rs in randomly creating transactions; and then our transaction::worker.rs file would receive the message from the mod.rs file and then broadcast the hash to the whole network?\n\n\n\nOr would it be simpler to implement some sort of one-file design, where we directly broadcast transaction hashes to the network?",
        "other_text": [
            "Either way would work.\n\nThe first method is probably more straightforward..\n\n\n\nOr would it be simpler to implement some sort of one-file design, where we directly broadcast transaction hashes to the network?\n\nIf you choose to implement it this way, you just need to pass &ServerHandle to the context, and can do server.broadcast after you've created a transaction (without needing finished_block_chan)",
            "thanks for the quick reply!"
        ]
    },
    {
        "title": "Assignment deadline extension",
        "question": "Hi everyone, \n\nWe appreciate the effort you have been putting in on the project. Since many of you have been facing difficulty on A7, we will be extending the submission deadline by a week.\n\nNew submission deadlines:\nPart 7 : November 16\nPart 8 : November 23\n\nFeel free to ask questions here on Ed (even if you feel they are trivial). Also encourage everyone to answer others' questions if you have faced similar issues. \n\nHope this helps.",
        "other_text": [
            "First of all, thank you so much! \u2764\ufe0f\n\nSecond, Pramod just sent a message saying that the extension is due 11/13. Which is correct?",
            "Apologies. It is due Wednesday 3pm (11/16)",
            "Thank you so much! This is huge."
        ]
    },
    {
        "title": "Updating blockchain in Generator",
        "question": "How does the transaction generator update its own state, as in how do we update it with what blocks have been mined and the which new transactions are inside it. The blockchain doesn't update in the generator.\n\n",
        "other_text": [
            "The generator needs to have access to the blockchain. It can use the state of the tip",
            "Okay perfect thanks"
        ]
    },
    {
        "title": "Theta in Handle",
        "question": "In our TransactionGenerator, we need to set a parameter named theta that controls the speed. Should this be added within our Handle struct? Where would we pass it in while running the generator? \n\n",
        "other_text": [
            "Yes it will be passed to the start function in the Handle (similar to how the miner start api passes lambda to the Handle)"
        ]
    },
    {
        "title": "Grading Policy",
        "question": "As mentioned in #313 , will grading be determined on just the four criteria in the specs about transactions? It does not matter if our longest chains between miners are synced within some interval?",
        "other_text": [
            "The grading for common prefix would be relaxed to the extent mentioned in the fourth point of the criteria. But it would be good to have the longest chains sync as much as possible for the last part of the project."
        ]
    },
    {
        "title": "Duplicate Transaction Grading",
        "question": "Could you please clarify this policy: \"\n\nNo duplicate transactions: there should be no duplicate transactions in the blockchain. However, we relax the grading of this item. If the unique transaction count divided by the total transaction count >=0.9 for every node, you get full grade for this item.\n\n\"\n\n\n\nSince it says \"for every node,\" is this saying that we are only testing duplicate transactions on a node by node basis? I see the same transaction hash across a few of my nodes, but each node itself maintains mostly unique transactions.\n\n\n\nTo me, this would make sense, since we have not formally preventing double-counting yet, but the only safeguard we have in place is to remove transactions from the mempool when we accept a block. However, what is preventing two blocks from sharing the same transactions before either block is accepted? Would this just be a coding decision on our part in terms of how to sample transactions from the mempool when we fill a block?",
        "other_text": [
            "Since it says \"for every node,\" is this saying that we are only testing duplicate transactions on a node by node basis\n\nYes, we will test this on each of the three nodes.\n\nHowever, what is preventing two blocks from sharing the same transactions before either block is accepted?\n\nIf two such blocks are mined, it is unlikely / not possible that both these blocks would lie on the longest chain.\nWe are only concerned about transactions which are part of the longest chain.",
            "I see; similarly, how can we modify the transaction generator to \" generates enough transactions to meet the following grading criteria.\" \n\n\n\nIf theta is fixed, what other means is there to have the generator make transactions faster?\n\n",
            "Yes we will be testing with theta=100. \ntheta is used to set the sleeping interval in thread::sleep(interval);\n\nYou can set the interval to be theta*x to change your txgen rate\n\n",
            "Likewise, if you modify difficulty to increase the mining rate of blocks (or in other words, increase the value of difficulty to make mining easier), this can also help offset very fast transactions. ",
            "Just ensure that you aren't generating thousands of blocks/txs (aim for slightly more than the required numbers) when you make mining easier: Network may get jammed, and longest chains may not match.\n\n"
        ]
    },
    {
        "title": "Do we need to broadcast generated transactions?",
        "question": "Why do we need to broadcast generated transactions? Can't the transaction generator just add transactions it creates to its respective mempool and and then those transactions will be broadcast via the miner putting those transactions into blocks and broadcasting newblockhashes? I think all the tests would be passed this way.",
        "other_text": [
            "It is not necessary that all nodes on a blockchain are miners, some might only be generating transactions. The tests are simply a rough guideline to build a running blockchain. "
        ]
    },
    {
        "title": "Longest Chain Forking",
        "question": "The longest chain forks after starting the transaction generator alongside the miner. I've tested with 3 nodes and 2 nodes, where all nodes are both mining and generating transactions.\n\n\n\n1. If I run just the miner on 2 nodes, the longest chain is the same\n\n2. If I run the transaction generator as well, the chain forks starting from the first non-genesis block. Printing logs has shown that each node never receives NewBlockHashes messages, and receives tons of NewTransactionHashes and Transactions messages. I've played around with both the block difficulty and the transaction generation speed. I've made block difficulty a bit easier than A6 & made the transaction generator sleep from theta / 5 to theta * 5 milliseconds. \n\n\n\nHas anyone else faced a similar issue?",
        "other_text": [
            "The issue seems to be the network getting clogged with too many transaction messages. \n(You require only 100-200 txs/min)\n\nMaybe start from a very slow transaction generator, and tune the sleep parameter such that you have 100-200 txs/min with theta=100.\n\n"
        ]
    },
    {
        "title": "API hanging for longest chain tx",
        "question": "I'm running longest-chain-tx with two miners and two generators, and while the first one prints the transactions successfully, the second tab just completely hangs (even though it receives the correct messages in the log). Would there be any solution to this? I've tried increasing the timeout to milis instead of micros, altering the difficulty, etc.",
        "other_text": [
            "Maybe it's a locking issue? Try printing logs before and after blockchain.lock().unwrap() in your api impl..\n\nAlso might be the case that you're still generating too many txs? (You should aim for 100-200 txs per minute)"
        ]
    },
    {
        "title": "Assignment submission netid",
        "question": "I noticed that when we submit files to canvas named netid.zip, canvas automatically renames the submission file to netid-X.zip where X is a number based on how many times we have already submitted a file (for prev. assignments) w that name. Is this ok?\n\n\n\n",
        "other_text": [
            "Yes this is fine"
        ]
    },
    {
        "title": "Generating valid transactions",
        "question": "\"Transaction generator should generate transactions that pass the checks. It can read the blockchain and the state to ensure that\"\n\n If we are referring to the current state (state of blockchain tip) to decide valid transactions, do all the generated transactions need to be collectively valid, or just each one individually?\n\nExample)\n\ntransaction generator:\n\ncurrent state: A = 5 coins\n\ntrx 1: A gives B 3 coins\n\ntrx 2: A gives B 4 coins\n\n\n^^\n\nAre both transactions considered valid in the generation process, or would the second transaction be considered invalid b/c we assume that the second transaction happens after the first generated transaction?",
        "other_text": [
            "One of these transactions will be invalid.\n\nOne way to avoid such scenarios may be creating and maintaining multiple key-pairs/accounts for each node..\nYou can then create concurrent, independent transactions (eg : A1 -> B1, A2 -> B4, etc)\n\n",
            "This would limit the number of transactions we're creating as well as make the code complicated since only one of the accounts will be in the state initially. \n\nIs creating invalid transactions okay as long as we're only adding valid transactions to the blocks we're creating?",
            "Yes"
        ]
    },
    {
        "title": "Verifying transaction",
        "question": "I'm not sure why but I'm failing to verify SignedTransactions. I used the detailed here: ring::signature - Rust (briansmith.org). It works when verifying the Transactions struct (the old tests). Any advice on how to fix this?\n\nThanks!",
        "other_text": [
            "In verify_signature, the message should be the transaction (not the hash) I think",
            "That makes sense. Thanks"
        ]
    },
    {
        "title": "overflow err",
        "question": "I am running my program for 5 mins and this seems to be happening. This is an integer (j) in my orphan buffer loop that keeps track of the length (code below the error). The error only pops up in the terminal when I refresh the page after waiting 5 mins. Is it because of the number of blocks/transactions there are? How do I fix it?",
        "other_text": [
            "when I refresh the page\n\nwhen you refresh the api page?\n\nProbably there are cases when o_length becomes less than 0. Maybe try reimplementing without using this?\n(I don't understand the code at first glance : what are i and j?)",
            "Ok, so there was an error in the code that I posted. The 'i' should be a 'j.' But changing that variable doesn't solve the error. \n\nj in this case is the counter that iterates through the orphan buffer (a vector of type block) to check if the parent exists in the buffer.\n\nThis checks the entire orphan buffer to see if a block is in the bc to put in instead of iteratively checking the block, it's child, etc. "
        ]
    },
    {
        "title": "Public keys",
        "question": "Thank you so much for your patience answering all the questions!\n\nI am following up this answer about the nodes' public keys.\n\nCould you please clarify what \"known publicly\" means in this answer? \n\nDoes this mean the public key is known because it is included into the SignedTransaction struct and sent together with the transaction? \n\nOr does this mean the public keys are known in advance (the nodes exchange their public keys upon startup)? If the nodes exchange their public keys in advance, could you please suggest how to implement this functionality? How many public keys can each node have?\n\n",
        "other_text": [
            "Both.\n\nAt startup, you can define key-pairs for each node in the genesis block.\nYou can assign these keys to the respective node according to its IP address in main.rs (see discussion in #298).\n\nA tx generator will also create multiple key-pairs (and store them). When these public keys receive an amount, they will be recorded in the State and hence will be known to everyone",
            "Thank you Ashwin.\n\nYou can set up accounts in the genesis.\n\nHow many accounts should be set per each node in the genesis (do you mean genesis block)?\n\nTo make them deterministic, you can use for eg: Ed25519KeyPair::from_seed_unchecked(&[seed; 32]).unwrap() with a fixed seed, or Ed25519KeyPair::from_pkcs8 with some pre-stored bytes.\n\nCould you please advise there the seed:u8 is coming from? How is it generated? How many seeds are created per each node?\n\nTo use these in the tx generator, one idea is to assign these deterministic private keys according to the IP port in main.rs (we will be using 127.0.0.1:6000, 127.0.0.1:6001, 127.0.0.1:6002 in the grading).\n\nCould you please explain this? ",
            "How many accounts should be set per each node in the genesis (do you mean genesis block)?\n\nOne account per node in the state of the genesis block (a.k.a ICO)\n\nCould you please advise there the seed:u8 is coming from? How is it generated? How many seeds are created per each node?\n\nYou can set a known deterministic value. For instance, if the IP port of my node is 127.0.0.1:6000, I will use the seed=1 to generate my key pair, if 127.0.0.1:6001 - I will use seed=2 and so on\n\n",
            "Thank you so much.\n\nOne more question please. Because State  is not implemented for A7, and only one account is created per node upon startup, how the nodes will know about the newly created accounts/addresses belonging to the other nodes?\n\n",
            "Oh this discussion is about A8.\n\nSorry for the confusion.\nFor A7, you can just use a random transaction, and sign it using any key-pair.\nAny other other node should be able to verify the SignedTransaction (like in A1)\n\n\"known publicly\" would just mean that it is part of the SignedTransaction struct, anyone can access it and verify the signature",
            "Thank you so much Ashwin!",
            "You don't need to implement accounts in A7",
            "At startup, you can define key-pairs for each node in the genesis block.\n\nAs the genesis block is identical for all nodes, does this mean that the nodes have access to the private keys of all other nodes?",
            "No this shouldn't happen.\nOnly the public keys must be stored in the genesis"
        ]
    },
    {
        "title": "Defining State struct",
        "question": "Are supposed to define the State struct in a separate module (similar to the miner and tx-generator) and then import it wherever we need? The alternative would be creating a new type in the types folder.\n\nAnother related question: Where do we store the state for each block? Are we adding a new field to the blockchain struct or is it similar to the mempool?\n\nI'm a little confused about how to start.",
        "other_text": [
            "Are supposed to define the State struct in a separate module (similar to the miner and tx-generator) and then import it wherever we need? The alternative would be creating a new type in the types folder.\n\nYou can define it in a pre existing module (like blockchain or block etc).\n\nAnother related question: Where do we store the state for each block? Are we adding a new field to the blockchain struct or is it similar to the mempool?\n\nThe state struct maps the hash of each block in the blockchain to a state. You can store it in the blockchain you have as a hashmap."
        ]
    },
    {
        "title": "A7 Adding Signature to transaction",
        "question": "What does this mean in the assignment specs... \n\n\n\n\"Now it's time to add the transaction and its Signature to SignedTransaction. As introduced in previous assignment, crate ring's signature may not be very convenient to use, so you can convert them to vector of bytes: let signature_vector: Vec<u8> = signature.as_ref().to_vec();. You must also add the signer's public key to SignedTransaction.\"\n\n\n\nWhere should we be adding the signature to the signed transaction.\n\n\n\nAlso, my A6 is submitted and i am confident it works. Would you mind verifying with autograder? ",
        "other_text": [
            "Where should we be adding the signature to the signed transaction.\n\nYou should construct a SignedTransaction structure similar to what you did in A1:\nIt should contain the Transaction, the public key of the sender/signer, and the signature\n\nWould you mind verifying with autograder? \n\nYes it passes the autograder now",
            "Should we get rid of the original Signed Transaction? ",
            "You can modify the same structure in transaction.rs",
            "And Should sign() now return a signed transaction? ",
            "sign() will still return a signature.\n\nThe signature will be one of the fields of the signedtransaction",
            "Im just confused because all this was already done in assignment 1. Are you asking us to do anything besides change the structure of transaction to the account setup? \n\n",
            "Yes you can use what you implemented in A1 (eg sign and verify functions). You only need to change the transaction fields.",
            "Ok thank you! Let me know if there is any partial credit for Late assignments. If not, no worries. ",
            "Unfortunately there is no partial credit for late submissions.\nHowever, we can grant you a one-time two-day extension for A7.\n\nYou can submit it by Friday evening",
            "Ok Thank you! ",
            "After a few sessions of office hours My code is still not working. Though I think it to be very close. \n\nI will be attending tomorrows office hours and hopefully I am able to finish A7. I apologize for my struggles in keeping pace with the class. It is not due to a lack of effort I can promise that. \n\nI will submit what I have now although I am certain the autograder will give it a 0. ",
            "I understand. A7 might take more time than other parts.\n\nWhat issues are you facing?\n",
            "One common mistake is in setting tx generation rate :\n(See https://edstem.org/us/courses/28225/discussion/2121310?comment=4853145)\n(You don't want too many transactions, only 100-200 per minute)\n\n\nYou might also have issues with locks not going out of scope",
            "Is there any partial credit for late assignments? \n\n"
        ]
    },
    {
        "title": "Variable or fixed number of transactions per block?",
        "question": "Hi there. \n\nCurrently, I have my code set up in the following manner. There is a constant variable n for the maximum number of transactions that a block can contain. In the miner loop, after a block has been mined, I add n transactions from the mempool to the block. However, if there are less than n transactions in the mempool currently, the program sleeps for ten milliseconds and loops again (in the hope that more transactions have been added to the mempool in the meantime by the transaction generator), and continues in this way until all n transactions have been added to the block. Only then, the finished block is sent through the channel to the worker module. (This seems to be working well, transactions and blocks are generated successfully and each block contains the same number of transactions). \n\nBut keeping the next assignment and practical applications in mind, is this an appropriate way to add transactions to a block? Or should there be a variable number of transactions in each block depending on how many are currently present in the mempool? As in, should the program not wait for more transactions to be generated and simply proceed to finish the block (as soon as the mempool runs out of transactions) and send it through the channel?\n\nAny clarification would be appreciated.\n\nThank you,\n\nSrija\n\n\n\n",
        "other_text": [
            "Instead of aiming for a fixed number of transactions, you can have a range (at least Tx_min and at most Tx_max) number of transactions that you put into the contents of your block.",
            "Got it, thank you."
        ]
    },
    {
        "title": "Generating key pair for genesis block",
        "question": "During office hours we were told to use key_pair::from_seed(0) to generate the key_pair for the genesis block. But that function doesn't exist in the type provided to us. I found this function in the ring library that seems similar:\n\nBut it seems like it recommends us not to use. Can we use this?\n\n",
        "other_text": [
            "Yes, this is the one you should use.",
            "Thanks!",
            "How does that work, since the provided seed must be a valid key?  It cannot be called on 0, I keep getting rejected key errors\n\n",
            "let seed = 0;\n\nlet key_pair = Ed25519KeyPair::from_seed_unchecked(&[seed; 32]).unwrap()",
            "What is the input type it takes?",
            "&[u8]"
        ]
    },
    {
        "title": "blockchain diverges after adding txgen",
        "question": "My blockchain was working fine in A6; however, upon adding the txgen, I find that the nodes are no longer reaching consensus. I played around with adjusting theta and checked that I wasn't ever sending empty network messages to reduce congestion.\n\nThis might be because my transactions are not the same across the nodes even though my txgen code was modeled to be just like miner's mod.rs and worker.rs files, but I'm not sure what might be causing this. Any insights?",
        "other_text": [
            "Are you setting the sleep interval in your txgen correctly?\nYou can set the interval used in thread::sleep(interval); to be theta*x to change your txgen rate. (We will be setting theta = 100)\n\n(You should aim for ~100 transactions per node per minute => your generator should sleep for ~0.5s after generating a tx)",
            "I believe so, I did the following in txgen/mod.rs\n\nlet interval = time::Duration::from_micros((i * 5000) as u64);\nthread::sleep(interval);\n\n\nI also tried playing around with theta but there doesn't seem to be much change in the consensus of the nodes",
            "This might be because my transactions are not the same across the nodes\n\nDid you check if the other nodes receive the txs and blocks in time?",
            "Yes, I am using print statements and it appears that the nodes are all registering the New transactions, blocks, and updates to the mempool ",
            "That's unusual... We would expect the longest chain to be the same if all nodes have received all the blocks right?\n\nMaybe the transactions within the block are somehow failing the validity checks before insertion?",
            "My transactions are different across the nodes when I call longest-chain-tx, though I implemented txgen the same way as the miner. Any thoughts on where this might be happening?",
            "it appears that the nodes are all registering the New transactions, blocks, and updates to the mempool \n\nSo basically it looks like : if node1 mines a block, the other nodes are receiving the block but not inserting into their blockchain.\n\nOnly bug I can think of right now is maybe there are some invalid transactions in the block which are failing your signature check\n\n(Maybe it's useful to check if the blocks in each node's longest chain were generated by the same node)",
            "I checked and indeed, the validation check for the transaction isn't working! \n\nI'm currently performing the validation check by using creating a verify function that does the following\n\n// t is of type Transaction, public_key is of type &[u8], and signature is of type &[u8]\nlet encoded_tx: Vec<u8> = bincode::serialize(&t).unwrap();\nlet peer_public_key = signature::UnparsedPublicKey::new(&signature::ED25519, public_key);\nlet result = peer_public_key.verify(&encoded_tx, signature);\nreturn result.is_ok();\n\n\nWhen I create each transaction, I make the receiver and signer addresses from a u8 array of 0s, the value is 0, account nonce is 0, and the signature the following way\n\nlet key = key_pair::random();\nlet encoded_tx: Vec<u8> = bincode::serialize(&new_tx).unwrap();\nlet signature = key.sign(&encoded_tx);\n\n\nDoes something look off here in the signature/verification?",
            "Seems correct... not immediately sure what the bug is\nBut you can reuse your sign, verify functions tested in A1 for this",
            "I am using the same sign and verify functions from A1\n\nLooking across two nodes, I find that in the transaction, the receiver, value, account nonce, and signature are all the same. However, the result of peer_public_key.verify() in the first code chunk returned an error.\n\nWondering if this line seems problematic?  let peer_public_key = signature::UnparsedPublicKey::new(&signature::ED25519, public_key);",
            "That line seems fine...\nWere you able to find a bug?",
            "I have not been able to find a bug yet unfortunately, though something that I noticed was when I create a new SignedTransaction, the signature is Vec<u8>, while in verify, I use &[u8]. Could this be problematic?\n\n",
            "That is fine..\n\n\nFor now, you could remove the check and make sure everything else is working; and try to fix this later.",
            "I figured it out!\n\nIt turned out to be an issue with the signer I passed in not being connected with the random KeyPair I generated.\n\nThanks so much for supporting me in debugging this :)",
            "\ud83d\udc4d\ud83d\udc4d"
        ]
    },
    {
        "title": "Transaction's withdrawing account and receiver address in Account-based model",
        "question": "In the Account-based model, we are supposed to check if the public key matches the owner's address of the withdrawing account. \n\nI'm confused what withdrawing account refers to here. Is the withdrawing account the receiver of the transaction? In A7 I assigned the receiver as a random Address, but now that we are implementing State, I'm wondering what I should set the receiver address to. #284 makes it seem like we should have a more explicit receiver Address than one generated randomly. \n\nAlso, where should this check occur?",
        "other_text": [
            "Is the withdrawing account the receiver of the transaction? \n\nThe withdrawing account refers to the sender of the transaction. You should add this check if you have added the sender's address in the Transaction.\n\n#284 makes it seem like we should have a more explicit receiver Address than one generated randomly. \n\nThe State would contain a list of known addresses. Your txgen can choose to send a tx to any of them",
            "So if we did not include the sender's address in the transaction, do we need to do this check still?",
            "If you don\u2019t have the sender\u2019s address in the transaction, you can skip this check.",
            "When generating the signed transactions within Txgen, I'm creating transaction structs that have their sender field initialized to equal the corresponding senders address. Then these transaction structs end up getting stored within the signed transaction. \n\nWhat / where am I supposed to perform the check on public key vs owners address? It sounds like this is supposed to happen within Txgen, but because I'm creating transactions that have assigned the sender to the appropriate address, this check seem redundant.\n\nAm I doing this check in the wrong place? Is another section of the code (ie, not in my transaction generator) supposed to be validating the actions of the transaction generator?\n\n",
            "You should perform this check in the network worker when a node receives a SignedTx from another node before adding it to the mempool\n",
            "Maybe I'm missing something obvious here, but we implemented Address as a 20-byte array while Public Key is a 32-byte array. How can we check that these two are the same?",
            "You implemented Address::from_public_key in A1. Can use that",
            "How should we be setting the public_key in txgen based on the sender's Address so that it will pass the test?",
            "In txgen, you will be choosing a sender keypair. \nSender address is derived from the public key in this keypair "
        ]
    },
    {
        "title": "How do you generate text using UTXO?",
        "question": "Code seems to break down every-time I add generate a transaction using utxo.\n\nCan someone explain the steps involved?\n\nSeems like accessing state is an issue as the state doesnt change frequently enough so multiple transactions from the same state are taken.",
        "other_text": [
            "To generate a new transaction from a UTXO state, you should follow this procedure :\n\n1. A node selects unspent output addresses from the state of the blockchain tip.\n\n2. Create transactions which have these output A as input and transfer a valid amount (less than what the UTXO balance has) to another address B and transfers the rest of the amount to A itself.\n\n3. Use the private key of A to sign the transaction and create a signed transaction to be added to the mempool and then broadcasted on the channel.",
            "How do we prevent the transaction from repeating this cycle with the same tip. i.e double spending",
            "(2) should ensure there is no double spending. Maybe you can go over each unspent output sequentially to ensure you don't visit the same output twice?",
            "The issue with 2 is if the loop goes again and the tip doesn't change there cant be an update to the state. So we have the same state",
            "I see what you mean. \n\nIn that case, the transaction generator of each node can keep track of the unspent outputs (maybe through a True/False flag in the state) that have been used to generate transactions till now. When you use a UTXO to generate a transaction, its flag can be set to True. When looping around again, only generate transactions from UTXO's whose flag is False. You can reset all flags to False when the tip gets updated.",
            "Okay, How do you deal with it when there is a fork. Since the state follows the longest chain i.e the tip what about transactions from blocks in a fork",
            "The state struct is a map from block hashes to state, so it would also have states corresponding to forks (i.e. every time you insert a block into blockchain, you should also insert a corresponding state).\n\nBut in the context of transaction generation, you can assume that it (i.e. txn generation) is being done only on the state of whatever the current blockchain tip is.",
            "Does this imply that the recipient of output A is owned by this transaction generator?",
            "Yes. I am assuming you also maintain a list of keypairs owned by the node. You can select any key from this list that is also in the state as an unspent output (basically meaning that the ''balance'' of this owned keypair is non zero).",
            "The README recommends us use the following structure for UTXO: HashMap<(transaction hash, output index), (value, recipient)>\n\nHowever, for transaction generation, we need to select a keypair that has an unspent output in the map (which is almost guaranteed depending on the implementation). In other words, we either:\n\nSelect a keypair then go through the entire hashmap until we find the recipient s.t. recipient == Address::from(keypair.public_key()) and use that unspent output in the new transaction\n\nRandomly pick from the HashMap until recipient is in the list owned by us. Then we use this output in the new transaction\n\nUnless I'm missing something, both of these are extremely unreliable and inefficient, so we'd need to maintain different structure to quickly find outputs in the map given the recipient.",
            "You do not need to have many keypairs per node. You can stop generating new keypairs after you have generated say 4-5 per node. I don't think this would take much time in the code if the keypair list is small enough.\n\n(1) might be inefficient but it's definitely not unreliable since you will be generating valid transactions.\n\nNote that this looks inefficient because we are simulating transaction generation, while on real blockchains, nodes know what txns they want to do and keep track of their utxo's.\n\n",
            "Fair enough. I will go with route #1 then. Thank you for your thoughts."
        ]
    },
    {
        "title": "transactions mining slower than miner loop",
        "question": "I have an issue where my miner mod.rs loop is looping through transactions and adding them to \"potential blocks\". Even if they fail the difficulty check, they are withdrawing transactions from my mempool faster than my mempool can generate them! \n\nShould we add a bit of sleep time in our miner loop so we can let the transactions accumulate before trying to mine a new one? But the issue then comes that with a harder difficulty, we are already mining less blocks and with a potential sleep we could significantly decrease the number of blocks mined, so what would be an ideal sweet spot?\n\nHow would we solve this?\n\nThank you for your help!",
        "other_text": [
            "You should withdraw transactions from mempool only if the block is successfully mined. So maybe have a separate function for collecting transactions and a separate one for actually removing them?",
            "doesn't the hash of the block depend on the content of the block? So how would the block remain valid if we add the transactions later? Or are you saying that maybe we can put the transactions back into the mempool if the block isn't passing the difficulty check?\n\n",
            "No I mean you add the transactions before you check the hash < difficulty condition. But you don't remove them from the mempool at this point.\n\nOnce you check hash < difficulty is satisfied, you remove the transactions in the mined block from the mempool.\n\n",
            "Oh wow I didn't even think of that!! Thank you! :)"
        ]
    },
    {
        "title": "Setting up new mod.rs file for transactions",
        "question": "How can we create a new file just like miner/mod.rs for transactions? When I try to copy over the contents of the file to a new file, the new file doesn't seem to be fully connected to the other modules (for instance, it does not recognize worker in pub mod worker; the way that it does in the first line of the minder/mod.rs file.",
        "other_text": [
            "Are you putting the new file in a new directory or under src/miner/?\n\nIf it's under the same folder (ie. src/miner/abc.rs) , put pub mod abc; in src/miner/mod.rs and it should work.\n\nIf it's in a new folder (ie. src/abc/), add pub mod abc; to src/main.rs\n\n",
            "if you mean you're trying to access something from src/miner/worker.rs inside your new file src/worker/abc.rs, add use super::worker; to your new file.\n\n"
        ]
    },
    {
        "title": "Assignment submission",
        "question": "Hi,\n\nI re-submit my assignment today for assignment 7, and instead of netid-x.zip, where x is a number, this time Canvas just generate long random characters for my submission, like netid-52f30301-905d-43ad-ab7c-f0ecabd57ed7.zip. Would it still be fine?\n\n",
        "other_text": [
            "Yes we will clean the zipfile names before autograding"
        ]
    },
    {
        "title": "Inserting transactions using miner",
        "question": "Do we jut arbitrarily test out inserting different length Vectors of Signed Transactions into the block as the contents of the mined block?\n\nDo we have to separately worry about transaction freshness here?\n\nWhen we insert transactions into the block being mined, do we remove them from the mempool hashtable?\n\n",
        "other_text": [
            "Do we jut arbitrarily test out inserting different length Vectors of Signed Transactions into the block as the contents of the mined block?\n\nYes you can add valid transactions upto some maximum number you should set.\n\nWhen we insert transactions into the block being mined, do we remove them from the mempool hashtable?\n\nWhen you insert a block into the blockchain (upon successful mining or receiving a valid block through the network), you should remove all the txs in the block from the mempool"
        ]
    },
    {
        "title": "Should we insert empty blocks into the blockchain?",
        "question": "It seems that there are two conflicting instructions in the assignment:\n\nThe README implies that the miner gets started first, right before the transaction generator. It is thus possible that the miner mines a block with no transactions.\n\nThe README mentions the following in grading: \"If the first transaction inside the second block of the three nodes are the same, you get full grade for this item. We use the second block since we exclude the genesis block.\" However, given the first point, it may be the case that the \"first transaction inside the second block\" does not exist.\n\nShould we thus only insert blocks into the blockchain if they have transactions? In other words, should our clients mine no blocks when the transaction generator is off? Or will the graders always start the transaction generators before they start the miners?\n\n",
        "other_text": [
            "Yes the transaction generator of a node will always be started before the miner.\n\n(optional) You can set a minimum number of transactions that you would want to include in a block before mining\n\n"
        ]
    },
    {
        "title": "Extension Until End of Day b/c Git Issues",
        "question": "Hello, I was hoping that I could submit the assignment a little later today. I had some computer difficulties with git and accidentally overwrote my code, so I had to start over. Thankfully, I remember how to do most of it, so I should be up and running soon. I would really appreciate it. Best, Tejas",
        "other_text": [
            "Sure, please submit it by tonight."
        ]
    },
    {
        "title": "Multiple withdraw transactions from an account in one Block",
        "question": "Hi,\n\nI have a question about the number of transactions in a block.\n\nIf I use the account-based model, I cannot add multiple withdrawing transactions from an account using the same account nonce. However, in the beginning, there is only 1 account assigned with a positive balance, which means all transactions can only withdraw from that account (all with the account nonce + 1). This implies that only one of the initial transactions can be put into a block (otherwise there could be double-spending transactions). \n\nDo we still have the number of lower limits for A8? If so, how should we deal with this problem? Thank you very much.",
        "other_text": [
            "Do we still have the number of lower limits for A8?\n\nNo, you don't need to satisfy the requirements for past assignments.\n\nThis implies that only one of the initial transactions can be put into a block\n\nYes this is true. \n\nAfter the first few transactions, you should be able to have independent, concurrent transactios (eg A->B, C->D) which can be inserted in the same block.\nOne way to do this is : tx-generators can create and save multiple key-pairs (accounts). \nWhen any new address receives a transaction, it should be added to the State.",
            "I have a similar question: Since the problem with multiple withdrawals from the same account is the nonce, can we do the nonce check on the state of the block we're creating instead of the state of the tip? Since we're copying the state of the tip before executing the first transaction, we know that all subsequent transactions will be valid. Is this approach correct?",
            "This would make verifying blocks/transactions harder, but would still prevent double spending? ",
            "Didn't fully understand your question. Are you suggesting we update the state after verifying each tx, and verify subsequent txs according to that state?\nThat would not work because transactions within a block are not ordered chronologically.\n\nSo when you are verifying/creating a block, you should make sure that all the transactions in the block makes sense according to its parent's state. (=> when you're creating a block, the tip's state)",
            "If we are not updating a temporary state after verifying each transaction, should we keep track of which sender addresses have been used when creating a block and only add valid transactions to a block with a sender address which has not been used before?",
            "You could use a temporary state, but check that transactions are valid according to this temporary state, as well as the parent state\n\n",
            "I think this works (and is possibly the simplest way to ensure there are valid blocks being generated)."
        ]
    },
    {
        "title": "state and ICO",
        "question": "Should the ICO occur when the genesis block is created (i.e. when the blockchain is initialized)? Also should the \"State per block\" hashmap be stored as a field within the blockchain struct or should it be kept separate similar to blockchain and mempool?",
        "other_text": [
            "You should store a HashMap<Block_hash, State> in your blockchain , i.e, there will be a State associated woth every block\n\nYes, the ICO should occur when the genesis block is created (You are defining the State of the genesis block)"
        ]
    },
    {
        "title": "Balance at ICO and accounts",
        "question": "I was a bit confused about the implementation details here. When we initialize an account, should we define an initial balance so that transactions have something to withdraw from?\n\nAlso, should we have a bank of accounts to send transactions from or should we just randomly generate accounts everytime we make a transaction?\u2019\n\n",
        "other_text": [
            "In the ICO, you need to have exactly one account (say A1) with a positive balance.\nAll other accounts would initially have a 0 balance, but will receive coins through transactions from A1.\n\n",
            "So basically does A1 initially contain the total balance that will ever be in circulation?",
            "Yes",
            "What account address do we use? Can this be random or is there a specific one?",
            "You can generate a random keypair from a predefined seed (for each node), and use that account\n\n#307 may be useful"
        ]
    },
    {
        "title": "check transactions for mempool",
        "question": "when we're doing the spending checks for a transaction before inserting it into the mempool, should we use the block state at the tip of the blockchain when looking up an account's balance and nonce?\n\n",
        "other_text": [
            "Yes you should."
        ]
    },
    {
        "title": "When to \"Execute a Block\"?",
        "question": "Do we execute a block as soon as it is added to a local blockchain, or only once it is k-deep in the longest chain?",
        "other_text": [
            "You are not required to implement k-deep for the assignment.\n\nFor the purposes of the project, you can execute a block when it's inserted at the tip of the blockchain\n\n"
        ]
    },
    {
        "title": "Removing tx from the mempool",
        "question": "Should we remove a tx from the mempool if its account nonce is lower than the longest chain's account nonce for a particular account?",
        "other_text": [
            "No, that would be an invalid tx; and the whole block should be rejected",
            "I thought we had to priodically clear the mempool of invalid transactions?",
            "That's right.\nAlso if you receive a block with a tx invalid according to the current state, you should reject the whole block",
            "So just to confirm, after updating the longest chain we have to remove txes from the mempool which are no longer valid??\n\n",
            "Yes",
            "Isn't there a potential that the longest chain switches though? In that case we would be throwing away txes that are potentially valid right?\n\n\n\nCan we just ignore this case?",
            "Yes that could happen.\n\nIn such a case, the onus is usually on the senders to resend their transaction if their tx isn't on the longest chain...\n\nFor the purposes of the assignment you can ignore this case",
            "we should remove the tx from the mempool if we cannot find the sender of the tx in the state of the blockchain tip right?\n\n",
            "Yes - that would mean the sender has no coins"
        ]
    },
    {
        "title": "Block state api",
        "question": "Quick question about how the output json should be formatted. To print the tuple as suggested, I am creating a vector of strings that represent \"(transaction hash, output index, value, recipient)\" and posting that as respond_json!(req, states);\n\nIt looks like this in browser:\n\n(raw data):\n\n\n\nIs this output format ok?",
        "other_text": [
            "I think so. Will confirm shortly",
            "Sorry, one more question to add on to that. Since my state is a map, and I get the UTXOs stored in there by iterating through the map, the order in which the state is output is not deterministic. So my state at block 10 is the same across the three nodes, but the ordering in each list output is different. Is that ok?",
            "Different ordering is fine. We will sort the entries before comparison",
            "Yes, this is fine. As long as it's a vec of strings",
            "Just double checking, each entry in the list needs to be a stringified form of the tuple and cannot be like a JSON object or ordered list?",
            "Correct",
            "The specs say (\"Account1\" is a placeholder for your entry representation.) And make sure to include \"address, account nonce, balance\" 3-tuple in the account information representation.\n\nSo can we use any representation we like (not necessarily the tuple like above), as long as it is one big string?",
            "Yes"
        ]
    },
    {
        "title": "Transactions to yourself",
        "question": "As a sender of a transaction, are you allowed to choose your own address as the receiver?",
        "other_text": [
            "Yes"
        ]
    },
    {
        "title": "state struct implementation",
        "question": "The state struct is suggested to be implemented as HashMap<account address, (account nonce, balance)>\n\n1) So I implemented as Hashmap<Address, (u32, u32)> which maps an account address to its nonce and balance. And I just call state.get(signer_address) to get the (u32, u32) pair - Is this correct? If so, how do I index the enum to find the account nonce and balance separately?state.get(signer address)[0] doesn't seem to work. \n\n2) For the state per block, we update the state of a particular address every time after a transaction, but a block contains mutilple transactions and multiple addresses, how can we have a state for the block?\n\n",
        "other_text": [
            "1. You can access the field of an enum like this: state.get(address).0\n\n2. The state per block is stored in the blockchain as Hashmap<block hash, State>. So each block is associated with a State struct which in turn maps all accounts and their states after the transactions in that block were executed. ",
            "also state should be included in the worker struct like the mempool right? ",
            "If it's a different object, yes.\n\nBut it's easier to have it as a field within the Blockchain struct"
        ]
    },
    {
        "title": "u32 <> usize conversion",
        "question": "We implemented Transaction.value as usize, nonce and balance as u32. The conversion between the two in this assignment is kinda a headache. I'm wondering if there are specific reasons for implementing these two values in different data types - since the major difference between u32 and usize is the memory size, which I don't see as a problem here?\n\n",
        "other_text": [
            "You can use any data types as long as it makes sense."
        ]
    },
    {
        "title": "setting up seed based on port",
        "question": "I get the idea of setting different seeds based on different IP ports, but not sure about implementation\n\nI tried use url::quirks::port to fetch the IP address and port =  127.0.0.1:6000 to check the port number, but doesn't seem to work. Thanks!\n\n\n\n",
        "other_text": [
            "You can use p2p_addr in main.rs\n\nEg: p2p_addr == \"127.0.0.1:6000\".parse::<net::SocketAddr>().unwrap()\n\n",
            "ic, sorry may be dumb q but aren't we setting up the genesis address in the blockchain's new() function? how can we pass in the p2p_address to the new() function?\n\n",
            "You can use this to pass keys to the new() function of transaction generator.",
            "similarly we should pass in this argument to transaction generator and miner since the transaction generator for node 6000 stores a different list of avaliable keys than the transaction generator for node 6001? \n\n",
            "Yes you can pass the initially generated keys to the tx generator.\n\nI don't think the miner needs it",
            "On a related note, in our transaction generator of node 6000, for example, are we only generating transactions that originate from the genesis address of node 6000? but this doesn't make sense since we want to dynamically create more key pairs....\n\nSo are we storing all avalible addresses into the State vector of node 6000 and pick a random address from the state vector to generate transactions in the tx loop?\n\n",
            "The tx generator should store a list of keys controlled by itself.\n\nInitially yes it will only contain the key hardcoded in the genesis. Once the txgen dynamically creates new key pairs, you can add these keys to the list.\n\n",
            "like by including \"key_pairs: Vec<Ed25519KeyPair>\" as part of the Context struct in transaction generator, and popping the last key pair before appending a newly generated pair in every loop?\n\n",
            "like by including \"key_pairs: Vec<Ed25519KeyPair>\" as part of the Context struct in transaction generator\n\nYes\n\nand popping the last key pair before appending a newly generated pair in every loop?\n\nno you don't need a newly generated pair in every loop, and shouldn't pop existing keys. ",
            "wait \n\nOnce the txgen dynamically creates new key pairs, you can add these keys to the list.\n\n\nhow can the txgen dynamically create new key pairs if we don't intentionally create new key pairs in each round? ",
            "You don't need to create them in each round\n\n(eg, you can create a new key with probability $p$, otherwise use existing keys for the tx)",
            "Why do we need to do this?"
        ]
    },
    {
        "title": "Transaction Mempool update",
        "question": "If i understand this correctly, we should implement Transaction Mempool update after we updated the state and before we inserted the block into the blockchain in Message::Block, correct?\n\nIs there anywhere else that we should do this update?\n\n",
        "other_text": [
            "Whenever you insert a block at the tip of the blockchain (miner, Blocks)"
        ]
    },
    {
        "title": "Efficient way to clean up mempool",
        "question": "Is there an efficient way to clean up the mempool following a state change? \n\nMy transaction generator produces transactions quickly, and upon updating my longest chain with a new block (and new state), almost all transactions that were created previously will now fail the transaction spending checks to validate balance and nonce. This is because I don't have many accounts set up, so the nonce check will almost certainly fail. \n\nIs a reasonable solution to this to clear out the mempool entirely after each block is inserted?\n\n",
        "other_text": [
            "1. Consider using a lower tx generation rate\n2. Maybe with some predefined probabilities you can create new accounts and send a tx from an existing keypair controlled by Node A to this new keypair controlled by Node A\n\nIs a reasonable solution to this to clear out the mempool entirely after each block is inserted?\n\nNo"
        ]
    },
    {
        "title": "Unique key pairs for different nodes and processes",
        "question": "The specs say: \"On different nodes/processes, transaction generator should control different key pairs.\"\n\nI'm not fully sure how to do this. Do we just create an empty vector of key pairs in the transaction generator (outside the loop) which is then populated when the loop starts by generating random key_pairs?  \n\n",
        "other_text": [
            "Initially you can set up one (deterministic) key-pair for every node, that is passed to the new() of tx generator of that node. (https://edstem.org/us/courses/28225/discussion/2118395?comment=4848486)\n\nLater on, the txgen can use this key to create transactions, and can also create new random keypairs. (store all of them in a vector)",
            "Will we need to pass in the same seed to the new() of blockchain since that's where we're creating the first state?",
            "Yes.\n\nOr you can pass a vector containing initial keypairs to new() function of tx generator",
            "I meant for creating the genesis block we'll need to pass it to the new() of blockchain. We'll also need to send it to the tx-gen.",
            "Sure.. You could also hard-code the seeds in the new() of blockchain ",
            "Wait I think I am confused about exactly what to do here. Doesn't the first account in the genesis block need to be different across all the nodes? And I thought we were using different seeds for the genesis account based on the different port numbers. How do we change the seed based on the node if we're hardcoding it in the new() function?",
            "You can hardcode 3 accounts in genesis using seeds say 0,1,2.\n\nThen you assign keypair with seed 0 to the tx generator of say node 6000, keypair with seed 1 to 6001, so on..\n(See #355) ",
            "You can store the public keys in the genesis state.\n\nWon't inserting 3 public keys in the genesis state violate the following requirement from the assignment specs?\n\nYou can do initial coin offering (ICO) by inserting an entry into State struct. In the grading section, we require the ICO to insert exactly one entry.\n\n",
            "We will not strictly enforce this. (but only one account has a positive balance)\n\nBut you can have a separate list containing known public keys; and add the account to the State only when it acquires some coins",
            "Given we are generating the same genesis block for each miner, wouldn't we need three accounts with positive balance (one for each node to initiate the first transactions from)?",
            "No, only one of the nodes (say A) will start with a positive balance.\n\nThe other nodes can start making transactions once it receives some coins from A.\n\n",
            "Makes sense. So to clarify, can we still get full credit if we have multiple accounts at ICO but only one has nonzero balance.",
            "Yes",
            "1. Should the genesis block's State only have one initial address corresponding to the node's seed or three initial addresses from all three node seeds? I'm confused because if it is the former (each State has a single address) and we start three nodes, and each of them separately creates a blockchain, wouldn't they each have three different genesis blocks since the respective States of each genesis block has a different initial address? This doesn't seem to make sense.\n\n2. Why does each node have to have a different list of addresses? Do they all have to be made using the same seed as the genesis block's initial address or can they be completely random? Are these addresses recipient addresses only or can they be senders as well?",
            "(#384) - Either design would work.\n\nif it is the former (each State has a single address) and we start three nodes\n\nThis single address would belong to the one node starting with a positive balance (and would remain the same across nodes).\n\n\n\nWhy does each node have to have a different list of addresses?\n\nFor a node to create transactions (i.e., to send coins), it needs access to the secret key corresponding to the sender account.\nSo every node needs to maintain a list of keypairs/accounts that it controls and can send coins from.\n\nDo they all have to be made using the same seed as the genesis block's initial address or can they be completely random?\n\nHardcoding one address for each node according to the seed is an easy way for all nodes to have access to the initial accounts that every node controls. You can later create random keypairs/accounts within the tx generator.\n\nAre these addresses recipient addresses only or can they be senders as well?\n\nRecipient addresses can be any of the known addresses in the current State. Sender can only be an address controlled by the node, since you need to know its secret key to sign the transaction",
            "So there will be no conflict if the three genesis blocks (one for each node) are different (meaning that each genesis block's State will only contain the address based on the node's seed and only one of them will have a positive balance while the other two are 0)?",
            "(meaning that each genesis block's State will only contain the address based on the node's seed and only one of them will have a positive balance while the other two are 0)\n\nThis is incorrect, would cause each node to have a different genesis block. If node A has a positive balance in ICO, then ALL genesis blocks' state would contain only the address corresponding to node A's seed.\n\n(you can just have all three addresses in the genesis block, with only one predefined node having positive balance. This is acceptable, and easier ig)"
        ]
    },
    {
        "title": "creating new accounts?",
        "question": "So if we only create new user accounts when the transaction generator create a new key pair (i.e. turning the new key pair into an address and append it to the current state), doesn't that mean when a node is picking receiver addresses (i.e. randomly selecting an address from the state), it can only access the addresses that it controls but not the addresses controlled by other nodes?\n\n",
        "other_text": [
            "The new account should be included in the State when it receives coins, and that tx is inserted into the blockchain.\n\nNow all other nodes can send coins to this address",
            "oh makes sense! thanks",
            "Could you expand on this? How do other nodes know about this new address from the state?",
            "The state would contain the balances of every account; since this is stored within the blockchain struct, all nodes can obtain a list of addresses from this"
        ]
    },
    {
        "title": "When to update state?",
        "question": "I am confusing when should we update the state and do a transaction check. Currently, I add my transaction check in the update state method, so every time we will update the state first, if it is a success, it means all transactions are validated, and I will add to the blockchain at the same time. But I soon realized there is a problem at the beginning of the blockchain, we only have one account under our control and we will generate the transaction based on that account. Let's say it is account A with a balance of 10 and nonce 0. And my initial state will record this information.\n\nI used to generate the valid transaction from the tip's state, which in this scenario is the initial state. And if I generate two transactions, one is sent to account B with a balance of 10, and nonce 1. And Another is sent to account C with a balance of 10, and nonce 1. Then, at least one of my transactions will be failed during the update state process, because running out of balance and with the same nonce. So my state chain and my blockchain are always stuck and do not expand. How should I resolve that issue?",
        "other_text": [
            "Yes at the beginning of the blockchain you would have this issue.\n\nYou can circumvent this for later blocks by creating multiple accounts controlled by the same txgenerator (see #345) "
        ]
    },
    {
        "title": "A7 misnamed API parameter?",
        "question": "Working through A8 currently, just realized that I messed up my tx-generator API by using lambda not theta. Have fixed it moving forward, hoping this won't cause too many problems with A7 grading.\n\nDo I need to re-submit or can it be worked around?",
        "other_text": [
            "Yes please resubmit.\n",
            "I just resubmitted, thank you very much!"
        ]
    },
    {
        "title": "account nonce",
        "question": "should the account nonce only be updated to nonce + 1 for the sender? or should we also increment the nonce for the receiver of a transaction as well?",
        "other_text": [
            "It is only updated for the sender."
        ]
    },
    {
        "title": "Json Formatting Questions",
        "question": "Below I have attached a photo of my attempt to format the Transactions array of arrays into text. \n\ncollect() is not callable for this setup. Do you all have any recommendations? ",
        "other_text": [
            "Create an empty vector v_string : Vec<Vec<String>> before the second for loop. Also, add another for loop inside the second for loop that iterates over SignedTransactions and pushes the hash of transaction into a vector after turning them to string. After this inner for loop ends, push this collected vector into v_string. You don't need the .collect() line if you do this.",
            "That sounds like it will work. Thank you"
        ]
    },
    {
        "title": "general overview of transactions in A8",
        "question": "I'm not totally sure how transactions work in this assignment; particularly, it seems like much of how they are handled in A7 must be changed.\n\nI assume that transactions should no longer be randomly generated with generate_random_transaction(). In creating a transaction, do we use an initial given / \"harcoded\" key pair to use as a sender address? Generally, what key pairs can we use as sender addresses and how do we get such addresses?  Also, are receiver addresses randomly chosen from the state? Similarly, what addresses can be used as receiver addresses and how can we get/access them?\n\nSome clarification would really help, thanks!",
        "other_text": [
            "Yes you would have a set of fixed key pairs each node would use (say each node controls 3 key pairs). See #307 on how to generate these key pairs.\n\nAlso, are receiver addresses randomly chosen from the state? Similarly, what addresses can be used as receiver addresses and how can we get/access them?\n\nYes receiver addresses should be randomly chosen from the state. Every node knows the other nodes' public keys and these can be used to get receiver addresses. ",
            "Thank you!\n\n"
        ]
    },
    {
        "title": "Negative transaction or balance",
        "question": "In the account based model, is a transaction allowed to have a negative value and/or can the balance of an account be negative? I am assuming no, but in Assignment 1 it said the type of  the value in a transaction should just be an integer and not an unsigned integer\n\n",
        "other_text": [
            "No, balance or txn amount cannot be negative.",
            "should we add a check to ensure this then when verifying transactions? Or should we change the type of value in the transaction struct to unsigned integer?",
            "either is fine"
        ]
    },
    {
        "title": "Receive Transaction Error / Merkel Tree Error",
        "question": "\n\nI am getting an error that the transaction is not being received? Am i missing something in this block? \n\n \n\nUPDATE: I was able to solve the crashing of the API by passing an empty vector into the merkle root of the block and solve the index out of bounds error. Now it is functioning but all the blocks are printing an empty array of transactions because I am no longer adding to the block from the mempool. \n\nAm i doing something in the wrong order? \n\n\n\n",
        "other_text": [
            "Here is merkle.rs where the error happens at line 52 when I pad the trees:\n\n\n\n",
            "I swapped it for tree.layers[0].len() - 1... It now does not crash but outputs all blank trasnactions. ",
            "\n\nHere is my code if that would help you offer guidance. ",
            "Is this the tx generator loop?\n\nYou don't seem to have created the transaction?\n\n(  finished_tx_chan.recv()  would work only if the sender on the channel sends a tx on it - can't be used in this scenario. You should create txs like you created blocks in miner loop) ",
            "That is my miner loop in which I add blocks from the mempool. I send transactions to the mempool in the transactions loop. I have practice today during office hours, but would you be available to meet afterward? Around 8pm? ",
            "Viraj is holding zoom office hours at 8pm. You can attend that if it's convenient",
            "I will",
            "Ok I got it to work! Testing and submitting shortly. One Thing I have noticed though is my block mining speed seems to have slowed. "
        ]
    },
    {
        "title": "/blockchain/state?block= response format",
        "question": "For the account-based model, what is the exact format of the  /blockchain/state?block= API method response?\n\nCurrently I am generating responses in the following format:\n\n[\"a0d741628fc826e09475d341a780acde3c4b8070, 5, 730762\",\"7f37ae93038b10a6b2faaa38c6dcda709141920d, 1, 48192\",\"85058f7a3f8d5c3ff96e34a0beee1a00ea52766b, 1, 5876\",\"aabe933be154a4b5094e1c4abf42866505f3c97e, 2, 783\",\"9ba4729212f7caac08634cc3ae76b27529f03827, 1, 18712\",\"f772080577a289eb315e45b7d4201c6142d870ec, 0, 44298\",\"d1759b347ee7adace917a6f93986994bccd6ee70, 0, 52969\"]\n\n1. Could you please let me know if this the correct format?\n\n2. Should the account entries be sorted in the response?\n\n\n\n\n\n\n\n",
        "other_text": [
            "1. Yes\n2. Not required, we will sort it before comparison",
            "Thank you Ashwin."
        ]
    },
    {
        "title": "multiple transactions from same address",
        "question": "Can the same address have multiple transactions within a block if their balance is sufficient? \n\nFor example, if we have the following scenario:\n\nA: account_nonce = 1; balance = 50\nB: account_nonce = 1; balance = 0\nC: account_nonce = 1; balance = 0\n\nTX1: A->B, 10 coins, account_nonce = 2\nTX2: A->C, 20 coins, account_nonce = 2\n\nWould a block containing both TX1 and TX2 (in any order) be valid?",
        "other_text": [
            "Would a block containing both TX1 and TX2 (in any order) be valid?\n\nNo\n\n(also see #345)",
            "if we create multiple key-pairs, should miners choose which transactions to add to a block to prevent double spending? For instance they could check that each address only spends once per block (while creating the content for a block), since for higher txn mining rates and randomized sender addresses, it is pretty likely that a block is rejected because one address has 2 transactions within a block.",
            "Yes, a miner should ensure that the block being created is not invalid"
        ]
    },
    {
        "title": "API block order",
        "question": "Does the longest chain start from block 0 or block 1?\n\n\n\nFor example, if the api wants the state for block 1, is that the genesis block or that block that comes after it?",
        "other_text": [
            "block 0 would be the genesis (state after ICO)"
        ]
    },
    {
        "title": "Generate Address from key_pair",
        "question": "Hello,\n\nI saw in #307 how to generate a public key pair that is deterministic for each node. But Transactions use Address rather than key pair, so I was wondering how we are supposed to deterministically get an Address given a key pair?\n\nAlso, just to clarify, this deterministic key pair for each node includes both the public and private keys, right? How are we supposed to deal with the public key, or is that all done internally in the signing function?\n\nThanks!",
        "other_text": [
            "You can use Address::from_public_key_bytes (that you implemented in A1) "
        ]
    },
    {
        "title": "Possible extension?",
        "question": "Hi, sorry for asking the extension again. But I have been taking nearly 24 hours on this assignment and still haven\u2019t debug successfully. Would it be possible to have a 1-day extension of the deadline?",
        "other_text": []
    },
    {
        "title": "How many accounts should each node control?",
        "question": "In #307, you said:\n\n\"Initially you can hardcode one keypair to each node.\n\nLater you can dynamically create more keypairs in the tx generation loop ; and store all the keys that the node controls in some vector.\"\n\nAnd in #364, you said:\n\n\"Yes you would have a set of fixed key pairs each node would use (say each node controls 3 key pairs)\"\n\n\n\nAre we graded on a specific number of key_pairs controlled by each node / a total number of accounts in the entire system?\n\nWould it be okay to stick with only 3 accounts in the entire system?",
        "other_text": [
            "In terms of grading criteria it looks like you probably could, but then you're going to be generating a ton of transactions for just one of them to work per block (due to the nonce check). I didn't like this so I made it so I can dynamically generate keys.\n\nOnce you've got the original 3 key_pairs (one per node) creating a list of newly generated Ed25519KeyPairs that are controlled by that same node isn't too bad. The way I did this was every time you assign a receiver to a transaction, with some probability I would create a new keypair, rather than send to an address already represented within state, and store this new keypair in a vector within the transaction generator. Then I assign the receiver to be this new keypair's corresponding public key address. Then the next loop iteration, when assigning a sender, you can randomly select one of the key pairs the node controls that are stored in the Vec<25519KeyPair>.\n\n",
            "I'm having rust problems since I can't append an Ed25519KeyPair to a vector (since it doesn't implement Clone/Copy and we don't have control over that struct). How did you get around this problem?",
            "vector.push(new_keypair) should work?\n\n",
            "The problem is I also need to use that value to get the receiver address, and rust won't let me do both. The following gives an error \n\ncannot borrow vec as mutable because it is also borrowed as immutable\n\n\nvec.push(key_pair);\n\n let bytes = key_pair.public_key().as_ref();",
            "Maybe your vec is not mutable",
            "The vec is set as mutable when I create it as a struct field",
            "Assign to bytes before pushing the key_pair to the vector",
            "Another workaround is to insert the keys outside the scope of the first borrow. "
        ]
    },
    {
        "title": "Transaction Mempool Update Timing",
        "question": "Can I do the Transaction Mempool Update at a time different than the suggested time (ie, not following a state update)? When I am mining blocks, I check if the transaction has a valid account nonce and balances before inserting it into the block. This seems like an ideal time to get rid of all invalid transactions, as I am already looping through all the transactions. \n\n",
        "other_text": [
            "Sure"
        ]
    },
    {
        "title": "How do I send Update signal to miner mod?",
        "question": "After adding a transaction verification function which requires a lock on the blockchain,  my miner loop now completely diverges.\n\nPreviously, the block was always successfully inserted after it was sent, so the parent hash was always the most recent block's hash. However, now it can fail, but I need to communicate that.\n\nThe Update signal is partially implemented, but I don't know how to send it over the control channel.\n\nOr is there a better place to check tx validity? Or should I assume txs from the mempool are valid?\n\n",
        "other_text": [
            "You should check tx validity before inserting into mempool. So afterwards you can assume mempool txns are always valid.",
            "(visible to staff only)\n\nWe need to check tx validity according to current/new State even when generating blocks right?\n(Eg: both A->B and A->C won't be valid concurrently)\nSo block validity won't fail",
            "Oh ok I misunderstood the question I think.",
            "If you are talking about checking validity with respect to parent's state, then yes you should do that while constructing new blocks in the miner. But then your block insertion would never fail because other nodes would also check the block txns with respect to its parents' state.",
            "How do I get access to the parent's state without having a lock on the blockchain?",
            "Maybe only clone the parent's state into a variable and then check validity against that? You won't need to lock the blockchain for that."
        ]
    },
    {
        "title": "Where to store account_nonce",
        "question": "I see that account_nonce is a field in the Transaction struct, but how are we supposed to link it with a given address? Do we look at the most recent state and increment from there? Or do we store it as part of the Address struct?",
        "other_text": [
            "Each account address will have an account nonce associated with it.\n\nWhen you create a transaction, the account nonce field should be set to sender_account_nonce + 1"
        ]
    },
    {
        "title": "What should the account nonce and balance be?",
        "question": "Should the account nonce be a randomly generated u32 and the balance be 0 when updating the states with the account-based model? ",
        "other_text": [
            "No, account nonce would be updated to prev_nonce + 1.\n\nBalance should be updated according to the values of the transactions in the block (after checking validity)",
            "What is prev_nonce in this case when a new block is created? Is it a randomly generated value?",
            "Account nonce is associated with transactions and accounts, not blocks.\n\nIf you're creating a tx from A to B, account nonce of the tx should be set to the A's (sender's) account nonce + 1.",
            "Should the state struct be instantiated in the Blockchain or Block struct? ",
            "A copy of State for a block refers to the state after executing the block. We recommend using HashMap-like storage, e.g., HashMap<block hash, state>\n\nYou can store this in the Blockchain struct."
        ]
    },
    {
        "title": "paniced at generating seed address?",
        "question": "Hey ser, I tried to use the given function to generate seed addresses but it keeps giving the panic message. I tried to use 0 in place of seed but the error message persists - so i think I called this function incorrectly. not sure how to fix this\n\n",
        "other_text": [
            "it should be &[seed; 32] I think"
        ]
    },
    {
        "title": "Assignment Deadline Extension",
        "question": "The deadline for part 8 of the project has been extended to Sunday 11/27 midnight.\n\nWe will be releasing the grades for part 7 shortly. You can use that time to respond to any comments on your part 7 submission as well.",
        "other_text": [
            "This is so kind! Thank you all very much!",
            "epic",
            "So amazing!!!!!"
        ]
    },
    {
        "title": "What do we do when there is no state corresponding with a block?",
        "question": "One thing I noticed while running the code was that sometimes when calling get() on the parent's hash, the state hashmap may not contain the state. Is this even possible in a correct implementation? I seem to be updating state every time I insert a block to a chain, so maybe it's a concurrency issue?\n\nNot sure if it's allowed for me to send the zip file of my code for the TAs to double check this. ",
        "other_text": [
            "Everytime you insert a block into the blockchain, you should also insert a state corresponding to the block into the state map. So this issue should not happen ideally.\n\nThe only time a state might be absent is if the block is orphan or the parent is not yet inserted into the blockchain.",
            "That's what's weird though. Currently I always do that, and the tip does show up in the blockchain, but there is no corresponding state. "
        ]
    },
    {
        "title": "Office hours on 11/22",
        "question": "Hi! Do we have office hours tomorrow since the schedule follows Friday?\n\n",
        "other_text": [
            "Yes, we will."
        ]
    },
    {
        "title": "Initial addresses needed in each node's blockchain",
        "question": "I know the seed is important for the tx-gen to know which of the public keys are under its control, but when we initialize the genesis in each blockchain, all 3 account addresses need to be in all 3 nodes initial state right? Because otherwise if Node A sends coins to another account, Node B will not recognize the sender and will call the transaction invalid.\n\nThen, subsequent new senders created can then be the \"receiver\" in the transaction so other nodes can add to the local state.\n\nHowever, when we start, we need all 3 accounts to be in all the genesis blocks? (With only 1 having a non-zero balance)? \n\nEdit: I know with respect to grading we need just 1 entry in ICO, but still confused on how other nodes won't reject the sender if they don't know it, or will it be like in the first run, the first sender will also be a receiver so then the other nodes can add it?",
        "other_text": [
            "all 3 account addresses need to be in all 3 nodes initial state right? \n\nYes, just like the genesis block, the genesis state should be the same across all nodes.\n\nHowever, when we start, we need all 3 accounts to be in all the genesis blocks? (With only 1 having a non-zero balance)?\n\nThe genesis block does not need to have any transactions. But the state corresponding to the genesis block should have all three addresses and some initial balances according to your ICO.",
            "Just as a follow up, for the assignment specifications, would this violate this requirement?\n\nSince the state hashmap would actually have 3 entries after ICO?",
            "We will relax this grading criterion.\n\nBut you can have just the one entry after ICO, and use a different list to store all known addresses/public keys."
        ]
    },
    {
        "title": "Different ordering of transaction output",
        "question": "In my block state api, the output of transactions have different order across 3 nodes. Would it be fine or should we order it before output?",
        "other_text": [
            "https://edstem.org/us/courses/28225/discussion/2183342?comment=4994926"
        ]
    },
    {
        "title": "Clarify Requirement 1 for Grading",
        "question": "Req 1 says: The initial state after ICO should contain only 1 entry.\n\nCould you clarify what this means?\n\nIn another Ed question, a TA said that\n\nWe will not strictly enforce this. (but only one account has a positive balance)\n\nBut you can have a separate list containing known public keys; and add the account to the State only when it acquires some coins\n\n\nSo after my ICO I have 3 entries, with only one having non-zero balance, but I'm confused about how this is tested, since our BlockState is printed as an arbitrary string representation.",
        "other_text": [
            "Could you clarify what this means?\n\nIt means that there should be only one UTXO, or only one account in the initial state after ICO (genesis state).\nHowever, if you have implemented account-based model such that there are 3 accounts, with only one having a positive balance, this is fine too.\n\n\n\nSo after my ICO I have 3 entries, with only one having non-zero balance, but I'm confused about how this is tested, since our BlockState is printed as an arbitrary string representation.\n\nWe will check requirement 1 manually. \nPlease ensure that your entry consists of \"transaction hash, output index, value, recipient\" 4-tuple - if UTXO, \"address, account nonce, balance\" - if account-based.\n\n"
        ]
    },
    {
        "title": "from_seed_unchecked() error",
        "question": "With the following code (provided by a TA)\n\nlet mut key_pair_seed = &[seed, 32];\n\n let mut key_pair = Ed25519KeyPair::from_seed_unchecked(key_pair_seed).unwrap();\n\n\nI'm getting the following error\n\nthread 'main' panicked at 'called Result::unwrap() on an Err value: KeyRejected(\"InvalidEncoding\")', src/blockchain/mod.rs:165:79\n\nand I can't find any info on this error online. Do you know why this is happening?",
        "other_text": [
            "It should be &[seed;32] not &[seed,32]",
            "Ohh I see, thanks!"
        ]
    },
    {
        "title": "New sender never included in block",
        "question": "I am wondering how do we deal with the edge case that:\n\n1. we generated a new sender,\n\n2. we set it as a receiver in that generated transaction and inserted it into the mempool\n\n3. when inserting into the block, we randomly don't pull this transaction out for a long time\n\n4. Subsequent transactions using the new sender are rejected by other nodes because the original transaction that would have allowed other nodes to add this to their receiver has not been included in any processed block so far?",
        "other_text": [
            "Subsequent transactions using the new sender are rejected by other nodes because the original transaction that would have allowed other nodes to add this to their receiver has not been included in any processed block so far?\n\nYou don't generate a transaction having this new account as sender until it has a positive balance in the current state of the blockchain tip (until it is inserted in a block on longest chain, it would not even be in the State)",
            "Just as a follow up, once we generate a new sender, when would we put the new account into our list of \"controlled keys\" that the tx-gen can use to generate transactions? I'm not sure how to manage both the set of controlled keys vs state in the blockchain tip.\n\nThis is because based on #373 it seems like transactions can be generated with the new sender after it has been through at least one transaction where it is the receiver of coins, so I feel like my edge case still applies, but I am not sure if I am understanding this correctly.",
            "Oh I see, is it that even if we pick it as a sender, if it isn't in our state, then we discard the transaction and generate a new one in the next cycle until either it is in the new tip or we pick a different sender?",
            "You only pick senders that have non-zero balance in the state.\n\nWhile picking receiver, you can choose from {addresses in the tip's state} + {controlled keys not yet in state}. This would ensure every controlled key also has non zero balance eventually.",
            "when would we put the new account into our list of \"controlled keys\" that the tx-gen can use to generate transactions?\n\nYou can put it as soon as you generate it in your txn generator. Just ensure that you use the controlled keys as receivers as well as senders afterwards."
        ]
    },
    {
        "title": "Assignment 7 grades",
        "question": "We have released A7 grades and comments on Canvas.\n\nFeel free to email me and Viraj / comment on canvas / private post on Ed if you have any questions/concerns.\n\n",
        "other_text": []
    },
    {
        "title": "State changes at block 10",
        "question": "My state at block 10 changes pretty frequently from being at 2 accounts to being at 3 or more accounts (most of the time its at 3 or more accounts). Does anyone have a reason why this might be happening and how does grading work for this section? Would my grader wait to see whether it changes to being 3 accounts in a given time frame after reloading a few times?\n\n",
        "other_text": [
            "If you are generating new accounts only with some probability, then it might happen sometimes that there are not many new accounts being included till block 10. Maybe try generating a fixed number of new accounts right away (maybe in the first 5 blocks) so that they always get included.\n\nIn any case we will run your code at least twice on different machines and give you the highest grade among all the runs."
        ]
    },
    {
        "title": "Grading question",
        "question": "Are we graded on the checks mentioned in A8 in addition to the ones mentioned in A7, or just the ones in A8? Thanks!",
        "other_text": [
            "The checks done in previous parts will not be done again."
        ]
    },
    {
        "title": "Weird node behavior",
        "question": "When running my 3 nodes and the corresponding API calls (starting miner and tx generator on all 3) I see some weird behavior. Node 6000 tends to get stuck only generating txs (and a new block every once in a while). Node 6002 tends to only mine blocks. Node 6001 always blocks.\n\nI believe this behavior could be caused by some mutex lock issues, but I have no idea how to start debugging. Has anyone ran into this error?\n\n",
        "other_text": [
            "Try zeroing in on what part of the code is getting stuck in each node by putting print statements on receiving each message in the network worker.\n\nAlso put prints in the miner.",
            "I found that its blocking in Message::NewTransactionHashes(). Specifically when trying to get access to the mempool, which never unlocks. However, I make sure to drop(mempool) in all my other code (and it should drop automatically when it goes out of scope), so I'm not sure what's going on.\n\n",
            "Do you have a condition that checks if the vector to be sent is non-empty before you do peer.write() everywhere in your network/worker code? Sometimes empty messages can flood the network and keep the mempool/blockchain locked.",
            "I'm broadcasting instead of peer.writing, is that correct?\n\nYes, I check that len > 0 when broadcasting from Message::Transactions.\n\nI also make sure that len > 0 when broadcasting from my tx_generator, but it only ever broadcasts at max 1 tx at a time, so this may be a cause for the issue.",
            "Message::NewTransactionHashes and Message::NewBlockHashes should be broadcast and the rest should be peer.write",
            "Okay yes thats what I'm doing",
            "So do you have any idea where it could be going wrong? When the theta for tx-generation is too high it seems to block more commonly.\n\nAlso sometimes (due to blocking I suppose), newblock messages are not getting through, leading to the longest chain diverging",
            "Sounds like some thread is holding the lock for too long.\n\nAre you using scopes to ensure that the lock goes out of scope as soon as you're done using the mempool?",
            "Not scopes, but I'm manually calling drop(mempool) after every time I'm done using it",
            "Was this working in Part 7 ? If so then focus on the newly introduced code in Part 8. For instance, check if the blockchain introduced in txn generator is unlocking properly. It might be that this blockchain is staying locked and is holding up the rest of the code.",
            "I am running into the exact same error. Did you manage to sort this out and have any tips?",
            "Yeah I eventually solved this.\n\nFirst, I made sure to manually drop() the blockchain and mempool after I was done with the variable in every occurrence where I used them (I had missed some, which was causing weird locks).\n\nSecond, I had to tune both the tx-generation and block-mining parameters so that neither was running too quickly compared to the other (which often led to locks)\n\n"
        ]
    },
    {
        "title": "Clarifying posts about initial addresses",
        "question": "I know there have already been a lot of questions related to setting up the initial key pairs and addresses, but after reading through Ed many times, I still have some confusion/questions about this. \n\nIn  #355, we are told:\n\nYou can use p2p_addr in main.rs\n\nEg: p2p_addr == \"127.0.0.1:6000\".parse::<net::SocketAddr>().unwrap() \n\nFrom what I understand, it sounds like this is saying in main.rs we pass the p2p_addr as an additional argument to new() for the transaction generator. Then inside new()  for tx gen, we check if p2p_addr == \"127.0.0.1:6000\".parse::<net::SocketAddr>().unwrap() , and if so, say our seed is 0 and calculate the keypair and address using seed 0. Otherwise, check if p2p_addr == \"127.0.0.1:6001\".parse::<net::SocketAddr>().unwrap() , and if so, say our seed is 1, etc.\n\nIs this a correct understanding? If so, I am not sure what the use of storing all three initial addresses in the genesis block state would be. If the post was saying something else, would you mind explaining this again? Thank you for your help",
        "other_text": [
            "\n\nIs this a correct understanding? \n\nYes\n\nIf so, I am not sure what the use of storing all three initial addresses in the genesis block state would be. \n\nThis would be helpful for your transaction generator in each node to generate random transactions by choosing the ''receiver'' part of the transaction from the previous blocks' state.",
            "Does \"previous block\" mean \"parent block?\" If so, since we are generating transactions in mod.rs, how would we know what the parent block would be at this point since we are only creating transactions to put into the mempool and not yet associating them with any particular block? \n\nAlso, when generating a tx inside of the tx gen mod.rs for loop, when choosing to send to an address from the State (as mentioned in #335), would we just use the iter function of Rust's HashMap one time to get the first key (address) that is returned by iter , or is there another way to get a key?",
            "Does \"previous block\" mean \"parent block?\"\n\nYes.\n\nhow would we know what the parent block would be at this point since\n\nIn the tx generator, you should create txs based on the blockchain tip's state.\n\n\n\nwould we just use the iter function of Rust's HashMap one time to get the first key (address) that is returned by iter\n\nYes, you can use any logic to choose the receiver address. Could even choose a random address",
            "Okay, thank you.\n\nHow could we just choose random addresses -- I thought we need to take addresses from the State? Or were you referring to how just sometimes we want to generate new random addresses?\n\n\n\nAlso, with regards to the logic for grabbing an address from the State randomly, I was more so wondering if you had a suggestion for another way to do this rather than using iter . I wanted to find a different way of getting the address from the State hashmap but just couldn't figure out how to do it.\n\n",
            "How could we just choose random addresses\n\nSorry, I meant you could choose an address from State randomly.\n\nlogic for grabbing an address from the State randomly\n\nYou could use the hashmap.keys() or hashmap.values() iterator: It would visit all the keys/values in arbitrary order",
            "Oh okay, that is why I was trying to do then. But we are only generating one transaction each time through the loop in mod.rs, right? In which case, even if we use hashmap.keys()  or hashmap.values() , we will only end up using the first item that is returned since we are only generating one transaction each time we go through the loop. Is this correct?",
            "Yes",
            "\"you should create txs based on the blockchain tip's state.\"\n\nDoes this mean that txgen's Context struct has to have a blockchain as well?",
            "Yes",
            "How do we add the initial Ed25519KeyPair generated inside blockchain::new() to the vector of Ed25519KeyPairs in txgen\u2019s Context struct? The only thing we have access to is the Address which is the key in the genesis block\u2019s State struct\u2019s Hashmap<Address, (account nonce, balance)>.",
            "You also have access to the seed used to generate the keypair in blockchain::new. You can use the same seed in tx-gen to get back the same keypair.",
            "Not sure if I'm missing something but when I try comparing p2p_addr == \"127.0.0.1:6000\".parse::<net::SocketAddr>().unwrap(), I get the error: \n\nbinary operation `==` cannot be applied to type `smol::async_net::unix::SocketAddr`rustcE0369\n\nIs there a simple way around this?",
            "You can try using eq()"
        ]
    },
    {
        "title": "How to update state?",
        "question": "I'm a bit confused about a lot of what's going on in the state updates. The way I have it currently implemented is that transactions are generated based on the tip of the local blockchain in the transaction generator. When I insert a block into the blockchain in miner mod.rs, I mine on top of the last parent that the block mined (not the tip of the blockchain). Then I perform a state update by cloning the block's parent's state and updating it accordingly in miner worker.rs and network worker.rs before inserting the block into the blockchain\n\nBecause of this, I'm a bit confused how the state updates between different nodes. Lets say we have Nodes A and B and Blocks {1,2,3} that belong to Node A and Blocks {4,5,6} that were mined by Node B.\n\nLets say the blockchain looks like this:\n\n1->4->2->5->3->6\n\nSince the blocks don\u2019t take the state from the tip of the blockchain but instead from the parents, the states for blocks 1,2,3 will not include accounts and information from 4,5,6 and vice versa. I'm a bit confused how this would make sense and whether I'm understanding state correctly in this scenario?",
        "other_text": [
            "I mine on top of the last parent that the block mined (not the tip of the blockchain).\n\nYou should always be mining on the tip of the blockchain."
        ]
    },
    {
        "title": "Office hours on Friday",
        "question": "We will be having Zoom office hours this Friday at 8 pm (11/25) instead of next Monday.\n\nMeeting Link : https://princeton.zoom.us/j/8756915306\n\n",
        "other_text": []
    },
    {
        "title": "Final take-home exam",
        "question": "What is the timeline for the take-home exam? Also what is the format of the exam? (Ie open-ended questions vs multiple choice, number of questions etc)\n\n\n\nThank you!",
        "other_text": []
    },
    {
        "title": "Blockchain syncs slower when transaction generator begins",
        "question": "When I run the three node miners by themselves, the blockchain builds very rapidly (20 blocks/minute) and syncs almost perfectly except for the last three blocks usually in the chain. However, when I start the transaction generator, the blockchain takes a lot longer to sync (it does eventually sync up but not in the amount of time allocated for running the program in this assignment). In addition, mining blocks takes a lot longer for some reason (the rate drops down to about 5 blocks/minute). Do you know why this might be an issue?\n\n",
        "other_text": [
            "I figured out that the problem here was that my mempool wasn\u2019t properly cleaning invalid transactions out of the mempool which would cause the miner to mine blocks really slowly."
        ]
    },
    {
        "title": "Duplicate transactions across adjacent blocks?",
        "question": "Been debugging for a while now, not totally sure why I am occasionally having duplicated transactions across blocks. Even limited to just single ones.\n\nThe blockchains grow slowly, but in sync, with a harder difficulty. With an easy one, they diverge rapidly.\n\nBit stuck at this point, seems like I shouldn't be depending on diff tweaking to make my program run.\n\nUpdate: tons of duplicated txs, but printouts indicate they're being deleted from mempool.",
        "other_text": [
            "Are you updating the state correctly? A child block with the same transaction as its parent would be considered invalid since the parent state would already have the nonce used in the parent block. So your miner should not insert the same transaction while mining the child block in the first place. Make sure you are doing this check in the miner/mod.rs.",
            "Was using tip, not parent. Thank you!"
        ]
    },
    {
        "title": "Rust Difficulty with Ed25519KeyPair (not clonable)",
        "question": "I'm having a lot of rust-related difficulties dealing with keypairs of type Ed25519 since they are not clonable. For instance, if I wanted to add a keypair to my keypair vectors and also send the keypair to my blockchain struct, how would it be possible to do both without cloning?\n\nWould you recommend passing around a &Ed25519 borrow/reference? However this leads to further complications. Is there any other workaround for this?",
        "other_text": [
            "One solution is to use to_bytes and from_bytes.\n\nHowever, I've been able to avoid using it as I use the keypair only once (while signing the transaction). The key pair that I add to my vector that owns the key pairs for that node is one that is created as a receiver. Therefore I don't need to use it anywhere else except inserting it into my vector.",
            "You don't need to send your key pairs to the blockchain struct. The blockchain only knows addresses (20 bytes each) through the state.\n\nThe keypair only needs to be sent to the vector of keys in the tx-generator.",
            "That makes sense, but what about the keypair for the genesis block, since we need that when calling blockchain::new() and the transaction generator/state is created only after/at the same time? \n\nthough i guess we can solve this by just sending the address corresponding to the keypair to the blockchain?",
            "Key pairs in the genesis state should be generated from a fixed seed (which is u32). So you only need to know the seed not the keypair. Use this function to do that."
        ]
    },
    {
        "title": "Account-based model State and ICO",
        "question": "I'm confused on what should happen at the ICO in the account-based model. Should there be a single account in the Hashmap? Does the State struct only contain accounts with a positive balance, or should accounts with a balance of 0 also be present in the State struct as well?",
        "other_text": [
            "#384"
        ]
    },
    {
        "title": "A7 Grading, # of Transactions",
        "question": "Hello, hope everyone is doing well and having a nice Thanksgiving!\n\nI had some questions/concerns about the grading of my A7 project. I see on Canvas that I lost 2 points due to not having enough transactions in the blockchain. Would I be able to receive some clarification on this point, or potentially receive a regrade / retesting? Before submitting, I was sure to test with 3 nodes with tx-generators at theta=100 and miners at lambda = 0, and I was comfortably hitting the 500 tx in 5 minutes. Currently, I am running it and just got 825 transactions in 5 minutes.\n\nIs it possible for this point of my grading criteria to be regraded, or to receive some feedback / info about how my code performed in testing/grading? Thanks",
        "other_text": [
            "Will rerun your code and let you know.",
            "@Viraj I re-ran this:\n\n#Transactions in 5 minutes is ~850. But there are ~8.7 transactions per block on average.\n\nMaybe run once on your computer too?\n\n",
            "Yes I am getting similar numbers. I think that was the reason behind the 2 marks.",
            "Hi Adam, \n\nWe had cut 2 points because there not enough transactions per block. There should be >= 10 txns per block on an average, we ran your code and are getting around 8 per block.",
            "Thank you for checking again. It may be possible I did not submit the most updated version of my code with proper parameters to hit >= 10 txns/ block. Would it be possible to revise this submission before the due date of the next? (understand if not)",
            "Sorry, this is not possible"
        ]
    },
    {
        "title": "Mempool Mixups between nodes",
        "question": "I'm getting a weird error where each node is generating transactions according to the senders in their node (separated by the deterministic key/pair seed). This happens in tx_gen/mod.\n\nHowever, upon going through the mempool in miner/mod, I'm also obtaining transactions that were generated from other keypairs/nodes. Is this normal, eg should all processes have the shared mempool? I guess this makes sense if we consider the transaction broadcast messages. \n\nIn such a case, should we just filter out the transactions that don't have a valid sender? I guess this also means that we may not hit our lower limit for the transaction count per block, but based on previous posts I'm guessing this is fine.",
        "other_text": [
            "You should include transactions created by any node/account in the block as long as it's valid.\n\nYes, your transaction broadcast messages would ensure that all nodes' mempools are in sync",
            "Does this then mean that for an account-based model, we have to add all 3 accounts to the state of each node in the ICO? because otherwise, how would transactions from other nodes be processed if we didn't have the sender information?\n\nand to satisfy the grading requirement, we can just choose one account (account 0 for instance) to have a non-zero balance in all of the three nodes?",
            "Does this then mean that for an account-based model, we have to add all 3 accounts to the state of each node in the ICO? \n\nYes.\n\nwe can just choose one account (account 0 for instance) to have a non-zero balance in all of the three nodes?\n\nYes."
        ]
    },
    {
        "title": "issues with creating copies of the state",
        "question": "I want to create a copy of the existing tip state so when I am looping through transactions in a block, I can check if the transactions together are valid so I can create a new state and insert it into the blockchain. I am having issues, however, where the error says, \"data is behind & reference and cannot be borrowed as mutable\"\n\nIs there a good way of creating a copy of a hashmap I can use for looping through transactions and inserting it into the state map when I insert the block if it is valid? \n\nThis is specifically the State struct within my blockchain block-state field <H256, State>\n\nMore Reference:\n\n",
        "other_text": [
            "You are cloning the reference. Maybe try cloning the variable itself? \n\ne.g. - (*current_tip_state).clone()",
            "It says a clone() trait doesn't exist, and I should implement it to make a deep copy. Is this the right way to go or is there a better solution?",
            "You should do #[derive(Clone)] before defining the State struct.",
            "Ah ok, after doing the derive clone it works; I think I am still not understanding correctly, does cloning the variable itself rather than the reference allow me to have two separate copies rather than modifying the same data? For example, can I just remove every key from the variable clone, but still have all the keys in the original reference?\n\nThank you so much for helping us out even on Thanksgiving, really appreciate it!",
            "Yes that is correct. You can try it as an experiment and see.\n\nNo problem!"
        ]
    },
    {
        "title": "issue unwrapping key when generating keypair",
        "question": "I am having an issue generating a key pair from a seed, where it says it is unable to unwrap the result of the key generation:\n\nIs there an error in how I am generating my key?",
        "other_text": [
            "Edit: I think my own comment worked ^^",
            "Maybe something like this might work? \n\n"
        ]
    },
    {
        "title": "Network Hanging after Block Insertion",
        "question": "I'm able to successfully create and insert a block in the network with the proper account info/transactions. However, upon insertion, the API/threads start hanging or loading slowly. Would you have any insight on why this might occur and how to fix it? It seems that transactions are no longer being generated after the blockchain insertion.",
        "other_text": [
            "See #390 . ",
            "Thanks! the solution was that in some places I was trying to acquire mempool and then blockchain, and in a few others blockchain first and then mempool -- which would lead to a deadlock situation. Appreciate the help!"
        ]
    },
    {
        "title": "Minimum Transaction Value",
        "question": "Is it possible to generate transactions that have a value of 0? The implications of this are that if you have 3 addresses to start off with (2 of which are 0), you could potentially create some transactions from one of those addresses to a new address with probability p that has value 0. This would then mean that an account is created with value 0.\n\nIt doesn't say anything against this in the grading guide, but I just wanted to check to make sure that no points would be deducted for accounts with balance = 0.",
        "other_text": [
            "Sure you can do that. But make sure there are non-zero transactions afterwards so that the state (i.e. the balances of those accounts) keeps evolving from block to block."
        ]
    },
    {
        "title": "Further clarification on deadlocking",
        "question": "I read through #403 and #390 but I am still running into an issue when my block miner hangs when trying to insert a block. More specifically, I have narrowed it down such that if I start my server, my tx-gen works perfectly, and continuously mines, but the second my miner finds a block under the threshold and calls self.shared_blockchain.lock().unwrap() everything hangs. I've been stuck debugging this for quite a while, but I am not making much progress\n\nNote: This worked perfectly in A7\n\nNote 2: This hanging happens even if I don't start the tx-gen before the miner\n\nNote 3: I have a lot of print statements before and after the checks, but on the terminal nothing prints out, when usually a lot does (i.e. when I increase difficulty and it doesn't find a block hash below threshold), but in this case, \"found 1!\" doesn't print either, but it does if I comment out all of the self.shared_blockchain.lock() statements\n\n",
        "other_text": [
            "If this was working in part 7, then you need to check the parts where you are handling the state in some way. If this is happening even if tx-gen is switched off, you should check if it is hanging in the network worker where you are using the state.",
            "In my tx-gen I do hold the locked blockchain for a while \n\nhowever, I doubt this is the issue because otherwise the miner wouldn't hang if I never started the tx-generator?",
            "Update 2: I tried doing a clone of the state and dropping the original values, but no effect. Maybe the blockchain is being locked in another file? \n\n"
        ]
    },
    {
        "title": "Getting KeyPair from Address?",
        "question": "I am running into a conceptual issue\n\n-> we are picking a sender from the state that has non-zero balance\n\n-> we are picking a receiver from either the state or a set of keys that we have generated\n\nWhenever a node sees a receiver that is not in the state, and it is a valid tx, it will add the new address to the state. \n\nBut, when we are picking a new sender, and we pick an address from the state, we don't have it's keypair to sign the transaction, how would we get this?\n\n If we only pick a sender that is both in our generated keypairs AND the state, then how would the tx-gen know when those keypairs have a balance now and not waste iterations of the loop with picking ineligible senders?",
        "other_text": [
            "we don't have it's keypair to sign the transaction, how would we get this?\n\nYou should choose the sender from the list of keypairs under your control, such that the address corresponding to that keypair has nonzero balance.\n\n\n\nwaste iterations of the loop with picking ineligible senders?\n\nWhenever you create a new keypair, you could always create a tx T1 sending coins to this account.\nThis keypair if picked as sender would be ineligible only if T1 hasn't been inserted in a block yet (which wouldn't happen too often)\n\n"
        ]
    },
    {
        "title": "3rd Node turning off?",
        "question": "I am getting an issue where my 3rd node is receiving and updating all the blocks, tx, state and randomly in the middle stops updating itself, while the first and second keep going in sync. Not sure how to get started in debugging this. Is this a problem in my network or something to do with network congestion?\n\nNote: It only happens some of the runs, it works most of the times (reaches the point where at blocks 0, 10, 20 have matching account info)",
        "other_text": [
            "We will run your code at least twice on different machines if this happens. Might be a case of network congestion, so for now you can try adjusting the tx-generator sleep time or mining difficulty.",
            "As a follow up, if this occurs in one of the runs by chance, will the test be run again for grading?"
        ]
    },
    {
        "title": "number accounts",
        "question": "For grading purposes, is it acceptable to maintain only the 3 main accounts over 5 minutes of mining? Requirement says \"The state at 10 and 20 should contain >=3 entries,\" so just wanted to check that if the number of accounts does not grow, that would be acceptable.",
        "other_text": [
            "This should be fine, as long as the balances in these accounts changes over time."
        ]
    },
    {
        "title": "lambda instead of theta",
        "question": "I got the feedback  \"All blocks are empty (no transactions)\" for my part 7.  When I ran it myself there were transactions.  I realized that I copied the miner/start code to tx-generator/start without renaming  lambda to theta.  Is it possible for me to resubmit with the renamed parameter?\n\n",
        "other_text": [
            "Yes you can resubmit"
        ]
    },
    {
        "title": "updating state when processing orphan buffer blocks",
        "question": "When inserting a block that was previously in the orphan buffer, do we need to perform a state update? I would think so because we need to update the ledger in case this becomes part of the longest chain, but wanted to check if this is necessary. \n\n",
        "other_text": [
            "Every time you insert any block into the chain, you should insert a corresponding state in the state map. Even when you insert a previously orphaned block."
        ]
    },
    {
        "title": "Account nonces in real blockchains",
        "question": "In existing blockchains with an account based systems, like ethereum, do account holders need to keep track of their account nonce like in our project or is there another system for preventing duplicate transactions?",
        "other_text": [
            "For Ethereum, the account holder does need to keep track of the nonce as any transaction with an incorrect nonce (duplicate or not the previous nonce + 1) will be rejected. In practice, any wallet software you use to interact with the blockchain will handle this for you and supply the correct nonce when it builds your transaction.\n\nSince the nonce starts from 0 and is always equal to the previous nonce + 1, the nonce is effectively always just the number of confirmed transactions this account has made, which can be retrieved by the RPC eth_getTransactionCount. So if you were writing code to send transactions (such as wallet software), you'd query a node at that endpoint to get that value first and then use it as the nonce for the next transaction. Transactions with the incorrect nonce are rejected.\n\nSomewhat related to this, an interesting consequence of this is that this can be used to cancel transactions. To cancel a transaction in Ethereum (while in the mempool, before being included in a block) you can send a new transaction with the same nonce as the one you want to cancel, but with a higher gas fee. The new transaction (which can simply be a transaction that does nothing) will be chosen since it has a higher gas fee and the original transaction will become invalid since that nonce has now been used already.\n\n"
        ]
    },
    {
        "title": "Updating the mempool",
        "question": "Should the mempool only contain transactions that are valid relative to the current state and to each other? i.e. if the mempool receives two transactions from the same account which are valid relative to the current state, should we reject the second transaction as we already have a transaction being withdrawn from that account? Or should we accept both transactions into the mempool and then just check transactions as they are added to a new block by the miner?\n\n\n\nMoreover, if we are being very selective about which transactions get into the mempool and only allowing ones which would be valid if put together in a block, is it still recommended to check transactions drawn from the mempool and put into new blocks as a precaution?",
        "other_text": [
            "You need to do this check only once. Might be better to do it while constructing a block in the miner rather than  while adding to mempool since you won't unnecessarily reject txns just because your tip is not updated yet.\n\nWhile adding to the mempool you can just check if txn signature is verified and nonce is not less than the nonce in the tips' state."
        ]
    },
    {
        "title": "Transaction Generator Stuck",
        "question": "Hello! When I ran the three nodes, I'm having an issue where once the mempool becomes empty, the transaction generator also stops generating new transactions, so there's no change in the states after the first 2-3 blocks. I'm hoping to have some help debugging this.\n\nFor context, in the transaction generator, I'm generating a new key pair with some probability, then looping through the vector of key pairs to create transactions so that each key pair (corresponding to an account with nonempty value, hence the check on line 173 of txgen/mod) has a chance of being the sender. From the print statements it looks like the code is stuck precisely at this step (so for some reason none of the key pairs in the vector are in the state of the block at the tip), and I'm not sure why this is happening.\n\nI've attached my code to this post for reference. Thank you! Also, Happy Thanksgiving!\n\n",
        "other_text": [
            "The problem might be in miner/mod.rs. All of the blocks you are mining are empty. Because of that there are no new entries being added to that state. So make sure the content of your blocks is always non-empty. \n\nYou should also put the content of the blocks first and then check if hash is less than difficulty. You are doing the reverse for some reason, which is incorrect, because the hash of the block is also over the merkle root of the content.",
            "Thank you! The error was indeed in miner/mod.rs, and it was a scope error where I cleared the mempool after each loop...haha."
        ]
    },
    {
        "title": "Account nonce for invalid transactions",
        "question": "Should the senders account nonce be updated every time they generate a transaction, or only if their transaction is valid?",
        "other_text": [
            "The nonce is updated in the state when a block containing that txn is inserted into the blockchain."
        ]
    },
    {
        "title": "Account nonce of newly created account",
        "question": "If an account is newly created by a transfer to a new address should this newly created account with the value of the transaction contained within it have account nonce 0 or 1?",
        "other_text": [
            "Account nonce is for the sender. The receiver would start with 0 (although any other initial value can work given you generate txns appropriately)."
        ]
    },
    {
        "title": "Final take-home exam released",
        "question": "The final exam is now available on the course website .\n\nThe exam is open-book but is expected to be completed without collaboration with others (fellow-students, instructors, etc).\nIt is due on the Dean's date (December 16th, 11:59pm ET).\n\n\nThe exact format of the submission will be provided shortly (will likely be on Gradescope)\n\n",
        "other_text": [
            "Hi, just wanted to ask about submitting the exam? when will it be open / is it already available on gradescope?\n\nThanks!\n\n"
        ]
    },
    {
        "title": "sending key_pairs",
        "question": "I've used the following code in main.rs (as per Office Hours) to get a vector of key pairs which I send to my tx-generator. When I try to run this with the rest of my code, I notice that the vector is of length 1, so only one of these key pairs gets added. \n\nHow should I approach this error? Can I just hardcode 3 key pairs and pass that as a vector into my tx-generator? ",
        "other_text": [
            "This is not an error, each of the three nodes is supposed to have only one keypair initially.",
            "Okay, what is the purpose of having the three separate key pairs? Is it to emulate 3 different actors? \n\nAdditionally I don't know if I'm handling them properly in my tx-generator file. I've added the key_pair to a field called address_pool (a vector of Ed25519KeyPair) and use the following code to set sender and receiver addresses. I've run into a rust error (not having a value for a key in my blockchain.states hashmaps), but I know I'm inserting these key/value pairs into the hashmap at some point in the code. Is there something wrong with how I've structured my code? \n\nmy tx/mod.rs\n\nmy miner/mod.rs",
            "Okay, what is the purpose of having the three separate key pairs? Is it to emulate 3 different actors? \n\nYes, that is why each node controls a different keypair.\n\nI've run into a rust error (not having a value for a key in my blockchain.states hashmaps),\n\nIn your tx/mod.rs you should choose a sender that is in the state of the tip of the blockchain and in the list of keys address_pool, only then will your transaction be valid. The receiver can be chosen randomly from the state or address_pool. The amount and nonce should be appropriately chosen after consulting the tip's state as well."
        ]
    },
    {
        "title": "Questions about A8",
        "question": "1. I\u2019m a bit confused on where I\u2019m supposed to be updating State. I know we have to update the state every time we insert a block into the blockchain, but does that include in the miner/worker.rs? Currently I am only updating State in miner/mod.rs after creating a block and inserting it into the chain, and in network/worker.rs after performing the checks and inserting the block into the blockchain. Should I also do it in miner/worker.rs after I insert the received block into the blockchain? This would require me to send the state from miner/mod.rs as well as the newly created block.\n\n2. I\u2019m also a bit confused on where I\u2019m supposed to be checking transactions and updating the mempool (removing invalid transactions from mempool). When I am building a new block in miner/mod.rs, should I be performing any checks on the transactions I\u2019m getting from the mempool? Currently I\u2019m only checking transactions in network/worker.rs when I receive a Blocks message and rejecting the block if they have invalid transactions. Where should the updating mempool occur?",
        "other_text": [
            "1. If you are doing it in miner/mod.rs, no need to do it again in miner/worker.rs\n\n2. When building a new block, you should be checking that the txns you are getting from mempool are valid with respect to the state of the blockchain's tip. While you are doing this, you can also remove any transactions you encounter that are outdated with respect to current tip (i.e. txn account nonce < tip account nonce). Validity checks like checking the signature can be done before adding txns to the mempool. \n\nYou should also remove transactions from mempool: (a) when you have successfully mined a block in miner/mod.rs, (b) after inserting any valid block into the blockchain in network/worker.rs.\n\n"
        ]
    },
    {
        "title": "updating state",
        "question": "I'm having some trouble with updating the state. I've sent over txs correctly and the block is definitely doing the tx checks and updates the state in my miner/mod.rs file but for some reason it doesn't actually update the state in the blockchain. I've tried using something like self.blockchain.lock().unwrap() right after all the transactions are added (line 241) to update the state field but then the whole thing just makes the network hang. Is there another way to do this?\n\nhere's the lines of code I think are not updated properly?\n\n\n\nhere's the debugging that shows that the states are being updated (using acct based model):",
        "other_text": [
            "This is happening because you are inserting the updated state into the cloned blockchain (line 186) not the actual blockchain. You can solve this by using the actual blockchain here.\n\nIf you are facing hanging issues, another way to solve this is to remove any state update code from miner/mod.rs or network/worker.rs and put everything in your blockchain.insert() function you have defined in blockchain/mod.rs. This would ensure that state is updated every time you insert a block without any new code introduced after part 7 that might give locking issues.",
            "got it. I'll move code over to blockchain/mod.rs. In my insert function, should the state only update once the block is added to the tip? (Orphan Blocks also use the insert function in my code except the tip doesn't get updated for those blocks)",
            "no, the insert function should add an entry to the state hashmap for every block inserted. ",
            "I was able to get it working so that state updated throughout my program. I'm running into two other issues though:\n\n1. The blockchain isn't being sent to the other nodes properly. I'll do a bit more debugging on my side but when I check the longest chain on 7001 and 7002 only the genesis hash shows up. If you have any pointers on that, I would appreciate it. \n\n2. Tx only start happening when I use the tx-generator on 7000. This is because my code has the ICO on the key associated with that port thus the sender only pulls from that address which is the only one with money. (The sender will also be other addresses that eventually get added to the address pool but if I start with an account that doesn't have money no txs will happen) Do I need to change the behavior of this for the grading of the assignment? ",
            "1. Try putting print statements in netwokr/worker.rs to see which messages are not being sent/received. Not sure why this would happen if it was working till part 7 but try to focus on code that you introduced after part 7.\n\n2. Yes this is expected since other accounts have zero balance till the 7000 account starts sending txns.",
            "Ok great! I think it ended up being a lock issue in one of my files that might have jammed the network? \n\nDoes the order for the state representation matter? Right now, I have the same values but they are in different orders. (i.e. Account 1, 2, 3 in 7000 and then Account 2, 1, 3 in 7001)",
            "No, order does not matter as long as the balances are consistent across nodes and they change every few blocks.",
            "awesome thank you so much!"
        ]
    },
    {
        "title": "tx mempool update in miner",
        "question": "I keep receiving the following error message when I try to update tx mempool after inserting a block in my miner loop. It seems that the length of the state map is never updated - when I moved the tx mempool update code outside the difficulty if condition, the length of the state map is always 1 for many rounds. \n\n\n\nfor context, I only update the state map in the network worker file after checking the block transactions, and I never received the state map updated message.\n\n",
        "other_text": [
            "Does your blockchain insert() function also update the state? If not then that is the source of this error. Because the get() function is not able to find a state corresponding to the tip, it is throwing this error. \n\nYou should insert a state every time you insert a block (can ensure this by putting the state update logic inside the blockchain insert function).",
            "gotcha, but I thought we also need to update the state hashmap in my network worker after going through all the transactions in a block (as following). Doesn't that make a repetitive state insertion then?\n\n",
            "or maybe I should pass in the new state as an additional argument to the insert() function, like insert (block, state) ",
            "Yes you can shift all this logic inside the insert function as well.\n\nIf not you should update and insert state somewhere before line 212 in miner/mod.rs"
        ]
    },
    {
        "title": "2nd transaction check: check if the public key matches the owner's address of the withdrawing account",
        "question": "I was wondering why we need State for the check above (in the account-based model)? It seems to me that the \"public key\" and the \"owner's address of the withdrawing account\" are all stored within the SignedTransaction we are checking (and thus no need to access State to do the comparison/check). \n\n",
        "other_text": [
            "Yes, you do not need the state to do that."
        ]
    },
    {
        "title": "My program does not work unless I print the letter m in the mining loop!!?!",
        "question": "I am absolutely baffled by this. On 3 nodes, my blockchain would fork. I did some debugging and I found that blocks messages were not getting processed fast enough to prevent forking. At first I tried reducing the number of transactions messages sent in case they were clogging the network worker but the problem persisted. Then in my debugging I added this line:\n\ndebug!(\"m\");\n\n\nto my mining loop just to see what the program was spending time doing instead of processing new blocks messages and all of a sudden everything works perfectly. I then undid the change that reduced the number of transactions messages and it still works. Literally the only thing that has changed is that the print statement has been added and everything works. As a test to ensure this was the problem, I deleted the project and redownloaded from my github, ran it and as expected it forks. Then all I do is add this print statement and it doesn't fork anymore and works perfectly. I am so confused this is like something straight off r/ProgrammerHumor. I am running this on Windows, does anyone know if this is something specific to Windows? Is it a problem with the Rust language? The smol crate that is used to broadcast the messages?",
        "other_text": [
            "The time it takes to execute the debug!() statement is just enough to stall the mining thread to lower the forking rate. If you remove the statement, your client does not run properly because it very likely has a concurrency bug (e.g. improper locking). This is not specific to Windows, the Rust language, or any crates. This is specific to your code.\n\nTry decreasing your mining rate by increasing the difficulty to hide your bug. If that doesn't work, think through your logic again in hopes of finding a fix.\n\nIt may also be useful (if not already implemented) to do the following optimizations:\n\nWhen mining a block, record the tip hash before you add up to BLOCK_SIZE transactions into the block or compute the Merkle tree. These operations are expensive and also require you to lock the mempool. By the time these operations are done, the tip of the blockchain might have changed. If the tip changed by the time you want to send the block to the worker (assuming the block satisfies the difficulty requirement), just throw away the block and start over. This may help minimize forking.\n\nWhen mining a block, add up to BLOCK_SIZE transactions into the block as normal. However, if the hash of the block is not below DIFFICULTY, do not restart the mining loop from the beginning. As long as the tip of the blockchain has not changed since you selected the transactions, you can simply try continuously changing the timestamp in the header, rehash the block, and re-evaluate it in comparison to DIFFICULTY. This optimization will drastically speed up your mining rate and also drastically decrease the proportion of time that your miner is holding the mempool and blockchain locks, which will help stabilize your client (minimize forking) at higher mining rates.\n\nLet me know if the above makes sense.",
            "Thanks so much, this was the problem! I didn't realize how expensive these operations such as computing the merkle root were in my implementation, and the blockchain was being locked while waiting for these operations to finish. I was able to fix the program by just dropping the locks immediately after I am done using them with std::mem::drop instead of waiting for it to go out of scope\n\n",
            "Sounds good! I'm glad you found an easy fix."
        ]
    },
    {
        "title": "Setting difficulty",
        "question": "Having transactions in a block increases the time it takes to mine the block. Therefore I reduced the difficulty in A7 so I can mine at a decent rate.\n\nIn this assignment, since two nodes don't have any transactions while one does, they mine at different rates (the nodes without the transactions mine very fast). This means that the first node's transactions won't make it to the longest chain.\n\nI'm able to avoid the issue by decreasing the difficulty to a certain point but this makes all the nodes mine really fast. And my code gets a weird error that I don't know how to debug when the mining rate is very high.\n\n\n\nAnother issue with a fast mining rate is that although there isn't a lot of forking, I can't make sure that the state at 0, 10, and 20 is different because a lot of the time blocks with no transactions go through. Although the state does evolve over time - just sometimes not exactly at 0, 10, and 20.",
        "other_text": [
            "In this assignment, since two nodes don't have any transactions while one does, they mine at different rates (the nodes without the transactions mine very fast).\n\nThis would be true only in the starting 2-3 blocks. After you transfer non zero balance to other nodes, they would also produce txns. You can slow down the mining rate so that there are no blocks that go empty after that.\n\nThe error seems to be occuring because the heights hashmap does not have a key for the tip.  Maybe you are updating the heights hashmap and inserting blocks in separate places?",
            "Would it be okay if I only mine a block if it has a transaction?\n\nI update the heights hashmap in the insert() function of blockchain.rs. This is my sequence of events in insert:\n\nInsert new entry into heights hashmap\n\nCreate new state and insert it into the blockchain\n\nInsert the block into the chain\n\nUpdate the tip if this block is the new highest block\n\nIt shouldn't cause an issue since it's in the same function, right?",
            "Would it be okay if I only mine a block if it has a transaction?\n\nYes.\n\nWould it be okay if I only mine a block if it has a transaction?\n\nYes, in that case shouldn't be an issue. Maybe try mining non-empty blocks only and then decrease the mining rate till you stop getting this error?",
            "That worked!"
        ]
    },
    {
        "title": "Assignment 8 Grading Policy",
        "question": "Just want to confirm, in A8, we will not be penalized for having less than 10 transactions per block and less than 500 transactions in 5 minutes correct? (these were the requirements in assignment 7). ",
        "other_text": [
            "Yes, you don't need to satisfy requirements of A7"
        ]
    },
    {
        "title": "Mempool iter",
        "question": "I'm stuck because mempool.iter() for a HashMap does not preserve ordering, and therefore, updating and check the state across the transactions in a mempool does not work properly. Is there a way to preserve ordering in a HashMap?",
        "other_text": [
            "While choosing txns from mempool to construct a block, you would only choose the ones that are valid with respect to the tips' state. Also, there would only be at most one txn where a particular keypair is sender. So ordering does not matter that much in our case."
        ]
    },
    {
        "title": "State API",
        "question": "A questions about the state API:\n\nIn the account based model, we are printing something which should look like: \n\n[\"address, account nonce, balance\", \"address, account nonce, balance\", \"address, account nonce, balance\"] \n\nwhere each thing in quotes is the info for one existing account correct? In #351 , it seems like other things are being printed as well.\n\n",
        "other_text": [
            "where each thing in quotes is the info for one existing account correct\n\nYes.\n\n#351 was UTXO model.",
            "Do we have to manually concatenate everything together, adding in commas and spaces, or is there an automatic way to do this?"
        ]
    },
    {
        "title": "EXAM",
        "question": "Do we right the answers in Text format and submit? For the plot questions can we simply get pictures from the explorers?",
        "other_text": [
            "You can use the plot from the explorer if it satsifies the requirements. And for Gradescope, I guess you don't need to put your name.",
            "Similar question: if we are submitting a PDF, do we put our name on it?"
        ]
    },
    {
        "title": "Office hours today",
        "question": "As the final assignment is due today any chance we will can have an Office hours tonight? :)\n\n",
        "other_text": [
            "7:45 pm at https://princeton.zoom.us/j/8756915306"
        ]
    },
    {
        "title": "Office hours right now",
        "question": "Holding office hours on the following link starting 7:45 pm.\n\nhttps://princeton.zoom.us/j/8756915306\n\n",
        "other_text": []
    },
    {
        "title": "Same longest chain across all three blocks, but different states showing on api",
        "question": "Whenever I check the longest chain of all my three nodes, all hashes are always the same from start to finish. However, when I examine the state of a given block and output the result in the blockchain/state API, different states appear. Does anybody know how the state for blocks could be inconsistent even though the longest chain itself is consistent?",
        "other_text": [
            "This shouldn't happen if the transactions within the block have been executed correctly.\n\nCheck if you are updating the new state from the parent block's state (not the tip's state) correctly"
        ]
    },
    {
        "title": "State API Output",
        "question": "Is this a good output for the state or should I remove the labels (like the string \"account nonce: \")\n\n[\"(address: d5025bb3b5085be913b0778c82f5c73aa831ed2c, account nonce: 1, balance: 985035)\",\"(address: a0d741628fc826e09475d341a780acde3c4b8070, account nonce: 2, balance: 14965)\"]",
        "other_text": [
            "This is fine."
        ]
    },
    {
        "title": "Using port value for seed to generate key pair",
        "question": "When using the port values (ex 6000 to 6002) to corresponding with the grading nodes, we were suggested to use hardcoded seeds, then run them with Ed25519KeyPair::from_seed_unchecked(&[seed; 32]).unwrap())\n\n as in #307 \n\n\n\nHow can we do this if the literals for 6000-6002 do not fit into the type u8 whose range is 0 to 255?",
        "other_text": [
            "Eg : You could seed=0 if port is 6000, seed=1 if port is 6001, etc.",
            "got it, thanks!"
        ]
    },
    {
        "title": "doesn't generate new sender addresses?",
        "question": "The number of accounts in my state map keeps at 3 despite the block is at 300th. Couldnt figure out if I did anything wrong in my function of generating sender addresses hmm\n\n\n\n",
        "other_text": [
            "When you're adding a new keypair, you need to send some coins from an existing keypair to this one.\nOtherwise it will have 0 balance, and won't be able to generate transactions as sender.\n\n\nIn the above code snippet, other nodes will not know of the existence of this account.\nYou can add an account to State whenever it receives coins, and it doesn't exist in State already",
            "wait so should I manually increase balance of the new keypair and decrease the balance of existing keypair, or set the new keypair as the recipent of this transaction so that other nodes can create an account for it?\n\n",
            "set the new keypair as the recipent of this transaction so that other nodes can create an account for it.",
            "thank you!\n\n",
            "sorry for a very late night question, but my first two nodes print nothing, while my third node only prints one transaction..Does the code below make it super hard to generate tx or something\n\n\n\n",
            "Initially only one of the nodes has a positive balance, so only that guy can create transactions.\nOnce the other addresses have received coins (txs have been added to a block in the longest chain), they can create txs themselves.",
            "also my 1st node is printing mining block messages, 2nd node printing network messages, and 3rd node printing nothing...is this normal?\n\n\n\n",
            "Doesn't look normal...\nAre the longest chains syncing? (you have started all 3 txgens and miners?)",
            "ic, should I call \"http://127.0.0.1:7000/miner/start?lambda=0\", then \"http://127.0.0.1:7001/miner/start?lambda=0\", then \"http://127.0.0.1:7002/miner/start?lambda=0\", and then similarly three sequential calls to \"http://127.0.0.1:7000/txgen/start?theta=100\"?\n\n",
            "Yes, but start the tx generators first."
        ]
    },
    {
        "title": "Orphan buffer unwrap None",
        "question": "Getting the following error (otherwise, everything is working as planned):\n\nthread '' panicked at 'called Option::unwrap() on a None value', src/network/worker.rs:164:83\n\nThis is the code (the second line is line 164)\n\nThis error doesn't seem like it should be possible. Thoughts? This code hasn't been touched since it added for the assignment where it passed all of the tests.\n\n",
        "other_text": [
            "Not sure, I think some edge case is happening because you're removing entries in the buffer.\n\nMaybe try using orphan_buffer.iter() instead\n\n"
        ]
    },
    {
        "title": "A7",
        "question": "Hi, \n\nI submitted what I believe is a working A7 on Nov 21st. Would you mind re-checking it? ",
        "other_text": [
            "Rechecked Part 7."
        ]
    },
    {
        "title": "Updating Parent State",
        "question": "Hi, \n\nDuring office hours we spoke at length about the New State and Parent state in my miner. \n\nI was wondering, does it make sense to update the parent state after every successful transaction insertion in the context of my transaction loop? See below. \n\nAlso, am I updating balances correctly? Because those keys are present they should update on insertion. \n\n",
        "other_text": [
            "Also, am I updating balances correctly? Because those keys are present they should update on insertion. \n\nYes\n\n\n\nI was wondering, does it make sense to update the parent state after every successful transaction insertion in the context of my transaction loop? See below. \n\nYou shouldn't update the parent state; it's already on the ledger.\nOnce a block is mined (or when you receive a block with all valid txs), you should insert the block, and add the corresponding new_state to the ledger",
            "But on the next transaction, shouldn't we be looking at the previous iteration of the transaction loop for our conditionals? ",
            "All the transactions added to a block should be valid according to the parent state",
            "Ok, thank you. I have practice now but will be at zoom office hours afterward. Thank you for taking another look at assignment 6!"
        ]
    },
    {
        "title": "Final Exam 2b",
        "question": "Are we expected to come up with an exact answer for the number of hashes to have a 95% chance at finding SHA256 collision or are we allowed to use the formulas on the birthday paradox wikipedia page under the Taylor series expansion?\n\nAlso, are all questions related to the Final Exam supposed to be private or can we ask public ed questions?\n\n",
        "other_text": [
            "Hi Max, yes, you can use the approximation, and we will update the requirement of the precision. For the data, you are welcome to use any data source.",
            "Also, I couldn't find a great way to export data from the website linked in problem 3b, I'm not sure if I can post this publicly but this website makes it easier to get the times between blocks in a dataset: https://explorer.btc.com/btc/blocks\n\n"
        ]
    },
    {
        "title": "A8 Transaction Generator",
        "question": "Would you mind explaining a little bit on how we should go about generating only valid transactions? Should there be a randomness component to it? How would we go about doing this?  My Code from A7 is below, obviously these transactions are completely random. ",
        "other_text": [
            "You should generate transactions that are valid according to the state of the tip of the blockchain.\n\n\n\nShould there be a randomness component to it?\n\nReceiver can be chosen randomly from the list of accounts in the tip's state. Sender should be chosen from the list of keypairs controlled by the node, which have a positive balance in the current state\n\n(Discussions in #307, #355, #373, etc. might be useful)"
        ]
    },
    {
        "title": "block difficulty problem",
        "question": "I dont know why but my block keeps not being able to pass the difficulty test despite I tried several values including 000effffffffffffffffffffffffffffffffffffffffffffffffffffffffffff, 00efffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff, and 0effffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff...\n\nAlso when I started two nodes with one mining and the other receiving, the receiving node only has the genesis block hash in its longest chain, not sure if this is related.\n\nCurious if you guys have any intuition on what might have happened\n\n",
        "other_text": [
            "in the miner, I set the difficulty as  let difficulty = {self.arc_mutex.lock().unwrap().hash_map.get(&parent).unwrap().header.difficulty};\nis this correct?\n\n",
            "where parent is the tip of the blockchain",
            "Yes this is correct, assuming parent is being set to the tip. Where are you setting pow_passed in network worker? Also why is the printed difficulty in the first screenshot different from what you have set it to be?",
            "Oh I fixed it - I was setting the difficulty to parent hash and changed it to the difficulty of the passing-in block. But the same error message as above persisted hmmm",
            "this is my pow test that is failing ^\n\nthis is the difficulty test in the miner that im also failing\n\n",
            "Can you move the difficulty test on line 225 in miner/mod.rs inside the if statement and see what is being printed when the block is mined?",
            "but i don't think it would pass the if conditions if the printed message says it's keeping failing right\n\ni'm wondering if a quick zoom screenshare will be easier? https://princeton.zoom.us/j/9572090251\n\nor maybe i can keep sending screenshots as well\n\n"
        ]
    },
    {
        "title": "Final exam instructions",
        "question": "We will be using Gradescope to gather your answers to the final exam, so please upload a pdf file and map the question number to your answer sheets' pages on gradescope. \n\nIf you can use LaTeX to typeset your solution, we would appreciate that. Otherwise, please write your solution as legibly as you can in any other way and upload a scanned PDF of the written solution to Gradescope.\n\nTo reiterate : the exam is open-book but is expected to be completed without collaboration with other students or instructors. \n\nThe exam is due on Dean's date, December 16th before midnight ET. ",
        "other_text": [
            "FAQs:\n\n1. For the plots in Question 1, please take a meaningful interval, e.g., one year. And you are allowed to use the suitable plots online directly. The goal of this question is just to get you familiar with the whole Bitcoin system via explorer. \n\nRemark: Take it easy when doing Q1, it is just an educational question whose aim is to get you familiar with Bitcoin explorer. Most of the answers can be found on a suitable explorer page.\n\n2. For Question 2, please just give an approximate answer in the form of $2^k$, where $k$ should be accurate to one decimal place.\n\n3. For Question 7, please calculate the worst-case solution for part (a) and the expectation for part (b).\n\n4. For the Monte Carlo method, it is very simple, you can easily find many resources online, or just ask ChatGPT:\n\nQ: What is the Monte Carlo method.\n\nA: The Monte Carlo method is a computational algorithm that uses random sampling to perform numerical calculations. It is often used in mathematical modeling and computer simulations to evaluate the performance of various algorithms, and to solve problems that are difficult or impossible to solve using other methods. This method is named after the city of Monte Carlo in Monaco, where it was first developed.\n\nQ: Explain it in a simple way with examples\n\nA: The Monte Carlo method is a way to solve problems using random numbers. For example, let's say you want to know the probability of winning a game of chance. One way to solve this problem is to use the Monte Carlo method, which involves simulating the game many times and counting the number of times you win.\n\nHere's how it might work:\n\nStart by simulating a single game of chance. This might involve rolling a pair of dice, flipping a coin, or picking a card from a deck.\n\nRepeat this process many times, each time keeping track of whether you win or lose.\n\nAfter simulating the game a large number of times, calculate the proportion of times that you won. This will give you an estimate of the probability of winning the game.\n\nSo, for example, if you simulate the game 100 times and you win 55 times, then your estimated probability of winning is 55%.\n\nFor our class, you can find some examples in the lecture notes, e.g., Lecture 6, you can use the Monte Carlo method to simulate $T_i^h$ and $T_j^a$ in the Analysis of the private attack under zero delay section."
        ]
    },
    {
        "title": "general question about exam",
        "question": "If this is allowed, may I ask a general question about the exam?\n\nIf a question is asking to use some data from the web site, are we allowed to use their official REST API specification to create a simple web client, that gets the data from the web site and then process/plot the data? \n\nFor instance, \n\nGET https://blockchain.info/rawblock/<tip> to get the latest block\n\nThe json response has all information about the block, and a reference to the parent block that can be used to iterate through the blockchain.\n\n",
        "other_text": [
            "Sure",
            "Thank you!"
        ]
    },
    {
        "title": "Final Exam Question 2 Computational Infeasability",
        "question": "For Q2B on the final exam, I'm able to derive a probabilistic formulation for the number of hashes needed for a 95% collision probability for the SHA256 case, but I'm unable to outright compute the number, even on high-powered calculators such as Wolfram Alpha. Would it be okay to leave the expression unsimplified, or is there another tool we can use to solve for the number of hashes needed?",
        "other_text": [
            "Hi, Ayush, please just give an approximate answer in the form of $2^k$, where $k$ should be accurate to one decimal place. We will update the problem instruction soon."
        ]
    },
    {
        "title": "Blockchain Panel Happening Now - Frist Campus Center!",
        "question": "Hey everyone,\nPUEA has a panel discussing the energy challenges and solutions of \u00a0blockchain technologies running now in the Frist Campus Center Multi-Purpose Room. The panel includes Troy Cross from the Bitcoin Policy Initiative and Luigi D\u2019Onorio DeMeo, Head of DeFi at AvaLabs. If you\u2019re free and interested in sustainable energy and blockchain for both Proof of Work and Proof of Stake, please come by!\u00a0",
        "other_text": []
    },
    {
        "title": "Allowed sources for Final",
        "question": "Are we allowed to look up concepts online for the final (and, of course, cite them) or are we limited to course material?",
        "other_text": [
            "Feel free to look up concepts online.\nThe exam is open-book.\n\n"
        ]
    },
    {
        "title": "Part 8 grades released",
        "question": "Project part 8 grades have been released. Please check any comments on your submission and resubmit by making the necessary changes.",
        "other_text": []
    },
    {
        "title": "Final Exam - Problem 2 Question",
        "question": "For the answers, do you want us to give the generic expressions in terms of $n$ or actually compute the results with $n \\in {4, 5, 6, 7}$?",
        "other_text": [
            "Hi Oleg, please just give an approximate answer in the form of $2^k$, where $k$ should be accurate to one decimal place for every $n$ in the question."
        ]
    },
    {
        "title": "Final Exam - question 1D",
        "question": "For question 1D on the exam it says to plot the change in difficulty. Is this only referring to the change from the current difficulty to the expected next difficulty? Or is it expected that we are plotting a larger time frame?",
        "other_text": [
            "Hi Katherine, please plot a larger time frame, e.g., 1 year."
        ]
    },
    {
        "title": "Final Exam - How to download data for Problem 3",
        "question": "I'm currently on Problem 3 and cannot find where to download the data from \n\nhttps://www.blockchain.com/explorer/blocks/btc\n\nCould anyone point me to how to do this? Or are we expected to use the API:\n\nhttps://www.blockchain.com/explorer/api/blockchain_api",
        "other_text": [
            "I used this site https://explorer.btc.com/btc/blocks to export the data as a .csv file\n\n"
        ]
    },
    {
        "title": "Part 8 Comments",
        "question": "Hello! For my submission for Part 8, I received a comment that one of my nodes is throwing an error after calling block api, but I downloaded my code and ran it on my own machine and did not run into this issue (I attached screenshots of what the output looked like for block = 20 for each node, after about 4 minutes). I have a few questions/requests:\n\nWould it be possible for me to have a screenshot of what the error looks like so I can try to figure out the issue?\n\nOne conjecture I have is that the mining/transaction generating rate isn't fast enough, so the block api throws an error because it hasn't gotten to the 20th block after 5 minutes, but this seems unlikely as I ran my code 2-3 times and was able to get there each time in about 4 minutes -- should I try to increase the rates even more, or do you think there's some other issue that I'm overlooking? I'm also confused why only one node is throwing the error, as I assume that whatever worked for one node should've worked for the other.\n\nThank you!\n\n",
        "other_text": [
            "I'll run your code again and let you know. If there is an error, we can figure it out during office hours.\n\n",
            "Hello! Sorry to bother you all about this again, but it's been a few days and I still am unable to figure out the error in my code (in particular, I'm still not seeing any error messages on my end) -- would it be okay if I submit a screen recording of me running the code from my end and a text file of all my outputs? I'll make sure to follow all the instructions in the grading criteria. If not, that's also completely fine. Thank you!",
            "I ran your code on a windows machine and was getting the same error, although I was getting more blocks mined before that happened. You can send me a recording of what is happening on your end. We will try on our end to see if we can regrade.",
            "Thank you! I attached the output to this post, and here's the link to the screen recording: https://drive.google.com/file/d/1p4I2qMpY9ilSYK1y4UIHj5Dzghze8luN/view?usp=sharing (I'm not sure how long it'll take to process.)",
            "Hi Nancy,\n\n(in the screen recording) You seem to be running the miner and tx-generator on only one node. In our test cases, we start tx-generator and miner on all three nodes (ports 7000, 7001, 7002).\n\nDoes it still run correctly in this scenario?",
            "I'm getting the same errors now... thank you both very much and I'll let you know if I have trouble debugging this.",
            "Hello! I just fixed the issue (I think) and have uploaded the new version on Canvas -- can you take a look? Thank you! Also I really apologize for taking up so much of you all's time debugging this really stupid issue, and I hope you all have a great rest of the semester. ",
            "I am getting this error on multiple nodes now. This is happening without calls to any display api.",
            "Hello! I realized that when I start my transaction generator before the miner, the mining rate is slower for some reason, so I changed the transaction generating rate and the number of transactions per block so that it's faster and submitted a new version -- I'm not sure if that fixes anything, but can one of you please take a look? Thank you! (Also, not related but I also submitted an updated version for Part 6 if that can be regraded as well -- my apologies if this is redundant, but I'm not sure how Canvas notification works on the instructor end.)",
            "Updated your A6 grade",
            "I ran her code ...\nGetting PoisonError on some nodes. One node is working properly\n\n"
        ]
    },
    {
        "title": "Q1 Clarification",
        "question": "Q1 has this subquestion: What is the (rough) size of new blocks in one month (in GB)?\n\n\n\nIs this question asking for the total number of GBs from new blocks in a month? \n\n\n\nAlso, when we are asked to plot the change in difficulty, or the change in block size, to what granularity are we expected to plot? For instance, would it be sufficient to take a plot of change in difficulty if we can find a suitable plot online?",
        "other_text": [
            "Yes, it's asking for the total number of GBs. And yes, you can take a suitable plot online.",
            "following up on this, does this also mean it is suitable to take a plot of the \"daily average block size\" that we find online? alternatively, it seems like we can download the block size information fairly easily (whereas the difficulty isn't as accessible), but do you want us to plot this average daily block size or should we plot every data point for block size?"
        ]
    },
    {
        "title": "Q3 Clarification",
        "question": "For part b, we are asked to parse through the data of the last two weeks. Are we expected to write our own web scraper for this? Just wondering, or if it is acceptable to use another website to grab the data.",
        "other_text": [
            "acceptable to use another website to grab the data.\n\nDefinitely acceptable. #450 "
        ]
    },
    {
        "title": "\"block display api not working\"",
        "question": "I received the above comment on my A8 submission, but I was wondering which API this is referring to? The APIs seem to be working on my end. Thanks!",
        "other_text": [
            "I'm getting this error when the state api is called:\n(http://127.0.0.1:7000/blockchain/state?block=1)",
            "Hi, apologies for the late response but I wanted to follow up anyway -- for some reason it only works for block=0 (genesis/ico) but I was not able to figure out why. Thanks!",
            "Your code is panicking at this line:\nlet block_state = &blockchain.state.get(&req_block).unwrap().state;\n\nMaybe the state hashmap is not being updated correctly in all nodes?"
        ]
    },
    {
        "title": "Q6 Clarification",
        "question": "Q6 asks for a simulation: (simulate the selfish mining attack discussed in the lecture with one attacker and one honestnode and plot the chain quality as a function of\u03b2, assuming the network delay is zero andtie-breaking always favors the adversarial blocks.)\n\nFirst, what is expected in our answer? Is given a plot of CQ vs beta enough, or to what extent are we expected to provide context and clarification on how we implemented the simulation?\n\nAbout simulating an attacker and an honest node with varying hashing power (I understand this to be beta), could this be as simple as using a RNG where the size of the first bin corresponds to the relative hashing power of the attacker, and the size of the second bin corresponds to the relative hashing power of the honest node? Here, I imagine we would just simulate iterations of the RNG as blocks being mined, and we would count each iteration of the RNG falling in the attacker bin as a block against optimal CQ.\n\nIf this is in the wrong direction, could you please provide some guidance on the expectations for simulation?\n\n\n\n\n\n",
        "other_text": [
            "Yes, giving a plot of CQ vs. beta is enough. If you are not confident about the result, you can describe the intermediate steps, which could help to get part of the credit if the final answer is incorrect.\n\nAs for the second question, I think it is probably beyond clarification but I would say the idea is correct, please use your discretion, and please post this kind of question as private later.\n\n"
        ]
    },
    {
        "title": "submit excel/code files?",
        "question": "If we use excel or write code to perform calculations or plot graphs for some of the final exam questions, should we submit those files as well or can we insert a screenshot of the code/describe the code in our assignment?",
        "other_text": [
            "You can insert screenshots or descriptions, we will grade based on the final results and only when the final results (plots and numbers) are incorrect we will check the intermediate steps."
        ]
    },
    {
        "title": "Office hours on 12/13",
        "question": "Today's (Tues 12/13) office hours would be held online at 4pm.\nLink : https://princeton.zoom.us/j/8756915306 \n\n",
        "other_text": []
    },
    {
        "title": "Q7 Clarification",
        "question": "Could the queuing system be clarified here? What does it mean for \"we split the transactions randomly into q queues, and each honest block is created from transactions drawn from one randomly chosen queue\"?\n\nIn part a of this question, does the worst case throughput need to written as a function of q?\n\nIn part b of this question, are we just plotting our expression from a? ",
        "other_text": [
            "Hi, please calculate the worst-case for part (a) and the expectation for part (b). The queuing system works like every transaction goes to a random queue, and every block extracts transactions from one queue.",
            "After the transactions get extracted from the queue, do those same transactions get recycled back into the queue after the block hash is computed (regardless of whether or not it passes the difficulty)?",
            "The transactions are only removed from the queue when the proposal block includes the transactions. So there is no recycle, but the transactions will remain in the queue for a while."
        ]
    },
    {
        "title": "A7 \"Worst Case\"",
        "question": "Hello, I just came from office hours with Viraj, who asked me to make this an Ed post on the wording of question 7.\n\nPart (a) asks for the \"worst case\" throughput, but it seems to expect an answer in the form of q that can be used for part (b). However, in the worst case, all miners would randomly select the same queue, which would effectively give the same conditions as the original problem with one transaction mempool. Should I be looking to calculate the expected value throughput instead, which would vary with q? Or am I interpreting the solution incorrectly?\n\nThank you a lot for your help.",
        "other_text": [
            "Hi Bryan, please calculate the worst-case for part (a) and the expectation for part (b)."
        ]
    },
    {
        "title": "Thanks so much guys!!",
        "question": "My blockchain is finally working yayyyyyyy thanks so much guys!! \n\n",
        "other_text": [
            "great!"
        ]
    },
    {
        "title": "Q4 Clarification",
        "question": "Q4 asks us to simulate a private attack with the Monte Carlo method. Have the specifications for the Monte Carlo simulation been specified anywhere? \n\nMy approach was just to run a large number of simulations in Python. In each simulation, I \"mine\" a number of blocks (= total time / specified mining rate), and check if the adversary can mine a k-long chain on the tip. I return the fraction of simulations in which the adversary succeeds.\n\nI wasn't sure how to set the number of simulations, or to choose the \"total time\" for which each simulation runs. The total time seems to have a major effect--a lot more blocks can get mined in a year vs a week, so the probability of the adversary succeeding increases correspondingly.\n\nI kept this private because wasn't sure if it revealed too much of my approach, but can switch to public later if deemed appropriate.\n\n",
        "other_text": [
            "Hi Aatmik, I guess you misunderstood the concept of success probability. Please take a look at the note from Lecture 6. And I will keep this thread private as this is too much information here."
        ]
    },
    {
        "title": "Citations",
        "question": "Hello, do we need to cite anything for the final?",
        "other_text": [
            "Hi, if you use any results outside the lecture, please cite the origins.",
            "Do you consider papers/resources linked in the lecture to be okay to use as long as we cite?",
            "Yes, you can use it with citation."
        ]
    },
    {
        "title": "Q1 Clarification",
        "question": "\"What is the block time of the newest bitcoin block?\" Is \"block time\" here the same as inter-block mining time?\n\n",
        "other_text": [
            "Hi, the block time refers to the timestamp of the block."
        ]
    },
    {
        "title": "Q2b Clarification",
        "question": "Are we expected to calculate a real number for this, or can we leave it as a variable in an equation?\n\n",
        "other_text": [
            "See FAQs (#442)"
        ]
    },
    {
        "title": "Later blocks confirmed first than earlier blocks?",
        "question": "This's not really related to a particular exam question, but it seems the Bitcoin block with height 766743 has a timestamp later than the block with height 766744. \n\nhttps://explorer.btc.com/btc/block/766743\n\nhttps://explorer.btc.com/btc/block/766744\n\nWhy would this ever happen? Am i missing something",
        "other_text": [
            "The bitcoin protocol allows timestamps later than the median timestamp of the previous 11 blocks, and earlier than 2 hours of the current network time.\n\nThis answer (and others on the thread) provide an explanation..\n\n",
            "Is this something to do with orphan blocks?"
        ]
    },
    {
        "title": "Q7 worst case",
        "question": "It would be good to get a clearer understanding of what is meant by worst-case here. It is easy to conceive of different worst cases. \n\nDoes worst-case simply mean that two blocks drawing transactions from the same queue in the same round we assume one of the blocks to be redundant? \n\nIs that an incorrect assumption? Or is it correct, but there are there additional assumptions missing?\n\n",
        "other_text": [
            "Your understanding is correct, it is as simple as this, but I have to move your question to private as it reveals too much information :)"
        ]
    },
    {
        "title": "Q1 clarification",
        "question": "Hi,\n\nFor Q1 (a), it asked us to list three features satisfied by a blockchain explorer. Does it ask us to find something related to security, liveness, etc.? For example, the longest-chain rule? I am not entirely sure what this question asks for.\n\nAlso, for Q1(d), when it asks for a plot of the change in bitcoin difficulty. Could we use the plot from the bitcoin explore website? Or we should plot it by ourselves. ",
        "other_text": [
            "Yes, take it easy when answering Q1, it is just an educational question, you'll be fine if you use a correct plot from the website."
        ]
    },
    {
        "title": "Q2 clarification",
        "question": "Is the second part of both part a and part b is the question saying that the hash output is of length 2^n or the size of the output space is 2^n?",
        "other_text": [
            "Hash output length is $2^n$ bits"
        ]
    },
    {
        "title": "Question weights on the exam",
        "question": "It would be helpful if we know how much each question is worth so we know how to properly allocate our time.\n\nThank you!",
        "other_text": [
            "Thanks for asking, we will distribute the points as: 10 points each for 1, 2, 3, 7 and 20 points each for 4, 5, 6.",
            "As an extension of this question, can we expect the final to be curved? Or what is the general expectation for grading criteria?"
        ]
    },
    {
        "title": "Take-Home Final 24-hour extension request",
        "question": "Hi,\n\nI would like to request a 24 extension on the due date of the take-home final exam. I found out that course instructors can grant short 24-hour extensions without additional approval and would appreciate being considered for one of these.\n\nI am seriously overwhelmed with 4 high-workload projects due on Dean\u2019s Date, a problem set due between now and then, and additionally I am flying to India this Tuesday. I have already been compromising my physical and mental health this past week, so this extension would make a big difference. \n\nI have put a lot of effort into this class and want to finish on a high note. Thank you so much for the consideration, and please let me know if this may be possible.\n\nBest,\n\nArin",
        "other_text": [
            "Hi Arin, sure, take your time and good luck with your finals.\n\n",
            "Hi Tianle,\n\nThanks so much for your lenience. If I feel that I have a  valid reason for an extension beyond 24 hours that is a bit personal, how would I go about asking for this? Who specifically on the course-side would I need to ask, and would I also need to ask my residential college dean? Again, thanks so much for all your help. I really appreciate it.\n\nBest,\n\nArin",
            "Hi Arin, perhaps you can email Pramod for this? I believe he will agree."
        ]
    },
    {
        "title": "Q4 Monte Carlo method clarification",
        "question": "Not sure if this is too exam related, but if so feel free to not answer. I just want to more clarification on the statement \"Simulate the private attack with your own choice of k, \u03b2 and \u03bb using Monte Carlo method.\" \n\n\n\nAre we asked to do Monte Carlo method to randomly sample all three parameters, or are we asked to fix the three parameters and do Monte Carlo method in other ways?\n\n",
        "other_text": [
            "Fix a value to the three parameters, and perform MC simulations ",
            "Also by \"simulation\", are we expected to write python codes or just argue theoretically?\n\n",
            "\"simulation\" doesn't mean theoretical arguments \ud83d\ude05"
        ]
    },
    {
        "title": "Lecture Note Derivation Usage",
        "question": "For certain derivations which are done in the lecture notes, is it okay to use those derivations in the final write-up so long as they are cited  and we explain them?\n\n",
        "other_text": [
            "Yes"
        ]
    },
    {
        "title": "Q4b",
        "question": "When we compare to the Nakamoto paper, do we also need to validate the finding in the paper under \"Solving for P less than 0.1%...\"? \n\nAlso, how can we justify \"matching the values in the Nakamoto table\"? If the general pattern / order of magnitude is that same, does that qualify as matching?",
        "other_text": [
            "Yeah I have a similar question: since Q4(c) implies that Satoshi's lambda equation is wrong, can we still use that equation as an assumption to solve Q4a and Q4b? If we use that equation, doesn't that mean we will get the same results as Satoshi, which defeat the purpose of the question? I'm just confused which part is given as assumption and which part should be something we test on.\n\n",
            "For the original question, yes, you can use 0.1% as the threshold. For showing the diffence to the Nakamoto paper, you are expected to use Monte Carlo method to plot the attack success ratio vs confirmation length k and show the difference between Nakamoto's calculation and yours. For Bofan's question, you shouldn't use that equation, and for doing Monte Carlo, you don't need that.",
            "Okay, thanks for clarifiying that.\n\nIt sounds like we should be comparing the success probability as it varies over k. It also sounds like we can use our own value for lambda for our Monte Carlo Method (extension of part a). Does this sound right?",
            "Yes.",
            "Also, for the value for lambda, should we replicate the Nakamoto paper in using \"lambda = z * q/p)\" or can we retain our value of lambda from part a?"
        ]
    },
    {
        "title": "Q5b setup clarify",
        "question": "I have a question about the setup of the balance attack: If both chains are equal length, the honest party would mine two chains with equal mining power. But if it finishes mining a block on the first chain, does it immediately stop its efforts of mining on the second chain (to keep the longest chain consistent)?\n\nIf so, is there any block broadcasting involved here since otherwise the second chain will always start with one less block than the first chain? Would appreciate some clarification on the setup!",
        "other_text": [
            "Do you mean the adversary or the honest party? The adversary will force the honest party to mine the other chain, and if the adversary mines a block, it will hold the block private and keep mining until the honest party mines a block.\n\n",
            "sorrry this q is for Q5a"
        ]
    },
    {
        "title": "Course Grading Policy",
        "question": "The course grading policy on the syllabus is split into 80% assignments and 20% final. What is the grading schema for the final grade distribution (A, A-, B+), etc?",
        "other_text": [
            "Sorry for the delayed response -- as a rule, we will be generous with the grading rubric. Most of you are on target for a solid A. Please write to me separately via email if you have specific concerns. ",
            "For clarification, I am wondering if a 93 raw will be translated to an A, a 90 raw will be translated to an A-, etc."
        ]
    },
    {
        "title": "Q5a",
        "question": "For this question, it says that \"Further, the adversary forces the honest party to split its mining equally among the two chains.\" Does the honest party mine equally in both the equal and unequal chain cases? \n\n",
        "other_text": [
            "In the unequal case, the honest party always mines the longest chain. In the equal case, you can assume honest party spends equal mining power on different chains."
        ]
    },
    {
        "title": "Q1 part j clarification",
        "question": "What exactly is this question asking us to plot? Is it asking the amount of bitcoin distributed in wallets? e.g. 10% of wallets have 0 - 1 BTC, 20% have 1 -  2 BTC, etc.?\n\nOr is it the %age of coins in wallets? e.g. 10% of coins are in 5% of wallets\n\n",
        "other_text": [
            "Either is fine."
        ]
    },
    {
        "title": "Part 1 e-g",
        "question": "For these three parts, do we examine the proportion that the mining pools held over all time or should this be more current (i.e. the last 24 hours or the last year). Especially for part g, should I be looking at the behavior of the mining pools from an \"All Time\" perspective or the current mining pools' behavior within the last 24 hours since those are presumably the ones that would do a 51% attack?\n\n",
        "other_text": [
            "Please use the current one."
        ]
    },
    {
        "title": "Final Q4,5,6 Explanation",
        "question": "Since these questions mainly rely on comparing the results of Monte Carlo sim to the theoretical, would it be helpful to the grader to have us explain key steps/design rationale of our Monte Carlo sim? \n\nOr is this unnecessary and is including the plot/answering the remaining parts of the question suitable?",
        "other_text": [
            "For the Monte Carlo method, please refer to https://edstem.org/us/courses/28225/discussion/2235222?comment=5172765"
        ]
    },
    {
        "title": "Final Q 1 part d plot",
        "question": "Question 1 part d asks to plot the change in bitcoin difficulty. Do we have to manually plot this using data found on the internet, or can we use a graph online as long as it shows we understand how to find the information/read it?",
        "other_text": [
            "Please refer to https://edstem.org/us/courses/28225/discussion/2235222?comment=5172765"
        ]
    },
    {
        "title": "Final - Probability of hash function collision",
        "question": "In the notes of lecture 2 it says The probability that there will be at least one collision among the\n\nm hashes is approximately \n\n$$1-e^{-m^22^{-k}}$$\n\nHowever, on the Wikipedia page linked, it says the probability of a collision is approximately\n\n$$1-e^{-m^2\\left(2\\cdot2\\right)^{-k}}$$\n\nI was wondering if this is an error in the notes or if I am misunderstanding the equations. Thanks!",
        "other_text": [
            "I think it's just because the lecture note ignores the constant."
        ]
    },
    {
        "title": "office hours normal this week",
        "question": "Quick check if the office hours are at usual hours this week?",
        "other_text": [
            "Will be holding office hours on zoom today : https://princeton.zoom.us/j/92002112501 Links to an external site.\n\n\n",
            "Hi, is office hours currently happening?"
        ]
    },
    {
        "title": "Q1j",
        "question": "Is one mining pool considered as a single 'wallet' for this question? If not, where can I find specific wallet info on the explorer?",
        "other_text": [
            "You may easily search this online."
        ]
    },
    {
        "title": "Question 4 - beta?",
        "question": "I'm a little confused with the wording of Problem 4. What does the beta symbolize in problem 4? What is the equivalent in the paper that was linked? And does lamba remain z*p/q?",
        "other_text": [
            "Please refer to Lecture note 6 for the literature of those notations."
        ]
    },
    {
        "title": "Q2 Question",
        "question": "Hello, I'm running into overflow errors in online calculators when trying to solve this problem. Do you have any tips/resources for how to reach a suitable answer?",
        "other_text": [
            "According to #442 \"please just give an approximate answer in the form of $2^k$, where k should be accurate to one decimal place\"",
            "Thanks!"
        ]
    },
    {
        "title": "Q7a \"Worst Case\"",
        "question": "I had some questions about what exactly the wording \"worst case\" means in context of 7a. Does worst case mean the fewest possible non redundant blocks, or does it mean the greatest possible number? Greater throughput is generally considered better, but in many contexts \"worst case\" refers to an upper bound in terms of big O complexity. Some clarification on what worst case means would be helpful",
        "other_text": [
            "It means the fewest possible non-redundant blocks."
        ]
    },
    {
        "title": "Monte Carlo Method",
        "question": "I am not familiar with the term \"Monte Carlo Method.\" Could you please define it or link to a resource where I could read about it. Google searches reveal lots of different definitions, so I'm not sure which to go with.\n\nThank you!",
        "other_text": [
            "Please refer to https://edstem.org/us/courses/28225/discussion/2235222?comment=5172765"
        ]
    },
    {
        "title": "Q7 - duration of the synchronized rounds",
        "question": "Hello,\n\nWhat is meant by \"the duration of the synchronized rounds\" in Q7? What lecture is this referring to?",
        "other_text": [
            "Please refer to lecture 8 and 9 for the description of Prism. The duration here refers to the duration between two confirmations."
        ]
    },
    {
        "title": "FAQs",
        "question": "Here are some FAQs which will be incrementally updated. Please try to find the answer first (from Lecture notes, Ed, Internet, or even asking ChatGPT).\n\nWe are working on setting up the Gradescope, it will open soon.\n\nFAQs:\n\n1. For the plots in Question 1, please take a meaningful interval, e.g., one year. And you are allowed to use the suitable plots online directly. The goal of this question is just to get you familiar with the whole Bitcoin system via explorer. \n\nRemark: Take it easy when doing Q1, it is just an educational question whose aim is to get you familiar with Bitcoin explorer. Most of the answers can be found on a suitable explorer page.\n\n2. For Question 2, please just give an approximate answer in the form of $2^k$, where k should be accurate to one decimal place.\n\n3. For Question 7, please calculate the worst-case solution for part (a) (where worst-case refers to the situation with minimum throughput) and the expectation for part (b). You can assume each block has one unit of transactions and count the throughput by units, and you can assume there is one unit of transactions in each queue.\n\n4. For the Monte Carlo method, it is very simple, you can easily find many resources online, or just ask ChatGPT:\n\nQ: What is the Monte Carlo method.\n\nA: The Monte Carlo method is a computational algorithm that uses random sampling to perform numerical calculations. It is often used in mathematical modeling and computer simulations to evaluate the performance of various algorithms, and to solve problems that are difficult or impossible to solve using other methods. This method is named after the city of Monte Carlo in Monaco, where it was first developed.\n\nQ: Explain it in a simple way with examples\n\nA: The Monte Carlo method is a way to solve problems using random numbers. For example, let's say you want to know the probability of winning a game of chance. One way to solve this problem is to use the Monte Carlo method, which involves simulating the game many times and counting the number of times you win.\n\nHere's how it might work:\n\nStart by simulating a single game of chance. This might involve rolling a pair of dice, flipping a coin, or picking a card from a deck.\n\nRepeat this process many times, each time keeping track of whether you win or lose.\n\nAfter simulating the game a large number of times, calculate the proportion of times that you won. This will give you an estimate of the probability of winning the game.\n\nSo, for example, if you simulate the game 100 times and you win 55 times, then your estimated probability of winning is 55%.\n\nFor our class, you can find some examples in the lecture notes, e.g., Lecture 6, you can use the Monte Carlo method to simulate Tih\u200b and Tja\u200b in the Analysis of the private attack under zero delay section.\n\n",
        "other_text": []
    },
    {
        "title": "5b: clarification of public release of blocks",
        "question": "For question 5b, the question states:\n\nIf both the chains are of equal length, the adversary picks one chain to mine on and forces the honest party to mine on the other chain. If the honest party succeeds in mining first, then the chains are of unequal length, and we return to the previous step. If the adversary succeeds in mining first, it holds the block in private and continues mining on the private chain until the honest party catches up. At that point, the adversary publicly releases its private blocks and the two chains are again of equal length.\n\nDoes this mean, let's say if the adversary has two blocks privately held on one chain and the honest miners just mine one new block on the other chain. The adversary only releases on of it's two blocks and continues to mine privately, as it just wants to keep the public version of the two chains the same length and force the honest miners on one of them, right? ",
        "other_text": [
            "Yes!",
            "but the extra blocks mined this round wouldn't be useful for the next round correct given the possibility of switching chains (so parent hash of blocks will change)? or would the attacker keeps mining on the same chain and accumulates tons of unpublished blocks over time\n\n",
            "Please note that when two chains have equal length, we assume the adversary can decide which chain the honest party will mine (because both are longest chains). And in Q5b, we assume \"forces the honest party to mine on the other chain\". In this setting, I'm not sure what's the possibility you are asking.\n\n"
        ]
    },
    {
        "title": "Q5a",
        "question": "In the unequal case, the honest party mines longest chain and the attacker party mines the shorter chain. If one party succeeds mining first, does the other party abandon mining what it has been mining and jump into the next iteration of choosing which chain to mine since the chain lengths are updated? Or does it finish mining the half-finished block before redeciding which chain to mine?\n\nIn other words, are two parties always deciding at the same time (that is, whenever one party finishes its block) which chain to mine, or are they following their own mining schedules? \n\n",
        "other_text": [
            "You can view it as deciding at the same time. And please note even the mining power of the adversary is less than the honest party, there is still probabilty that the attack will success, which is similar to private attack.",
            "Sorry, I missed the part of whether abandon the history you asked. The history isn't abandon, just make an analogy to private attack .\n\n",
            "if they are always deciding at the same time, wouldn't the attacker be in an eternal disadvantage with a significantly less mining power, since it will almost always finish its block after the honest party and has to keep trying on the shortest chain without much progress?\n\n"
        ]
    },
    {
        "title": "Q3b Scraping Data Values from Table",
        "question": "This question asks us to use data from blockchain.com to plot the empirical CDF and I was thinking of aggregating the values from the \"mined\" section and graphing it to see if the resulting distribution is similar to that from part a.\n\nIs there a faster way to scrape all of this data or do we need to copy it manually into our own graph? \n\n",
        "other_text": [
            "You can use other explorer if you find it's easier to export the data."
        ]
    },
    {
        "title": "Gradescope has been set up",
        "question": "Gradescope has been set up, please upload your answer and mark the question number.",
        "other_text": [
            "I'm getting an authorization error when I try to follow the link to the course. Can I get the course code to manually add it?",
            "Hi Prachi, are you using canvas to log in to Gradescope? Usually it should work, if it doesn't please use this code: PXGKZX\n\n",
            "I have an email alias. My account for gradescope is using ps1021@princeton.edu, and COS470 was adding my psin@princeton.edu email (I've had the same issue with another class before). I was able to add myself using the code!"
        ]
    },
    {
        "title": "selfish mining simulation",
        "question": "Since there is no real \"attacker success\" stopping point for selfish mining, are we expected to fix a time frame and test how the chain quality vary across beta?\n\n",
        "other_text": [
            "Yes, you can set a sufficiently long time frame for the simulation.",
            "Is it equally suitable to set a finite block limit for the simulation?",
            "Sure"
        ]
    },
    {
        "title": "Final Q4b",
        "question": "How come the values in Nakamoto's value show a probability of 1.0 when k=0?\n\nIt was my understanding, and I read in the notes, that in order to be successful, the adversary needs to mine k+1 blocks before the honest miners mine k+1 blocks. How can the probability for success be 1 when the adversary still has to beat the honest miners?",
        "other_text": [
            "We are aware of this confliction, I think it's because this k+1 should be k, but let me double check and get back to you later.",
            "The notes say \"the private attack is successful exactly when the total time to mine k + 1 blocks by the adversary is faster than the time the honest miners take to mine their k + 1 blocks\". Isn't a private attack also successful if it catches up to the honest process after k+2, k+3, etc. blocks?"
        ]
    },
    {
        "title": "Q7b: parameters",
        "question": "For question 7b, do we just choose some values for $\\lambda$ and $\\Delta$ and sweep $q$ for the plot?",
        "other_text": [
            "Sure, you can choose some configurations of $\\lambda$ and $\\Delta$ for the plot."
        ]
    },
    {
        "title": "Q4 clarification: what constitutes one MC trial",
        "question": "The MC method involves repeating one experiment over and over again to estimate the probability of success.\n\nI'm trying to understand what is involved in a single trial of the experiment we are expected to do in Q4\n\nIs a single trial:\n\nOne attack, i.e. we have the selfish and honest nodes mine k + 1 blocks and check what is faster\n\nOne blockchain, i.e. we simulate the entire mining of a finite block blockchain which has both selfish and honest miners, and see if selfish miners can ever violate security at any point in the mining proces",
        "other_text": [
            "Good question! I think it should be the first one, i.e., one attack. If you simulate one blockchain instead, as the chain getting longer it is always possible that the adversary can violate the chain at some point."
        ]
    },
    {
        "title": "Q6 b Selfish Mining",
        "question": "If the honest block chooses to build on a honest block instead of an adversarial block, does it mean that all the previously privately mined blocks by the adversary are invalid now since their parent hash were previous adversarial blocks\n\nbasically when the honest block decides to build on Block1, Block3 becomes invalid since they were built assuming parent is Block2?",
        "other_text": [
            "Yes.",
            "Also is the question asking for a 3d plot with chain quality, beta, and p, or two 2d plots that plots chain quality against beta and p separately?\n\n",
            "Either is fine."
        ]
    },
    {
        "title": "Q5b winning condition",
        "question": "In question, it said, \"We say this attack is successful if there exists a time when both chains are of equal length greater than k.\" If the adversary hash power is greater than honest, and it pick chain_1 to mine privately, it is possible that the honest miner would never catch up the chain length in chain_2. In such a scenario, if both chain_1 and chain_2 length is greater than k, does it means the adversary's balance attack succeeds? \n\n",
        "other_text": [
            "Yes, because the released adversarial chain is still of same length."
        ]
    },
    {
        "title": "Private attack lecture notes derivation",
        "question": "The lecture notes give an upper bound on the probability of deconfirmation of a block (which is what we want for the private attack). But when I plot that expression, it gives me weird values (they don't match the graph that follows the equation). They also don't follow the probability derived using the negative binomial distribution (which is supposed to be the correct estimation for the private attack).\n\nAm I interpreting the equation wrong?\n\n\n\n^ I cannot recreate the red line using $P = e^{log_e(4\\beta(1-\\beta))(k+1)}$. e.g. if we plug in $\\beta = 0.3, k = 0$ it evaluates to 0.84.",
        "other_text": [
            "We are aware of this confliction, I think it's because this k+1 should be k, but let me double check and get back to you later.",
            "Replacing k + 1 with k also doesn't fix it (it just fixes the case for k = 0). The rest remains off the actual values.",
            "That's because in the lecture it only gives an upper bound?",
            "Oh okay, that makes sense. I was confused because the graph said that this gave the true as well as simulated values.\n\n"
        ]
    },
    {
        "title": "Q4: Network delay",
        "question": "Does the question expect us to make any assumptions about network delay?\n\nAre assumptions different for different parts?",
        "other_text": [
            "You can simply assume there is no delay."
        ]
    },
    {
        "title": "Part 7 clarification",
        "question": "Just to clarify, we don't plot the worst-case throughput for part 7 right? Just the regular throughput and then analyze what happens to that as q goes to infinity.",
        "other_text": [
            "please calculate the worst-case solution for part (a) (where worst-case refers to the situation with minimum throughput) and the expectation for part (b)."
        ]
    },
    {
        "title": "Attacker Party only attacking transactions?",
        "question": "It's not related to the exam per se, but speaking of security attacks, wouldn't another attack strategy be that the attacker takes some honest transactions and intentionally mine on a shorter chain so that the block can be accepted (so the transactions will be removed from the mempool) but the honest transactions would never go through (since the wallet balance only relfects the state of the tip of  the longest chain?)\n\n\n\nI know it's kinda costly but it's still possible right?\n\n",
        "other_text": [
            "I think a transaction is only removed from the mempool when it is in a confirmed block. ",
            "the block is confirmed but confirmed on the shorter chain. this would also cause removing from the mempool based on our implementation right?",
            "In bitcoin, a block is only confirmed when k-deep on the longest chain. Our implementation didn't have any notion of confirmation so this question doesn't really apply to that."
        ]
    },
    {
        "title": "Gradescope Final Submission",
        "question": "Are we expected / Should we attach code to our final project submission, or should we just leave it in a PDF word document or the like?",
        "other_text": [
            "If you are confident about your final results, you can just submit the results, otherwise you can attach the code.",
            "There isn't a good way to attach the code on gradescope, should we just convert a python notebook to PDF and put it at the end?",
            "That's ok."
        ]
    },
    {
        "title": "Final exam deadline extended",
        "question": "The deadline for the final exam has been extended to Tuesday, December 20 - 11:59pm .",
        "other_text": []
    },
    {
        "title": "Q7b setup clarify",
        "question": "Given the number of blocks (say, 10) and the number of transaction queues (say, 5), is the throughput deterministic, or there is variability in that all the 10 blocks may pick the same queue? If it's variable, I'm assuming we are still expected to perform Monte Carlo method even though the question didn't specifically ask for it?\n\n",
        "other_text": [
            "Yes, you should compute the expectation. And you can reason out that part.\n\n",
            "followup question, are we expected to plot q to infinity as part of the graph, or can we just reason out that part?\n\n"
        ]
    },
    {
        "title": "Clarification of the definition of private attack",
        "question": "To make the comparison with balance attack eaiser, we use the following definition for private attack: We say the private attack is successful if there exists a time when the length of the adversarial chain is greater than or equal to the length of the honest chain, which are both greater than $k$.\n\nNote this is slightly different from the Nakamoto paper and the lecture note where the definition is equivalent to replacing \"greater than $k$\" with \"greater than or equal to $k$\".\n\nIf you already submitted, no worries, we will check which definition you were using.",
        "other_text": []
    },
    {
        "title": "Q7 Clarification",
        "question": "When it said \"Trivially, one may say the throughput of Prism is simply \u03bbt\u2206 blocks per round,\" does the throughput here only need the number of transactions block and each round's duration? Do we care how many transactions are in the transaction block? \n\nIn the worst-case scenario, do we want to know how many transactions block we could have per round? If two transaction blocks contain the same transactions, would both transaction blocks be valid and count into throughput? Because all the transactions (that are in the transactions block) will stay in the queue for a while until a proposer block grabs the transactions block to remove these transactions from the queue. \n\n",
        "other_text": [
            "You can think of it as each transaction has one unit of transactions and compute the throughput by unit. So if two blocks have same transactions, they only contribute 1 unit.\n\n"
        ]
    },
    {
        "title": "Q3(b) Detail",
        "question": "For the comparison aspect, do we need to do anything other than show the different plots? This is what I have. Is this sufficient?\n\n\n\n",
        "other_text": [
            "It's ok."
        ]
    },
    {
        "title": "Q7 throughput",
        "question": "Hi,\n\nFor question 7, do we need to consider adversary block in the worst scenario? For example, adversarial hash power has a beta fraction of mining, and honest block only have (1-beta) fraction.\n\n",
        "other_text": [
            "For simplicity, you don't need to consider this."
        ]
    },
    {
        "title": "Q4(a) Success Probability Threshold",
        "question": "Theoretically, I believe that the mining rate should not affect the probability of private attack success, especially since any increase or decrease in theta would be the same for the adversary and the honest miners. I am a little unfamiliar with Monte-Carlo Simulations, so I was wondering whether the similarities between these values of success probabilities are close enough to validate that belief:\n\nAlso, the definition of a success probability for a blockchain is from the Lecture 6 notes, \n\nwhen the sum of the mining times for the honest for $k+1$-blocks is greater than the sum of the mining times for the adversary for $k+1$ blocks. Is this understanding accurate? My code is below:\n\n",
        "other_text": [
            "It is close enough. And for the private attack, please use the definition in #507. Where the difference is that if adversary can catch up the honest party later than $k$ blocks, it's also considered as a success, which is similar to the balance attack setting.\n\n"
        ]
    },
    {
        "title": "Deadline extension",
        "question": "Thank you very much to the staff for extending the deadline, the exam is proving to be much harder than anticipated.\n\nWould it be possible to change the extension to the official take-home deadline of Thursday (22nd)? Many students have finals earlier in the week and will not be able to use this extension for all.\n\nIt is fine if not possible. Thanks!",
        "other_text": []
    },
    {
        "title": "Q4a/b",
        "question": "Does our monte carlo simulation need to be completely coded from scratch or can we base our success probability function off the one given by Nakamoto in the bitcoin whitepaper and then use the same code, just with different parameters for 4 part b? ",
        "other_text": [
            "I think we are expected to code our own simulation because the one provided by Nakamoto is not accurate (cauz it assumes lambda = z*q/p). I don't think we can call his code as a simulation per se, more like an implementation of his formula.\n\n",
            "Thanks, Bofan! That's the correct answer."
        ]
    },
    {
        "title": "Q6 range for B",
        "question": "Hello!\n\nIn the course notes, it was said that beta should be less than 1/2. I was wondering if we should take this into account and in general, limit the range of beta that we are testing against chain quality? If so, what should that range be? Would it be 0 to 0.50?\n\nIn addition, would the range for p be 0 to 1?\n\nThanks!",
        "other_text": [
            "Sure, you can take beta from 0 to 0.5 and p from 0 to 1."
        ]
    },
    {
        "title": "Final show work?",
        "question": "Hello,\n\nI was wondering if for our submission for the final exam, we needed to show work, or if only the final solution/diagrams were needed.\n\n(By work, I am referring to for example code written to run the simulations)\n\nThanks!",
        "other_text": [
            "If you are pretty confident about your final results, it is ok to only include them, otherwise, you can attach the code after your solution.",
            "Just out of curiosity, would attaching work/code enable partial credit for questions where the answer isn't completely correct but the methodology was?",
            "Yes."
        ]
    },
    {
        "title": "Question 4 clarifications",
        "question": "1. How are we defining the success probability in this question? is it the number of attack blocks divided by the overall blocks?\n\n2. When we simulate private attacks, can we run a single test or should we run it over a range of values similar to the whitepaper?\n\n3. (more specifically part c) How should we prove there is/isn't a Poisson distribution? Do we need to plot the values or do probability values suffice?\n\n\n\n4. What does \"closed form\" mean?",
        "other_text": [
            "1. The success probability is the probabilty that one attack attempt succeeds (see #507 for the definition of success).\n\n2. Please use a range of values.\n\n3. It's better to plot it.\n\n4. Closed form means the answer is an algebraic expression of the corresponding values."
        ]
    },
    {
        "title": "Q7b transaction numbers",
        "question": "So for 7b when we are simulating the throughput as a function of q, I\u2019m a little confused about the number of transactions. We are told that the transaction block mining models a poisson process, however, how often are the transactions that go into the queues being repopulated? I know within a single round, the transactions remain on the queue until accepted but should we assume just a very large number of transactions are divided amongst q queues for every round? Also, should we make assumptions about how many transactions go into a single block? Should this be a random number?",
        "other_text": [
            "You can assume each block has one unit of transactions and count the throughput by units, and you can assume there is one unit of transactions in each queue."
        ]
    },
    {
        "title": "Q7 worst-case vs expected",
        "question": "I had some confusion surrounding \"worst case\" vs \"expected.\" From previous discussions, it seems that 7a is regarding worst case and in 7b we should plot expected throughput vs q. \n\n7a - upon reasoning this out, I get a numerical value for worst case using logic of how the worst-case scenario for a queue would play out. Is the answer supposed to be some kind of expression instead of a simple numerical value? Am I thinking too simply by suggesting a single number for the number of non-redundant blocks per round?\n\n7b - I found an expression for expected throughput that was based on the premise that we have q different queues, and the expected value of non-redundant blocks is related to finding the probability that a block is from a different queue multiplied across the total blocks. Is this approach for expected throughput reasonable? \n\nThanks!",
        "other_text": [
            "Yes, it's reasonable, and you may find this simplication helpful: \"You can assume each block has one unit of transactions and count the throughput by units, and you can assume there is one unit of transactions in each queue.\""
        ]
    },
    {
        "title": "Q4 Clarification",
        "question": "Part 4d says to derive a closed-form expression by \"correcting\" the distribution from part 4c. Based on this wording, it seems that we're being explicitly told here that the distribution from part 4c is wrong. Is it true that the distribution from part 4c is wrong based on this wording or am I misinterpreting it?",
        "other_text": [
            "It is wrong \ud83e\udd2b\n\n"
        ]
    },
    {
        "title": "Further extension of final exam deadline",
        "question": "Upon request, we have decided to extend the deadline to Dec 22 further. Please take your time. Most of you did an excellent job in programming assignments which is the major part of the grade, so take it easy and good luck with your final exam :)\n\n",
        "other_text": []
    },
    {
        "title": "Q6b how to plot the 3 vars",
        "question": "For 6b it asks us to plot the chain quality as a result of Beta and probability. For the graph, should we use Beta and Probability as the two axes and represent chain quality in terms of like a color map? Or, should we use the axes for probability and chain quality and then use multiple lines for different Beta values?",
        "other_text": [
            "Either is fine :)"
        ]
    },
    {
        "title": "Final Exam Q4 Monte Carlo Simulation Calculated Attack Success Probability Precision",
        "question": "How precise are the attack success probabilities we calculate through the Monte Carlo simulation supposed to be? i.e. if we run our simulation multiple times how close should the outputs be? \n\n\n\n",
        "other_text": [
            "Hi Ben, you can use a number of iteration that when increasing it (e.g., doubling) there is no significant difference in the results.",
            "Also does 1000 repetitions sound reasonable for the simulation?"
        ]
    },
    {
        "title": "Q7a expression",
        "question": "For Q7a, are we expected to derive an expression of worst-case throughput as a function of q since the worst-case throughput would be very different depending on q? or are we calculating the absolute worst-case regardless of any parameters?\n\n",
        "other_text": [
            "It could depend on $q$."
        ]
    },
    {
        "title": "Late submission?",
        "question": "Hi, I saw the notification that said we would have our final exam deadline on Dec 22nd. In Gradescope, we still have a submission deadline on the 20th, and the 22nd is for the late due date. If we submit after Dec 20th, will it consider as late submission, and will we get a late penalty on that?\n\n",
        "other_text": [
            "No, you can submit until 22nd"
        ]
    },
    {
        "title": "5a clarification q",
        "question": "In this question, when it says \"significantly more blocks than k,\" what does significant mean? \n\n",
        "other_text": [
            "For example, you can use 3k as a threshold.\n\n",
            "Should the simulation stop when one chain is significantly longer than the other, or simply once the honest miners have mined a certain amount (3k), regardless of the chain lengths?",
            "I meant $3\\cdot k$ instead of 3000 here."
        ]
    },
    {
        "title": "Office hours this week",
        "question": "Are we having normal office hours this week? ",
        "other_text": [
            "Hi Ben, please post your questions on Ed and we will try to answer them.\n\n"
        ]
    },
    {
        "title": "5c clarification",
        "question": "Are we putting the plots of all beta values in part 5A and part 5B and the plots from 4A, 4B, and 4C into one? I'm a little confused what the x and y axes will be and I think it may be hard to differentiate even with color. How can we make this plot look better for the graders? ",
        "other_text": [
            "You can choose a few representative configurations, with x being k and y being the probability."
        ]
    },
    {
        "title": "Clarification of balance attack (q5)",
        "question": "In the directions in 5a, it says that the \"Adversary always publicly releases any successfully mined block.\"\n\nBut in the lecture notes (lecture 8), it says that \"The adversarial miner simply privately mines on the two blocks forking from the genesis itself.\"\n\nI'm confused because in the algorithm given on the final, it seems that when the chains are equal length, the adversary should be privately mining, but they instead stop mining altogether. If the adversary stops mining, then it doesn't matter that the honest mining power is split between the two chains, because the adversary isn't gaining anything from this attack anyway.",
        "other_text": [
            "There are several settings for balance attacks; please follow the specific instruction. For example, 5b gives a privately mining version. And you are right that whether splitting honest mining power does matter for the success probability."
        ]
    },
    {
        "title": "Question 4(b) Parameters Clarification",
        "question": "Hello,\n\nI wanted to get a clarification regarding which parameters we should test for Question 4(b):\n\nGiven that #513 states that the assumption lambda = z*q/p) is incorrect in the paper, which I agree is the problem with Nakamoto's code, I wanted to confirm which values we should test over.\n\nIs it okay that I set the mining rate $\\lambda = 1/600$ (1 block per 600 seconds)? Or is there another value to test on?\n\nAnd then the beta value (proportion of mining power that the adversary has is $q = \\{0.1, 0.3\\}$ with the block values of 0-10 and 0-50 (per 5 blocks) respectively.\n\nAre those the values that we should test over?\n\nAlso, are we supposed to show the values for z given each value of q for P < 0.001 as well?\n\nThank you for the clarification; just wanted to make sure that I understand what you meant by \"parameters in Nakamoto's table\".",
        "other_text": [
            "You can choose $q\\in\\{0.1, 0.3\\}$ and $z\\in[1, 10]$ and $\\lambda$ doesn't matter here."
        ]
    },
    {
        "title": "General Question about Length of Blockchain",
        "question": "If a chain forks from the genesis block, is its length = 1 even before it mines a block on the fork? \n\nOr in other words, after one block is mined in a fork, is the length of that chain 2?",
        "other_text": [
            "It depends on the context. Which question are you considering specifically?\n\n",
            "In question 4, should the adversarial and honest chains start with the genesis block and a length of 1?",
            "Yes, please also refer to #507 for detailed definition.",
            "So the block that they both share (i.e. $B'$) should be counted in the length? This seems counterintuitive to the notes. \n\n",
            "Yes, the definition in #507 is different from the note but more align to the balance attack.\n\n",
            "I am still a little confused. Therefore, in the following case, where $k = 2$ and only two blocks have been mined since the genesis/shared block, the lengths of the chain are $3$ and the private attack has a success?\n\n",
            "Yes."
        ]
    },
    {
        "title": "Q7 Clarifications",
        "question": "Should we assume that there are always enough pending transactions to fill up all q queues?\n\nAlso, can we have multiple transactions in a single queue? If so, how exactly does that work and how does a miner decide which to include? If not, then can we assume that throughput is maximized at q?",
        "other_text": [
            "Please refer to #517 ."
        ]
    },
    {
        "title": "Q5b Clarification",
        "question": "\"If both the chains are of equal length, the adversary picks one chain to mine on and forces the honest party to mine on the other chain. If the honest party succeeds in mining first, then the chains are of unequal length, and we return to the previous step. If the adversary succeeds in mining first, it holds the block in private and continues mining on the private chain until the honest party catches up. At that point, the adversary publicly releases its private blocks and the two chains are again of equal length.\"\n\nThis implies that if the adversary mines on the private chain s.t. the private chain is always ahead of the honest party's chain, then the private chain is never publicized, and so the attack would technically be unsuccessful.\n\nI know I'm reading this very literally, so how are we expected to treat this scenario?",
        "other_text": [
            "Sorry, I don't quite understand your question. Are you saying the attack is unsuccessful because the private chain is always longer than but not equal to the honest chain?",
            "\"it holds the block in private and continues mining on the private chain until the honest party catches up\"\n\nWhat I'm saying is that if the honest party never catches up, the adversary never releases its blocks. Hence there will not exist two chains of equal lengths, and the attack fails.",
            "Here \"catch up\" means honest party mines a new block, which always happens unless honest party has no mining power.",
            "So, in the case that the chains are equal, and the adversary mines a block first, does the adversary just wait until the honest party mines a block? In that case, the chains will be equal again, and the same situation will repeat. This is especially exacerbated in the case where $\\beta > 0.5$. Should this situation just repeat until the honest miner finally mines a block faster and the chains are unequal again? What is the point of the adversary waiting and not mining the private chain as to create a private attack?\n\nIf it does not wait and continues the mine on that private chain, then Oleg's question still applies i.e. the honest party may never catch up. "
        ]
    },
    {
        "title": "Clarification on Private Attack Definition",
        "question": "Following the definition from #531, I am a bit concerned because when running the simulation, the threshold for the success of a private attack is $\\beta = 0.435$ with $k = 6$ and $\\lambda = 1/600$, which is less than the 51% seemingly expected. You can see my code below:\n\n# from definition on ed :\n# counting the original shared block as 1st block\n# success when len(advers) > len(honest) > k\ndef sim_private_attack_simple(k, beta, rate):\n    advers, honest = 1, 1 # length starts at 1\n    for block in range(1, k * 3): # mining starts post genesis\n        honest += random.expovariate((1-beta) * rate)\n        advers += random.expovariate(beta * rate)\n        if advers <= honest and block >= k:\n            return True\n    return False\n\n\nSince the length starts at $1$ and if $k = 2$ like in the diagram I shared in #531 , only two iterations (i.e. two more blocks to be mined) will be required to check whether the private attack has succeeded. Is this accurate? ",
        "other_text": [
            "I'm not sure where the 51% here comes from. If you are referring to the \"51% attack\", it holds when $k\\to\\infty$."
        ]
    },
    {
        "title": "Q4 trouble with simulations",
        "question": "I don't think I'm doing the simulations correctly because I am getting results (particularly for 4c) that align with Nakamoto's reasoning (i.e. I am getting a Poisson distribution with $\\lambda = k \\frac{\\beta}{1 - \\beta}$).\n \n\nShould I be doing my simulations some other way or does this seem okay? Otherwise, what might be the issue?",
        "other_text": [
            "The actual distribution is very similar to a Poisson but not exactly the same. In you simulation, the time scale seems a little coarse-grained that your each trail consists one unit of time (so the increments of length is Poisson distribution). It could be possible that within this time there are multiple blocks mined which makes things complicated. You can probably use a very small lam and keep the current simulation or use the event of \"a new block is mined\" as the trail.",
            "If I were to use the event \"a new block is mined,\" would that mean I need to sample the time between each newly mined block from a Poisson distribution (with $\\lambda = 600$ for example since each block is mined on average every 10 minutes)? I know in #442 you said that we could simulate $T_i^a$ and $T_j^h$ from Lecture 6 so I'm just trying to clarify what that means. Would the times $T_i^a$ and $T_j^h$ be sampled from an exponential distribution, as outlined in Lecture 6?",
            "If you want to simulate the interval, please note that the inter-arrival time of the Poisson process follows an exponential distribution (https://en.wikipedia.org/wiki/Poisson_distribution).\n\n",
            "I feel like I shouldn't be getting this many successes but I can't find anything wrong with the code.",
            "Please note that in numpy, the variable of the exponential distribution is $1/\\lambda$."
        ]
    },
    {
        "title": "q4 precision",
        "question": "For q4, recalculating Nakamoto's values, I have been getting significantly varying results each time I run it and my results are fairly imprecise. My strategy has been to run the Montecarlo simulation 10,000 iterations, where in each iteration I calculate the the honest and adversarial miner's time to produce 2000 blocks. For each of these blocks I calculate the time it takes the honest and adversarial miner to mine the block (randomly drawing from an exponential distribution) and add this time to the total time it has taken for the miner to reach this block level. If at any block level greater than k, the adversarial miner's time is less than the honest ones I end the simulation and mark it as a success. \n\nAs I do 10,000 iterations I can only calculate success probability to 0.0001 precision. This is a problem as some of the k-values Nakamoto models should have values less than 0.0001. I also have the problem of significant variation among results. The simple solution would be increasing from 10,000 to say 1,000,0000 iterations but already 10,000 iterations takes a long time to run. \n\nMy question is how precise are we expected to make our answer and do I need to approach this question in a different way to achieve this precision. My understanding is that we are supposed to calculate the probability of success for the adversary at any point of time in the future and thus I have chosen a large number of blocks to model in the future 2,000, is this not a correct interpretation, or can I get away with a smaller number of blocks to model?\n\n",
        "other_text": [
            "You can use, for example, 3k to replace 2000, and if you find it hard to be very precise, just simulate for small k like 1-30.",
            "3k would take more time but I ran some tests and found the probabilities don't change much for B = 0.1 if I simulate even only 50 or 100, rather than 2000 blocks per simulation, I think this is because the probability is so low for even k = 50. With 100 blocks I'm able to run the simulation for 10,000,000 iterations which seems to give pretty good precision.\n\nFor question 4 b, however are we supposed to only recreate Nakamoto's firs two tables, or also the third one (solving for p)?: \n\n",
            "(From Nakamoto white paper)",
            "Oh I meant $3\\cdot k$ instead of 3000."
        ]
    },
    {
        "title": "Balance Attack Success for 5(b)",
        "question": "The nuanced version of the balance attack states that \n\nIf both chains are of equal length [...] and if the adversary succeeds in mining first, it holds the block and private and continues mining on the private chain until the honest party catches up.\n\nWhat should we do if the honest party does not catch up? This is seemingly a likely scenario when $\\beta > 0.5$ (in fact, my code hangs on this particular part because the honest party does not catch up.",
        "other_text": [
            "The private chain can be arbitrarily long, and the \"catch up\" here refer to the public chains.\n\n",
            "Yes, but in the nuanced case, it is written:\n\nIf both the chains are of equal length, the adversary picks one chain to mine on and forces the honest party to mine on the other chain. \n\nSo, for example, if the adversary chooses chain 1  and continues to mine on it, and then honest miner chooses chain 2, what do you mean by private vs. public chains? I believe the same question is being posed in here #533, so apologies for the duplicate question. \n\nThe case I present is that when the \n\nchains are equal:\n\nadversary mines first on, for example, chain 1\n\nhonest mines second on, for example, chain 2\n\nWhat does the adversary do after the honest miner completes mining its block on chain2 and publishes?\n\nIt makes sense that adversary releases on chain 1  to equalize them, but by then, the adversary could have mined even more on chain 1, especially if $\\beta > 0.5$. \n\nIf the adversary does not continue to mine, does this loop of \"chain equal, adversary mines first\" only stop when the honest mines first after chain is equal?\n\nThank you so much for your help!",
            "If the honest miner completes mining its block on chain2 and publishes, the adversary will release on chain1 to equalize the lengths and keep mining on chain1 and forcing the honest miner to mine on chain2. You can think of this process as similar to a private attack.",
            "For $\\beta > 0.5$, as this is a private attack, the chains would not balance, no? Since on chain 1, the adversary will continue to mine faster than the honest, and the distance between the chains will just continually increase. In this case, do we consider the balance attack to succeed or to fail?",
            "It is a success because the adversary can always make the released chains to be of equal lengths.\n\n"
        ]
    },
    {
        "title": "Q4 Lambda",
        "question": "I'm confused by what lambda represents in the terms of Q4. On Sakamoto's white paper, its addressed as just the \"Poisson distribution\"\n\nHowever, Professor's Lecture 6 notes calls it the \"mining rate\" or \"difficulty parameter\"\n\nWhich one is the lambda defined in Q4? Are they the same Lambda?\n\n",
        "other_text": [
            "Please follow the notes to interpret $\\lambda$ as the parameter of the Poisson process of mining. In Nakamoto's paper, he used $\\lambda$ as the parameter of a different process."
        ]
    },
    {
        "title": "Q4 when to stop simulation",
        "question": "Since in Q4, we need to check if there exists any time T when the length of the adversarial chain is greater than or equal to the length of the honest chain, when both are greater than k, and this time T could theoretically be infinitely far in the future, for how long should we run our simulation for? Should we fix a total number of blocks to be mined, and should this fixed limit depend on our value of k (e.g. be proportional to k)? \n\n",
        "other_text": [
            "Yes, $3\\cdot k$ should work.",
            "I think 3k has been suggested by TAs as an acceptable limit"
        ]
    },
    {
        "title": "Incentives for attacking",
        "question": "We saw that the worst-case attack for PoW mining is the private attack and you need to have above a certain threshold of the mining power in order for any attack to be successful. Does this mean that in the real world almost 100% of the miners on a chain are behaving honestly?\n\nBecause if the attackers are above the required threshold, we probably would have detected an attack?",
        "other_text": [
            "Attacks do happen in real world, for example, you can check this https://dci.mit.edu/51-attacks"
        ]
    },
    {
        "title": "Office Hours Tomorrow",
        "question": "Any chance we could have a final office hours tomorrow? ",
        "other_text": [
            "Sorry, we are not holding office hours anymore, as this has been long after the original deadline."
        ]
    },
    {
        "title": "Q2 Probability of Hash Collisions",
        "question": "In the course notes (cryptographic primitives), it is described that the probability of at least one collision among m hashes is approximately 1 - exp(-(m^2)(2^(-k))):\n\nHowever on wikipedia the probability is listed as 1 - exp(-(m^2)((2k)^(-1)))\n\nI would have just gone with the probability provided in the course notes but I saw in the faqs it said to express your answer in terms of 2k, for which the wikipedia probability would make sense. Is there a mistake in the course notes? And should we use probability listed on wikipedia? ",
        "other_text": [
            "Sorry, it should be $2^k$ instead of $2k$ due to some Latex typo. And you can use formula from Wiki.\n\n"
        ]
    },
    {
        "title": "Question 6",
        "question": "For Problem 6, when should we end an individual simulation and calculate the chain quality? Would it be reasonable to do this when the longest chain reaches a set threshold of length?\n\n",
        "other_text": [
            "That only seems reasonable! Can't run it forever.",
            "You can use $3\\cdot k$ as a threshold."
        ]
    },
    {
        "title": "URGENT!!!",
        "question": "Hey Good evening\n\nI need help. My laptop isn't switching on. Im trying to submit it but it got wet and its not working!!! I cant get in to email it to myself. I wanted to ask if i could please submit it abit late. I know we already got alot of extensions but its really urgent and I dont know when I can access it Next. Im trying to dry it right now but its not working!\n\nI dont mind loosing points for late days but Im so scared i will miss out on all the points",
        "other_text": [
            "Hi Max, I'm sorry to hear that, please take your time and it's ok to submit it tmr.\n\n",
            "Thank you. I will keep you guys updated\n\n",
            "We just extended the late submission by one day, please directly submit your solutions to Gradescope.",
            "Good evening. My laptop has gone in for repairs. I know it isnt complete but the only part of the assignment I have and I found is part 1 - 3. All my other simulations were on my laptop and I havent been able to get access to another laptop because school is over. Should I bother submitting part 1- 3. And is there any other way I can get extra credit on this course. Ive worked really hard on this and I feel like Im about to loose the last few points I need to get a good grade.",
            "Ive updated it to be more recent and redone what I could. I didnt edit the fonts or anything my apologies"
        ]
    },
    {
        "title": "Follow up on Q2 FAQ",
        "question": "I am still a bit unsure of how we were asked to write our solutions to question 2. From the FAQ:\n\n\"For Question 2, please just give an approximate answer in the form of 2, where $2^k$ should be accurate to one decimal place.\"\n\nFor part A, I needed to raise a power to a power, but I'm not sure if it is okay to leave the answer in this form (since the FAQs seem to say our answer should be 2 raised to a decimal. Does this sound okay?\n\nFor part B, I can write my answers in the form of $2^k$, where k is a decimal $*$ n, but the decimal itself would also be different for different n. Do we need to instead find a way to get one expression in terms of n that works for any n? Thanks.\n\n",
        "other_text": [
            "Sorry, it should be $2^k$ instead of $2k$ due to some Latex typo.",
            "That is good confirmation. Would you mind providing any insight on the questions above regarding partA and partB? Thank you for your help",
            "Please answer the questions with the specified $n$s (256(n=8), 4, 5,6,7) in the description. You don't need to give a general expression to variable $n$.",
            "Is it 2^k or 2k? on my laptop it comes out as 2k which is confusing to me considering lecture notes.",
            "I figured the 2k in the FAQ was supposed to say $2^k$ instead based on other Ed posts, lecture notes, etc."
        ]
    },
    {
        "title": "q5a starting conditions",
        "question": "For q5a does anyone understand if starting out: mining starts at genesis so the adversary won't mine until the first block is made and the chains are now unequal OR mining starts with two blocks forked from genesis already there? \n\nAlso if it is two blocks forked from genesis already there, do we count these two blocks in each chain towards length k? \n\n",
        "other_text": [
            "Hi Ben, it's the first case, i.e., the adversary won't mine until the first block is made."
        ]
    },
    {
        "title": "5b vs 4",
        "question": "Can we interpret 5b as essentially the same situation as 4? If the private miner always chooses to mine on the same chain, it seems like it is now just a race between the private and honest miners as the simulation in 4 was. ",
        "other_text": [
            "Yes."
        ]
    },
    {
        "title": "Final solutions",
        "question": "Would be great if we could get the solutions including the coffee if it exists). The should were especially tricky to figure out. \n\nThank you! ",
        "other_text": [
            "Hope you liked the course and the take-home problem set. We are working on an official set of solutions and, although not sure if we will publish them, we are happy to discuss 1:1 anytime. We can do the coffee (or dinner) as part of COS/ECE 473 next semester when we discuss DeFi. That class will have a very different feel: every lecture will have a hands-on lab component to supplement the lectures/slides. \n\n    Happy holidays everyone. "
        ]
    }
]