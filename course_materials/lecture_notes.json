{
    "lecture_11.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\usepackage{markdown}\n\\usepackage{amsthm}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\newcommand{\\indicator}{{\\bf 1}}\n\\newcommand{\\pramod}[1]{{\\color{red}\n\\footnotesize[Pramod: #1] }}\n\\newcommand{\\xw}[1]{{\\color{green}\n\\footnotesize[Xuechao: #1] }}\n%\\theoremstyle{definition}\n\\newtheorem{definition}{Definition}\n\\newtheorem{theorem}{Theorem}\n\\newtheorem{lemma}{Lemma}\n%\\let\\proof\\relax\n%\\let\\endproof\\relax \n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 11}\n\\cfoot{\\thepage}\n\n\\title{Lecture 11:  Scaling Energy via Proof-of-Stake}\n\\author{Principles of Blockchains, Princeton University,  \\\\ Professor:  Pramod Viswanath \\\\ Scribe:  Xuechao Wang}\n%\\date{March 9, 2021}\n\\date{\\today}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nIn the past lectures we have seen proposals that significantly improve the performance of Bitcoin while retaining its security. One aspect that has remained unchanged is the PoW mining procedure inherent to the Bitcoin protocol. PoW mining consumes a huge amount of resources (electricity and specialized computer hardware), comparable to that of a medium to large sized country. In this lecture, we study how to replace PoW by an alternative that is computationally trivial, thus eradicating  the electricity consumption inherent to Bitcoin. The alternative to PoW is called Proof of Stake, which is the focus of this lecture. \n\\end{abstract}\n\n\n\\section*{Introduction}\nThe blockchains we have seen this far, from Bitcoin to its improvements, are based on the proof-of-work (PoW) mining procedure. The PoW procedure is central to the design, serving multiple roles: protecting against network spam, serving as a block proposer election procedure, deterring protocol level attacks from adversaries. However, the PoW mining procedure is extremely resource consuming, both in terms of sheer electricity requirements as well as specialized computer hardware (GPUs) to speed up the search for nonces. Electricity consumption connected to Bitcoin's mining has been estimated to be comparable to that of a medium to large sized country. Another way of looking at the outsize electricity wastage of Bitcoin: a single Bitcoin transaction consumes electricity equivalent to 750,000 credit card (e.g., Visa) transactions. Not only is this comparison staggering, worse is the observation that as more participants enter the Bitcoin ecosystem, the mining procedure gets more competitive, and more electricity is consumed. This is a form of {\\em reverse} network effect, where the more the participation, the worse the efficiency. As such, an extremely compelling dimension of Bitcoin scaling is {\\em energy}. This is the goal of this lecture, where we will focus on a specially attractive option, {\\em Proof of Stake} (PoS), as a replacement to PoW. \n\n\\section*{From PoW to PoS}\n\nIn a PoW protocol, successful mining (``work\") is related to being able to propose a block; the larger the fraction of hash power, the more the probability of success in the mining ``lottery\" (the right to the next valid block on the blockchain). In  proof of stake (PoS) protocols, the mining lottery is simply replaced so that  each node wins with probability proportional to its {\\em stake} in the total pool. The stake refers to the total amount of coins the node has, as estimated based on the confirmed ledger up to the point of mining; security of the ledger ensures that each honest node has the same estimate of the stake. \n\n\n\nIn this lecture, we focus on how to design a secure PoS protocol by mimicking the  PoW longest chain protocol as much as possible. In the longest chain protocol,  a miner succeeds in finding a {\\sf nonce} such that the following inequality is satisfied:\n\\begin{equation}\n    \\label{eqn:pow}\n    H{\\rm (prev\\_hash,merkle\\_root,nonce)} < T,\n\\end{equation}\nwhere $H(\\cdot)$ is a cryptographic hash function, prev\\_hash is the hash of the header of the previous (parent) block, merkle\\_root is the Merkle root of the transactions in the block, nonce is an integer that can be adjusted by the miner, and $T$ is a pre-defined threshold deciding the mining difficulty.    \n\nWhen a PoS system is launched, a collection $\\mathcal{N}$ of nodes is initialized. Each node $n \\in \\mathcal{N}$ is initialized with a coin possessing stake ${\\rm stake_n}$, and a public/secret key pair ${\\rm (pk_n,sk_n)}$ for signatures. The genesis block contains all public keys and initial stakes of all nodes. For now, let us assume the stake of a node does not change according to the transactions in the blockchain. This is called the static stake setting. We now discuss how to design a leader election mechanism in the PoS system by modifying Equation~(\\ref{eqn:pow}). \n\nTo eliminate the role of hash power, the {\\sf nonce} in Equation~(\\ref{eqn:pow}) must be removed. Also to prove the ownership of a coin, we can feed the public key of the coin into the hash function. Since we want each node to win with probability proportional to its stake, the right hand side of Equation~(\\ref{eqn:pow}) should be proportional to the stake. Combining both of these, we make our first attempt at the PoS lottery.\n\n\\noindent{\\bf PoS Attempt 1.} A node $n$ succeeds in mining a block if\n\\begin{equation}\n    \\label{eqn:pos1}\n    H{\\rm (prev\\_hash,merkle\\_root,pk_n)} < T\\cdot{\\rm stake_n}.\n\\end{equation}\n\nHowever, even though the {\\sf nonce} is removed, a node can still try to ``game\" the lottery by trying different Merkle roots (this is done by inserting different  transactions and different orderings in the block). Then again nodes equipped with better machines will have the advantage in winning this lottery; such an attempt is referred to as a {\\em grinding attack}.  Therefore, the Merkle root in the block header also has to be removed.\n\n\\noindent{\\bf PoS Attempt 2.} A node $n$ succeeds in mining a block if\n\\begin{equation}\n    \\label{eqn:pos2}\n    H{\\rm (prev\\_hash,pk_n)} < T\\cdot{\\rm stake_n}.\n\\end{equation}\n\nHowever, for a fixed $T$, there is always a non-zero probability that no one can satisfy Equation~(\\ref{eqn:pos2}); in this case, the protocol simply stalls forever. A way out is to allow everyone a second chance if no one wins the first round of the lottery. We can add one more variable in the hash function: the timestamp {\\sf ts}. We can discretize the time, for example, each node makes one attempt every second. \n\n\\noindent{\\bf PoS Attempt 3.} A node $n$ succeeds in mining a block if\n\\begin{equation}\n    \\label{eqn:pos3}\n    H{\\rm (prev\\_hash,ts,pk_n)} < T\\cdot{\\rm stake_n}.\n\\end{equation}\n\nSince time keeps progressing (at least for honest nodes), this attempt prevents the stalling issue. However, since the block header no longer contains the Merkle root of all the transactions, the transactions can be added (or altered) into the block content {\\em after} the node wins the lottery. So, unlike PoW, the entire block is no longer ``sealed\" by the PoS. How to ensure that the blockchain is tamper-resistant? \n\nOne possible solution is the following: while the block headers are linked by hash pointers, the block contents also form a hash chain (see Figure~\\ref{fig:pos}). With this structure, the adversary cannot modify the entire chain as long as some of the blocks are owned by honest nodes. Nevertheless, an adaptive adversary can still corrupt all honest nodes who own blocks on the chain and again the adversary is able to change any block on the chain. This can be resolved by a cryptographic primitive called {\\it Key Evolving Signature} (KES), where keys are periodically erased and generated, while the new key is linked to the previous one. A simple example of KES involves periodically changing the secret key of any coin by its hash output. The block content must be signed by the winner of the lottery using KES. We can ask honest nodes to erase all the old keys, which ensures immutability of the contents of honest blocks against an adaptive adversary.\n\n\\begin{figure}\n    \\centering\n\\includegraphics[width=0.6\\textwidth]{figures/pos.png}\n\\caption{Comparison of PoW and PoS blockchain structures. In  the PoW longest chain, the header of each block contains a Merkle root of the block content, hence the entire block is sealed by PoW. In the PoS longest chain, to avoid grinding, the block content is added after the header wins the lottery. To guarantee tamper resistance, the block content has hash pointers to the block header and the previous block content. }\n\\label{fig:pos}\n\\end{figure}\n\nNote that the set of public keys is available to every node which means the winner of a lottery is actually known to the public ahead of time, so an adaptive adversary may still corrupt/bribe an honest node who is going to win the lottery at a known time in the future. To avoid this, we introduce another cryptographic primitive called {\\it verifiable random function} (VRF), which enables the nodes to run the lottery with their {\\em secret keys} as opposed to the public keys; the output of the VRF is verified using the corresponding public key. This is summarized below. \n\n\\noindent{\\bf PoS Attempt 4.} A node $n$ succeeds in mining a block if\n\\begin{equation}\n    \\label{eqn:pos4}\n    {\\rm VRF(prev\\_hash,ts,sk_n)} < T\\cdot{\\rm stake_n},\n\\end{equation}\nwhere VRF generates a pseudorandom number with a proof of its correctness. A node with a secret key $sk$ can call {\\sc VRFprove}$(\\cdot,sk)$ to generates a pseudorandom {\\em output} $F_{sk}(\\cdot)$ along with a {\\em proof} $\\pi_{sk}(\\cdot)$. Other nodes that have the proof and the corresponding public key $pk$ can check that the output has been generated by VRF, by calling {\\sc VRFverify}$(\\cdot,F_{sk}(\\cdot),\\pi_{sk}(\\cdot),pk)$. The output of a VRF is computationally indistinguishable from a random number even if the public key $pk$ and the function {\\sc VRFprove} are revealed.\n\n\\section*{Nothing-at-stake Attack}\n\nNote that in Equation~(\\ref{eqn:pos4}), there is still one variable in the hash function that the adversary can grind on: ${\\rm prev\\_hash}$. While the honest nodes are asked to mine on the tip of the longest chain, the adversary tries to grow blocks {\\em everywhere} in the block tree and tries to surpass the longest honest chain (see Figure~\\ref{fig:nas}). This is possible because the adversary can use the same stake to mine blocks at many nodes in the blocktree without much computational cost; hence, this strategy is  known as a {\\em nothing-at-stake} (NaS) attack.\n\n\\begin{figure}\n    \\centering\n\\includegraphics[width=0.8\\textwidth]{figures/NaS.png}\n\\caption{Nothing-at-stake attack.}\n\\label{fig:nas}\n\\end{figure}\n\nWhile the number of adversarial blocks grows exponentially under the NaS attack, fortunately the depth of the adversarial tree grows only linearly. \\href{https://eprint.iacr.org/2017/656}{This paper} shows that the growth rate of the longest chain in the NaS tree turns out to approach $e\\beta\\lambda$ where $e$ is the base of the natural logarithm (approximately 2.718), if the adversarial mining rate is $\\beta \\lambda$. Hence, the effect of the NaS attack is to {\\em amplify} the growth rate of the private chain by a factor of e, roughly double the rate at which the private chain would have grown. Therefore, the NaS attack is successful when $e\\beta\\lambda > (1-\\beta)\\lambda$, i.e., $\\beta \\geq 1/(1+e) = 26.89\\%$.  Could a different attack (such as the balancing attack we have seen on {\\sf GHOST}) succeed with even smaller adversarial hash power? It turns out that the private attack again is  the worst case attack even in the PoS setting: \n using the idea of blocktree partition and Nakamoto block introduced in Lecture 6 (from a \\href{https://arxiv.org/abs/2005.10484}{recent paper}), we can show that the protocol is secure (safe and live) against all attacks as long as $\\beta < 1/(1+e)$. Therefore, we conclude that the security threshold for adversarial hash power for this protocol is exactly $ 1/(1+e)$. This is roughly half the threshold of 50\\% of adversarial mining power for the security of the corresponding PoW longest chain protocol.\n\n\\section*{Boosting Security Threshold}\nA natural question would be whether the threshold can be raised to 50\\%, matching the PoW longest chain  threshold; ideally this improvement is achieved by a simple modification of the PoS protocol. Towards this, we observe that the PoS protocol in Equation~(\\ref{eqn:pos4}) is vulnerable to the NaS attack because each block in the blocktree provides a source of randomness and starts a new independent lottery. To mitigate this issue, we can update the source of randomness {\\em less frequently}. \n\n\\noindent {\\bf Ouroboros PoS Protocol.} A first order idea is to never update the randomness and only draw it from the genesis block.\n\n\\noindent{\\bf PoS Attempt 5.1.} A node $n$ succeeds in mining a block if\n\\begin{equation}\n    \\label{eqn:pos5_1}\n    {\\rm VRF(hash(Genesis),ts,sk_n)} < T\\cdot{\\rm stake_n}.\n\\end{equation}\n\nThis is the lottery used in a PoS protocol called \\href{https://eprint.iacr.org/2017/573.pdf}{Ouroboros Praos}, which is deployed as part of the \\href{https://cardano.org/}{Cardano} project. The Ouroboros PoS protocol proceeds in discrete epochs; essentially a new genesis block starts off each epoch. Recent works have established that the protocol in Equation~\\ref{eqn:pos5_1} is secure as long as the {\\em majority} of staking power is honest, matching the threshold of the PoW longest chain protocol. Further, the private attack is the worst possible attack, and the resulting security threshold (on honest staking power) the optimal one; the \\href{https://arxiv.org/abs/2005.10484}{proof methodology} of Nakamoto blocks espoused in the analysis of the NaS attack is also applicable here. \n\nHowever, the Ouroboros Praos protocol in Equation~\\ref{eqn:pos5_1} is vulnerable to a bribing attack, where the adversary establishes a website where it can offer a bribe to anyone who posts their credentials for proposing blocks in an upcoming epoch (see Figure~\\ref{fig:bribing_structure}). Although a node's future proposer status is not public knowledge (thanks to VRF), this bribing website can solicit such information ahead of time and help launch a fatal attack. In particular, a double-spend attack can be launched using these bribed nodes: the adversary bribes these leaders to sign a forked version of the blockchain that it hoards till the block $s$ is confirmed by a $k$-deep rule. After that point, the adversary releases the hoarded blockchain to all the users, thus switching the longest chain and confirming a block $s'$ (which contains a double spend) instead of $s$. We note that while the adversary requires $k+1$ winners out of $2k+1$ lotteries to respond to the bribe, the total stake represented by these bribed winners can be a very tiny fraction of the total stake.\n\n\\begin{figure}[ht]\n    \\centering\n\\includegraphics[width=0.6\\textwidth]{figures/bribing_website.png}\n\\caption{Structure of bribing attack.} \\label{fig:bribing_structure}\n\\end{figure}\n\n\\begin{figure}[ht]\n%\\begin{wrapfigure}{r}{.43\\textwidth}\n    \\centering\n\\includegraphics[width=0.6\\textwidth]{figures/bribing_ouroboros.png}\n\\caption{Bribing attack on Ouroboros Praos.} \\label{fig:ouroboros}\n\\end{figure}\n\n\\noindent {\\bf $c$-Correlation PoS Protocol.} \nA smooth way to reduce the frequency of source of randomness in the PoS lottery is the following, proposed as $c$-correlation  in \\href{https://arxiv.org/pdf/1910.02218.pdf}{this paper}. In this rule, the common source of randomness remains the same for $c$ blocks, and is updated only when the current block to be generated is at a depth that is a multiple of $c$ (see Figure~\\ref{fig:c-correction-protocol}). When updating, the hash of block header is used as the new source of randomness, i.e.,\n\\begin{align*}\n{\\rm RandSource}(b):=  \n\\begin{cases}\n\\text{\\sc VRF}\\big({\\rm RandSource}(\\text{parent}(b)), {\\rm ts}, {\\rm sk}) , &\\quad \\text{if } {\\rm depth}\\big(b\\big)\\%c=0,\\\\\n{\\rm RandSource}(\\text{parent}(b)), &\\quad \\text{otherwise}.\n\\end{cases}\n\\end{align*}\n\n\\begin{figure}\n    \\centering\n\\includegraphics[width=0.5\\textwidth]{figures/c_correlation_figure.png}\n\\caption{A snapshot of a block tree under $c$-correlation protocol with $c = 5$. Each block has a header consisting of header=(RandSource(parent), timestamp).  The content of the block includes the transactions and the RandSource of the block to be used in the next lottery. This random source is preserved from parent to children blocks, until one mines a block at height that is a multiple of $c$. In such a case, a new RandSource is drawn using the hash of the current header and the secret key of the block proposer. }\n\\label{fig:c-correction-protocol}\n\\end{figure}\n\n\\noindent{\\bf PoS Attempt 5.2.} A node $n$ succeeds in mining a block if\n\\begin{equation}\n    \\label{eqn:pos5_2}\n    {\\rm VRF(RandSource(parent),ts,sk_n)} < T\\cdot{\\rm stake_n}.\n\\end{equation}\n\nWhen $c=1$, this recovers the protocol in Equation~(\\ref{eqn:pos4}), where the NaS attack is most effective. When $c=\\infty$, this recovers the protocol in Equation~(\\ref{eqn:pos5_1}), where the NaS attack is least effective (nonexistent). \nIncreasing $c$  gracefully increases the security threshold (see Table~1). In Figure~\\ref{fig:threshold_day}, we plot the security threshold of $c$-correlation, with the practical implication that $c$-correlation can achieve comparable security with a much smaller epoch size than the current implementation of Ouroboros as part of the Cardano project.\n\n\\begin{table}[h]\n\\begin{center}\n\\begin{tabular}{ |c|c|c|c|c|c|c|c|c|c|c| }\n \\hline\n $c$      & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\\\ \\hline\n $\\phi_c$   & e & 2.22547  & 2.01030 & 1.88255  & 1.79545  & 1.73110 & 1.68103 & 1.64060 &1.60705 & 1.57860 \\\\\n \\hline\n $\\beta^*_c$ & $\\frac{1}{1+e}$& 0.31003 & 0.33219 &0.34691 &0.35772 & 0.36615 & 0.37299 &\n 0.37870 & 0.38358 & 0.38780\n \\\\ \\hline\n\\end{tabular}\n\\end{center}\n\\caption{Numerically computed growth rate $\\phi_c$ and stake threshold $\\beta^*_c$.}\n\\end{table}\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.6\\textwidth]{figures/threshold_day.jpeg}\n    \\caption{The security threshold $\\beta^*_c$ of $c$-correlation against the epoch size, equaling to $c$ times the inter-block time, which we set to be $20$s, to match the implementation of Ouroboros in Cardano. The Cardano project currently updates the common randomness every 5 days (21600 blocks), while the security threshold of $c$-correlation can approach $1/2$ with much higher randomness update frequency.}\n    \\label{fig:threshold_day}\n\\end{figure}\n\n\\section*{Dynamic Stake Using $s$-truncation}\nWith the PoS protocol in Equation~(\\ref{eqn:pos5_2}) we have successfully completed the secure conversion of the PoW lottery into the PoS lottery. One hitch remains: the stake of the nodes used to compute the success level in the lottery is {\\em static}, i.e., not changing. This is undesirable for two reasons: a node with no current stake can participate in the lottery (raising barriers to new entrants) and an incumbent participates in the lottery at a great cost since it cannot use its coins for any transactions (creating incentives for rent seeking). A natural approach is to allow {\\em dynamic stakes} to determine the success in the PoS lottery; after all, the ledger is dynamically updated as new blocks enter the longest chain and get confirmed (when deep enough) and the security of the PoS longest chain rule guarantees consistency of the ledger amongst all the honest nodes. How to systematically rein in dynamic stake to the PoS lottery and to do it without allowing new attack vectors is the focus of this section. \n\nIn the dynamic stake setting, the stake of a node $n$ is not only changing over time  as transactions are added to the blocktree, but also over which {\\em chain} we are referring to in the blocktree. Different chains in the tree contain different sequences of transactions, leading to different stake allocations. One needs to specify which chain we are referring to, when we access the stake of a node. If we simply use the state of the parent block to decide the stake of each node, the adversary can {\\em grind on the stake of its coin} (the right hand side in Equation~(\\ref{eqn:pos5_2})).\n\nIn this stake grinding attack, once the adversary is elected as a leader at some time and proposed a new block, it can include transactions in that block to transfer all stake to a coin that has a higher chance of winning the lottery at a later time. In the example of Figure~\\ref{fig:grinding}, the adversary owns coin A and coin B. When it gains the right to proposer a block, it creates two blocks (privately) with the same header: in one block, it transfers the stake from A to B; in the other, it transfers the stake from B to A. In the lottery for the next level, the adversary can use its full stake to participate in two lotteries, therefore its chance of winning is doubled by grinding on its stake.\n\nTo prevent such a grinding on the stake, a natural attempt is to use the stake in the block with depth $\\ell-s$ when trying to create a block at depth $\\ell$ on the main chain where $s$ is chosen large enough so that nodes have reached consensus on the block with depth $\\ell-s$. However, there remains  a vulnerability. Consider the adversary growing its own private chain from the genesis block (or any block in the blocktree). Initially, the private chain grows at a rate $\\beta\\lambda$.\nHowever, after $s$ blocks from the launch of the private chain, the adversary can start grinding on the private key of the coin; once a favorable coin is found, it can transfer the stake to the favored coin by including transactions in the first ancestor block in the private chain. This is possible as all blocks in the private chain belong to the adversary. It can alter any content of the private chain and sign all the prior blocks again.\n\nWith such a stake grinding attack, the adversary can potentially win a lottery every slot in the private chain, eventually overtaking the public blocktree, which grows at a constant rate $(1-\\beta)\\lambda$. To prevent this private grinding attack, a new fork choice rule called $s$-truncated longest chain is proposed in \\href{https://eprint.iacr.org/2018/378.pdf}{this paper}.\n\n\\begin{figure}\n    \\centering\n\\includegraphics[width=0.5\\textwidth]{figures/stake_grinding.png}\n\\caption{Stake grinding attack. A and B are two coins owned by one node P. When P wins one lottery, it creates two blocks (privately) with the same header: in one block, P transfer the stake from A to B; in the other, P transfers the stake from B to A. In the lottery for the next level, P can use its full stake to participate in two lotteries, therefore its chance of winning is doubled by grinding on its stake.}\n\\label{fig:grinding}\n\\end{figure}\n\n\\noindent{\\bf New fork choice rule.}\nNote that in the stake grinding attack, the private chain grows slowly at the beginning, so instead of comparing the length of the chains, we can compare the density of the chains when there is a fork. In particular, at any time, an honest node keeps track of one main chain that it appends its next generated block to. Upon receiving a new chain of blocks, it needs to decide which chain to keep. Instead of comparing the length of those two chains, as in the longest chain rule, we compare the creation time of the first $s$ blocks after the fork in truncated versions of those two chains.\n\nLet $b_{\\rm fork}$ be the block where those two chains fork. The honest node counts how long it takes in each chain to create, up to $s$ blocks after the fork.\nThe chain with shorter time for those $s$ blocks is chosen, and the next generated block will be appended to the newest block in that selected chain. One caveat is that we only apply this $s$-truncation when comparing two chains that both have at least $s$ blocks after forking. If one of the chains has fewer than $s$ blocks after forking, we use the longest chain rule to determine which chain to mine on. This completes the successful conversion of the PoW lottery to the PoS version, even accounting for dynamic stake variation.   \n\n\\section*{Dynamic Availability Using VDF}\nAn important feature enjoyed by {\\sf Bitcoin} is called {\\em dynamic availability}: {\\sf Bitcoin} can handle an uncertain and dynamic varying level of participation in terms of mining power; Miners can join and leave as desired without any registration requirement. Can we achieve similar dynamic availability in the PoS version?\n\nNote that in practice, perhaps not every stakeholder is interested in participating in the protocol (consensus layer). A certain fraction of people possess stake as investment; we call them offline nodes. Those stakeholders actively participating in the protocol are called {\\em online} nodes. The protocol we presented as far is secure if less than a certain fraction (e.g., 27\\% for $c=1$ ) of the online nodes are adversarial, but with an additional assumption: {\\em all adversarial nodes are always online.}  While this assumption seems reasonable (why would an adversary go offline?), in reality this can be a very restrictive condition. Generally, in public blockchains, PoW or PoS, no node is likely to be adversarial during the launch of a new blockchain token (because the token has little value);  adversaries only begin to emerge later during the life-cycle. \n\nThis additional assumption underlying the protocol is not superfluous but is in fact {\\em necessary} for its security. Suppose for the first year of the existence of the PoS-based blockchain, only $10\\%$ of the total stake is online. Out of this, consider that all nodes are honest. Now, at the beginning of the second year, all $100\\%$ of the stake is online out of which $20\\%$ is held by adversary. At any point of time, the fraction of  online stake held by honest nodes is greater than $0.8$. However, the protocol is not secure since the adversary can use its $20\\%$ stake to immediately participate in all past lotteries to win blocks all the way back to the genesis and then grow a chain {\\em instantaneously} from the genesis to surpass the current longest chain (Figure \\ref{fig:aot}(a)). This is because generating blocks in the PoS protocol is almost costless (just need to run all the lotteries using old timestamps). Thus, due to this ``costless simulation'', newly  online adversary nodes not only increase the current online adversary stake, but effectively increase past online adversary stake as well. In contrast, PoW does not suffer from the same issue because it would take a long time to grow such a chain from the past and that chain will always be behind the current longest chain. Thus, PoW provides an {\\em arrow of time}, meaning nodes cannot ``go back in time'' to mine blocks for the times at which they were not online. This property is key in endowing PoW protocols with the ability to tolerate fully dynamic adversaries wherein both  honest  nodes  and  adversary  can have  varying  participation (Figure \\ref{fig:aot}(b)). \n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=\\textwidth]{figures/dynamic_adversary_attack_PoS.pdf}\n    \\caption{(a) Newly coming online stakeholders in the PoS protocol can grow a chain from genesis instantaneously. (b) Newly joined miners in the PoW protocol take a long time to grow such a chain and is always behind.}\n    \\label{fig:aot}\n\\end{figure}\n\nA recent proposal, called \\href{https://arxiv.org/pdf/2010.08154.pdf}{PoSAT}, addresses this dynamic availability issue. It uses a cryptographic primitive called Verifiable Delay Function (VDF) for the block proposal lottery to provide an arrow of time. VDFs are built on top of iteratively sequential functions, i.e., functions that are only computable sequentially: $f^{\\ell}(x) = f \\circ f \\circ ... \\circ f(x)$, along with the ability to provide a short and easily verifiable proof that the computed output is correct. Examples of such functions include (repeated) squaring in a finite group of unknown order, i.e., $f(x)=2^x$ and (repeated) application of secure hash function (SHA-256), i.e., $f(x) = {\\rm Hash}(x)$. The VDF will also produce a proof for each output, and verifying the output with the help of the proof is much faster than computing the output. This is really a cryptographic magic! While VDFs have been designed as a way for proving the passage of a certain amount of time (assuming a bounded CPU speed), it has been recently shown that these functions can also be used to generate an unpredictable randomness beacon. Thus, running the iteration till the random time $L$ when $f^{L}(x)$ is within a certain threshold will result in $L$ being a geometric random variable. This randomized VDF functionality can be used to create an arrow-of-time in the PoS protocol. \n\n\\noindent{\\bf PoS Attempt 6.} A node $n$ succeeds in mining a block if\n\\begin{equation}\n    \\label{eqn:pos6}\n    {\\rm VDF(RandSource(parent),ts,sk_n)} < T\\cdot{\\rm stake_n}.\n\\end{equation}\n\nWith VDF, the adversary cannot go back in time and create a longer chain than the honest chain immediately, because creating a longer chain now requires time. While the adversarial chain is growing, the honest chain is growing at a larger speed. Therefore, PoSAT is secure in the dynamic available setting.\n\n\n\\section*{References}\n\nThere are broadly two families of PoS protocols: those inspired by the Nakamoto longest chain protocol and those derived from decades of research in Byzantine Fault Tolerant (BFT) protocols. In this lecture, we covered most existing Nakamoto-style PoS protocols. A clean adoption proposed in  \\href{https://eprint.iacr.org/2017/656}{this paper}  achieves security when the adversary controls less than $27\\%$ fraction of total stake. Both \\href{https://eprint.iacr.org/2017/573.pdf}{Ouroboros Praos} and \\href{https://arxiv.org/pdf/1910.02218.pdf}{c-correlated PoS} boost the security threshold: while the former is vulnerable to a bribing attack (due to predictability of the lotteries), the latter provides a tradeoff between predictability and security. Finally, we see the $s$-truncation rule in \\href{https://eprint.iacr.org/2018/378.pdf}{Ouroboros Genesis} enables dynamic stake and \\href{https://arxiv.org/pdf/2010.08154.pdf}{PoSAT} achieves dynamic availability.\nAttempts at blockchain design via the BFT approach include \\href{https://algorandcom.cdn.prismic.io/algorandcom\\%2Fa26acb80-b80c-46ff-a1ab-a8121f74f3a3_p51-gilad.pdf}{Algorand} and \\href{hotstuff: bft consensus with linearity and responsiveness}{Hotstuff}. The adaptation of these new protocols into blockchains is an active area of research and engineering, and we will take a closer look at this family of protocols in the next two lectures.\n\n\n\\end{document}",
    "lecture_17.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\usepackage{markdown}\n\\usepackage{amsthm}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\newcommand{\\indicator}{{\\bf 1}}\n\\newcommand{\\pramod}[1]{{\\color{red}\n\\footnotesize[Pramod: #1] }}\n\\newcommand{\\xw}[1]{{\\color{green}\n\\footnotesize[Xuechao: #1] }}\n\\newcommand{\\surya}[1]{{\\color{magenta}\n\\footnotesize[Surya: #1] }}\n%\\theoremstyle{definition}\n\\newtheorem{definition}{Definition}\n\\newtheorem{theorem}{Theorem}\n\\newtheorem{lemma}{Lemma}\n%\\let\\proof\\relax\n%\\let\\endproof\\relax \n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 17}\n\\cfoot{\\thepage}\n\n\\title{Lecture 17: Bootstrapping Blockchains}\n\\author{Principles of Blockchains, University of Illinois,  \\\\ Professor:  Pramod Viswanath \\\\ Scribe:  Suryanarayana Sankagiri}\n\\date{March 25, 2021}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nIn the lectures so far, we have studied the security and performance of blockchains in a {\\em steady state}, i.e., when the participation is steady and engaged. In this lecture, we study the {\\em transient} phase of blockchains: how to securely and efficiently {\\em bootstrap} blockchains via careful incentives and design choices. We discuss several practical approaches to bootstrapping PoW and PoS blockchains. We also discuss popular methods to start new blockchains piggybacking off existing blockchains, especially {\\sf Ethereum}.\n\\end{abstract}\n\n\\section*{Introduction}\nToday, we take the security of well-established blockchains like Bitcoin and Ethereum for granted. Partly, this assurance is based off of the past track record of the blockchains; there has not been any fatal attack on them so far. Additionally, we have provable guarantees, based on mathematical models, that show that if an adversary wants to attack the system, they must control close to $50\\%$ of the mining power in the system. In Bitcoin, currently, the total mining power in the system is enough to compute more than $10^{20}$ hashes per second. To compare, a good GPU today could compute around $10^{8}$ hashes per second. Thus, it seems \\textit{economically infeasible} for an adversary to own that much computing power. Put differently, Bitcoin's security comes from the extensive computing power already invested into the system.\n\nIn its initial days, Bitcoin did not have such a strong level of security, simply because there were a much smaller number of miners in the system. In those days, the Bitcoin hash rate was close to $10^6$ hashes per second (the mining difficulty has changed by around fourteen orders of magnitude to keep the mining rate constant). Matching this hash rate would not have been hard for an adversary (even if they were limited to the computers of $2009$). Even today, a new blockchain would presumably start off with a much smaller total computation power than what Bitcoin and Ethereum have today. How, then, do we preserve security of these blockchains? In this lecture, we will explore some methods to `bootstrap' blockchains, first for Proof-of-Work systems and then for Proof-of-Stake systems. Finally, we will look at methods of piggybacking of existing blockchains.\n\n\\section*{Bootstrapping PoW Blockchains}\nWe discuss a few different principles to bootstrap Proof of Work blockchains. These principles are complementary, and multiple of them can be applied simultaneously to the same system.\n\n\\subsection*{Incentives via block rewards}\nThe first security measure we discuss is an incentive-based one, which argues that miners are likely to be rational; they would not attack the system if they would hurt themselves economically by doing so. In an incentive-compatible blockchain system, it'd be extremely unlikely that a set of miners controlling a majority of the mining power would collude together to attack the system, since doing so would hurt them economically. It does not provide any security guarantees if indeed, for some reason, a $51\\%$ adversary does attack the system.\n\nWe know that, in steady-state operation, mining rewards in PoW blockchains provide an incentive to miners to behave honestly. In fact, these rewards can incentivize miners to act honestly in the initial phases of the blockchain too. One way to do so is to give early miners an extra incentive in terms of greater mining rewards, as was done in Bitcoin. Here, the mining reward began with $50$ bitcoins per mined block. It is reduced by half every few years ($210,000$ blocks), and is currently at $6.25$ bitcoins per block. Thus, early miners had an extra incentive to remain honest.\n\nIn terms of its dollar value at that time, the initial block rewards were not worth much. However, it was believed that the price of Bitcoin would increase once it gained greater acceptance; indeed, this belief has been validated. A miner with significant mining power would stand to gain a lot in the future if it helped maintain Bitcoin's security, and thereby, its reputation, by following the protocol. If, instead, it performed a double spend attack, it would get a one-time gain from the attack. As a penalty, it would lose the value of all its mining rewards, as the attack would drive the price of Bitcoin down to zero very fast. Thus, correct incentives helped maintain Bitcoin's security in the initial years.\n\n\\subsection*{Checkpointing}\nA second method of bootstrapping PoW blockchains is to employ a \\textit{checkpointing mechanism}. Broadly speaking, this method employs a trusted party (or a group of parties) that checkpoints blocks at regular intervals, and new blocks must be mined below the latest checkpoint to be considered valid. Users can use the checkpoints as a basis of confirmation: i.e., they confirm blocks up to the last checkpoint. The checkpointing mechanism is essentially a BFT (permissioned) consensus protocol, executed by a special set of checkpointers.\n\nIn the previous lecture, we saw that checkpointing (via a finality gadget) can help secure the longest-chain protocol under periods of asynchrony. Similarly, the checkpointing mechanism can also act as a guard-rail against an adversary with more than $50\\%$ mining power, as long as the checkpointing mechanism acts correctly. The important point to note here is that the checkpointers are not chosen via mining. Rather, they are a set of entities (corporations, foundations, etc.) with some credibility who are appointed just for the sake of securing a PoW blockchain in its initial stages. Thus, it is fair to assume that a majority (or super-majority) of them will be honest.\n\nLet us examine the security of such a checkpointing based protocol under the presence of an adversary with majority mining power. The safety of the protocol is easy to argue; it follows from the safety of the checkpointing mechanism. However, liveness is harder to achieve. A simple implementation of a checkpointing system could lead to poor liveness guarantees (e.g., see \\href{https://eprint.iacr.org/2020/173.pdf}{this work}). Figure \\ref{fig:CQAdvMaj} shows the variation of the chain quality, a metric of liveness, with epoch length and adversarial mining power.\n\nLiveness is important to have in order to incentivize honest nodes to stay in the system. Indeed, if honest blocks do not get included in the ledger, honest miners will not be able to accrue any reward, and will therefore leave the system. In earlier checkpoint-based protocols, we were willing to forego liveness when the network was asynchronous. This is because periods of asynchrony are typically small and infrequent. Here, ensuring liveness is important because an adversary may retain a mining majority until a large number of users join the system, which could take time.\n\n\\begin{figure}\n    \\centering\n    \\includegraphics{figures/CQAdvMaj.png}\n    \\caption{Chain Quality degrades sharply with an increase in the adversarial mining power, and with an increase in the epoch length (period between checkpoints)}\n    \\label{fig:CQAdvMaj}\n\\end{figure}\n\nThere are two major principles to have a liveness-guaranteeing checkpointing mechanism (under $> 50\\%$ adversary). The first is that the checkpointers should generate a fresh random string with every new checkpoint, and this random string should be included in all descendants of the checkpoint block. Such a mechanism ensures that all blocks below a checkpoint block must be mined \\textit{after} the block has been marked as a checkpoint. The adversary cannot take undue advantage of its mining power by mining many blocks beforehand; the counter of blocks is set to zero with every checkpoint block. \n\nThe second principle is for checkpoints to introduce reference links to blocks that are not on the main chain, which are likely to be honest blocks. The main idea is that honest blocks are produced in proportion to the honest mining power, but they may not be on the main chain due to the adversary ignoring them. These reference links point to honest blocks and bring them into the ledger, leading to a chain quality that is equal to the honest mining power. The idea of using reference links to improve chain quality was also used in FruitChains. An entire system, with both these principles, is illustrated in Figure \\ref{fig:advocate}.\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width = \\textwidth]{figures/advocate.pdf}\n    \\caption{The Advocate system, which provides optimal chain quality even in the presence of an adversarial majority. Such a system provides a useful checkpointing mechanism to bootstrap PoW blockchains.}\n    \\label{fig:advocate}\n\\end{figure}\n\nHistorically, in Bitcoin, Satoshi Nakamoto used to issue checkpoints at regular intervals. This practice was discontinued in $2014$, presumably once they realized that Bitcoin has sufficient mining power to be secure on its own. In this case, it was a single trusted honest party that was issuing checkpoints. A more robust method would be to have a permissioned set of users doing so.\n\n\\subsection*{Hardfork}\nIn the world of blockchains, a \\textit{hard fork} (or hardfork) is a point in the blockchain where the protocol undergoes a major change, and these changes are incompatible with the previous version. Blocks produced as per the new protocol will be deemed invalid as per the old protocol and vice-versa. A hard fork could be used to introduce new features into the blockchain, in order to improve its security or performance. Hard forks could also be used to correct security bugs in the existing codes. This happened with Ethereum in the case of the \\href{https://en.wikipedia.org/wiki/The_DAO_(organization)}{DAO vulnerability}.\n\nTo understand hard forks better, consider the following example. Suppose the miners of Bitcoin decide that they would like to increase the mining rate of Bitcoin by a factor of ten, in order to increase its throughput. To increase the mining rate, they would have to lower the difficulty of the blocks. In essence, the block difficulty adjustment formula must be changed from the current version. If all nodes agree to undertake this change simultaneously, then the protocol will make a smooth transition to the new version. However, this is not possible in a decentralized system. Some nodes will be unaware of the new changes for a while and therefore they will ignore blocks produced by the new rule, treating them as invalid. Because of this, there will be a major fork in the system; this phenomenon gives rise to the term hard fork.\n\nIn some cases, all nodes eventually agree to the software update. In this case, the fork with the older format of blocks gets stalled, while the fork with the newer format continues to grow. However, there are instances when some nodes prefer the updates, while others do not. In this case, two forks continue forever. In essence, the fork with the updated protocol is a new cryptocurrency/blockchain. The (hard) fork marks the beginning of the new system. Some nodes migrate to the new system, while others remain in the old one. Note that this is not a security vulnerability; once a node clearly decides which version of the software it wants to follow, the blockchain continues to guarantee security. Many cryptocurrencies have been launched in this way, the most popular being Bitcoin Cash, which is a hard fork from Bitcoin. The history of hard forks from Bitcoin can be \\href{https://www.investopedia.com/tech/history-bitcoin-hard-forks/}{found here}.\n\nA cryptocurrency that is launched as a hard fork from an established blockchain retains the distribution of coins (or more generally, the state of the system) as recorded in the last block before the fork. If the new system is appealing, it very quickly gathers a large number of miners (i.e., a large computing power) since miners in the old system can seamlessly transit to the new system. This gives the system a strong security backing, as it starts in a fairly decentralized fashion. In addition, the new system inherits most of the security features from the existing blockchain; only the new features must be verified.\n\n\\subsection*{Soft Forks}\n\\textit{Soft forks}, in contrast to hard forks, are software updates that are backward compatible. In such an update, even those who have not updated their software will treat new blocks as valid. It is possible that those following the new update treat the old blocks as invalid. In this case, as long as a majority of miners upgrade their software, the blockchain continues to function smoothly; blocks produced by the old software will quickly get stale. Compared to a hard fork, a soft fork allows users to slowly transit to the new system. However, for the soft fork to come into effect, a majority of the miners should be running the updated software. Just like hard forks, soft forks are also used to include better features to an existing system. \n\nIn Bitcoin, new transaction types (or new scripts) have been introduced as soft forks. A prominent example of this is the SegWit update, which stands for \\textit{segregated witness}. Recall that in Bitcoin, blocks have a maximum size of $1MB$. This places a limit on the number of transactions that can be included in a block. SegWit is a proposal that reduces the size of transactions in Bitcoin, which allows one to include more transactions per block while still obeying the $1MB$ limit. The basic idea of SegWit is to keep the signatures on transactions outside the main block. As such, all transactions in Bitcoin must be signed. However, the signature can take up to $65\\%$ of the space in a transaction. Separating the signature reduces the transaction size separately. The signatures are still present; they are just moved to an additional part of the block that does not count as part of the $1MB$ limit. The phrase ``segregated witness'' reflects this design principle (the term witness refers to the signatures here).\n\n\\subsection*{Proof-of-Burn}\n\nProof-of-burn is a method by which users can migrate from an established blockchain system like Bitcoin to a new one. To burn coins, nodes send Bitcoins to a verifiably unspendable address (say, an address with a fixed public key for which it is virtually impossible to come up with a corresponding secret key). In exchange, they receive a reward in the native currency of the new blockchain. Users may also receive mining rights proportional to the amount of coins they have burned. In effect, this creates a new system where the mining power is proportional to the money one has burned. Compared to Proof-of-Work, this method is less resource intensive, and equally secure. It piggy-backs off an established blockchain. You can read more about this idea \\href{https://en.bitcoin.it/wiki/Proof_of_burn}{here}.\n\n\\section*{Bootstrapping PoS Blockchains}\nIn any Proof of Stake system, block proposers are chosen based on the stake that nodes have recorded in the ledger. Thus, for a PoS system to get started, some amount of stake (coins) must be distributed amongst the initial participants. Moreover, this initial stake distribution {\\em must be recorded in the genesis block} (unlike a PoW blockchain where the genesis block can have no record of coins and ownership, as in Bitcoin). Whatever be the initial distribution, a Proof-of-Stake system could suffer from a rich-get-richer phenomenon. Those with higher stake are more likely to mine blocks, and thereby accrue block/transaction rewards. This would then increase the chance of them mining future blocks. \n\nIf left unchecked, the compounding of wealth could lead to extensive centralization. One way to reduce the compounding of wealth effect is to start off with a large amount of initial stake distributed fairly uniformly across nodes. Here, the initial stake is large relative to the block/transaction rewards. A second way to reduce this effect is to re-design the mining rewards with time: if rewards increase with time, the stake distribution after some time is likely to be more uniform than the case where rewards remain constant (or decrease).\n\nThere are different ways to gather an initial set of stakeholders. These strategies could be used by any cryptocurrency, even a PoW based one; however, they are {\\em essential} for a PoS based blockchain to get off the ground. One method could be a proof-of-burn strategy, where one must pay in some form to gain coins of a new system. A different method could be to just distribute a small amount of coins for free to as many different users as possible. Many companies offer rewards on their service upon joining or to existing users for giving referrals. Others simply give out freebies. This marketing ploy, when adopted by cryptocurrencies, is called an \\textit{airdrop}. For example, one could gain some coins upon tweeting about the new currency. Apart from gaining an initial base of stakeholders, the currency also gains more visibility/popularity.\n\nA popular term used during the launch of a new cryptocurrency is that of an ICO, which stands for initial coin offering. This is modeled (and named) after the concept of an IPO (initial public offering). Here, new tokens are offered for a fixed price in some fiat currency (dollars). ICOs are often used as an investment opportunity by users, but they carry the same risks as a company IPO; arguably, they are riskier.\n\n\\section*{Bootstrapping via Layer 2 Solutions}\nToday, many new tokens are launched on the Ethereum Virtual Machine Platform. This platform is extremely flexible, and supports a wide range of functionalities. Such tokens take the Ethereum ledger's security (based on Nakamoto consensus) for granted, and are built for very specific applications. Each new token is essentially a new cryptocurrency, which can be used for its own specific purpose (e.g., it can be used only on Walmart). By piggy-backing off of Ethereum, it derives many of the basic safety features for free. \n\nA vast majority of tokens on Ethereum are ``ERC-20\" tokens. ERC-20 is a standard for tokens, which  sets some basic rules, such as how tokens can be transferred, how new tokens can be generated, etc. Having a common set of rules ensures these tokens are compatible and can be exchanged with each other easily. Moreover, they are also compatible with the backbone Ethereum system (e.g., all gas fees in ERC-20 tokens are denominated in ETH, the native token of Ethereum). \n\nOnce we have a token on the Ethereum system, one can employ creative ways to get people to adopt the token, via smart contracts. A bonding curve contract is a special contract that adjusts the price of a token (in terms of ETH or Dollars) based on its demand. As the popularity of a contract soars, its price increases. Thus, early participants get better deals. Similarly, ICOs can also be automated via smart contracts.\n\n\\end{document}",
    "lecture_05.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\usepackage{markdown}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\newcommand{\\pramod}[1]{{\\color{red}\n\\footnotesize[Pramod: #1] }}\n\n\\let\\proof\\relax\n\\let\\endproof\\relax\n\\usepackage{amsthm}\n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 5}\n\\cfoot{\\thepage}\n\n\\title{Lecture 5:  Bitcoin System-Putting it All Together}\n\\author{Principles of Blockchains, Princeton University,  \\\\ Professor:  Pramod Viswanath \\\\ Scribes: Suryanarayana Sankagiri and Xuechao Wang}\n%\\date{February 9, 2021}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nIn this lecture, we cover some aspects regarding transactions in Bitcoin. Transactions give semantic meaning to the decentralized ledger enabled by a blockchain. We discuss how Bitcoin gets its monetary value and how money is transferred from one user to another. We highlight the different safety checks that users can perform to prevent any form of cheating. This leads to the notion of validating a block. We argue that validating blocks is a storage and computation intensive process. and show how Bitcoin can support light clients that perform a limited extent of validation. Finally, we take a high-level view and discuss how a blockchain can act as a distributed computer, running arbitrary programs termed as smart contracts.\n\\end{abstract}\n\n\\section*{Introduction} \nIn any currency/banking system, there are some basic requirements that the system must provide for. We list them here:\n\\begin{enumerate}\n    \\item There should be a unit of currency/money.\n    \\item There should be a standard way of keeping accounts, i.e., keeping track of how much money each person owns, and transferring money between accounts. \n    \\item No user should be able to create new money from thin air. Put differently, there should be a fixed amount of money in the system at any given time, and new money should be introduced in a systematic manner.\n    \\item A user should not be able to spend more money than he/she owns. There should be a way to verify whether or not this happens.\n    \\item One user should not be able to spend someone else's money (at least, not without their permission).\n\\end{enumerate}\nLet us see how the Bitcoin system provides these features.\n\n\\section*{Bitcoin and Satoshi}\nThe basic unit of currency in the Bitcoin system is, simply, Bitcoin. The smallest denomination of a Bitcoin is called a Satoshi. It is equal to $10^{-8}$ Bitcoins. All transactions must be some integer multiple of a Satoshi. Just as all other currencies in the world have exchange rates, there is an exchange-rate between Bitcoin and the dollar. As of today, February 9 2021, one Bitcoin is worth $48,000$ US dollars. Due to various factors (including greed and speculation), the exchange rate between Bitcoin and dollars is very volatile. Whether Bitcoin should be thought of as a currency (like the US Dollar) or a store of value (like the precious metal, gold) has been debated widely; the mainstream view is that Bitcoin is a combination of both. Economically valuing Bitcoin, both in the short and long terms, is an active area of research. In this lecture we will see aspects of the Bitcoin system that helps understand the economic aspects of Bitcoin, both as a currency and a store of value. \n\n\\section*{Transactions}\nIn ordinary parlance, the term \\textbf{transaction} refers to an exchange of something of value. In the context of Bitcoin and cryptocurrencies, a transaction is simply a message that specifies the transfer of money from one entity to another. In fact, transactions are the data-values that get recorded on the blockchain. The blockchain as a ledger is therefore an ordered list of transactions. From this publicly verifiable ledger, any user can detect whether transactions are made according to certain rules or not, thereby lending credibility to the ledger and the currency.\n\nIn Bitcoins, transactions have a well-defined structure, which we elaborate upon below. One can take a look at the structure of real Bitcoin transactions \\href{https://www.blockchain.com/explorer}{here}.\n\n\\paragraph{Addresses}\nNaively, in a currency system, there should be some notion of an account; a transaction notes the transfer of money from one account to another. In Bitcoin, the notion of accounts is replaced with that of \\textit{addresses}. Bitcoins are allocated to addresses, and these addresses are also used to decide where Bitcoins will be sent to, in a transaction. What exactly is an address and how is one generated? In Bitcoin, an address is simply the hash of a public key. Recall the notion of digital signatures, and that of public and private keys. New pairs of keys, and thus new addresses can be generated at will by a single user.\n\nOne idiosyncrasy of Bitcoin is the following. In order to receive coins, a user needs to only publish its address, not its public key. However, to spend coins, a user must also reveal its public key. This is explained below.\n\n\\paragraph{Transaction inputs and outputs}\nA transaction in a Bitcoin is a statement that records a transfer of money from one address to another. More broadly, a transaction records a transfer of money from one set of addresses to another. Every transaction has a set of \\textit{transaction inputs} and \\textit{transaction outputs}. Each transaction input states the amount of Bitcoin being spent by a particular address. Each transaction output states the amount of Bitcoin being received by a particular address. In a transaction, the total money being spent should add up to the total money being received. %We shall see the reason for allowing multiple transaction inputs and outputs shortly.\n\n\\paragraph{Signatures on transactions}\nEach transaction must be signed by all the users that are spending money. This is a basic safety feature that prevents others from spending one's money without authorization. As mentioned above, each address has a one-to-one correspondence with a public key, which in turn has a one-to-one correspondence with a private key. A user that wishes to spend Bitcoins associated with a particular address creates a transaction appropriately, and then signs the transaction using the corresponding private key. It then broadcasts the transaction along with the corresponding public key. Anyone who that sees a signed transaction can verify whether it was signed by the person owning the address (and thereby, the coins in the address). Thus, signatures help other users validate transactions. More generally, if a transaction spends Bitcoins from multiple addresses, there must be signatures corresponding to each of these addresses.\n\n\\paragraph{UTXOs} So far, we have seen how transactions are used to transfer money from one address to another. What prevents a user (i.e., an address) from spending more money than it has? One method would be to keeping track of the balance of each address, adding or deducting its value as money is received/spent from the address. Bitcoin adopts a different approach; here, every transaction input must be a transaction output of an earlier transaction. Linking transaction inputs to past inputs provides a proof that the address indeed has sufficient money to spend. \n\nWhen a new transaction output is created, we say that it is \\textit{unspent}. At some time in the future, it gets consumed as part of transaction input, at which point it is \\textit{spent}. A valid transaction must only include \\textit{unspent transaction outputs} (UTXOs) as its inputs. While honest users will always ensure this, a dishonest user can try to \\textit{double-spend} its money. In order to prevent this, honest users must keep track of the set of UTXOs at all times, and must validate every new transaction in the blockchain against this set. We elaborate more on this in later sections. The above method of validating transactions is called the \\textbf{UTXO model}. A more natural technique would be the \\textbf{account-based model}, where the balance is maintained for each address. This latter model is adopted in other cryptocurrencies such as Ethereum (and also in regular banks).\n\nWe now see why a Bitcoin transaction allows for multiple transaction inputs and outputs. First, let us consider the need for multiple outputs. Suppose a particular user owns a single Bitcoin address, to which it has received 2 Bitcoins in a particular transaction. Even if it wants to spend a fraction of that money (say, 1 Bitcoin), it must spend the only UTXO it has, which is of 2 Bitcoins. In such a case, it creates two transaction outputs, one to the address it actually wants to send the money to, and the other to itself (the change). The latter output could be to the original address, or to a new address. Next, let us consider the case of multiple inputs. Suppose an address (i.e., user) has received 1 Bitcoin each in two different transactions, and it would now like to pay 2 Bitcoins to another address. It can then include two transaction inputs in a single transaction in order to pay this amount.\n\n\\paragraph{Cryptocurrency wallets} In reality, keeping track of UTXOs, and measuring them up for each transaction is difficult. In addition, a single user ought to spawn new addresses regularly, for the sake of maintaining anonymity. These addresses (and the corresponding keys) must be generated carefully, without revealing even a hint of the private key. Further, they must be stored securely. All these functionalities are taken care of by a \\textit{cryptocurrency wallet}. Wallets are simply software that perform a lot of these tasks in the back-end, allowing users to transact in Bitcoin as one would using a bank account. Using a wallet requires trusting the software of the wallet. In principle, one can participate in the cryptocurrency system without the use of a wallet, but most users use a wallet.\n\n\\paragraph{Transaction fees} We mentioned above that the total value in a transaction's inputs must add up to the total value in its outputs. In reality, the sum of values in the output is slightly lower than the inputs. The remaining amount, called the \\textbf{transaction fees}, is claimed by the miner of the block that includes this transaction. The transaction fees are an incentive for a miner to include a particular transaction in the block being mined. Transactions with higher fees get included faster in the blockchain, while those with lower fees get added later. The fees vary with time, and are often calculated automatically by wallets according to a  particular fee rate, measured in Satoshi per kilobyte. You can learn more about transaction fees and fee rates  \\href{https://en.bitcoin.it/wiki/Miner_fees}{here}. Roughly speaking, fees are of the order of ten dollars per transaction.\n\n\\paragraph*{Coinbase transactions}\nThe preceding discussion is on how money is exchanged by users in the Bitcoin system. How is money introduced in the system in the first place? The answer is simple: new Bitcoins are generated with every new block. Every block includes a special transaction, called the coin-base transaction, in which the miner gets for itself a fixed number of Bitcoins. Initially, the rewards were $50$ BTC per block. Every $210,000$ blocks mined, or about every four years, the reward given to Bitcoin miners for processing transactions is cut in half. So far, there have been three halvings, and the current reward is $6.25$ BTC per block. Block rewards will continue till the year $2140$, after which there will be no new Bitcoin introduced in the system. The total volume of currency that will be ever be used is capped at $21$ million, of which around $18.5$ million coins are already in circulation. Coinbase transactions, along with transaction fees, are an additional incentive mechanism for Bitcoin users to actively participate by mining. In the initial years of Bitcoin, coinbase transactions formed the major component of the rewards; with time, the contribution of transaction fees is catching up. \n\nFigure \\ref{fig:bitcoin_halving} shows how the Bitcoin block reward decreases by half every four years. We are currently at 6.25 Bitcoins per block. The figure also shows the total number of Bitcoins in circulations. The halving scheme ensures that the total number of Bitcoins ever produced will taper off to a total of $21$ million Bitcoins.\n\nFigure \\ref{fig:block_rewards} shows the same metric as in Figure \\ref{fig:bitcoin_halving}, but the reward is now measured in dollars instead of Bitcoin. This figure is useful to understand the incentives for mining. The block rewards (along with the transaction rewards) must offset the cost of mining. As more users join the system with time, a particular miner must compute more hashes (and thus must spend more on electricity) to mine a block. Block rewards (in terms of dollars) have gone up too, providing an incentive for users to mine in spite of the increasing difficulty. There is a subtle balance between the various economic factors that govern the level of mining power in the Bitcoin system.\n\\begin{figure}[p]\n    \\centering\n    \\includegraphics[width = 0.8\\textwidth]{figures/bitcoin_halving.png}\n    \\caption{Bitcoin block reward in bitcoins. Figure sourced from \\href{https://www.coindesk.com/bitcoin-halving-explainer}{here}}\n    \\label{fig:bitcoin_halving}\n\\end{figure}\n\n\\begin{figure}[p]\n    \\centering\n    \\includegraphics[width = 0.8\\textwidth]{figures/block_reward.jpg}\n    \\caption{Bitcoin block reward in dollars. Figure sourced from \\href{https://www.cmcmarkets.com/en/learn-cryptocurrencies/bitcoin-halving}{here}}\n    \\label{fig:block_rewards}\n\\end{figure}\n\n%\\pramod{please put a figure of how bitcoin's block reward scheme changes over time. give some numbers as examples.}\n\n\\paragraph*{Transaction mempool}\nWhenever one user wants to pay another using Bitcoin, it generates an appropriate transaction, signs it, and broadcasts it through the entire network. Ultimately, the transaction is simply a message (a string of bits) in a particular semantic form. The size of a message is  a few kilobytes; the exact size depends on the number of transaction inputs and outputs. The transaction is propagated across the Bitcoin network using the diffusion protocol. Miners keep looking out for new transactions and add them to their memory, called the \\textbf{mempool} (they do so after verifying the signature on the transaction). At any given point in time, a miner is working on a particular block, which contains some transactions from its mempool. A miner can include new transactions from its mempool into its working block at will (or even remove them). As such, it would like to include as many transactions as possible in order to maximize its sum total transaction rewards. However, there is an upper bound on the total size of a block. Thus, a miner prioritizes blocks with a higher transaction fee rate, i.e., a higher fee with a smaller size. A transaction with a high enough transaction fee is included immediately by all miners into their working block. The lucky miner who finds the proof-of-work first gets to ``claim\" the reward; again the claim on the reward is only honored when the block is confirmed, i.e., buried deep enough in the longest chain. \n\nNote that there is a certain latency between the transaction first being issued and the transaction being confirmed on the blockchain. The first factor behind the latency is that it takes time for a newly issued transaction to be included in any block; this latency can be reduced by increasing the mining fee. The second factor is that it takes time for a block that includes the transaction to be buried deep enough. Here, a user may trade-off latency with security (in Bitcoin). Other blockchain designs, which we explore in future lectures, may not have this trade-off.\n\n\\section*{Validating a block}\n\n\\paragraph{The state of the system} In the above discussion, we covered many important points explaining how Bitcoin enables a money-exchange system. One issue that was skirted is, how do users verify that a single coin is not spent twice? In the context of Bitcoin, this issue boils down to verifying that a transaction's inputs have not been spent already. As such, the only way to verify this is to keep track of the set of UTXOs (unspent transaction outputs) at all times. This set is often referred to as the \\textbf{state} of the system. Note that these outputs are for those transactions that are already in the blockchain, and have not been spent in the blockchain. Thus, the state changes  every time the longest-chain grows (or more generally, changes). It is important to note that the state is separate from the mempool, but is linked in the following way. Honest users build a block from transactions in the mempool. However, they only choose those transactions that are valid, and they check the validity using the information in the state. In an account-based model, the state would simply be the roster of all account balances. More generally, the state of a blockchain system contains a summary of all the entries in the ledger thus far, which can be used to validate new entries. \n\nFigure \\ref{fig:utxo_size} shows the number of UTXOs in the Bitcoin system as a function of time. Clearly, it has grown many-fold since the beginning, and it will continue to grow as Bitcoin becomes more popular. With each UTXO being a few hundred bytes, the size of the UTXO set is now over $5$ GB. As such, this might seem like a moderate amount which can be easily stored. However, each node must perform many read, write and delete operations on this set. Thus, the set must be stored in the memory (preferably, on-chip memory) rather than on the disk. Given this requirement, the UTXO size is too large for regular devices to store; it requires specialized hardware. The large UTXO size is another dimension of the scalability challenge. %\\pramod{point out that this growing in size over time. give some numbers to get an idea of the current size. }\n\\begin{figure}[htbp]\n    \\centering\n    \\includegraphics[width = 0.8\\textwidth]{figures/UTXO_size.png}\n    \\caption{Number of UTXOs over time in Bitcoin. Figure sourced from \\href{https://www.blockchain.com/charts/utxo-count}{here}}\n    \\label{fig:utxo_size}\n\\end{figure}\n\n\\paragraph{Validating blocks} When a miner receives a new block, it must perform certain sanity checks, of which two are important. First, it checks whether the proof-of-work meets the required threshold. Second, it checks whether the transactions in the block are consistent with the state. This means that it must check whether every input in every transaction belongs to the state or not. If it does, the miner accepts the block, removes the relevant transactions from its mempool, and also updates the state. Updating the state involves deleting spent transaction outputs and adding the newly generated ones. While constructing a new block to mine on, the same validation steps are taken preemptively.\n\n\\paragraph{Light nodes and stateless clients}\nStoring the state of the system and validating each transaction in every block requires storage and computation power. Bitcoin allows for light nodes/clients, who can participate in the system with much lesser computation and storage power. A light client merely verifies the proof of work on blocks. It may further selectively verify the validity of transactions, especially those that concern itself. As such, a light client does not store the state of the system which prevents it from validating transactions.\n\nThere are proposals to augment the functionality of light nodes, by creating so-called \\textbf{stateless nodes}. These nodes can validate transactions/blocks without storing the full state at all times. They merely download the requisite state information to validate a block, one block at a time, and then delete it once the block is validated. In order to do so securely, the state is stored in the form of an accumulator, which we discussed in Lecture 2. The stateless client option is being pursued vigorously by Ethereum. See, e.g., the discussion \\href{https://ethresear.ch/t/the-stateless-client-concept/172}{here}. A fully functional stateless client for Bitcoin, which makes use of Merkle tree accumulators, has been built by the \\href{https://www.media.mit.edu/projects/utreexo/overview/}{UTREEXO project}.\n\n\\section*{Smart contracts}\nSo far, we have seen how blockchains can be used to implement a currency system. Essentially, the blockchain as a ledger records payments from one party to another, thereby keeping tab of all parties' balances. Transactions are simply messages recording the transfer of money. However, blockchains are much more versatile; they can also be used to run \\textit{smart contracts}. Smart contracts are programs that are run by the peers in the blockchain system. The notion of a transaction is broadened to include these pieces of code as well. Smart contracts come into play when two parties want to exchange money subject to some terms and conditions. In the physical world, they would draw up a contract. A trusted third party/authority would be needed to ensure that both parties follow the contract. When run on a blockchain, smart contracts eliminate the need for a single trusted third-party. Instead, the decentralized trust of the blockchain (in other words, the honest majority of the system) ensures that the contract gets executed correctly.\n\nIn this lecture, we only focus on smart contracts in Bitcoin, which are rather limited in scope. Ethereum, a subsequent cryptocurrency, allows for much more diverse programs as smart contracts; we will learn about that in a later lecture.\n\n\\paragraph{Scripts in Bitcoin}\nSmart contracts are simply called scripts in Bitcoin. To understand scripts, we need to broaden our understanding of transactions from merely statements recording the transfer of money. As we saw before, a transaction consists of inputs and outputs, with outputs recording the transfer of Bitcoins to some address. What we did not mention before is that every transaction output includes a script, consisting of \\textit{opcodes}, which specify conditions that must be satisfied in order to spend the coins mentioned in the output. The default condition is that the spender of the output must provide a public key that hashes to the pertinent address, and must sign the message with the corresponding private key. Earlier, we presented this as a sanity check; however, this is explicitly specified as a script in every regular transaction.\n\nBitcoin scripts also allow for additional conditions, such as requiring that the transaction is not spent until a particular time, requiring that a transaction is spent by a particular time, requiring a message that is signed by multiple private keys, etc.\nAn interesting and useful script that emerges from a combination of these conditions is that of a hashed timelock contract (HTLC). HTLCs are useful in setting up escrow funds. If Alice wants to pay Bob in exchange for some other good, then Alice would like to pay Bob only after she is guaranteed to get the good from Bob, and Bob would like to release the good only after he is guaranteed to be paid by Alice. An HTLC enables such terms to encoded as a smart contract on a blockchain. You can learn more about HTLCs \\href{https://www.investopedia.com/terms/h/hashed-timelock-contract.asp}{here}. A full list of opcodes used in the Bitcoin script is given \\href{https://en.bitcoin.it/wiki/Script}{here}.\n\n\\newpage\n\n\\section*{Project: Rust Implementation of Bitcoin Clients}\n\nIn this project, you are going to build a simplified Bitcoin client with full node functionality. The goal of the client is not to run in Bitcoin mainnet or any public testnet. Instead, the goal is to run it inside your team and let you have fun with it. You have plenty of freedom of designing and implementing this project. We provide some code in the \\href{https://gitlab.engr.illinois.edu/ece598pv/ece598pv-sp2021}{Gitlab repository}. The project will be split into 6 weeks with checkpoints every week as listed below.\n\n\n\\markdownInput{markdowns/week1.md}\n\\markdownInput{markdowns/week2.md}\n\\markdownInput{markdowns/week3.md}\n\\markdownInput{markdowns/week4.md}\n\\markdownInput{markdowns/week5.md}\n\\markdownInput{markdowns/week6.md}\n\n\\input{Problem_sets/Lec5_PS}\n\n\\end{document}",
    "lecture_04.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\usepackage{caption}\n\\usepackage{subcaption}\n\\let\\proof\\relax\n\\let\\endproof\\relax\n\\usepackage{amsthm}\n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 4}\n\\cfoot{\\thepage}\n\n\\title{Lecture 4:  Peer to Peer Networking for Blockchains}\n\\author{Principles of Blockchains, Princeton University,  \\\\ Professor:  Pramod Viswanath \\\\ Scribes: Soubhik Deb, Ranvir Rana and  Suryanarayana Sankagiri}\n%\\date{February 4, 2021}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nIn this lecture, we cover the networking aspects of a blockchain system. We introduce the notion of peer-to-peer networks, of which a blockchain is an example. We describe how messages are broadcast to all users in such a network. We specify the details of the networking layer in Bitcoin. This lecture also covers two interesting ways of improving the network layer protocols. The first, called \\textsf{Perigee}, is a technique to reduce the delay in propagating messages. The second, called \\textsf{Dandelion}, reduces the extent to which an eavesdropper can track messages to its source.\n\\end{abstract}\n\n\\section*{Basic primitives and random network construction}\nIn blockchain systems, the basic network-layer operation is to {\\em broadcast} messages. By broadcast, we mean that a user sends some information/message to all other users in the system. There are two basic blockchain elements being broadcast:\n\\begin{itemize}\n    \\item data values that are to be recorded on the ledger\n    \\item blocks\n\\end{itemize}\n\nIn a decentralized system such as a blockchain, the network should have\n\\begin{itemize}\n    \\item Robustness from a single point of failure: No centralized server;  \n    \\item Robustness from censorship: No centralized server; \n    \\item Robustness from nodes going offline, high churn rate; \n\\end{itemize}\nAdditional desirable properties include\n\\begin{itemize}\n    \\item a message that is broadcast should reach all users as quickly as possible\n    \\item a message that is broadcast should not be traceable back to its origin (for the sake of anonymity/privacy)\n\\end{itemize}\nThe need for robustness implies that we do not want a client-server relationship; we settle for a peer-to-peer (P2P) network where each node has identical behavior.\n%A distributed system's security is closely tied to its network assumption; hence it is essential to design the network to mirror these assumptions. We understand p2p networking using the Bitcoin network as a reference.Examples of a P2P network include Napster and  BitTorrent. \n\nConsider a set of users in a P2P network. An \\textit{overlay network} depicts the connections between nodes, and is represented as a graph. It abstracts out the physical network switches and routers and defines virtual links between nodes. Two nodes that are connected by a link can exchange messages directly. Those that are not connected by a link must find a path connecting them on this overlay network in order to communicate messages.\n\nOverlay networks can be split into two base categories: structured and unstructured. Structured overlay networks, like \\href{https://en.wikipedia.org/wiki/Chord_(peer-to-peer)}{CHORD}, assign an identifier to each node and uses that to construct well-defined routing rules. These networks are excellent for routing sending point to point messages, a use case not required for Bitcoin. Structured networks are suitable for broadcast, too; any message transmission takes $O(\\log N)$ hops on CHORD with $O(\\log N)$ connections per node.\n\nOn the other hand, unstructured networks like $d$-regular graphs have no node identifiers; a node connects to $d$ other nodes randomly. While routing point to point messages takes $O(\\log N)$ hops, it's impractical since finding the path from point A to point B involves many peer queries. On the other hand, broadcast is very efficient using gossip and takes $O(\\log N)$ hops. Thus, the number of hops required is the same as the structured network with the added benefit of $O(1)$ peer connections. Hence, the Bitcoin network uses an unstructured $d$-regular overlay network. \n\nHow does broadcast take only $O(\\log N)$ steps? We first need to understand the gossip-flooding-based broadcast protocol. The flooding protocol mimics the spread of an epidemic. Once a node is ``infected\", it infects its peers and forever stay's infected. It is easy to see that the spread of information will happen exponentially; hence the information will take $O(\\log N)$ hops to spread to all nodes. To formally understand the spread, we note that $d$-regular graphs with $d\\geq 3$ are an \\textit{expander graph} for large sizes ($|V|$) with high probability. An expander graph is a connected but sparse graph ($|E|=O(|V|)$) with the following property: $|\\partial A| \\geq \\epsilon|A|$ for any connected sub-graph $A$ with $|A|<0.5|V|$. Here, $|\\partial A|$ refers to the number of vertices outside $A$ with at least one neighbor in $A$. A gossip message originates with $A(0)$ as the broadcasting node with $|A(0)|=1$, in the next hop, it will spread to $\\partial A(0)$ with $|A(1)|\\geq (1+\\epsilon)|A(0)|$. This recursion continues and we have $|A(k)|\\geq(1+\\epsilon)^kA(0)$. Thus, the number of steps to reach half the number of nodes is logarithmic in the number of nodes. It can be shown that the other half of the nodes can also be covered in $O(\\log N)$ time.\n\n\n%Engineering issues (peer discovery, bootstrap, churn). Implementation connections (to the lab experiment). Validation of tx, blocks. How does that impact networking? What about skipping validation and doing cut-through routing? Compact blocks. (RR)\n\n\\section*{Bitcoin P2P network: A systems view}\nIn Bitcoin, peers connect to each other and communicate using the TCP protocol. The codebase allows for eight outgoing connections and up to 117 incoming connections. The network has a high churn rate (rate at which users enter/leave the system); hence, the node must be ready to connect to new peers. Moreover, to ensure that the peers we are connecting to are chosen randomly, the node keeps a large list of nodes running Bitcoin in the form of their (IP, port) tuple and establishes a connection to one of them randomly when a slot opens up.  \n\nHow does a node bootstrap its list of peers? This happens by connecting to a set of DNS seed nodes. The seed nodes are not heavily decentralized; hence completely relying on the peer list provided by them is not advisable. On connecting to the initial set of peers, a node asks its neighbors for their peer list using {\\tt getAddr} and {\\tt Addr} messages. The node keeps refreshing its peer list regularly by exchanging peer lists with its peers. \n\nTransmission of all block and transactions happen through the inventory message {\\tt inv}, on receiving an {\\tt inv} message the node checks if it has the block or the transaction in its local storage. If not, it sends the {\\tt getData} message to fetch those blocks and transactions from the peer. Since block sizes are relatively large, block transmission can optionally happen in 2 stages. On receiving the {\\tt inv} message, the node may ask for headers first using {\\tt getHeaders} and ask for complete blocks only if a header chain is established. This header-first block transmission increases queries but can decrease the net bandwidth usage. It may also prevent nodes from accepting PoW invalid blocks since the node can check from the header whether PoW is valid. \n\nWe saw in the previous lecture that some nodes might be malicious. A question that may arise is: what stops malicious nodes from flooding the network with invalid blocks and transactions (i.e., with invalid PoW and/or signatures)? Such flooding will saturate the network and increase transmission delay to unacceptable levels. Such an attack is prevented by a simple design decision, forward message to peers only after validating the message; i.e., a node sends an {\\tt inv} block message to its peers only after validating the block. If the adversary creates an invalid block, the block will not be propagated beyond one honest node. Additionally, nodes maintain their peers' reputation using some predefined heuristics; if a peer misbehaves (say by sending a transaction with invalid signatures), its reputation is downgraded and after a certain lower threshold is disconnected.  \n\nAs a side effect, forward after validation structure increases the net delay in broadcasting a block across the network. Several ``trusted\" relay networks have been established for speeding up propagation. Once a block is validated by a peripheral node in a relay network, it is gossiped to all other nodes before performing local validation since the inter-node communication is trusted. An example is FRN (fast relay network); it creates a hub and spoke model with trusted servers as hubs. \n\nAnother proposal to speed up propagation is using compact blocks. Note that a transaction is broadcast in the network twice. Once when the transaction is generated and the second time as a transaction is a block. We can remove this redundancy by introducing compact blocks. For nodes enrolled for compact block relaying, their peers guess the transaction the node has received while forwarding a new block and only send a compact block containing the original block contents sans the guessed transactions. Any mismatch in guessing is resolved later using a {\\tt getblktxn} message. \n\n\\section*{Random Geometric Graphs}\nIn the random network topology, each node in the peer-to-peer (P$2$P) network $G$ chooses $c$ other nodes uniformly at random from the set of all nodes in the network $G$ and sets them as its neighbors. Thus, whenever a node $n$ needs to broadcast a message, it transmits the message to these $c$ neighbors who in turn relays the message to their own neighbors. While the result graph is a expander with low diameter, the shortest path taken for routing a message from the source to the destination is sub-optimal in the sense that the length of this shortest path could be much worse than the {\\em geodesic} shortest path (see Fig~\\ref{fig:random-topology}). Furthermore, the random network topology fails to take into account the heterogeneities present in the internet: different users could have different bandwidth and processing power, non-uniformity in mining power that make a difference to networking efficiency. \n\n{\\sf Perigee} is a recent P2P protocol that aims to create a random {\\em geometric} graph topology; this way the shortest path on the connectivity graph is also the shortest {\\em geographic} (geodesic)  path. There are two types of neighbors for a node $n$: (a) \\textit{outgoing neighbors}: the set of neighbors to whom the node $n$ sends and receives messages; (b) \\textit{incoming neighbors}: the set of neighbors from whom message is only received. {\\sf Perigee} is a decentralized algorithm  for selecting the set of outgoing neighbors with the objective to minimize the time it requires for a broadcast message to reach $90\\%$ of the nodes in the network. The overarching idea of {\\sf Perigee} is to update the set of outgoing neighbors by exploiting the information gathered by interacting with the current set of outgoing neighbors while exploring new connections in the network; this is done by making a connection to the classical \\href{https://epubs.siam.org/doi/abs/10.1137/S0097539701398375}{multi-armed  bandit problem} in statistical decision making theory.\n\nIn {\\sf Perigee}, a node $n$ in proceeds in a round-by-round basis under the following steps:\n\\begin{enumerate}\n    \\item A round comprises of $M$ unique messages that has been broadcast in the network. Let these $M$ messages in round $r$ be represented by $\\mathcal{M}^r$ and $\\Gamma^r$ represent the set of outgoing neighbors in round $r$. For each message $m \\in \\mathcal{M}^r$, the node $n$ records the timestamp $t^m_{\\text{nbr}}$ when that message $m$ was received from each of its outgoing neighbor $\\text{nbr} \\in \\Gamma^r$. The node $n$ also records the earliest timestamp $t^m_{\\text{earliest}}$ when it received the message $m$. Note that it is possible that the node $n$ received the message $m$ for the first time from a non-outgoing neighbor.\n    \\item At the end of the round, the node $n$ assigns score to each of its outgoing neighbors based on the timestamps it recorded in step $1$. Towards that end, the node $n$ first determines $t^m_{\\text{nbr}} - t^m_{\\text{earliest}}$ for each outgoing neighbor $\\text{nbr} \\in \\Gamma^r$ and message $m \\in \\mathcal{M}^r$. Now, the node $n$ employs a scoring method to assign scores to each outgoing neighbors. There are two flavors of scoring methods. \n    \\begin{itemize}\n        \\item \\textit{Scoring each outgoing neighbor individually.} For each outgoing neighbor $\\text{nbr} \\in \\Gamma^r$, the score is computed as $90\\textsuperscript{th}$ percentile of the set $\\{t^m_{\\text{nbr}} - t^m_{\\text{earliest}} \\vert m \\in \\mathcal{M}^r\\}$. This scoring approach  reflects a preference to retain an outgoing neighbor from which messages are received relatively earlier. Thus, lower the score for a neighbor $\\text{nbr}$, higher is the preference to retain that neighbor in the next round. Therefore, assuming  $k$ out of $\\mid \\Gamma^r \\mid$ outgoing neighbors are to be retained for the next round, the node $n$ retains the outgoing neighbors that are among the $k$ lowest scorers.\n        \\item \\textit{Scoring groups of neighbors jointly.} In contrast to previous approach, the idea behind joint scoring is to assign the score to a group of neighbors $\\Gamma_{\\text{retain}}$. First, set $\\Gamma_{\\text{retain}} = \\phi$ and determine the outgoing neighbor $\\text{nbr} \\in \\Gamma^r$ that has the lowest $90\\textsuperscript{th}$ percentile of the set $\\{t^m_{\\text{nbr}} - t^m_{\\text{earliest}} \\vert m \\in \\mathcal{M}^r\\}$ and include it in $\\Gamma_{\\text{retain}}$. Then, score each $\\text{nbr} \\in \\Gamma^r \\setminus \\Gamma_{\\text{retain}}$ by computing the $90\\textsuperscript{th}$ percentile of the set \\[\\{ \\min(t^{m}_{\\text{nbr}} - t^{m}_{\\text{earliest}}, \\min(\\{t^{m}_{\\text{nbr}'} - t^{m}_{\\text{earliest}} \\mid \\text{nbr}' \\in \\Gamma_{\\text{retain}}\\})) \\mid m \\in \\mathcal{M}^r\\}.\\] Include the $\\text{nbr} \\in \\Gamma^r \\setminus \\Gamma_{\\text{retain}}$ with the lowest score in $\\Gamma_{\\text{retain}}$. Essentially, we are determining the outgoing neighbor in  $\\Gamma^r \\setminus \\Gamma_{\\text{retain}}$ that best complements the existing neighbors in $\\Gamma_{\\text{retain}}$ to minimize the time required for the node $n$ to receive $90\\%$ of the messages. Assuming  $k$ out of $\\mid \\Gamma^r \\mid$ outgoing neighbors are to be retained for the next round, this process is continued until $\\mid \\Gamma_{\\text{retain}} \\mid = k$.\n    \\end{itemize}\n    This step describes the process for retaining $k$ outgoing neighbors from $\\Gamma^r$ by \\textbf{exploiting} the information gathered from interacting with neighbors in round $r$. The retained outgoing neighbors are included into $\\Gamma_{r+1}$.\n    \\item  Next, the node $n$ does \\textbf{exploration} by selecting uniformly at random $\\mid \\Gamma^r \\mid - k$ nodes from the set of all nodes in the network that are not in $\\Gamma^r$ and are included in $\\Gamma^{r+1}$. \n\\end{enumerate}\n\\begin{figure}[ht]\n\\centering\n\\begin{subfigure}{.5\\textwidth}\n  \\centering\n  \\includegraphics[width=.75\\linewidth]{figures/random_topology.pdf}\n  \\caption{Random network topology}\n  \\label{fig:random-topology}\n\\end{subfigure}%\n\\begin{subfigure}{.5\\textwidth}\n  \\centering\n  \\includegraphics[width=.75\\linewidth]{figures/perigee.pdf}\n  \\caption{Perigee}\n  \\label{fig:perigee}\n\\end{subfigure}\n\\caption{Observe that, for Perigee, shortest path follows much closer to the geodesic shortest path.}\n\\end{figure}\n\n\n\n\\section*{Network Anonymity and Privacy}\nIn a blockchain system, the blockchain data structure is visible to all participants. In the context of a cryptocurrency, the blockchain contains every transaction in the history of the currency. More generally, it can contain sensitive data of users, which should not be made public. Indeed, this is a necessary feature of blockchains if it is to be publicly verifiable ledger. How then can one obtain privacy in blockchains?\n\nFor the sake of privacy, Bitcoin originally proposed using pseudonymous identifiers. Each user participates in the system via one or more psuedonym, each of which is linked to a public key. This paradigm has been adopted by most cryptocurrencies today. Anybody observing the blockchain learns only the transaction patterns of each pseudonym. As long as these pseudonyms cannot be linked to the owner's human identity, privacy is preserved. However, multiple studies have shown that such a system is vulnerable to de-anonymization attacks, particularly in the presence of side information. % \\cite{narayanan2009anonymizing,backstrom2007wherefore,fistful,androulaki2013evaluating,ober2013structure}.\n\nHere, we focus on a specific class of de-anonymization attacks wherein an adversary who observe traffic flowing over the P2P network can obtain some information about the users. In most cryptocurrencies, new transactions are spread over the network according to some pre-specified flooding protocol (typically a gossip algorithm). If an adversary observes this traffic at a fine enough time resolution -- e.g., by setting up a supernode that connects to many nodes -- it can often link transactions (and hence the pseudonym of the sender) to the IP address that originated the transaction. The IP address can then be associated to a human identity by other means. We then discuss an alternate networking protocol called \\textbf{Dandelion} which provides theoretical privacy guarantees.\n\n\\subsection*{A mathematical model}\nWe first discuss a mathematical model for the network de-anonymization problem. The model involves the protocol by which messages are spread in the network, and a model of the adversary that collects information about this process and tries to identify the source of the message. Typically, the underlying network is modeled as a graph $G = (V,E)$. Here, $V$ denotes the set of all nodes participating in the blockchain system and $E$ is the set of edges representing TCP connections between nodes. As a simplification, we consider the problem of de-anonymizing a single message (transaction/block) sent by a particular node $v^* \\in V$. When modeled as above, the problem of de-anonymization boils down to guessing $v^*$ given some observations of how the message has spread. \n\n%Although messages sent in the network include both transactions, for this portion we will be concerned only with transactions. This is because we want to link the The source of the transactions\n\nIn the context of de-anonymization, there are two main adversarial models: \\emph{eavesdropper adversaries} and \\emph{botnet (spy-based) adversaries}. Eavesdropper adversaries run a supernode that connects to all (or a substantial subset) of nodes in the network (Figure \\ref{fig:eavesdropper}).\n From the perspective of an honest node, the eavesdropper looks just like any other node. Honest nodes therefore relay transactions normally, allowing the eavesdropper to collect timestamps and other metadata. Combined with information about the graph topology, this metadata can be used to infer the source of a particular transaction. One important property of eavesdropper nodes is that they typically do not relay messages; they only collect communications relayed by other nodes. \n\nBotnet or spy-based adversaries (Figure \\ref{fig:botnet}) \n instead consist of a set of corrupt, colluding nodes that participate in the network normally, both accepting \\emph{and} relaying information. We let $p$ denote the fraction of spies in the network, and let $V_A, V_H \\subseteq V$ denote the set of adversarial and honest nodes, respectively. As the name suggests, this adversarial model is motivated by a botnet that spawns cryptocurrency nodes. The key difference compared to the eavesdropper adversary is that each botnet node may have limited visibility into the network (e.g., if it only connects to a few peers rather than the entire network), and botnet adversaries may inject packets into the network. \n\n\\begin{figure}\n\\begin{minipage}{0.5\\textwidth}\n\\centering\n    \\includegraphics[width=1.2in]{figures/eavesdropper}\n    \\caption{Eavesdropper adversary. A well-connected supernode eavesdrops on relayed communications.}\n    \\label{fig:eavesdropper}\n\\end{minipage}\n\\hspace{0.1in}\n\\begin{minipage}{0.5\\textwidth}\n    \\centering\n    \\includegraphics[width=1.2in]{figures/botnet}\n    \\caption{Botnet adversary. Red nodes represent  corrupt ``spy nodes\", which use observed metadata to infer the transaction source.}\n    \\label{fig:botnet}\n\\end{minipage}\n\\end{figure}\n\nAs discussed in the sections above, many cryptocurrencies---including Bitcoin---broadcast content using a gossip protocol called \\emph{diffusion}. Under diffusion, each node transmits the message to each of its neighbors with independent, exponentially-distributed delays. The problem of detecting the source of a diffusion process over a graph is well-studied. An \\href{https://ieeexplore.ieee.org/abstract/document/5961801}{early work}  who studied this problem in a so-called \\emph{snapshot model}. Under this model, the diffusion process is allowed to spread in the network until some time $T$. At this time, the adversary gets to observe which nodes have the message, and which do not. The authors showed that one can reliably infer the source of a diffusion process, even as $T$ grows to infinity.\n\nThe de-anonymization algorithms suggested in this and other works revolve around the notion of \\textit{centrality} or symmetry; because diffusion spreads content symmetrically on the underlying network, the message (roughly) spreads in a disc over the graph, with the true source at the middle of that disc. The above results imply that an adversary with partial global oversight can infer the shape of the disc and identify the central node with non-negligible probability. These results suggest that diffusion is poorly-suited to protecting users' anonymity at the network level, which motivates the need for alternative spreading protocols that protect users' anonymity.\n\n\\subsection*{Dandelion}\nThe key idea that emerges from the analysis of diffusion is that one must break the symmetry of the message spreading (aka gossiping) protocol in order to prevent the adversary from accurately guessing the message.  The {\\sf Dandelion} P2P networking protocol, which incorporates this idea, has two phases: a \\textit{stem phase} (aka anonymity phase) and a \\textit{fluff plase} (aka diffusion phase). In the stem phase, each node propagates each message along a randomly chosen direction. After a random number of hops, the stem phase ends. Then, in the fluff phase, the transaction is broadcast via diffusion to the rest of the graph. As mentioned, the stem phase provides the anonymity guarantees, while the latter fluff phase helps propagate the message to all users without much delay.\n\n\nThe {\\sf Dandelion} protocol is explained in more detail below. {\\sf Dandelion} proceeds in asynchronous epochs; each node advances its epoch when its internal clock reaches a random threshold (in practice, this will be on the order of minutes). Within an epoch, the main algorithmic components of {\\sf Dandelion} are:\n\\begin{enumerate}\n    \\item \\textbf{Anonymity graph:} The random walk takes place on an overlay of the P2P graph called the anonymity graph. This overlay should be chosen either as a random cycle graph (i.e., a 2-regular graph) or a 4-regular graph. This 4-regular graph is embedded in the underlying P2P graph by having each node choose (up to) two of its outbound edges, without replacement, uniformly at random as {\\sf Dandelion} relays. This does not produce an exact 4-regular graph, but an approximation.Each time a node transitions to the next epoch, it selects fresh {\\sf Dandelion} relays.\n    \\item \\textbf{Forwarding of a nodes own transactions:} Each time a node generates a transaction, it forwards the transaction in stem phase along the same randomly-selected outbound edge on the anonymity graph. If the anonymity graph is a cycle, there is only one outbound edge per node; otherwise, the node must choose one of its two outbound edges.\n    \\item \\textbf{Relaying of other nodes transactions} Each time a node receives a stem-phase transaction from another node, it either relays the transaction or diffuses it. The choice to diffuse transactions is pseudo-random, and is computed from a hash of the nodes own identity and epoch number. Note that the decision to diffuse does not depend on the transaction itselfin each epoch, a node is either a diffuser or a relay node for all relayed transactions. If the node is not a diffuser in this epoch (i.e.,it is a relayer), then it relays transactions pseudo-randomly; each node maps each of its incoming edges in the anonymity graph to an outbound edge in the anonymity graph (with replacement). This mapping is selected at the beginning of each epoch, and determines how transactions are relayed.\n    \\item \\textbf{Robustness mechanism} Each node tracks, for each stem-phase transaction that it sends or relays,whether the transaction is seen again as a fluff-phase transaction within some random amount of time. If not, the node starts to diffuse the transaction\n\\end{enumerate}\n\n% \\subsection*{Guarantees on Dandelion}\n% The key theoretical result concerning {\\sf Dandelion} provides upper bounds on both the \\textit{precision} and the \\textit{recall} with which an adversary can estimate the source of a message. \\textit{define precision, recall.}\n\n\n\\section*{Reference material}\n\n{\\sf Perigee} is a recent P2P protocol that adapts the network topology to a random geometric network, presented in ``\\href{https://dl.acm.org/doi/abs/10.1145/3382734.3405704}{Perigee: Efficient Peer-to-Peer Network Design for Blockchains},\" \nMao, Deb, Venkatakrishnan and Kannan, PODC 2020. %{\\sf Perigee} uses ideas from the \\href{https://epubs.siam.org/doi/abs/10.1137/S0097539701398375}{multi-armed  bandit}  problem in theory of statistical  decision making. \n\n{\\sf Dandelion} networking was invented in ``\\href{https://dl.acm.org/doi/abs/10.1145/3084459}{Dandelion: Redesigning the Bitcoin Network for Anonymity},\" Fanti, Venkatakrishnan and Viswanath, Sigmetrics 2017. \n\n\n\\end{document}",
    "lecture_12a.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage[english]{babel}\n\\usepackage{listings}\n\\usepackage{fancyhdr}\n\\usepackage{makecell}\n\\usepackage{threeparttable}\n\\usepackage{subfig}\n\\usepackage{graphicx}  \n\\newsavebox{\\measurebox}\n\\pagestyle{plain}\n\\fancyhf{}\n\\usepackage{tabularx} \n\\usepackage{multirow}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n%\\usepackage{hyperref}\n\\usepackage{markdown}\n\\usepackage{amsthm}\n\\usepackage{caption}\n%\\usepackage{subcaption}\n\n\\newcommand{\\indicator}{{\\bf 1}}\n\\newcommand{\\pramod}[1]{{\\color{red}\n\\footnotesize[Pramod: #1] }}\n\\newcommand{\\xw}[1]{{\\color{green}\n\\footnotesize[Xuechao: #1] }}\n%\\let\\proof\\relax\n%\\let\\endproof\\relax \n\n\n\n\\newcommand{\\POM}{$\\mathsf{POM}\\ $}\n\\usepackage{float}\n\\usepackage{amsmath}\n\\usepackage[colorlinks=true, allcolors=blue]{hyperref}\n\\graphicspath{ {./figures/} }\n\\newcommand{\\h}{\\textsf{H}}\n\\newtheorem{lemma}{Lemma}[]\n\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 12}\n\n\\title{Lecture 12:  Layer 2 Scaling: Side Blockchains}\n\\author{\nPrinciples of Blockchains, Princeton University, \\\\ \nProfessor: Pramod Viswanath \\\\ \nScribe: Peiyao Sheng\\\\\n}\n%\\date{March 4, 2021}\n\\date{\\today}\n\n\n\\begin{document}\n\\maketitle\n\n\\begin{abstract}\n    So far, we have considered scaling methods that alter the consensus protocol itself (albeit in modest ways). In this lecture, we study how to scale existing blockchain performance {\\em without} changing the consensus layer. This is done  by extracting trust from the  consensus embedded in the core blockchain, but offloading computation and storage. Given that the consensus protocol (layer 1) is untouched, these methods are known to afford {\\em layer 2} scaling.  In this lecture we study an alternative layer 2 scaling called  {\\em side blockchains}; this approach can handle account based systems and smart contracts.\n\\end{abstract}\n\n\n\n\\section*{Introduction}\nIn the last four lectures, we have considered proposals to scale throughput, latency, storage, communication and computation (and energy). In each of these proposals, the longest chain consensus protocol was modified. In a practical blockchain already operating in the real world, it is quite onerous to change the consensus layer: such a change would require a ``meta consensus\" among the participating nodes, i.e., consensus on how to change the consensus mechanism! Even a successful switch in the consensus mechanism would still lead to a ``hard fork\" in the ledger where the two paths would be following different consensus protocols. In this context, proposals to scale performance without changing the consensus layer are very appealing. Such are the goals of this lecture, where we discuss the two most promising ``layer 2\"  proposals that scale performance by offloading computation and storage  without impacting the core technology of blockchains (``layer 1'') and overall security. The  mechanism studied in this lecture is via {\\em side chains} and allows a general account based model and smart contract. \n\n\n\\section*{Side Blockchains}\nA side blockchain is a smaller blockchain (in terms of trust represented for example by  the number of nodes or hash power). The side blockchain is connected to a trusted blockchain by having its nodes propose blocks by committing the hashes of the blocks periodically to the trusted blockchain (Fig.\\ref{fig:two-layer}). The ordering of blocks in the side blockchain is determined by the order of the hashes in the trusted blockchain; this way the security of the side blockchain is directly derived from that of the trusted blockchain. This mechanism is simple, practical, and efficient -- a single trusted blockchain can cheaply support a large number of side blockchains, because it does not need to store, process, or validate the semantics of the blocks of the side blockchains. Rather, it only orders and records the hashes of these blocks. These side blockchains can remain safe and live even if they do not have honest majority. In many ways, the overall architecture of such a system is similar to that of a uni-consensus based sharded blockchain, which we saw in the previous lecture.\n\n\\begin{figure}\n\\centering\n\\sbox{\\measurebox}{%\n    \\begin{minipage}[b]{.43\\textwidth}\n    \\centering\n    \\subfloat\n    []\n    {\\label{fig:two-layer}\\includegraphics[width=\\textwidth]{twolayer.pdf}}\n\n    \\subfloat\n    []\n    {\\label{fig:three-layer}\\includegraphics[width=\\textwidth]{threelayer.pdf}}\n    \\end{minipage} \n}\n\\usebox{\\measurebox}\n\\begin{minipage}[b][\\ht\\measurebox]{.51\\textwidth}\n  \\subfloat\n    []\n    {\\label{fig:ACeD}\\includegraphics[width=\\textwidth]{ACeD.pdf}}\n  \\end{minipage}\n\\caption{(a) Side blockchains commit the hashes of blocks to a larger trusted blockchain. (b) An oracle layer is introduced to ensure data availability. (c) ACeD is a scalable data availability oracle.}\n\\end{figure}  \n\n\\paragraph{Data Availability Attack}\nBoth the side-blockchain scheme and the sharded blockchain scheme are vulnerable to the \\textit{data availability attack}. In this attack, a malicious node in a side blockchain network (or a shard) commits the hash of a block to the trusted blockchain without transmitting the block data to the other nodes. Let us understand why this is a serious problem. When preparing a single ledger out of the blockchain, should users wait until they receive this missing block, or should they skip this block in the ledger they prepare? If they decide to wait, they may be kept waiting indefinitely, leading to a loss of liveness. If instead they move on and prepare the ledger by ignoring the block, the adversary may reveal the block at a later time, at which point it cannot be ignored. The block may contain transactions that are incompatible with the rest of the ledger, causing a safety violation.\n\nThe data-availability attack is a well-known attack in the blockchain community, first introduced in the context of \\textit{light clients} in blockchains. It was popularized in \\href{https://github.com/ethereum/research/wiki/A-note-on-data-availability-and-erasure-coding}{this note} by Vitalik Buterin of Ethereum and an \\href{https://arxiv.org/abs/1809.09044}{accompanying paper}. Light nodes merely store the headers of blocks and verify the proof-of-work criterion. They rely on full nodes to validate the block, and to provide a \\textit{fraud proof} if the block is invalid. Now consider the following data-availability attack: an adversary publishes a block header but does not publish the block data. A full node would simply ignore such a block until it receives the complete block data (which may never come). Thus, for all purposes, such a block would be an invalid block for a full node. How can a full node convince a light node to also ignore the block? A fraud proof would not be useful here. Rather, the light nodes and full nodes can construct a \\textit{data-availability proof} for themselves, a technique described in \\href{https://arxiv.org/abs/1809.09044}{this paper}. Such a proof can convince a light node whether or not a block of data is available.\n\nIn the context of light nodes, the data-availability attack is not fatal. Typically, miners also run full nodes. If a certain block is unavailable, they simply ignore it and mine in parallel to it (i.e., mine on its parent block). As long as the block remains unavailable, no honest miner will build on it. Eventually, it will fall out of the longest chain. At this stage, light nodes will automatically ignore such a block. In contrast, the attack is more serious in the context of side blockchains and sharding. The crucial difference is that a side blockchain (or a shard) may not have an honest majority of miners/full nodes. Thus, there is no consistent, systematic way for a side blockchain's (or a shard's) participants to decide whether or not to include a missing block in their ledger. A \\textit{data availability oracle} is a tool by which nodes in such a system can be ascertain whether or not a block is available. Such an oracle must defend against various kinds of data-availability attacks. The properties that such an oracle must satisfy are given below. Many early techniques designed to protect against the data-availability attack, such as \\cite{yu2020coded, al2018fraud} do not provide as strong a security guarantee as an oracle. This is primarily because they were designed to protect light nodes, where strong security properties were not essential; as described, even if the data-availability attack was successful, it would not be fatal. A comparison of the data-availability attack and its solutions for light nodes versus side blockchains is given in Table~\\ref{tab:attack}.\n\n\\paragraph{Data Availability Oracle}\nA \\textit{data availability oracle} is an intermediate layer that accepts blocks from side blockchains, pushes verifiable commitments to the trusted blockchain and ensures data availability to the side blockchains. The oracle layer nodes work together to reach a consensus about whether the proposed block is retrievable (i.e., data is available) and only then commit it to the trusted blockchain.  (Fig.\\ref{fig:three-layer}). There are some straightforward constructions of such an oracle.\n\\begin{itemize}\n    \\item {\\em Repetition}: each oracle node keeps a full copy of the block.\n    \\item {\\em Dispersal}: divide the block into several chunks and evenly disperse the chunks to oracle nodes. each node keeps a part of the block.\n\\end{itemize}\n{\\em Repetition} can simply conduct a voting to decide on the majority result, however the communication and storage overhead is proportional to the number of oracle nodes. If the number of oracle nodes is small (and yet deemed trustworthy), this is a very feasible approach. In a true decentralized sense this approach is not scalable. {\\em Dispersal} minimizes the redundancy of data, but is not secure since even one malicious oracle node can violate the retrievability. So a trade-off between security and scalability is spotted here and the key challenge is how to securely and efficiently share the data amongst the oracle nodes to verify data availability.\n\n\\begin{table}[]\n\\centering\n\\caption{Data availability attack in two scenarios.}\n\\label{tab:attack}\n\\begin{tabular}{|l|l|}\n\\hline\n\\multicolumn{1}{|c|}{Bitcoin light nodes}                                                        & \\multicolumn{1}{c|}{Sidechain clients} \\\\ \\hline\nLight nodes random sample chunks                                                                 & Oracle nodes store dispersed data      \\\\ \\hline\n\\begin{tabular}[c]{@{}l@{}}Rely on one honest full node to \\\\ reconstruct the block\\end{tabular} & Any client can reconstruct the block   \\\\ \\hline\n\\begin{tabular}[c]{@{}l@{}}Probabilistic secure: need enough \\\\ light nodes to ensure reconstruction\\end{tabular} &\n  \\begin{tabular}[c]{@{}l@{}}Deterministic secure: specific protocol \\\\ to guarantee reconstruction\\end{tabular} \\\\ \\hline\n\\end{tabular}%\n\n\\end{table}\n\n\\paragraph{Erasure Coding}\nTo design a scalable oracle, we introduce the use of erasure coding. The dispersal protocol can not tolerate even one malicious node hiding one data chunk of the block, but by adding redundancy to the block through appropriate erasure codes\\cite{lin2001error}, any $1-\\alpha$ fraction of the data chunks are enough to reconstruct the entire block, where $\\alpha$ is undecodable ratio determined by a pair of erasure code and decoding algorithm, which is the least fraction of data adversary needs to hide to make the block undecodable.  \n\nFor example, an $(n,k)$ Reed-Solomon (1D-RS) code\\cite{reed1960polynomial} evenly partitions a block $B$ of $b$ bytes into $k$ data symbols of $b/k$ bytes each as $B=[m_1,\\cdots,m_k]$, and linearly combines them to generate a coded block with $n$ coded symbols, $C = [c_1, \\dots, c_n]$. If the undecodable ratio $\\alpha = 1/3$, and there are $n$ oracle nodes and each of them is assigned with one coded symbol to store, then any subset of $2/3$ coded symbols in $C$ is enough to reconstruct the entire coded block.\n\n\\paragraph{Coding integrity and correctness} Intuitively, one can use a Merkle tree to provide proof of inclusion for any coded symbol. But a malicious block producer can construct a Merkle tree of a bunch of nonsense symbols so that no one can successfully reconstruct the block; this is the so-called {\\em incorrect-coding} attack. An approach to detect such attacks is via an {\\em incorrect-coding proof} (also called ``fraud proof\"), which contains symbols that fail the parity check and can be provided by any node who tries to reconstruct the data.  The size of the proof determines the efficiency of the fraud proof method. We find that the fraud proof of 1D-RS contains $k$ coded symbols, essentially not much better than downloading the original block ($n$ symbols). To reduce the size of the fraud proof, 2D-RS \\cite{al2018fraud} places a block into a $(\\sqrt{k}, \\sqrt{k})$ matrix and apply $(\\sqrt{n},\\sqrt{k})$ Reed-Solomon code on all columns and rows to generate $n^2$ coded symbols; 2D-RS reduces the fraud proof size to $O(\\sqrt{b}\\log b)$ if we assume symbol size is constant. Further, a cryptographic hash accumulator called Coded Merkle Tree (CMT) \\cite{yu2020coded} is proposed and reduces the proof size to $O(\\log b)$. However, note that CMT is designed for light nodes to randomly sample coded symbols for data availability check, it provides probabilistic security and thus can not solve the oracle problem for side blockchains.\n\n\\subsection*{ACeD}  \\href{https://arxiv.org/abs/2011.00102}{Authenticated Coded Dispersal} (ACeD) is a recent work that proposes a scalable solution to the data availability oracle problem. The performance comparison between ACeD and other solutions is in Table~\\ref{tab:comparison}. There are four core components in ACeD, as depicted in Figure~\\ref{fig:ACeD}. \n     \\begin{itemize}\n         \\item A coded commitment generator called {\\em Coded Interleaving Tree}  (CIT), which is constructed layer by layer in an interleaved manner embedded with erasure codes. The interleaving property avoids downloading extra proof and thus minimizes the number of symbols needed to store. \n         \\item A pair of dispersal and retrieval protocol are designed to disperse tree chunks among the network with the least redundancy and ensure the retrievability of all data. \n         \\item A hash-aware peeling decoder is used to achieve linear decoding complexity. The fraud proof is minimized to a single parity equation.\n     \\end{itemize}\n\n\n\\begin{table}[]\n\\centering\n\\caption{Performance metrics for different data availability oracles ($N$: number of oracle nodes, $b$: block size).}\n\\begin{threeparttable}\n\\resizebox{\\textwidth}{!}{\n\\begin{tabular}{|l|l|c|c|c|c|c|}\n\\hline\n\\multirow{3}{*}{}    & maximal   & \\multicolumn{2}{c|}{normal case}                              & \\multicolumn{2}{c|}{worst case}                               & \\multirow{3}{*}{\\begin{tabular}[c]{@{}c@{}}communication \\\\ complexity\\end{tabular}} \\\\ \\cline{3-6}\n                     & adversary & storage                       & download                      & storage                       & download                      &                                                                                      \\\\\n                     & fraction  & \\multicolumn{1}{l|}{overhead} & \\multicolumn{1}{l|}{overhead} & \\multicolumn{1}{l|}{overhead} & \\multicolumn{1}{l|}{overhead} &                                                                                      \\\\ \\hline\nuncoded (repetition) & 1/2       & $O(N)$                        & $O(1)$                        & $O(N)$                        & $O(1)$                        & $O(Nb)$                                                                              \\\\ \\hline\nuncoded (dispersal)  & 1/N       & $O(1)$                        & $O(1)$                        & $O(1)$                        & $O(1)$                        & $O(b)$                                                                               \\\\ \\hline\n1D-RS                & 1/2       & $O(1)$                        & $O(1)$                        & $O(b)$                        & $O(b)$                        & $O(b)$                                                                               \\\\ \\hline\n2D-RS \\cite{al2018fraud}                & 1/2       &     $O(1)$                    &     $O(1)$                      &          $O(\\sqrt{b}\\log b)$      &          $O(\\sqrt{b}\\log b)$                 &      $O(b)$                                                                        \\\\ \\hline\nACeD                 & 1/2       & $O(1)$                        & $O(1)$                        & $O(\\log b)$                   & $O(\\log b)$                   & $O(b)$                                                                          \\\\ \\hline\n\\end{tabular}}\n\n\\end{threeparttable}\n\n\\label{tab:comparison}\n\\end{table}\n%why download efficient for ACeD be log n? I thought it is only a constant fraction of block like gamma b .\n\\begin{table}\n\\centering\n\\caption{System Performance Metrics}\n\\label{tab:metrics}\n\\renewcommand{\\tabularxcolumn}{m} \n\\resizebox{\\textwidth}{!}{\n\\begin{tabularx}{\\textwidth}{|c|c|>{\\raggedright}X|}\n\\hline\n\\textbf{Metric} & \\textbf{Formula}&\\textbf{Explanation} \\tabularnewline\n\\hline\nMaximal adversary fraction & $\\beta$ & The maximum number of adversaries is $\\beta N$.\n\\tabularnewline\n\\hline\nStorage overhead & $D_{\\text{store}} / D_{\\text{info}}$& The ratio of total storage used and total information stored.\n \\tabularnewline\n\\hline\nDownload overhead & $D_{\\text{download}}/D_{\\text{data}}$ & The ratio of the size of downloaded data and the size of reconstructed data.\n\\tabularnewline\n\\hline\nCommunication complexity &$D_{\\text{msg}} $ &Total number of bits communicated.\n\\tabularnewline\n\\hline\n\\end{tabularx}}\n\\end{table}\n\n\n\n\\paragraph{Coded Interleaving Tree} CIT is as efficient as CMT on the fraud proof size due to the similar tree structure, but with an entirely different set of construction rules. Specifically, CMT uses a {\\em pull model} to randomly sample symbols via an anonymous network, thus is applicable only to light nodes. In contrast, CIT is designed to support a secure deterministic dispersal with a {\\em push model}, there is no anonymity assumption, and  is designed to be incentive compatible.\n\nThe construction rules of CIT are best seen in stages.  \nCIT takes a block proposed by a client as an input and creates three outputs: a commitment, a sequence of coded symbols, and their proof of membership $\\mathsf{POM}$. The commitment is the root of CIT, the coded symbols are the leaves of CIT in the base layer, and \\POM for a symbol includes the Merkle proof (all siblings' hashes from each layer) and a set of parity symbols from all intermediate layers. \n\nThe construction process of an example CIT is illustrated in figure \\ref{fig:tree}. Suppose a block has size $b$ bytes, and its CIT has $\\ell$ layers. The first step to construct the CIT is to divide the block evenly into small chunks, each is called a data symbol. The size of a data symbol is denoted as $c$, so there are $s_{\\ell} = b/c$ data symbols. And we apply erasure codes with coding ratio $r \\le 1$ to generate $m_{\\ell} =s_\\ell/r$  coded symbols in the base layer. Then by aggregating the hashes of every $q$ coded symbols we get $m_{\\ell}/q$ data symbols for its parent layer (layer $\\ell-1$), which can be further encoded to $m_{\\ell-1} = m_\\ell/(qr)$ coded symbols. We aggregate and code the symbols iteratively until the number of symbols in a layer decays to $t$, which is the size of the root.\n\n\n\\begin{figure}[hbt]\n    \\centering\n    \\includegraphics[width=0.85\\textwidth]{CIT.png}\n    \\caption{(1) CIT construction process of a block with $s_{\\ell} = 8$ data symbols, applied with erasure codes of coding ratio $r = \\frac{1}{4}$. The batch size $q = 8$ and the number of hashes in root is $t=4$. (2) Circled symbols constitute the 15th base layer coded symbol and its $\\mathsf{POM}$. The solidly circled symbols are the base layer coded symbol and its Merkle proof (intermediate data symbols), the symbols circled in dash are parity symbols sampled deterministically.}\n    \\label{fig:tree}\n\\end{figure}\n\nFor all layers $j$ except for root, $1\\le j \\le \\ell$, denote the set of all $m_j$ coded symbols as $M_j$, which contains two disjoint subsets of symbols: data symbols $S_j$ and parity symbols $P_j$. The number of data symbols is $s_j = r m_j$. Specifically, we set $S_j = [0, rm_j)$ and $P_j=[rm_j, m_j)$. Given a block of $s_{\\ell}$ data symbols in the base layer, the aggregation rule for the $k$-th data symbol in layer $j-1$ is defined as follows:\n\\begin{equation}\n  Q_{j-1}[k] = \\{ \\h(M_{j}[x])\\ |\\ x \\in [0,M_{j}), k = x \\bmod rm_{j-1} \\} \n\\end{equation}\n\\begin{equation}\nM_{j-1}[k] = \\h(\\mathsf{concat}(Q_{j-1}[k]))\n\\end{equation}\nwhere $1\\le j \\le \\ell$ and $\\h$ is a hash function. $Q[k]$ is the tuple of hashes that will be used to generate $k$-th symbol in the parent layer and \\textsf{concat} represents the string concatenation function which will concatenate all elements in an input tuple.\n\nGenerating a \\POM for a base layer symbol can be considered as a layer by layer sampling process as captured by the following functions:\n\\begin{equation*}\n\tf_{\\ell}: [m_{\\ell}] \\to {m_{\\ell-1} \\choose 2}, \\cdots,  f_{2}: [m_{\\ell}] \\to {m_{1} \\choose 2};\n\\end{equation*}\nEach function maps a base layer symbol to two symbols of the specified layer: one is a systematic symbol and the other is a parity symbol. \nWe denote the two symbols with a tuple of functions $f_j(i) = (p_j(i), e_j(i))$, where $p_j(i)$ is the sampled systematic symbol and $e_j(i)$ is the sampled parity symbol, each is defined as follows:\n\n\\begin{equation}\n\\label{eq:pe}\n    p_{j}(i) = i \\bmod rm_{j-1}  ; \\;\\; e_{j}(i) = rm_{j-1}  + (i \\bmod (1-r) m_{j-1})\n\\end{equation}\nwhere $p_{j}: [m_{\\ell}] \\to [0, rm_{j-1})$ and $e_{j}: [m_{\\ell}] \\to [rm_{j-1}, m_{j-1})$. Note that the sampled non-base layer systematic symbols are automatically the Merkle proof for both systematic and parity symbols in the lower layer.\n\nThere are two important properties of CIT. (1) It guarantees that if at least $\\eta\\le 1$ ratio of distinct base layer symbols along with their \\POM are sampled, then in every intermediate layer, at least $\\eta$ ratio of distinct symbols are already picked out by the collected $\\mathsf{POM}$. It ensures the reconstruction of each layer of CIT. % (Lemma~\\ref{lm:recon}, {\\em reconstruction} property). \n(2) All sampled symbols at each layer have a common parent, %(Lemma~\\ref{lm:sibl}, {\\em sibling} property), \nwhich ensures the space efficiency of sampling.\n\n%\\begin{lemma} \n%\\label{lm:recon}\n%(Reconstruction) For any subset of base layer symbols $W_\\ell$, denote $W_j := \\bigcup_{i\\in W_\\ell}f_j(i)$ as the set of symbols contained in \\POM of all symbols in $W_\\ell$. If $|W_\\ell|\\ge \\eta m_\\ell$, then $\\forall j\\in[1,\\ell]$, $|W_j|\\ge \\eta m_j$.\n%\\end{lemma}\n\n\n%\\begin{lemma}\n%\\label{lm:sibl}\n%For any functions  $p_j(i)$ and $e_j(i)$ defined in equation \\ref{eq:pe}, where $1\\le j\\le \\ell$, $0\\le i< m_{\\ell}$, $p_j(i)$ and $e_j(i)$ are siblings.\n%\\end{lemma}\n\n%%\\section*{Summary}\n%This lecture we discuss external scaling methods, including payment channels and side blockchains. They are both layer 2 scaling -- built directly on top of an existing blockchain infrastructure as layer 1 to improve the performance. Payment channel has high throughput, low latency and cost. But it requires nodes to stay online, and its computations are closely tied to the original blockchain. Side blockchain utilizes some smaller independent blockchains to store data and execute computation, but is vulnerable to data availability attack. We further introduce an data availability oracle layer to solve the problem and demonstrate a scalable solution ACeD run by a group of permissioned nodes to provide an interoperability service across blockchains.\n\n\n\\bibliographystyle{plain}\n\\bibliography{bibfile}\n\n\\end{document}",
    "lecture_20.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\usepackage{markdown}\n\\usepackage{amsthm}\n\\usepackage{listings}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\newcommand{\\indicator}{{\\bf 1}}\n\\newcommand{\\pramod}[1]{{\\color{red}\n\\footnotesize[Pramod: #1] }}\n\\newcommand{\\xw}[1]{{\\color{green}\n\\footnotesize[Xuechao: #1] }}\n\\newcommand{\\surya}[1]{{\\color{magenta}\n\\footnotesize[Surya: #1] }}\n%\\theoremstyle{definition}\n\\newtheorem{definition}{Definition}\n\\newtheorem{theorem}{Theorem}\n\\newtheorem{lemma}{Lemma}\n%\\let\\proof\\relax\n%\\let\\endproof\\relax \n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 20}\n\\cfoot{\\thepage}\n\n\\title{Lecture 20: Blockchain Computer of Ethereum}\n\\author{Principles of Blockchains, University of Illinois,  \\\\ Professor:  Pramod Viswanath \\\\ Scribe: Yichi Zhang, Suryanarayana Sankagiri}\n\\date{April 6, 2021}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nThe Ethereum Virtual Machine (EVM) is the global virtual computer whose state every participant on the Ethereum network stores and agrees on. Any participant can request the execution of arbitrary code on the EVM; code execution changes the state of the EVM. The Ethereum Virtual Machine is the runtime environment for smart contracts in Ethereum. Ethereum's state is a large data structure which holds not only all accounts and balances, but a machine state, which can change from block to block according to a pre-defined set of rules, and which can execute arbitrary machine code. The specific rules of changing state from block to block are defined by the EVM.\n\\end{abstract}\n\n%\\section*{Smart Contracts}\n\n\\section*{Blockchain as a Decentralized Computer}\nIn this course so far, we have studied many blockchain consensus protocols, such as the longest-chain protocol, Prism, Streamlet and Hotstuff. Such protocols allow mutually distrustful parties to agree on an ordered list of transactions. The canonical use-case of such a protocol is to implement a currency system. In such a system, the transactions merely record the transfer of money from one account (or public-key) to another. However, a blockchain protocol can be used as the basis of a much more powerful abstraction: a decentralized computer. The Ethereum blockchain implements such an abstraction; this system is called an Ethereum Virtual Machine or EVM.\n\nTo understand blockchains as a virtual computer, we must generalize certain notions pertaining to blockchains. Firstly, we broaden out understanding of the \\textit{state} of a blockchain. In a currency system, the state is simply a record of the money held in each account at any point in time. In the case of EVM, the state can be thought of as the information that is stored on a computer. At a high level, the state is a database that contains some useful data in some specific form, and also contains a list of executable programs. As we shall see, in EVM, the account data is a subset of all recorded data. As before, all nodes in the network store a local copy of the state. The longest-chain protocol is a consensus mechanism that ensures that all nodes have a consistent state.\n\nNext, we view each transaction as a request to make a change in the blockchain state. Transactions that we saw earlier, i.e., one that records a transfer of currency, is simply a special case of such a transaction. Such a transaction reduces the account balance of the sender and raises the balance of the recipient. However, transactions could have more complex instructions, such as: ``transfer $10 \\text{ETH}$ from account $A$ to $B$ if account $B$ has less than $10 \\text{ETH}$; else, transfer $10 \\text{ETH}$ to account $C$\". Generalizing further, a transaction is an instruction (i.e., a request) to perform some computation on the current state of the blockchain and return a new state. Figure \\ref{fig:blockchain_computer} illustrates this concept. \n\n\\begin{figure}[htbp]\n    \\centering\n    \\includegraphics[width = 0.8\\textwidth]{figures/blockchain_computer.png}\n    \\caption{Transactions change the world state, i.e., the state of the blockchain global computer}\n    \\label{fig:blockchain_computer}\n\\end{figure}\n\nJust as in Bitcoin, any participant can broadcast a transaction, i.e., a request for the EVM to perform some arbitrary computation. Upon seeing such a transaction, a miner executes the computation and checks that it leads to a valid state transition (e.g., it doesn't lead to any account balance going negative). It then includes the transaction in its new block. Upon receiving a newly mined block, all nodes validate the block by performing all the computations again,  and verifying that the new state is indeed as is recorded in the block. A transaction request must be accompanied by some fee, i.e., some amount of Ether, to incentivize miners to perform the computation. Typically, these fees are proportional to the duration of the computation.\n\nTo summarize,\n\\begin{quote}\n    The Ethereum Virtual Machine is the global virtual computer whose state every participant on the Ethereum network stores and agrees on. Any participant can request the execution of arbitrary code on the EVM; code execution changes the state of the EVM.\n\\end{quote}\n\n\\section*{Smart Contracts}\nIn practice, different participants may want to perform very similar computations at different points in time. It is not practical for them to write new code every time they want to request a computation on the EVM. A better model, which is adopted by EVM, is to allow application developers to upload programs (reusable snippets of code) into the EVM storage, which can then be referred to by a transaction. We call the programs uploaded to and executed by the network \\textit{smart contracts}. Typically, a smart contract will have some internal state variables, in addition to holding some piece of code. \n\nOne example of a smart contract could be a token-exchange smart contract; it takes as input a certain amount of Ether and issues out a new token, or vice-versa. In this case, a user would call the smart contract with the amount of Ether it wants to exchange for the token, and possibly the highest exchange-rate it is willing to tolerate. The state would record the current exchange-rate for the token, which would be a function of its past demand/supply. It could also store the maximum amount available of the new token, so that it does not issue a token if it is not available. More generally, a smart contract deals in the transfer of digital assets.\n\nAny developer can create a smart contract and make it public to the network, using the blockchain as its data layer, for a fee paid to the network. Any user can then call the smart contract to execute its code, again for a fee paid to the network. A smart contract can invoke other smart contracts as part of its code. Thus, developers can build arbitrarily complex decentralized apps and services: marketplaces, financial instruments, games, etc.\n\n\\section*{Basic terms for EVM}\nLet us now understand some of the building blocks of the EVM in more detail. \n\n\\subsection*{Accounts}\nIn Ethereum, there are two types of accounts:\n\\begin{itemize}\n    \\item \\textbf{Externally Owned Accounts.} These accounts are like bank accounts. They hold some amount of currency, and one can pay or receive currency from this account.\n    \\item \\textbf{Contract Accounts.} In addition to being able to store, send and receive currency, these accounts store some piece of code. Transactions made to this account trigger this code.\n\\end{itemize}\nLet us elaborate on accounts some more. Externally Owned Accounts are easy to understand, as they arise naturally in a currency exchange system. If we think of Ethereum as solely a currency system, then we would have only Externally Owned Accounts. Each such account stores two fields:\n\\begin{itemize}\n    \\item \\textbf{Amount:} The total amount of currency stored in this account\n    \\item \\textbf{Nonce:} This is a count of number of transactions sent by this address.\n\\end{itemize}\nThe nonce of an account is incremented by one every time a new transaction is created by this account (i.e., every time money is spent from this account). Basically, the nonce prevents transactions from being executed multiple times. The role of a nonce becomes clear once we discuss transactions in the following section.\n\nWe now discuss contract accounts. In Ethereum, contract accounts are the means of storing and referencing smart contracts. We have already seen that smart contracts are pieces of code that any user can access, verify, and call via a transaction. In Ethereum, the following design choice was made: each smart contract is stored as a contract account. Such an account stores the contracts code (which is immutable), as well as some data that may be needed to execute the code. For example, if the smart contract issues new tokens in exchange for Ether, the data could store the current exchange rate, and/or the total number of tokens remaining. In essence, the account data contains some state information needed for this particular contract itself. The code itself is written as a list of functions.\n\nLet us now put together externally owned accounts and contract accounts in the same framework, as is indeed done in Ethereum. For each account, the pertinent account information is summarized in the form of an \\textit{account state}. Every account state has the following four fields:\n\\begin{itemize}\n    \\item Nonce: In an externally owned account, this denotes the number of transactions created by this account. In a contract account, it denotes the number of contracts created by this account.\n    \\item Balance: The amount of Ether owned by this account, in Wei, a denomination of Ether. There are $10^{18}$ Wei per Ether.\n    \\item Storage Root: The data for the smart contract is stored as a Merkle tree. The storage root is simply the root node of the Merkle tree, and is a compact representation of the whole data. In externally owned accounts (and contracts with no storage), this field is empty.\n    \\item Code Hash: The hash of the code of the smart contract. The code is written in Solidity, a high-level programming language. It is written as a set of routines (or functions). This part of the account state is immutable. In externally owned contracts, this field is the hash of the empty string.\n\\end{itemize}\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width = \\textwidth]{figures/Account State.pdf}\n    \\caption{A summary of an account state}\n    \\label{fig:account_state}\n\\end{figure}\nFigure \\ref{fig:account_state} stores the  \nThe set of all accounts and account states are collated together in the form of a huge Merkle trie. This set of information is called the \\textit{world state}. Every transaction makes a change in the world state. This is what is illustrated in Figure \\ref{fig:blockchain_computer}.\n\n\\subsection*{Transaction}\nA transaction is a single cryptographically-signed instruction. A transaction is submitted by an external actor and its external owned account (EOA). There are two practical types of transaction, contract creation and message call.\nTransactions follow the atomicity. This means that the transaction cannot be divided or interrupted. Either all parts in transactions are done or nothing would be done. Transactions cannot be overlapped and must be executed sequentially. Transaction order is not guaranteed and the miner can determine the order of the transaction in a block. The order between blockers is determined by a consensus algorithm such as PoW. A submitted transaction includes the following information:\n\\begin{itemize}\n  \\item recipient: The receiving address (if an externally-owned account, the transaction will transfer value. If a contract account, the transaction will execute the contract code).\n  \\item signature: The identifier of the sender. This is generated when the sender's private key signs the transaction and confirms the sender has authorised this transaction. \n  \\item value: The amount of ETH to transfer from sender to recipient (in WEI, a denomination of ETH).\n  \\item data: Optional field to include arbitrary data.\n  \\item gasLimit: The maximum amount of gas units that can be consumed by the transaction. Units of gas represent computational steps.\n  \\item gasPrice: The fee the sender pays per unit of gas.\n\\end{itemize}\nHere is an example of a transaction object:\n\\begin{lstlisting}\n{\n    from: \"0xEA674fdDe714fd979de3EdF0F56AA9716B898ec8\",\n    to: \"0xac03bb73b6a9e108530aff4df5077c2b3d481e5a\",\n    gasLimit: \"21000\",\n    gasPrice: \"200\",\n    nonce: \"0\",\n    value: \"10000000000\",\n}\n\\end{lstlisting}\n\n\n\\section*{Order-Execute Structure}\nGeneral structure of the blockchain contains the following three phases:\n\\begin{enumerate}\n    \\item Order\n    \\item Execute\n    \\item Update state\n\\end{enumerate}\nThe Order phase is a consensus protocol for example the longest chain protocol, which we have already discussed in the previous lectures. In this lecture, we will mainly focus on the Execute phase and the Update state phase.\n\\subsection*{Update state}\nState is a persistent storage that is on the disc. In the state of a payment system, the account information includes the following fields:\n\\begin{itemize}\n  \\item Address: Address of an account. This is used for identification.\n  \\item Account-nonce: An integer that indicates the number of transactions this account has executed.\n  \\item Balance: An integer represents how many tokens this account has.\n\\end{itemize}\nIn the smart contract system like Ethereum, there are two additional fields that are needed:\n\\begin{itemize}\n  \\item Code: A sequence of OPCODEs\n  \\item Account storage: A key-value pair storage. Key is 256-bit and the value is also 256-bit. \n\\end{itemize}\n\n\n\\subsection*{Execute}\nThere are two types of codes that could involve in the EVM. First is called EVM OPCODE, which is a low level stack-based language that is similar to the machine code or assembly code. Second is called Solidity, which is a high level code that is similar to C++, Java and other object-oriented programming language. Usually people write contracts in Solidity and the compiler will compile the high level programming language into OPCODE for the machine to execute.\n\n\\subsubsection*{OPCODE}\nOPCODE is identified by a byte (8 bits from 0X00 to 0XFF)\\footnote{Full OPCODE see https://github.com/crytic/evm-opcodes}. As we mention before, OPCODE is a stack-based language and EVM will keep a first-in-last-out (FILO) stack during the execution. Each item in stack consists of 256 bits and the maximum capacity of the stack is 1024 bits. OPCODE will insert/remove items into/from the stack. This stack is a volatile data structure and the contents will be removed after the execution. Here is a detailed OPCODE instruction figure.\n\\begin{center}\n    \\includegraphics[width=\\textwidth]{figures/OPCODE3.png}\n\\end{center}\nFrom the figure we can find that the OPCODE is divided into 11 parts and each part has different usage. Different starting hexadecimal value of the OPCODE represent different functionalities. For example, all OPCODE starting with 0 (i.e. 00, 01, 02, ..., 0B) are used to perform the arithmetic operations and all OPCODE starting with 1 (i.e. 10, 11, ..., 1D) are used to perform the comparison and bitwise logic operations.\n\n\\subsubsection*{Stack and Memory}\nAnother important part in EVM is memory which is also a data structure for execution. Memory consists of an array of bytes and is addressed by an unsigned 256 integer. Each item in the memory is only one byte. The OPCODE can read and write the memory. Like the stack in EVM, memory is also a volatile data structure and will be deleted after the execution.\n\n\\subsubsection*{Storage}\nUnlike stack and memory, storage is key-value stuctured persistent database that is maintained in a hash accumulator. Keys and values in storage are both 32 bytes long. The OPCODE can read and write the storage. The storage will not be created before the exection and will not be removed after the execution.\n\n\\subsection*{Execute OPCODE example}\n\\subsubsection*{Stack example}\nHere is a simple example that illustrate how we could use the memory to perform an addition in EVM stack.\n\\begin{center}\n    \\includegraphics[width=\\textwidth]{figures/Memory-lecture20.png}\n\\end{center}\nFirst, the memory is empty and we first use PUSH1 (OPCODE = 0x60) operation to place a one byte item (number 1) onto the stack. Then we do another PUSH1 operation to place another one byte item (numerb 2) on to the stack. At last, we perform an ADD (OPCODE = 0x01) to add those two numbers and get the result 3.\n\\subsubsection*{Memory example}\nHere is an example OPCODE sequence.\n\\begin{lstlisting}\nPUSH1 0x01\nPUSH1 0x02\nADD\nPUSH1 0x00\nMSTORE\nPUSH1 0x20\nPUSH1 0x00\nRETURN\n\\end{lstlisting}\nIn this example, the program will first push two numbers onto the stack and then perform an addition. It then pushes another number 0x00 onto the stack. Now the program will perform a MSTORE (OPCODE = 0x52) operation, which will save the word from stack to the memory starting from address 0x00. At last, the program pushes another two numbers (0x20 and 0x00) to the stack and perform the RETURN (OPCODE = 0xF3) operation which will halt the program and return the value in memory from address 0x00 to address 0x20.\n\n\n\\section*{Contract}\nContract is a special type of account and therefore every contract should have five fields just like normal user account. Here is the way that user can create a contract and execute specific functionality within a contract.\n\\subsection*{Creation of a contract}\nWe can create a contract by a transaction. To create a contract, we need to provide the initialization OPCODE. Usually, this is done by the compiler and the programmer only need to give the instructions in Solidity. Here is the initialization for a contract:\n\\begin{itemize}\n  \\item Address: Hash of the information code.\n  \\item Account-nonce: Initialize to 0.\n  \\item Balance: Initialize to 0.\n  \\item Code: OPCODE.\n  \\item Account storage: Empty.\n\\end{itemize}\n\n\\subsection*{Execution a contract}\nAfter a contract is created, it is public and visible on the blockchain. This means that all users in the Ethereum ecosystem can call and execute the contract if they know the address of the contract. To call the contract, the user needs to provide the following three information in the transaction:\n\\begin{itemize}\n  \\item Contract address.\n  \\item Call data.\n  \\item Gas fee.\n\\end{itemize}\nCall data is the hash of the function name that the user wants to call. Since one smart contract may contain more than one functions, user needs to provide the hash value of the specific function he wants to execute.\n\n\\subsection*{Example of a smart contract}\n\\subsubsection*{Create a smart contract}\nHere is an example of a simple smart contract. In this contract named \\texttt{Nothing}, there is a function that actually does nothing. To create this smart contract, we need to first write out the Solidity code.\n\\begin{lstlisting}\npragma solidity ^0.6.3;\ncontract Nothing {\n    function nothing() public {\n    }\n}\n\\end{lstlisting}\nThe Solidity compiler will then compile the Solidity code and it will give the OPCODE as following.\n\\begin{center}\n    \\includegraphics[width=6cm]{figures/OPCODE.png}\n    \\hspace{1cm}\n    \\includegraphics[width=6cm]{figures/OPCODE2.png}\n\\end{center}\nNotice that the OPCODE on the left is the same as the code on the right. However, the OPCODE on the left is the raw code translated from the compiler and the gray part of the code on the right is the function that we have in the contract. Everything before the gray part is the instruction code that tells the system to store the code into the contract.\n\\subsubsection*{Execute a smart contract}\nTo execute a smart contract, we need to know the address of the smart contract that we want to execute. After knowing the address, we also need to know the hash value of the specific function name and this is the call data. In the \\texttt{Nothing} smart contract example, the call data = \\texttt{0x448f30a3}. In the OPCODE, the contract will check the call data by command \\texttt{CALLDATALOAD  PUSH4 0x448f30a3 EQ}. In this command, CALLDATALOAD (OPCODE = 0x35) will get input data of the current environment and check if the call data matches the sequence \\texttt{0x448f30a3} using the EQ (OPCODE = 0x14) operation. If everything matches, the smart contract can execute the OPCODE of the function \\texttt{nothing}.\n\n\\section*{Gas}\nGas is designed to prevent someone writing or running into an infinite loop by mistake. It is a generalization of transaction fee. Every execution of OPCODE will produce some amount of gas. There are three concepts related to gas in EVM:\n\\begin{itemize}\n  \\item Gas Capacity: This is the maximum gas this transaction could use.\n  \\item Gas Usage: This is the gas that is incurred when OPCODEs and other operations execute. Gas usage has the following three properties:\n  \\begin{itemize}\n  \\item Memory fee increases quadratically with usage.\n  \\item Storage fee is much heavier than memory fee.\n  \\item Base fee that every transaction pays.\n  \\end{itemize}\n  If the gas usage exceeds the gas capacity, the execution aborts and nothing will be processed.\n  \\item Gas Price: This is the price for the gas. This is set by the caller of the contract or the sender of the payment. The actual fee equals to the product of the gas usage and the gas price.\n\\end{itemize}\nAs the device evolves, the gas fee rules are not a perfect measurement for the cost of running the contracts and the gas fee has changed many times in the history.\n\n\\section*{Payment}\nThere are two types of accounts in the EVM. One is user and the other is contract.\n\\begin{center}\n\\begin{tabular}{| c | c | c |}\n\\hline\n  & User & Contract \\\\ \n  \\hline\n Address & Hash of the public key & Hash of creators address and code \\\\ \n \\hline\n Account-nonce & Number of executed transactions & 0 all the time   \\\\\n \\hline\n Balance & User account balance & 0 all the time   \\\\\n \\hline\n Code & Empty all the time & OPCODE   \\\\\n \\hline\n Account storage & Empty all the time & READ/WRITE from code   \\\\\n \\hline\n\\end{tabular}\n\\end{center}\nThere are two types of transactions that could happen in EVM. One is the pay to the user and the second is the call of a contract.\n\\begin{center}\n\\begin{tabular}{| c | c | c |}\n\\hline\n  & Pay to User & Call a Contract \\\\ \n  \\hline\n Receiver & User & Contract \\\\ \n \\hline\n Value & Transaction value & 0    \\\\\n \\hline\n Gas Capacity & Set by sender & Set by sender   \\\\\n \\hline\n Gas Price & Set by sender & Set by sender   \\\\\n \\hline\n Call Data & Empty & Set by sender   \\\\\n \\hline\n\\end{tabular}\n\\end{center}\n\n\\end{document}\n",
    "lecture_07.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\usepackage{markdown}\n\\usepackage{amsthm}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\newcommand{\\pramod}[1]{{\\color{red}\n\\footnotesize[Pramod: #1] }}\n\\newcommand{\\xw}[1]{{\\color{green}\n\\footnotesize[Xuechao: #1] }}\n%\\theoremstyle{definition}\n\\newtheorem{definition}{Definition}\n\\newtheorem{theorem}{Theorem}\n\\newtheorem{lemma}{Lemma}\n%\\let\\proof\\relax\n%\\let\\endproof\\relax \n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 7}\n\\cfoot{\\thepage}\n\n\\title{Lecture 7:   Liveness of Bitcoin}\n\\author{Principles of Blockchains, Princeton University,  \\\\ Professor:  Pramod Viswanath \\\\ Scribe:  Xuechao Wang}\n%\\date{February 16, 2021}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nIn the previous lecture we have considered {\\em safety} of a block: the event that once a block is deemed to be confirmed (because it is buried deep enough in the longest chain), then the probability it will be deconfirmed is small. While safety is a very important security property of a blockchain protocol, an equally important is {\\em liveness}: this is the event that (honest) transactions get included into blocks, and further that the blocks feature in the longest chain. Liveness ensures that all transactions make their way into the ledger and safety ensures that eventually the transactions stay permanently in the ledger (with high probability). Together liveness and safety ensure the {\\em security} of the blockchain protocol. The focus of this lecture is the liveness of the longest chain protocol. We will see that the longest chain protocol is live exactly under the conditions that the protocol is safe (derived in the previous lecture). We quantify the ``level\" of liveness and make connections to how fairly the incentives are distributed among the honest and adversarial miners. As part of this study, we  identify  worst-case adversarial strategies that minimize liveness  and fairness (in incentive distribution). Finally we study a simple, but powerful, modification to the longest chain protocol that yields optimal liveness and fairness properties. \n\\end{abstract}\n\n\\section*{Chain Quality}\n\nWe begin with two properties of a longest chain in the blocktree that will help us quantify the level of liveness of the protocol.  \n\n\\begin{definition}[Chain Growth]\nFor a blockchain protocol, we define the chain growth of a longest chain $\\mathcal{C}$ as the average growth rate of  $\\mathcal{C}$ (number of blocks per unit time), denoted as ${\\rm CG}(\\mathcal{C})$.\n\\end{definition}\n\n\n\\begin{definition}[Chain Quality]\nFor a blockchain protocol, we define the chain quality of a longest chain $\\mathcal{C}$ as the fraction of honest blocks in $\\mathcal{C}$, denoted as ${\\rm CQ}(\\mathcal{C})$.\n\\end{definition}\n\nPositive chain growth ensures that the chain keeps growing and new blocks are continuously added to the longest chain. Due to the random nature of the mining operation, an honest miner will have a non-zero chance to succeed in mining a block. Thus CG is  positive as long as the honest mining power $(1-\\beta) > 0$. However, this is not enough to guarantee  liveness: this is because a block mined by an adversary   may fail to include honest transactions (or even be empty) and the entire longest chain may be made up of such adversarial blocks. However, positive chain quality ensures that a positive fraction of blocks mined by honest nodes enter the longest chain. Thus positive chain growth and positive chain quality together combine to  ensure that any honest transaction will eventually be added to a block on the longest chain and to the ledger, which gives us  liveness. \n\nNow that liveness is guaranteed, one can study a more fine grained property of {\\em fast time scale liveness}: having enough blocks mined by honest nodes on the longest chain (i.e., high CQ) ensures that transactions enter the blockchain at a fast clip -- thus CQ helps quantify the level of liveness. Furthermore, CQ quantifies  {\\em fairness}:  since block rewards are provided to blocks in the longest chain, having blocks mined by honest nodes in the longest chain ensures that honest miners are rewarded. Next we will derive lower-bounds on chain growth and chain quality as a function of  adversarial fraction of hash power $\\beta$, total mining rate $\\lambda$ and maximum network delay $\\Delta$.\n\nWe first derive the lower bound on the chain growth. As we have seen in Lecture 6, under the limit of a very large number of honest miners (each with infinitesimally small mining power), the growth rate of a pure honest chain is $\\frac{(1-\\beta)\\lambda}{1+(1-\\beta)\\lambda\\Delta}$ when the network delays for all messages are exactly $\\Delta$. One can see that the adversary really cannot do anything better than this. Delivering an honest block earlier than $\\Delta$ time or publishing any adversarial block will just increase the chain growth. Therefore, we have the bound:\n\\begin{equation}\n\\label{eqn:cg}\n    {\\rm CG} \\geq \\frac{(1-\\beta)\\lambda}{1+(1-\\beta)\\lambda\\Delta}.\n\\end{equation}\n\nNext we derive a lower-bound on the chain quality. If the chain growth is CG and the adversary can mine blocks at a rate of at most $\\beta \\lambda$, by the definition of the chain quality, we have a lower bound:\n\\begin{equation}\n\\label{eqn:cq}\n    {\\rm CQ} \\geq \\frac{{\\rm CG}-\\beta \\lambda}{{\\rm CG}}, \n\\end{equation}\nwhere the equality is achieved when every adversarial block enters the longest chain. Plugging (\\ref{eqn:cg}) into (\\ref{eqn:cq}), we have\n\\begin{equation}\n    {\\rm CQ} \\geq \\frac{\\frac{(1-\\beta)\\lambda}{1+(1-\\beta)\\lambda\\Delta}-\\beta \\lambda}{\\frac{(1-\\beta)\\lambda}{1+(1-\\beta)\\lambda\\Delta}} = \\frac{1-2\\beta - \\beta(1-\\beta)\\lambda\\Delta}{1-\\beta}.\n\\end{equation}\n\nOne can check that ${\\rm CQ > 0}$ if $\\frac{(1-\\beta)}{1+(1-\\beta)\\lambda\\Delta} > \\beta$, which is exactly the same threshold as the safety guarantee as we have seen in Lecture 6. Therefore, we can conclude the following security guarantee on the longest chain protocol.\n\\begin{theorem}\nThe longest chain protocol is safe and live, exactly under the following condition:  $\\frac{(1-\\beta)}{1+(1-\\beta)\\lambda\\Delta} > \\beta$.\n\\end{theorem}\n\nIn Lecture 6, we have seen that the private attack achieves the security threshold. Now a natural question would be: is there a specific adversarial strategy that achieves the minimum chain quality? A ``selfish mining\" attack  described in \\href{https://arxiv.org/abs/1311.0243?source=post_page---------------------------}{this paper}, answers this question and is discussed next. Before that, one can see that to achieve the minimum chain quality, the attack has to guarantee two properties: \n\\begin{itemize}\n    \\item  every adversarial block enters the longest chain; so every adversarial block is useful.\n    \\item every adversarial block displaces an honest block in the longest chain; so every adversarial block is doubly useful. \n\\end{itemize}\n\n\n\\section*{Selfish Mining}\nConsider the following adversarial strategy (see Figure \\ref{fig:selfish}):\n\\begin{itemize}\n    \\item The adversary always mines on the block at the tip of the longest chain, whether the chain is  private or public. Upon successful mining, the adversary maintains  the block in private to  release it at an appropriate time (discussed next). \n    \\item When an honest miner publishes a block the adversary will release a previously mined block at the same level (if it has one). We assume that the adversary can break ties in its favor, so honest miners will mine on the adversarial block.\n\\end{itemize}\n\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width =13cm]{figures/selfish.png}\n    \\caption{Selfish mining example.}\n    \\label{fig:selfish}\n\\end{figure}\n\n\n\n\\section*{Optimal Chain Quality}\n\nIf the adversary decided to follow protocol, then the chain quality of the longest chain protocol would be ${\\rm CQ} = 1- \\beta$; indeed one cannot expect any CQ better than this. A natural question would be: can we improve the design of the longest chain protocol to achieve this optimal chain quality under arbitrary adversarial strategy? Especially interesting would be if this design were only a slight modification of the longest chain protocol.  \\href{https://eprint.iacr.org/2016/916.pdf}{Fruitchains} is one such modification that achieves optimal CQ, and at fast time scales.\n\nIn the longest chain protocol, safety of a block (provided by how many blocks are mined underneath) and  the incentives associated with a block (both the transaction rewards and block rewards, cf.\\ Lecture 5) are {\\em coupled}. The key idea of Fruitchains is to {\\em separate} the two properties -- incentives and safety  -- by embodying them in two separate block structures:\n\\begin{itemize}\n    \\item  a {\\em transaction block}, which contains all the transactions (or {\\sf data}) of the blocks in the longest chain protocol; \n    \\item a {\\em proposer block}, which contains the header of the blocks in the longest chain protocol. \n\\end{itemize}\nIt is  important to cryptographically {\\em couple} the two types of blocks and this is done via \nembedding the hash of each transaction block inside one of the proposer blocks (see Figure~\\ref{fig:fruitchains1}). \nThe two types of blocks are further coupled during the mining process via ``2 for 1 mining\", also known as {\\em cryptographic sortition}. This is described next.\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width =10cm]{figures/prism0.png}\n    \\caption{Comparison between blocks in the longest chain protocol and the transaction and proposer blocks in Fruitchains.}\n    \\label{fig:fruitchains1}\n\\end{figure}\n\n\n\n\n\\subsection*{Cryptographic Sortition}\nIn the mining process, the two types of blocks -- transaction and proposer blocks -- are mined {\\em together}. A miner first forms a ``superblock\", essentially the same as a regular block in the longest chain protocol: the superblock contains two parts, a  transaction block and a  proposer block.   However this is where the similarity ends. We say a superblock is successfully  mined if \n\\begin{equation}\n    Hash({\\sf nonce}, {\\sf superblock}) < T_{\\rm tx} + T_{\\rm prop}. \n\\label{eq:sortition}\n\\end{equation}\nFurther, every successfully mined superblock is identified as either a transaction block or a proposer block based on the hash output: \n\\begin{itemize}\n    \\item \nidentify the superblock as a proposer block if the hash output is less than $T_{\\rm prop}$; \n\\item identify the superblock as a transaction block if the hash output is in the range $[T_{\\rm prop}, T_{\\rm tx} + T_{\\rm prop})$.\n\\end{itemize}\nDue to the random output nature of hash functions, the probability a superblock is identified as a proposer (transaction)  block is proportional to $T_{\\rm prop}$ ($T_{\\rm tx})$, respectively. This process where two distinct types of blocks are mined jointly and only one of the blocks is identified as the output of the mining process is known as ``two-for-one mining\" or ``cryptographic sortition\" (see Figure~\\ref{fig:sortition}). \n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width =10cm]{figures/sortition.png}\n    \\caption{Superblock containing a transaction block and a  proposer block is ``two-for-one\" mined; the resulting  cryptographic sortition identifies either the transaction or proposer block as the winner of the mining process.}\n    \\label{fig:sortition}\n\\end{figure}\n\n\\iffalse\n\\pramod{\n1) explain high level idea of Fruitchains. deconstruction of the blocks' roles. separate transactions (data or fruits/rewards) from the security enabled by the longest chain protocol. This creates two types of blocks. this story is similar to Prism deconstruction story, except voting blocks are not there.\n\n2) then talk about the need to couple the two types of blocks; after all security has to be joint. bring up sortition and 2:1 mining. \n\n3) next bring up  a  prism 1.0 like structure. Point out why it has optimal CQ, under selfish mining attacks. how about the setting of the threshold for 2:1 mining? what impact does that have on optimal CQ under selfish mining? \n\n4) now adversary ma deviate from protocol even in publishing tx blocks. it could mine tx blocks in private and then release it at an opportune time. to avoid this, we do reverse pointer from tx blocks to tip of the longest chain. (parent blocks in your language). Summarize the full Fruitchains protocol. does this impact hash threshold setting? if so how? \n\n5) Give an intuitive argument for the overall security of the fruitchain protocol and optimal CQ. ideally as much  full proof as possible, using the notation and proof results from before.\n}\n\\fi\n\n\\subsection*{Fruitchain Protocol}\n\nWe can put together the cryptographic sortition process to summarize the Fruitchains protocol. Every miner creates a superblock containing a transaction block (consisting of transactions not in the ledger) and a proposer block (which has a hash pointer to the parent proposer block and hash pointers to {\\em all} the transaction blocks that are not referred by its proposer ancestors). The  proposer block mining is conducted using the longest chain rule and transaction blocks have no chaining or constraints.  See Figure \\ref{fig:fruitchains1} for illustration. The success of the superblock mining process is decided by Equation~(\\ref{eq:sortition}) and the actual hash output decides whether to interpret the superblock as a transaction block or a proposer block.  The ledger is an ordered list of transactions and is generated as follows: order the proposer blocks according to the longest chain,  order the transaction blocks referred to by each proposer block (e.g., ordered based on the hash value of the transaction block) and further order   the transactions within a transaction block (e.g., lexicographic ordering of the transactions in the Merkle tree representation). \nWe argue the safety and liveness properties of the fruitchain protocol as follows. \n\n\\noindent {\\bf Safety}. Let $\\lambda_{\\rm tx}$ and $\\lambda_{\\rm prop}$ be the mining rate of the transaction blocks and proposer blocks respectively; these mining rates are directly proportional to the difficulty targets $T_{\\rm tx}$ and $T_{\\rm prop}$, respectively. The safety of this protocol  follows directly from the safety of the longest chain protocol: as long as $\\lambda_{\\rm prop}$ is small enough, i.e., \n$$\\frac{(1-\\beta)}{1+(1-\\beta)\\lambda_{\\rm prop}\\Delta} > \\beta,$$\nthe $k$-deep proposer block in the longest chain will be permanent with high probability (for large enough $k$). This stabilizes the ledger guaranteeing safety. \n\n\\noindent {\\bf Liveness}. The main claim is that the optimal CQ of $1-\\beta$ is achieved  regardless of the adversarial strategy on transaction and proposer block mining. We first examine the selfish mining attack: even if an adversary tries to ``erase'' some proposer blocks mined by an honest party (which contains some honest transaction blocks) by selfish mining, by the liveness (positive CQ and CG) of the the longest chain protocol, eventually an honest party will mine a new proposer block including those transaction blocks that were displaced and with large enough $k$, this proposer block will be safely included in the ledger. We know that the mining of the honest and adversarial transaction blocks follows Poisson process with rate $(1-\\beta)\\lambda_{\\rm tx}$ and $\\beta \\lambda_{\\rm tx}$ respectively. And by the liveness of the the longest chain protocol, every honest transaction blocks will be eventually included into the proposer chain. Therefore, by considering an average on the entire longest proposer chain, we have \n$$ {\\rm CQ} \\geq \\frac{(1-\\beta)\\lambda_{\\rm tx}}{(1-\\beta)\\lambda_{\\rm tx} +\\beta\\lambda_{\\rm tx}} = 1-\\beta.$$\nNote that here we define chain quality as the fraction of {\\em honest transaction blocks}  instead of honest proposer blocks, and further determining mining rewards by transaction block yields fair rewards. It is interesting to note that the safety and optimal CQ properties of the Fruitchains protocol do not constrain the mining rate $\\lambda_{\\rm tx}$ of transaction blocks (determined by the difficulty target $T_{\\rm tx})$. However, having a low difficulty target $T_{\\rm tx}$ will lead to a large rate of production of transaction blocks which will need to be distributed over the underlying network. In the next lecture we will see that the constraint on the transaction block mining rate imposed by a careful modeling of the network capabilities (capacity and delay). \n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=8cm]{figures/fruitchains.png}\n    \\caption{The Fruitchains protocol. }\n    \\label{fig:fruit}\n    \\vspace{-0.2in}\n\\end{figure}\n\n\\noindent {\\bf Finetuning the Fruitchains protocol}. The Fruitchains protocol described above guarantees long term optimal chain quality. However, in the context of a short timescale, the protocol is vulnerable to a private  block attack: an attacker could keep successfully mined transaction blocks private, and suddenly release a large number of them at the same time, thereby creating a very high fraction of adversarial transaction blocks in some small segment of the proposer chain. This issue is  resolved by  requiring that a transaction block should ``hang'' from a proposer block which is not too far from the proposer block which includes it.  Each  the transaction block has  two parent blocks, a  confirmed parent and a proposer parent: the confirmed parent is a recently stabilized/confirmed proposer block (i.e., $k$-deep block) that the transaction is hanging from; the proposer parent should be the tip of the longest proposer chain. Note that a proposer block  also has a confirmed parent because the transaction block mining and proposer block mining are conjoined  by the two-for-one mining process, although the proposer block generation and interpretation does not care about this field. See Figure~\\ref{fig:fruit} for an illustration. We say that a transaction $B_{\\rm tx}$ is recent with respect to a proposer chain $\\mathcal{C}$ if the confirmed parent of $B_{\\rm tx}$ is a block that is at most $R$ deep in $\\mathcal{C}$, where $R$ is a {\\em recency} parameter. Our goal is achieved by requiring  proposer blocks only include recent transaction blocks. By setting the recency parameter $R$ reasonably large, any transaction block mined by an honest player will be included sufficiently deeply in the proposer chain. Therefore, the optimal CQ property continues to hold true. Moreover, since only recently mined transaction blocks can be included, the optimal CQ is achieved even for  short segments of the longest chain. \n\n\n\n\\iffalse\nFruitchains runs an instance of the longest chain protocol but instead of directly putting the transactions inside the blockchain, the transactions are put inside ``fruits'' and fruits are included by blocks. Mining fruits also requires solving some PoW puzzle. Fruitchains uses \\textit{cryptographic sortition} (a.k.a. {\\it 2-for-1 mining}) to ensure that miners mine blocks and fruits concurrently and they do not know the type of the blocks until the puzzle is solved. Miners combine the contents of a block and a fruit they are mining into a \\emph{superblock} and perform proof-of-work mining on it. The range of a valid proof-of-work is divided into two disjoint intervals $[0,T_b)$ and $[T_b, T_b + T_f)$, corresponding to a block or a fruit respectively. Whether a superblock is a block or a fruit is then decided by looking at which interval its proof-of-work falls into.\nAdditionally, in Fruitchains, a fruit is required to ``hang'' from a block which is not too far from the block which includes the fruit.\n\nIn Fruitchains, each of the fruit will have two parent blocks, we call them fruit parent and block parent: the fruit parent is a recently stabilized/confirmed block (i.e., $k$-deep block) that the fruit is hanging from; the block parent should be the tip of the longest chain. Actually a block will also have a fruit parent because the fruit mining and block mining are piggybacked atop each other, but a block actually does not care about this field. See Figure ~\\ref{fig:fruit} for illustration. We say that a fruit $B_f$ is recent w.r.t. a chain $\\mathcal{C}$ if the fruit parent of $B_f$ is a block that is at most $R$ deep in $\\mathcal{C}$, where $R$ is called the recency parameter. The Fruitchains protocol requires that blocks only include recent fruits. Intuitively, the reason why fruits need to be recent is to prevent the ``fruit withhold attack'': without it, an attacker could withhold fruits, and suddenly release lots of them at the same time, thereby creating an very high fraction of adversarial fruits in some small segment of the chain.\n\nIntuitively, the reason why the Fruitchains protocol guarantees optimal CQ is that even if an adversary tries to ``erase'' some block mined by an honest player (which contains some honest fruits), by the liveness of the the longest chain protocol, eventually an honest player will mine a new block including those fruits and the block will be stable -- in fact, by setting the recency parameter $R$ reasonably large, we can make sure that any fruit mined by an honest player will be included sufficiently deep in the chain. Moreover, since only recently mined fruits can be included, the optimal CQ is achieved even for some short segment of the chain, which provides fast time scale liveness. \n\nFruitchains can be easily adapted to work under a variable mining power setting. We can adjust the mining difficulty using the same way as the Bitcoin rule (as we have seen in Lecture 3), and the mining targets of transaction block and proposer block remain the same ratio using two-for-one mining. If rewards and transaction fees are designed to distribute proportional to the transaction block mining difficulty, then this protocol still guarantees optimal CQ under a variable mining power setting.\n\n\\fi\n%\\section*{Scaling Bitcoin}\n%How to improve the design of the longest chain protocol to achieve optimal chain quality? Introduce Prism 1.0 (long time scale CQ optimality) and Fruitchains (short time scale CQ optimality). This type of an improvement is an example of improving the longest chain protocol's core design, while not deviating too far. This type of design will be a guiding principle for the next module of the course: Scaling Bitcoin. Here we will improve throughput, latency and compute/storage/communication requirements of Bitcoin. \n\n\n\\input{Problem_sets/Lec7_PS}\n\n\\end{document}",
    "lecture_01.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 1}\n\\cfoot{\\thepage}\n\n\\title{Lecture 1: Introduction to Blockchains}\n\\author{Principles of Blockchains, Princeton University,  \\\\ Professor:  Pramod Viswanath \\\\ Scribe: Suryanarayana Sankagiri}\n%\\date{January 26, 2021}\n\n\\begin{document}\n\\maketitle\n\\section*{What are blockchains?}\nBlockchains are the technology underlying decentralized trust systems.  Let us unpack this sentence, one phrase at a time.\n\n\\paragraph{Decentralized system} A decentralized system is one where no single entity (person/company) is responsible for the smooth operation of the system. Indeed, blockchains are peer-to-peer systems, where each peer has the same prescribed behavior; no peer is unique. Peers communicate with each other by exchanging messages. Beyond this message exchange, peers function independently of one another.\n\n\\paragraph{Trust} Trust underpins human society. Trust enables cooperation, which is the hallmark of human activities and organizations (consider this quote from Y. Harari extracted from his book {\\em Sapiens}:  Humans are the only animals to cooperate flexibly in large numbers). The underlying mechanism of trust dictates how large the size of human cooperation can get. \n\n\\paragraph{Tribal Trust} Historically, humans organized themselves around tribal societies, with the trust derived from a shared genetic composition and language and customs, with inherent limitations to the size of such cooperation. \n\n\\paragraph{Institutional Trust} In the last 60 years (since the end of WWII), the dominant human organization has been institutional. Examples include ``The University of Illinois at Urbana-Champaign and the ``US Supreme Court and ``US Dollar. The underlying mechanism of trust is a set of laws (e.g., the Constitution of the USA) and transparent and rigorous enforcement of the law (e.g., no one is above the law mandate). This notion of trust has enabled human societies to cooperate on a global scale. However, the drawback is that the institutions are centralized, and the power to enforce and promulgate the laws is concentrated in the hands of a few individuals. The concentration of power leads to unintended consequences, including corruptibility, autocratic tendencies, and rent-seeking.\n\n\\paragraph{Decentralized Trust} The siren song of blockchains is that the scaling and flexibility of institutional trust are possible without its negative aspects, i.e., the creation of a decentralized trust system. Blockchains are guaranteed to be secure even if some fraction of peers act maliciously. The only requirement is that sufficiently many peers operate according to the prescribed behavior. This is called the honest majority assumption. Thus, any user of a blockchain does not need to trust all peers in the system or even one particular peer. Instead, it just needs to trust that a majority of peers are honest. This is a key feature of blockchains that are not present in other peer-to-peer systems, or indeed, any other system.\n\n\\textbf{Digital platforms} A digital platform is one in which two (or more) parties interact, and some transaction takes place. There are many examples of digital platforms today. For example, Amazon/eBay is a platform for the exchange of goods. It provides a place where sellers can list goods that they are selling, and buyers can choose to buy any listed goods. Among other things, the platform ensures that the transaction takes place securely. It also handles disputes in transactions. Other examples of platforms are Uber/Lyft (for rides), AirBnB (for temporary accommodation), etc. Digital platforms have played a significant role in the global economy in the last decade.\n\nThe aforementioned digital platforms are not truly decentralized in the sense, they do not offer distributed trust. By using any platform, we implicitly trust the (single) company behind that platform to handle transactions faithfully. The platform holds a lot of power in arbitrating disputes. It can also arbitrarily decide the fees to charge for the service. (Of course, the reputation/popularity of the platform is at stake, which prevents it from behaving arbitrarily). \n\nBlockchains hold the promise to decentralize the digital platforms we see today. From a users perspective, the platforms functionality will be identical. However, the platform will no longer be operated by a single company but rather a multitude of small stakeholders, each running the same blockchain code. The trust factor in the system becomes distributed.\n\n\n\\section*{Bitcoin is the first blockchain}\n\nThe term blockchain was introduced in late 2008 with the advent of Bitcoin. Bitcoin is a cryptocurrency: a decentralized, digital payment platform. As such, cryptocurrencies are one of the simplest applications of blockchains. Today, there is a multitude of blockchain designs for cryptocurrencies and other applications. However, they all retain many of the core design components that were introduced in Bitcoin. Thus, the term blockchain has remained in all of them.\n\nBitcoin is one among many attempts in history to create a decentralized, digital payment platform (the term currency is to be thought of as a token that is used on this payment platform). Unlike all previous attempts, Bitcoin has stood the test of time. Its popularity, which can be measured by its price in dollars, has grown many-fold over the twelve years since its introduction. In the last six-seven years, Bitcoin has also been studied theoretically, giving us a better understanding of its design and its limitations. This has also given rise to ideas on how to improve its design.\n\nA major reason behind the popularity of Bitcoin is its strong security property, coupled with its truly decentralized nature. It is now well understood that as long as $51\\%$ of the peers in Bitcoin are honest, the system is secure (the exact conditions are slightly different, but this suffices for the moment). This has been shown theoretically and has also been borne out in practice. Moreover, anyone can freely join and leave the Bitcoin system at any time; the system is permissionless.\n\nDespite its benefits, there are major drawbacks of Bitcoin, which impact its viability. Some issues can be categorized as scaling issues. For example, the system can only process about seven transactions per second. In contrast, Visa (a centralized digital payment mechanism) processes 50,000 transactions per second. If all people in the world are to switch from Visa to Bitcoin, the system must scale its transaction throughput. Other issues are a lack of desirable properties. For example, if the network is disrupted, transactions that are once confirmed can be reverted. (We say that Bitcoin does not offer finality in confirming transactions).\n\nSome issues of Bitcoin have been addressed in existing systems. For example, Ethereum is a system that allows much more flexibility in terms of the platforms/services that can be created in a blockchain. Many other issues are topics of active research. Currently, there is no one perfect blockchain system. Research in Bitcoin spans designing new systems, analyzing the design theoretically, building them in practice, and testing out the implementation. Thus, it involves all facets of engineering.\n\n\\section*{What this course is about}\nThis course covers the \\textbf{fundamental design principles of blockchains}. We study how different blockchain designs impact its security, scalability, and other desirable features. The lectures are divided into three modules.\n\n\\paragraph{Understanding Bitcoin} The first six lectures cover the complete design of Bitcoin. At the end of this module, you will be able to understand the system as a whole and how it functions as a secure, decentralized payment platform. We will introduce various terms pertaining to Bitcoin and cryptocurrencies (e.g., UTXOs, hash pointers, longest chain rule) and cryptography on a need to know basis. We will study some attacks on Bitcoin and under what conditions Bitcoin is secure under those attacks.\n\n\\paragraph{Scaling Bitcoin} The second module aims to improve the throughput, latency, and resource usage (energy, compute, storage, and communication needs) of Bitcoin while maintaining the same security levels. The goal is to work within the overall architecture of Bitcoin itself and systematically improve various design elements. \n\n\\paragraph{Beyond Bitcoin} The third module covers alternate blockchain protocols that offer properties that are simply not present in Bitcoin. These include accountability, resistance to $51\\%$ adversarial attacks, transaction finality, and privacy (the exact meaning of these terms will be made clear later on). We also see how these properties can be combined with Bitcoin-like blockchains via the notion of a finality gadget. This gives us a blockchain with many desirable properties.\n\n\n\\paragraph{Teaching Philosophy} This course emphasizes the implementation of blockchains (in software). Thus, the bulk of the evaluation will be based on two projects. The first project involves implementing a Bitcoin client. This will make use of all the concepts learned in the first module of the course. The second project will involve implementing a finality gadget of your choice on top of Bitcoin (from the third module). {\\sf Rust} will be the programming language that is used.\n\n\n\\section*{Reference material}\n\nThis course covers a wide terrain of blockchain designs, from the now-classical to the very recent research literature. We recommend two basic blockchain materials to supplement the fast pace of this course:\n\\begin{itemize}\n    \\item Bitcoin and Cryptocurrency Technologies: A Comprehensive Introduction, A. Narayanan et. al., Princeton University Press. \n    \\item \\href{https://nakamoto.com/introduction-to-cryptocurrency/}{Introduction to  Cryptocurrencies}, an online course by H. Qureshi. \n\\end{itemize}\nTwo advanced courses cover blockchains from a conceptual and mathematical viewpoint. They provide complementary resources to the material covered here. \n\\begin{itemize}\n    \\item \\href{http://web.stanford.edu/class/ee374/}{EE 374} at Stanford by Prof. David Tse. \n    \\item \\href{https://ece595uwseattle.github.io/}{ECE 595} at the University of Washington by Prof. Sreeram Kannan\n\\end{itemize}\nThe following two sources are good references for consensus algorithms that are the underpinnings of blockchains.\n\\begin{itemize}\n    \\item \\href{https://sites.google.com/view/cs598cal}{CS 598LR} at UIUC by Prof. Ling Ren. \n    \\item \\href{https://www.distributedconsensus.net}{Foundations of Distributed Consensus and Blockchains} by Prof. Elaine Shi\n\\end{itemize}\n\n\\input{Problem_sets/Lec1_PS}\n\n\\end{document}",
    "lecture_16.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\usepackage{markdown}\n\\usepackage{amsthm}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\newcommand{\\indicator}{{\\bf 1}}\n\\newcommand{\\pramod}[1]{{\\color{red}\n\\footnotesize[Pramod: #1] }}\n\\newcommand{\\xw}[1]{{\\color{green}\n\\footnotesize[Xuechao: #1] }}\n\\newcommand{\\surya}[1]{{\\color{magenta}\n\\footnotesize[Surya: #1] }}\n%\\theoremstyle{definition}\n\\newtheorem{definition}{Definition}\n\\newtheorem{theorem}{Theorem}\n\\newtheorem{lemma}{Lemma}\n%\\let\\proof\\relax\n%\\let\\endproof\\relax \n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 16}\n\\cfoot{\\thepage}\n\n\\title{Lecture 16: Bridging BFT protocols with the longest chain protocol}\n\\author{Principles of Blockchains, University of Illinois,  \\\\ Professor:  Pramod Viswanath \\\\ Scribe:  Suryanarayana Sankagiri}\n\\date{March 23, 2021}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nIn the past two lectures, we have studied BFT protocols that are an alternative to longest chain protocols. The BFT protocols offer strong safety guarantees (at times even when the  network is not synchronous)  while deprioritizing liveness; the exact reverse is true in the longest chain protocol. In this lecture, we study how to construct blockchains that have both protocols, BFT and longest chain, as constituents; the goal is to have both strong safety and liveness properties, along with forensic capabilities. \n\\end{abstract}\n\n\\section*{Introduction}\n%By now, we have seen many different blockchain protocols, each of which have a unique set of properties. Nevertheless, all \nBlockchain protocols must satisfy two basic properties: safety and liveness. Roughly speaking, safety says that all parties will have consistent views of the blockchain, while liveness says that new blocks will get included in the blockchain at a regular rate. Safety and liveness are jointly referred to as security properties.\n\nFor any given protocol, security properties cannot be guaranteed unconditionally. Rather, they are guaranteed to hold only under some assumptions, e.g.,  the system has honest majority (or $2/3$ super-majority) and the network is synchronous. Naturally, we would like safety and liveness to hold under as large a set of conditions as possible; e.g., safety and liveness guarantees under $1/2$ honest majority would be preferable over these guarantees under $2/3$ honest majority. We begin by examining the different assumptions required for security by the different blockchain protocols we have seen in the lectures.\n\nA major strength of the (Proof-of-Work) longest-chain protocol is that it works in a truly permissionless setting. Put differently, it handles variable participation levels; parties may join or leave the system at any time. The key point here is that it remains secure even if the number of active participants drops to one (as long as we have honest majority at all times). This property is called {\\em adaptivity}. % or {\\em dynamic availability} (we shall use the first term). \nOn the flip side, safety guarantees in the longest chain protocol are probabilistic, not deterministic. More importantly, the protocol does not remain secure during extended periods of asynchrony. During such periods, the adversary can easily build many blocks and overturn blocks that are $k$-deep, thereby violating the safety of the $k$-deep confirmation rule. It also loses liveness.\n\nIn the last two lectures, we have seen permissioned (committee-based) BFT protocols that offer deterministic safety (so-called {\\em finality}). Crucially, the safety property holds even during extended periods of asynchrony. By definition, permissioned protocols do not have adaptivity;  i.e., the protocol will not be live when not enough nodes participate (although safety is inviolable).  Tables \\ref{tab:CAP_properties_adaptive} and \\ref{tab:CAP_properties_final} summarize the properties of adaptive protocols (like the longest-chain protocol) and the finality-offering protocols (like HotStuff).\n\\begin{table}[htbp]\n\\centering\n\\caption{Adaptive rule}\n\\label{tab:CAP_properties_adaptive}\n\\begin{tabular}{|l|c|c|}\n\\hline & Asynchrony & Synchrony \\\\ \\hline\nStatic Participation & Neither & Safe, Live \\\\ \\hline\nVariable Participation & Neither & Safe, Live \\\\ \\hline\n\\end{tabular}\n\\end{table}\n\\begin{table}[htbp]\n\\centering\n\\caption{Finality-preserving rule}\n\\label{tab:CAP_properties_final}\n\\begin{tabular}{|l|c|c|}\n\\hline & Asynchrony & Synchrony \\\\ \\hline\nStatic Participation & Safe & Safe, Live \\\\ \\hline\nVariable Participation & Safe & Safe \\\\ \\hline\n\\end{tabular}\n\\end{table}\n\nIn summary:\n\\begin{quote}\n    The longest chain protocol prioritizes liveness over safety; BFT protocols prioritize safety over liveness. In other words, BFT protocols offer finality but not dynamic availability; longest chain protocols offer dynamic availability but not finality. \n\\end{quote}\nA natural question is whether it is possible to construct a blockchain protocol that offers {\\em both} properties: finality {\\em and} adaptivity. In this lecture, we will first see how \\textit{finality gadgets} give us a blockchain system with two different confirmation rules: one guaranteeing adaptivity, and the other, finality. Finality gadgets are interesting because they neatly combine a BFT protocol with the longest-chain protocol, in order to create a protocol with the best-of-both-worlds. We will also discuss the \\textit{CAP theorem}, which tells us that it is impossible to have a single blockchain protocol with both properties. This is a fundamental result with wide implications in distributed systems, some of which we discuss in the last part of this lecture.\n\nBeyond adaptivity versus finality, there are  other dimensions that contrast the longest-chain protocol from committee-based protocols. One important factor is the latency in confirming blocks. The Nakamoto consensus protocol is slow to confirm blocks. One must wait for blocks to be $k$-deep before they can be confirmed. Blocks arrive as per the mining rate, which is set proportional to the inverse of the maximum network delay $\\Delta$. Thus, the latency of the longest-chain protocol is $O(k\\Delta)$. We have seen how protocols like Prism can help reduce this to $O(\\Delta)$. However, protocols like HotStuff offer even better latency of $O(\\delta)$, where $\\delta$ is the real network delay (which can be much smaller than the worst-case upper bound). This property is called  \\textit{responsivity}; the protocol responds to the real network delay. Note that not every committee-based protocol is responsive, e.g., Streamlet is not.\n\nOnce again, a natural question to ask is can we have a responsive protocol in a permissionless setting? %It turns out that the answer to this question is yes!\nOne method to achieve this is via a protocol design called {\\sf Hybrid Consensus}, which neatly combines a BFT protocol with the longest chain protocol. \n\n\\section*{{\\sf Hybrid Consensus}}\nThe main goal of the {\\sf Hybrid Consensus} approach is to develop a Proof of Work permissionless system with fast confirmation. In particular, we want protocols that are \\textit{responsive}, i.e., the confirmation delay is proportional to the true network delay than the estimated upper bound. In Algorand, which works in a Proof of Stake system, Verifiable Random Functions were used to elect a committee, which then ran a fast-confirmation protocol. Taking a cue from Algorand, the crucial task at hand is to elect a committee of a fixed size in a PoW system, and moreover, do so periodically.\n\nLet us first see how to elect one committee of size $\\textsf{csize}$. Let us run the Nakamoto consensus protocol until $\\textsf{csize} + k$ blocks are mined. Then all parties are guaranteed to agree on the first $\\textsf{csize}$ blocks (except with negligible probability). Each block includes the miner's public key. Lo and behold, we have elected a set of $\\textsf{csize}$ nodes (to be precise, $\\textsf{csize}$ public keys, multiple of which could be held by the same person/entity). This committee is chosen in a fair, decentralized manner (due to PoW) and is agreed upon by everyone (because of the security of the PoW longest chain protocol). Once a committee is chosen, it executes a responsive BFT protocol (like HotStuff) to confirm transactions. Thus, transactions are actually confirmed by the BFT protocol, not the longest-chain protocol! Figure \\ref{fig:hybrid_consensus} illustrates this idea.\n\n\\begin{figure}[htbp]\n    \\centering\n    \\includegraphics[width = 0.8\\textwidth]{figures/hybrid_consensus.pdf}\n    \\caption{The Idea Behind {\\sf Hybrid Consensus}}\n    \\label{fig:hybrid_consensus}\n\\end{figure}\n\nHaving covered the basic idea behind the protocol, we examine it in more detail. Firstly, note that even if we wanted to elect a single committee, honest miners cannot afford to stop mining; if they do, the adversarial miners can create a longer chain with purely adversarial blocks, which will then decide the committee. Secondly, to run a responsive BFT protocol like HotStuff, we would like an honest super-majority of $> 2/3~\\textsf{csize}$ parties in the committee. This must be reflected in the honest-to-adversarial ratio in the PoW protocol. In fact, if we use the plain longest chain  protocol, we need a $3/4$ honest majority, because of imperfect chain quality.  Rather, if we use FruitChains, (see Lecture 7), we can do with a $2/3$  honest majority.\n\nIt is important to be able to  keep rotating the committee, for two reasons. First, we cannot rely on the committee to remain online continuously for an extended period of time. Secondly, an adversary can corrupt the committee after it is elected (although presumably, with some lag). By rotating the committee frequently, we can mitigate attacks by an adaptive adversary. The rotation is conducted in a  straightforward manner:  once a committee is formed, it keeps confirming transactions for a fixed period of time, until which time the PoW blockchain grows by $\\textsf{csize}$ more blocks. Once this happens, the old committee hands over the responsibility of transaction confirmation to the new committee. Note that all parties in the protocol have the same view of the committee. \n\nThe main advantage {\\sf Hybrid Consensus} brings over the longest-chain protocol is that it is a responsive protocol. Let us now examine some of its limitations. Firstly, if we would like a responsive BFT protocol, the adversarial threshold it can tolerate is $1/3$, down from $1/2$. This is inevitable; any responsive protocol can tolerate at most $1/3$ Byzantine adversaries. While there are BFT protocols that tolerate $1/2$ adversaries, their latency is $O(\\Delta)$. Secondly, the protocol completely breaks down under asynchrony, because the committee election mechanism itself loses both safety and liveness. If there is no consensus on who belongs to the committee, there can be no consensus on the transactions confirmed by them. For similar reasons, security of the whole scheme is probabilistic, not deterministic. Lastly, honest committee members must remain active throughout the duration of time that it is a member of the committee. If a large fraction of them stop participating, the protocol will stall. Thus, in terms of guaranteeing safety and liveness under a wide variety of conditions, {\\sf Hybrid Consensus} actually does worse than the longest-chain protocol -- it does not guarantee liveness under variable participation.\n\n\\section*{Finality Gadgets}\nA finality gadget, as the name suggests, is designed to provide deterministic safety guarantees, i.e.,  ``finality\"  into a PoW blockchain. Ideally, the blockchain endowed with the gadget should provide finality in addition to, and not at the expense of, adaptivity. The natural approach is to combine a committee-based BFT protocol with the longest-chain protocol. After all, we are seeking ``the best of both worlds'', i.e., adaptivity, like the longest-chain protocol, and finality, like a BFT protocol. Let us examine how we may combine these two protocols to get the desired benefits.\n\n\\subsection*{A two-layer design}\nIn its simplest form, a finality gadget is a layer-two committee-based BFT protocol, which runs on top of a (layer-one) longest-chain protocol. One can use any adaptive protocol instead of the longest-chain protocol, but for this lecture, we shall focus on the longest-chain protocol. To elaborate, there are two sets of nodes in the system: \\textit{miners} and \\textit{checkpointers}. Miners produce new blocks, carrying transactions, using PoW and the longest-chain rule. There could be any number of miners, but we assume that the mining rate of the system remains constant. The checkpointers are a distinguished committee of $n$ nodes, separate from the miners. The checkpointers do not produce any blocks of their own. Rather, they execute a committee-based BFT protocol by voting on blocks produced by the PoW mining process. Thus, there are two consensus protocols being executed in parallel, to achieve consensus on the \\textit{same} set of blocks (transactions).\n\n\\paragraph{Checkpointing.} The notion of checkpointing is new, and we elaborate on it a little more here. Suppose the longest chain protocol proceeds for some time, and the block tree grows to a certain height. Consider a block that is six-deep; a user could confirm it, with the hope that all future blocks would be descendants of this block. However, the confirmation guarantee would be probabilistic, as we know. How could we make the confirmation guarantee deterministic? In other words, how can we checkpoint this block? \n\nIt comes the checkpointing committee. The committee's job is to checkpoint blocks, by issuing \\textit{checkpoint certificates} for blocks. A checkpoint certificate for a block $B$ is a collection of at least $2n/3$ signed messages of the form $\\langle \\mathsf{finalized}, B \\rangle$; such a block is said to be checkpointed. These messages arise naturally in nearly all committee-based BFT protocols. Any node that receives this certificate is assured that this block is confirmed deterministically. This node could be a miner, a checkpointer, or simply an observer of the system. Naturally, the checkpoint blocks, issued by the layer-two gadget, should lie on the longest chain, to maintain consistency with the layer-one protocol. How can this be done?  \n\nThe checkpointers keep track of the blocks being mined. At regular intervals, they execute a (single-shot) BFT protocol, where inputs to this protocol are blocks produced by the miners. Honest nodes input blocks that lie on the longest chain, but have not been checkpointed yet. Typically, blocks at a certain fixed depth are chosen; say, a depth of $6$. This would ensure that if nodes have chains of the same length and have $6$-deep common prefix, their inputs would be the same. Checkpointers exchange votes on each other's inputs, and finally agree on one particular input; this forms the checkpointed block. The overall system is illustrated in Figure \\ref{fig:finality-gadget}.\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width = 0.8\\textwidth]{figures/finality_gadget.pdf}\n    \\caption{Finality gadget.}\n    \\label{fig:finality-gadget}\n\\end{figure}\n\n\\paragraph{Two ledgers and their properties.} The salient feature of a finality-gadget based system is that it provides \\textit{two different confirmation rules}. Firstly, the $k$-deep rule continues to remain a viable confirmation rule in the system, since blocks are being mined as per the longest-chain protocol. A node that is simply observing the blocks mined in the system can easily follow this rule to confirm blocks. Such a node may remain completely oblivious to the checkpointing protocol. This rule provides \\textit{adaptivity}. The second confirmation rule comes from the checkpointers, who issue \\textit{checkpoint certificates} for certain blocks at regular intervals. This collection of messages certifies that block $B$ has been agreed upon by the checkpointers. The confirmation rule for the finality gadget is to simply confirm the latest checkpointed block, and all its ancestors. This rule provides \\textit{finality}.\n\nWhat does it mean for a confirmation rule to provide adaptivity or finality? To understand this, we need to appreciate the following points:\n\\begin{itemize}\n    \\item Every confirmation rule generates a ledger: it is the sequence of all transactions in the order of the blocks confirmed by the particular rule. \n    \\item Over a long time, the two ledgers are consistent: all transactions that appear in one ledger also appear in the other, and they are in the same order.\n    \\item At any given point in time, one ledger could be slightly ahead of the other (i.e., confirm a few more transactions). Typically, we expect the $k$-deep rule (for small/moderate $k$) to confirm blocks more optimistically than the checkpoint-based ledger. Thus, the ledger produced by the $k$-deep rule will be a bit ahead of the checkpoint-based ledger.\n\\end{itemize} \nSafety and liveness are defined for \\textit{each ledger} in a natural way: safety means that once a transaction appears in the ledger, it stays there forever, while liveness means that new transactions keep getting added to the ledger. It is indeed possible that under certain conditions, different ledgers have different security guarantees. For example, under variable participation, an adaptive ledger will be both safe and live, whereas a finality-based ledger will only be safe, not live. To summarize, the notions of adaptivity and finality actually apply to each confirmation rule (i.e., ledger), rather than the entire protocol.\n\nUnder optimal conditions (i.e., static and synchronous), both ledgers grow at the same rate. Under variable participation, the finality-preserving ledger stalls, while the adaptive ledger keeps growing. As soon as static participation returns, the finality-preserving ledger catches up. %Thus, there is an ebb-and-flow like property of the difference between the two ledgers, just like the tides.\n\n\\paragraph{Two confirmation rules.} The notion of multiple confirmation rules may seem surprising at first, but if we think about it, it is a natural concept. In fact, the longest-chain protocol alone is equipped with a multitude of confirmation rules! To understand this better, let us make a distinction between the block production rule and the confirmation rule of the protocol. The block production rule is to propose a new block at the tip of the longest chain one has seen so far; this is the rule that gives the longest-chain protocol its name. The confirmation rule is to confirm a block that is buried $k$-deep, along with all the ancestors of this block. All players follow the same block production rule. However, each user can choose its own confirmation rule, i.e.,  they each choose their value of $k$ independently, depending on the level of security they prefer and the latency they are willing to tolerate.\n\n\\paragraph{Validity conditions.} A point to note is that there is some flexibility in choosing the \\textit{inputs} to the BFT protocol and in deciding what inputs are \\textit{valid} ones. Some validity conditions must be introduced, or else malicious checkpointers could propose arbitrary blocks for checkpointing, and these might get checkpointed. A validity criterion would help honest nodes ignore invalid blocks. Introducing the right validity conditions is a challenging design question. For example, we would like checkpoints to be issued for relatively new blocks. Checkpointing an old block is not of much use, for it will already be confirmed with very high probability using the $k$-deep rule. At the same time, one should not confirm a block very close to the tip, as the longest-chain may deviate from there. Checkpointing a $d$-deep block, for some moderate value of $d$, is a possible trade-off.\n\n\\paragraph{Permissioned or Permissionless?} In the design so far, the checkpointers are a permissioned set of nodes. Can we make the checkpointing mechanism permissionless? In principle, they could be rotated regularly from a large set of players using a PoS mechanism, as done in Algorand. Even so, some level of a permissioned system is inevitable. A pure PoW system cannot offer the finality properties we desire (the closest we could do was what was done in {\\sf Hybrid Consensus}, but that does not meet our requirements). For simplicity, in this lecture, we just assume that the checkpointers are fixed for the duration of the protocol. \n\n\\paragraph{Examining Adaptivity and Finality.}\nWe introduced finality gadgets with the aim of combining a committee-based BFT protocol and the longest-chain protocol to get a system with both adaptivity and finality. The system design gives us two confirmation rules, and leads us to believe that the $k$-deep rule would provide adaptivity, and the checkpoint-based rule would provide finality. Let us examine closely whether we indeed achieve this. \n\nIn our two-layer design, adaptivity of the $k$-deep rule clearly holds, because blocks are mined just as they are in the regular longest-chain protocol. The layer-two checkpointing protocol has no bearing on the layer-one protocol. How does the checkpointing protocol fare under variable participation? If enough number of checkpointers are not actively participating, the protocol simply stalls. Once all honest checkpointers are back online, they resume checkpointing blocks. Thus, under variable participation, the checkpointing protocol turns off and then back on for arbitrary durations, depending on the participation level. This merely affects the liveness of the protocol; the safety remains intact at all times. \n\nLet us now turn to finality. We want the finality gadget to protect the protocol under periods of asynchrony. In other words, even after a period of asynchrony, all blocks until the last check-pointed block should remain confirmed. We do not expect that any new blocks will be checkpointed in this period. Once synchrony resumes, the protocol should start checkpointing new blocks, and thus regain liveness. Does the aforementioned design satisfy this requirement?\n\nUnfortunately, it does not. Consider an extended period of asynchrony. The adversary can create a new chain that forks back from before the last checkpointed block, and becomes the longest chain. Once synchrony resumes, all miners will find the adversarial chain as the longest chain and will mine on that. There will be no new blocks below the last checkpointed block! At this point, the checkpointers must either stall completely or (consciously) break safety by switching chains. Either of these is undesirable. \n\nThe key reason for this issue is that we have created a two-layer solution. This means that the behavior of miners does not depend on the checkpointers. For a finality gadget to be effective, miners must respect the checkpointed blocks. In particular, miners should mine below the latest checkpointed block. Of course, we would like to have some longest-chain-like properties as well. A natural suggestion is that miners follow the \\textit{checkpointed longest chain rule: extend the longest chain below the latest checkpoint block}. Since the latest checkpoint block is also the checkpointed at the latest height, this rule could also be stated as: mine on the longest block that contains all the checkpoint blocks. Under synchrony, all checkpoints would be on the longest chain by design. Following the checkpointed longest chain rule would be the same as following the longest chain rule. Thus, the new protocol would inherit the security guarantees of the old protocol. On the other hand, the checkpoints protect the system during an extended period of asynchrony. If the adversary mines blocks deviating before the previous checkpoint, all honest nodes would simply dismiss such blocks as invalid. For all practical purposes, every new checkpoint acts like a new genesis block.\n\nThe design of checkpointed longest-chain protocol requires some care, because the checkpointing protocol actually affects the miners. One area of vulnerability is the behavior of the checkpointing protocol during variable participation. It is possible that the checkpointing protocol is stalled for a very long time, due to low participation. Once participation resumes, we expect the protocol to resume checkpointing quickly, and close to the tip of the longest chain. At all times, the protocol must ensure that the checkpoints are always on the longest chain. Doing so requires paying special attention to the validity conditions mentioned beforehand. We  refer to \\href{https://arxiv.org/pdf/2010.13711.pdf}{this paper} for more details.\n\n\\section*{The CAP theorem}\n\\subsection*{Blockchains and the CAP theorem}\nWe have seen how finality gadgets give us dual-ledger protocols, with one ledger providing adaptivity and the other, finality. A natural question to ask is, can we have a \\textit{single ledger} that gives both adaptivity and finality? Unfortunately, this is not possible. The impossibility is a consequence of a celebrated result in distributed systems, known as the CAP theorem (CAP stands for Consistency, Availability and Partition tolerance). Roughly speaking, the CAP theorem states that during a network partition, a distributed system must make a choice between availability (liveness) and consistency (safety); it cannot offer both. Moreover, this choice must be encoded in its design itself. Thus, systems can be classified as availability favoring or consistency favoring, based on their design.\n\nBlockchains, being distributed systems, also inherit the trade-offs implicated by the CAP theorem. It states that a protocol cannot be adaptive and, at the same time, offer finality. The essence of the impossibility result is that it is difficult to  distinguish network asynchrony from a reduced number of participants in the blockchain system. Hence, a protocols behavior must be similar under both these conditions. The CAP theorem also sheds some light on why we see two totally different classes of protocols in today's blockchain space. Protocols based on the longest-chain idea favor liveness, which lends them the adaptivity property. Committee-based BFT protocols (such as Hotstuff) favor safety, which makes them finality-guaranteeing. %As quoted in \\href{}{this paper}, ``a fundamental dichotomy holds between protocols (such as Bitcoin) that are adaptive, in the sense that they can function given unpredictable levels of participation, and protocols (such as Algorand) that have certain finality properties.\"\n\nThe CAP theorem does, in fact, allow for resolving the adaptivity-finality trade-off at a {\\em  user level}. We have seen that a carefully constructed finality gadget gives us two distinct confirmation rules: one that guarantees adaptivity, and  the other, finality. Such a protocol lets clients make a {\\em local choice} between availability and finality. Depending on the nature of the transactions, clients can make a choice of which confirmation rule they would like to apply. For example, for low-value transactions such as buying a coffee, one may prefer adaptivity over finality. In contrast, for high-value transactions such as buying a Tesla, it is natural to choose finality over adaptivity.\n\n\\subsection*{Historical notes}\nThe CAP theorem was originally proposed in the late 1990s, in the context of a web service, which is an example of an internet scale distributed system. Traditionally, distributed systems were spread over a small physical area and over a small number of computers. Consistency was considered to be of foremost importance, and people were willing to trade-off some degree of availability for it during times of faulty communication. This was not a problem, as network partitions were rare and quickly fixed.\n\nWhen designing internet-scale distributed systems, researchers realized that insisting on perfect consistency was causing inefficiency in terms of availability (being quick to generate responses). The CAP theorem was the result of the realization that one had to give up some degree of consistency in order to achieve the necessary availability. This is not always a bad thing! It also showed that consistency can be recovered during good network conditions.\n\nA couple of real-world examples helps us understand why we may want to trade-off consistency for availability. When we scroll through any social media such as Instagram or Twitter, we would like it to generate a feed instantly (i.e., be available). These platforms are able to do so by generating the feed ahead of time, based on data locally available at the server close to where we are accessing them from. We do not care that much about whether our feeds are consistent, i.e., whether the same piece of news, or the same photo shared by a friend, appears at the same time, on all of our feeds. Another example would be the behavior of the COVID vaccine registration websites. When we open the website, they might show that a few vaccines are available, allowing us to sign up. Since many people are signing up in parallel, it is quite possible that the few slots available are gone by the time we finish. However, the website does not keep checking with all of its servers to see if doses have run out every second. If it did, the web page would freeze up! Instead, websites choose to remain available, providing a smooth experience for its users. At the time of confirming, it does a consistency check, and provides a confirmation only after making sure that doses have not been overbooked. That's why this step takes time. A similar experience is seen in many other websites as well, such as in Amazon (e-retail) or Instacart (groceries).\n\nThe CAP theorem is nuanced enough to allow for great flexibility in design. For example, different ``components'' of the system can have different behavior: some components may favor safety, while others may favor liveness. These components could be different kinds of operations, data, or users. For example, an e-retail server may favor availability for browsing goods, but would favor consistency when it comes to actually purchase one. A newspaper website may favor availability in terms of its news content, but consistency when it comes to storing user's passwords and subscription details. Lastly, we have seen how finality gadgets in blockchains give users a choice between safety and liveness.\n\n\\subsection*{Proof of CAP Theorem}\nIt is relatively straightforward to prove the CAP theorem for a toy model of a distributed system. Consider a system in which there are two servers, $p_1$ and $p_2$. Both servers store a certain variable $V$. Initially, the variable $V$ has value $x$. Then, they are partitioned into two disconnected parts of the network. During partition, some client sends a write request to server $p_1$, requesting that $V$ be set to $y$. Since $p_1$ cannot communicate to $p_2$, it is faced with the following two choices:\n\\begin{itemize}\n    \\item It can act as ``available'' to the client, i.e., it can send an ``ok'' response to the client and set $V = y$. $p_2$ will still have $V$ set to $x$. In this case, when some other client contacts either $p_1$ or $p_2$, they will get inconsistent responses, i.e., consistency is lost.\n    \\item If it fails to establish communication to $p_2$, it will not respond ``ok'' response to the client and set $V = x$. In this case, $p_1$ prioritizes consistency over availability, since it remains unavailable to the client.\n\\end{itemize}\nThe same trade-off is faced by $p_2$ as well, when a client issues a read request. Ideally, it should establish contact with $p_1$ to check if $V$ has been re-written or not. However, it cannot establish a contact due to the network partition. It has the choice to either eventually return a response (and risk returning the wrong response) or to never return a response. Thus, if communication is asynchronous (i.e., processes have no a priori bound on how long it takes for a message to be delivered), it is impossible for the system to guarantee both consistency (safety) and availability (liveness).\n\\begin{figure}\n    \\centering\n    \\includegraphics[width = 0.8\\textwidth]{figures/CAP-proof.pdf}\n    \\caption{A visualization of the trade-offs implicated by the CAP theorem}\n    \\label{fig:cap_thm_proof}\n\\end{figure}\n\n\\section*{References}\nThe ideas behind {\\sf Hybrid Consensus} have appeared in a few works, such as \\href{https://www.usenix.org/system/files/conference/usenixsecurity16/sec16_paper_kokoris-kogias.pdf}{ByzCoin}. It was formally studied for the first time in \\href{https://eprint.iacr.org/2016/917.pdf}{this paper}. The idea of a finality gadget was first proposed by Buterin and Griffith in the form of \\href{https://arxiv.org/pdf/1710.09437.pdf}{Casper FFG}. This work did not specify a complete system, but provided some of the main ideas that are still in use. More recent works, such as \\href{https://eprint.iacr.org/2019/504.pdf}{Afgjort} and \\href{https://arxiv.org/pdf/2007.01560.pdf}{GRANDPA}, provide a full system design. Moreover, they provide a more principled approach to building finality gadgets, identifying many of the issues that we identified in this paper. However, both these works do not provide all the necessary security guarantees. Afgjort, being a layer-two design, cannot provide security under asynchrony, while GRANDPA is vulnerable to attacks in the variable participation setting, due to malicious checkpointers.\n\nTwo concurrent works, titled \\href{https://arxiv.org/abs/2009.04987}{Ebb-and-Flow} and the \\href{https://arxiv.org/pdf/2010.13711.pdf}{checkpointed longest chain}, identify the adaptivity-finality trade-off as implicated by the CAP theorem, and provide a solution to resolve the trade-off at the user level. Among these solutions, Ebb-and-Flow provides a more general solution, allowing for \\textit{any} BFT protocol to be combined with \\textit{any} adaptive protocol. However, the protocol does not provide intrinsic validity: to get a complete and consistent ledger, the protocol requires a certain post-processing to discard invalid (or duplicate)  transactions. The checkpointed longest chain solution overcomes this issue, at the expense of generality.\n\nThe CAP theorem for blockchains was stated and proven by Lewis-Pye and Roughgarden in \\href{https://arxiv.org/pdf/2006.10698.pdf}{this paper}. Strictly speaking, it precludes the possibility of achieving finality in the Proof of Work setting. It does not explicitly classify protocols on the basis of their adaptivity-finality properties. It leaves open the question of whether both finality and adaptivity can be achieved in a more homogeneous fashion in the Proof of Stake setting.\n\\end{document}\n\n\\begin{itemize}\n    \\item The history of the CAP theorem: Distributed Database. ACID v/s BASE. \n    \\item Proof of CAP theorem. \n    \\item Beyond databases: different notions of consistency (safety), availability (liveness).\n    \\item (May skip this). Implications of the CAP theorem for other impossibility results. FLP impossibility, lower bounds on communication complexity, and so on.\n    \\item Systems with component-wise consistency-availability trade-offs.\n    \\item Blockchains. classification into two types of protocols. \n    \\item Ebb-and-flow specification. Snap-and-chat, our design.\n\\end{itemize}\n\n% \\section*{Multiple Confirmation Rules}\n% \\paragraph{The longest-chain protocol} Let us first familiarize ourselves with the notion of multiple confirmation rules in the same blockchain protocol. Firstly, note that the longest-chain protocol itself is equipped with a multitude of confirmation rules! In fact, for each value of $k$, the $k$-deep rule is a different confirmation rule. To understand this better, let us make a distinction between the block production rule and the confirmation rule of the longest-chain protocol. The block production rule is to propose a new block at the tip of the longest chain one has seen so far; this is the rule that gives the protocol its name. The confirmation rule is to confirm a block that is buried $k$-deep, along with all the ancestors of this block. All players follow the same block production rule. However, each user can choose their own confirmation rule. I.e., they each choose their value of $k$ independently, depending on the level of security they prefer and the latency they are willing to tolerate.\n\n% \\paragraph{Self-consistent rules} We make some simple but important remarks here. First, we note that all the confirmation rules are self-consistent: a block that is $k_1$ deep is also $k_2$ deep for all $k_2 < k_1$. Thus, the set of blocks confirmed by the different rules are nested: blocks confirmed by the $k_1$ deep rule is always a subset of blocks confirmed by the $k_2$ deep rule. Second, note that the block production rule is also consistent with the confirmation rules. Indeed, by following the longest-chain rules, new blocks keep burying older blocks deeper into the chain, thereby increasing the list of confirmed blocks. The significance of these remarks will be evident soon.\n\n% \\paragraph{Finality gadgets} How can we equip the longest chain protocol with a new confirmation rule that offers finality? One idea is to employ a layer-two protocol called a {\\em finality gadget}. A finality gadget is a committee-based BFT protocol and is executed by a distinguished set of $n$ nodes called {\\it checkpointers}. The checkpointers do not produce any blocks of their own. Rather, they vote on blocks produced by the mining process and aim to achieve consensus on them by means of a {\\em checkpoint certificate}. \n\n% A checkpoint certificate for a block $B$ is a collection of at least $2n/3$ signed messages of the form $\\langle \\mathsf{finalized}, B \\rangle$. These messages arise naturally in any committee-based BFT protocol. This collection of messages certifies that block $B$ has been agreed upon by the checkpointers. The checkpointers keep issuing certificates on new blocks as they come, in an iterative fashion. The checkpointers ensure that the sequence of checkpointed blocks all lie on a chain. To be consistent with the block production rule, the checkpointed blocks must be on the longest chain of the protocol. The confirmation rule for the finality gadget is to simply confirm the latest checkpointed block, and all its ancestors. This rule provides deterministic confirmation; a checkpointed block will never be unconfirmed, since every subsequent checkpoint shall be its descendant. \n\n% \\paragraph{A satisfactory solution?} A finality gadget on top of the longest chain protocol apparently provides a solution to the problem we outlined. The longest chain protocol proceeds as it would without the finality gadget and thus retains its properties. In particular, the $k$-deep rule remains a viable confirmation rule. In addition, the finality gadget provides a second confirmation rule. Intuitively, the former is an adaptive confirmation rule and the latter is a finality providing one. So does this design work?\n\n% It turns out that the straightforward design mentioned above fails to address some issues. Nevertheless, it has many of the correct ideas; in particular, we shall continue to look at designs where one set of parties are miners (executing the longest-chain protocol) and another set of parties are checkpointers (executing a BFT protocol). The correct design requires a more careful integration of the BFT protocol with the longest-chain protocol. To appreciate these nuances, we first specify in more detail the safety and the liveness requirements from the two different confirmation rules. Next, we look at some attacks that violate one or more of these requirements. These attacks pave the way towards the correct design. \n\n% \\section*{The Desired Properties}\n% To state the desired properties, we must first state some settings of the environment.\n\n% \\subsection*{Environment conditions}\n% \\paragraph{Variable Participation Setting} In this setting, the number of active participants in the protocol varies with time and cannot be predicted beforehand. By participants, we refer to both miners and checkpointers. To elaborate:\n% \\begin{itemize}\n%     \\item {\\bf Miners:} We assume that the number of active miners does not vary too rapidly, and thus the mining rate of the system remains more or less constant. In essence, the variable level of participation does not affect the PoW mining component of the protocol. We also assume that the fraction of active adversarial miners among all active ones is bounded throughout by $\\beta < 1/2$. The longest-chain protocol is both live and safe under this setting.\n%     \\item {\\bf Checkpointers:} Recall that there are at most $N$ checkpointers ($N$ is known and fixed). In the unsized setting, the number of active checkpointers can only reduce. We model inactive checkpointers by terming them \\textit{sleepy} (or offline). A sleepy checkpointer neither sends nor receives messages. The adversary can control when a certain checkpointer becomes sleepy or active. When the number of active checkpointers is $n$, we assume the number of active adversarial checkpointers is bounded by $f < n/3$. Any committee-based BFT protocol is not guaranteed to be live under these settings, although it does remain safe.\n% \\end{itemize}\n\n% \\paragraph{Static Participation Setting} The \\textit{static participation} setting, where all $N$ checkpointers are active. It is a special case of the variable participation setting. Both the longest-chain protocol and committee-based BFT protocols are safe and live under static participation.\n\n% \\paragraph{Asynchrony} Asynchrony refers to a network condition where messages can be delayed for arbitrarily long times. The adversary has static control of message delivery, and can deliver messages in arbitrary order, whenever it pleases. This statement applies to messages sent by miners and checkpointers, both. We know that committee-based BFT protocols are safe under asynchrony, but not necessarily live. The longest-chain protocol loses both safety and liveness under extended periods of asynchrony.\n\n% \\paragraph{Synchrony} Synchrony refers to a network condition where all messages suffer a bounded delay $\\Delta$, and this $\\Delta$ is known. Both the longest-chain protocol and committee-based BFT protocols are safe and live under synchrony. Synchrony can be thought of as a special case of asynchrony.\n\n% Clearly, the static participation setting and the synchronous setting are the ideal conditions under which both protocols are safe and live. Under variable participation, the longest-chain protocol with the $k$-deep rule is the preferred protocol, while under asynchrony, one would prefer to have a BFT protocol. In the real-world, we may encounter both scenarios! In such a case, it is desirable to have a protocol of the form we outlined above.\n\n% \\subsection*{Formal Properties}\n% Having defined the conditions above, we can now state what we want from an adaptive confirmation rule and a finality-guaranteeing confirmation rule.\n\n% \\paragraph{Adaptive rule:} The adaptive confirmation rule must remain safe and live under synchrony, and under variable participation. By default, this also includes the setting of static participation.\n\n% \\paragraph{Finality-preserving rule: } The finality-preserving confirmation rule must remain safe under asynchrony and under variable participation, i.e., under all conditions. Under synchrony and static participation, it must be live.\n\n% In summary:\n% \\begin{quote}\n%     The adaptive rule should have security properties of the longest-chain protocol and the finality-preserving rule should have security properties of a committee-based BFT protocol.\n% \\end{quote}\n\n% In particular, this means that the finality-preserving rule should become live whenever the setting changes from asynchrony to synchrony, and from variable to static. \n",
    "lecture_12b.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage[english]{babel}\n\\usepackage{listings}\n\\usepackage{fancyhdr}\n\\usepackage{makecell}\n\\usepackage{threeparttable}\n\\usepackage{subfig}\n\\usepackage{graphicx}  \n\\newsavebox{\\measurebox}\n\\pagestyle{plain}\n\\fancyhf{}\n\\usepackage{tabularx} \n\\usepackage{multirow}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n%\\usepackage{hyperref}\n\\usepackage{markdown}\n\\usepackage{amsthm}\n\\usepackage{caption}\n%\\usepackage{subcaption}\n\n\\newcommand{\\indicator}{{\\bf 1}}\n\\newcommand{\\pramod}[1]{{\\color{red}\n\\footnotesize[Pramod: #1] }}\n\\newcommand{\\xw}[1]{{\\color{green}\n\\footnotesize[Xuechao: #1] }}\n%\\let\\proof\\relax\n%\\let\\endproof\\relax \n\n\n\n\\newcommand{\\POM}{$\\mathsf{POM}\\ $}\n\\usepackage{float}\n\\usepackage{amsmath}\n\\usepackage[colorlinks=true, allcolors=blue]{hyperref}\n\\graphicspath{ {./figures/} }\n\\newcommand{\\h}{\\textsf{H}}\n\\newtheorem{lemma}{Lemma}[]\n\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 13}\n\n\\title{Lecture 13:   Layer 2 Scaling: Payment Channels}\n\\author{\nPrinciples of Blockchains, Princeton University, \\\\ \nProfessor: Pramod Viswanath \\\\ \nScribe: Ranvir Rana\\\\\n}\n%\\date{March 4, 2021}\n\\date{\\today}\n\n\\begin{document}\n\\maketitle\n\n\\begin{abstract}\n    So far, we have considered scaling methods that alter the consensus protocol itself (albeit in modest ways). In this lecture, we study how to scale existing blockchain performance {\\em without} changing the consensus layer. This is done  by extracting trust from the  consensus embedded in the core blockchain, but offloading computation and storage. Given that the consensus protocol (layer 1) is untouched, these methods are known to afford {\\em Layer 2} scaling. Two prominent instances are  {\\em payment channels} (focused on the UTXO state management system) and {\\em side blockchains} (can handle account based systems and smart contracts). This lecture studies the former of these methods.\n\\end{abstract}\n\n\n\n\\section*{Introduction}\nIn the last three lectures, we have considered proposals to scale throughput, latency, storage, communication and computation. In each of these proposals, the longest chain consensus protocol was modified. In a practical blockchain already operating in the real world, it is quite onerous to change the consensus layer: such a change would require a ``meta consensus\" among the participating nodes, i.e., consensus on how to change the consensus mechanism! Even a successful switch in the consensus mechanism would still lead to a ``hard fork\" in the ledger where the two paths would be following different consensus protocols. In this context, proposals to scale performance without changing the consensus layer are very appealing. Such are the goals of this lecture, where we discuss the two most promising ``layer 2\"  proposals that scale performance by offloading computation and storage  without impacting the core technology of blockchains (``layer 1'') and overall security. The first mechanism is via {\\em side chains} and allows a general account based model and smart contract. The second mechanism is via {\\em payment channels} and is more restricted, e.g., to the UTXO model of handling payments.  \n\n\n\n\\section*{Payment Channels}\nPayment channels support users to make payments for multiple times off chain while only submitting transactions on-chain to start the channel and handle a dispute. It locks parts of the state of the blockchain when starting a channel, processes transactions associated with this locked state in an application layer, and finally unlocks the channel with the updated state.\n\nIn a UTXO system like Bitcoin, a transaction contains a sequence of inputs and outputs. Outputs serve as {\\em locks} for a specific amount of funds, while inputs serve as keys of corresponding outputs to unlock the funds and transfer them between accounts. There are three new types of cryptographic primitives that allow ``flexible locks\", so that the trust can be extracted outside the blockchain. In particular there are three important cryptographic primitives we explore here.\n\\begin{itemize}\n    \\item {\\sf Multisig}. the locking transaction needs to be signed by $k$ out of $n$ public keys\n    \\item {\\sf Hashlock}. unlocking requires the owner's public key and a secret\n    \\item {\\sf Timelock}. requirement is related to block height and other time-based conditions\n\\end{itemize}\n\n%Generally, \\textsf{KeyGen} $\\rightarrow (sk, pk)$\n%\\pramod{Need to go through these 3 crypto primitives in detail, give directions to libraries and setup some MPs if possible. The idea is that these details will really help in the description of the payment channels below. }\n\n\nAccording to the payment direction,  payment channels can be classified into three categories, one-way payment channels, two-way payment channels and payment networks. Here we discuss the first two types. %\\pramod{if things are getting complicated, we can just focus on the first type. The important thing is to explain in as much detail as needed to actually code up a prototype. The lecture notes are a form of engineering spec, not a Wiki article. :-)}\n\n\\subsection*{One-way payment channels}\nOne-way payment channels  only allow funds to flow in one direction, from payer to recipient. For example, suppose Alice wants to pay Bob in increments of 0.1 BTC up to a maximum of 1 BTC. Each of the payments can be made ``on-chain\", however the payment channel proceeds in the following steps (see Figure~\\ref{fig:channel}). \n\\begin{enumerate}\n    \\item \\textbf{Creating the channel.} Alice signs a {\\em funding transaction} and posts it on the blockchain to create the channel. The funding transaction contains a single input with 1 BTC that is signed by Alice, the output can either: \n    \\begin{itemize}\n        \\item contain an address that is derived from both Alice and Bob's public keys (\\textsf{multiaddr = GetAddrbyAccount(pk$_1$, pk$_2$)}). And it can only be unlocked with both Alice and Bob's secret keys, neither one can unlock it alone. \n        %\\peiyao{The sentence should give such information: there exist a function we can use to generate address given pubkey, the unlock part will be explained below in closing the channel point.}\n        % \\pramod{can you talk a bit about how the multisig is executed, whether it is off-chain or on-chain and how the off chain is reflected onto the on-chain transaction?}\n        \\item contain Alice's address, and a timelock that specifies the expiration time of the channel.  %\\pramod{there is something weird about this part -- we are talking about how Alice pays Bob, but you are only covering what happens if Bob is not paid and how Alice recovers her money} \\peiyao{This is the second branch. \n        If Bob is online, he can receive the payment through posting a closing transaction, otherwise the coins return to Alice after the time expires. \n    \\end{itemize}\n    \\item \\textbf{Updating the payments.} After creating the channel, Alice can make payments to Bob and each payment creates an intermediate off-chain transaction, which is called {\\em commitment transaction}. A commitment transaction uses the output of funding transaction as input, and specifies how the funds held by Alice are sent to Bob through the output, e.g. 0.9 BTC to Alice, 0.1 BTC to Bob. Alice can continue paying Bob through the payment channel in this fashion. Each time she wants to pay another 0.1 BTC to Bob, she constructs a new commitment transaction from the same funding transaction output and sends it to Bob. Those commitment transactions are held by Bob, who can later decide to post any one (and only one) of them to the blockchain to receive the funds.\n    \\item \\textbf{Closing the channel.}  To close the channel, a {\\em closing transaction} is generated and posted on blockchain to close the channel and update the state. There are two possible ways to close the channel corresponding to the funding transaction,\n    \\begin{itemize}\n        \\item Cooperative: Bob posts a commitment transaction, whose input contains a signature signed with both Alice and Bob's secret keys (2-of-2 {\\sf multisig}). The signature will be verified on-chain and once it matches the output address of a funding transaction, Alice successfully makes the payments.  %\\peiyao{this paragraph corresponds to two functions in MP, sig = sign(sk1, sk2) and verify(multiaddress, sig)}\n        \\item Non-cooperative: Bob is offline and channel expires (e.g. one-day {\\sf timelock}), Alice posts the closing transaction on chain whose input contains Alice's signature and an expired timelock, Alice recovers her money.\n    \\end{itemize}\n\n\\end{enumerate}\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.6\\textwidth]{figures/channel.png}\n    \\caption{A one-way payment channel example.}\n    \\label{fig:channel}\n\\end{figure}\n\\subsection*{Two-way payment channels}\nTwo-way payment channels enable two parties to transfer funds to each other. Suppose now Alice and Bob both have 0.5 BTC to make payments. Consider the following steps (see Figure~\\ref{fig:2channel}). \n\\begin{enumerate}\n    \\item \\textbf{Creating the channel.} The funding transaction now contains two inputs, each with 0.5 BTC, the first is signed by Alice and the second is signed by Bob. The output contains 1 BTC signed by both Alice and Bob using 2-of-2 {\\sf multisig}. Before starting making payments, Alice and Bob will each create a secret and exchange the hashes of the secrets with each other.  The opening transaction will not be signed and posted on-chain until Alice and Bob receive a special commitment transaction respectively. The commitment transaction  here will contain an input with 1 BTC signed by both Alice and Bob (the output of a funding transaction), and two outputs. For the transaction that is held by Alice, the outputs are (1) 0.5 BTC to Bob, and (2) 0.5 BTC with timelock to Alice or to Bob if he knows Alice's secret, these outputs are signed by Bob. Similar for Bob, the outputs are signed by Alice and contain (1) 0.5 BTC to Alice, and (2) 0.5 BTC with one-week timelock to Bob or to Alice if she knows Bob's secret.\n    \\item \\textbf{Updating the payments.} Alice and Bob start generating a normal commitment transaction. Suppose Alice wants to send Bob 0.1 BTC, then she will sign a transaction with outputs: (1) 0.4 BTC to Alice, and (2) 0.6 BTC with one-week timelock to Bob or to Alice if she knows Bob's secret. For each payment, Alice and Bob will generate a new secret and exchange the older secret to ensure that the older transaction will not be posted on chain.\n    \\item \\textbf{Closing the channel.} When one of the parties is offline, the channel can be closed by revealing any one of the commitment transactions in a non-cooperative way. And in the cooperative situation, Alice and Bob can create a transaction sending the settled balance to each party.\n\n\\end{enumerate}\n\n\n\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.6\\textwidth]{figures/twoway.png}\n    \\caption{A two-way payment channel example.}\n    \\label{fig:2channel}\n\\end{figure}\n\n\n\\subsection*{Multi-hop payment channels}\n\n\n\n\n\\end{document}",
    "lecture_10.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\usepackage{markdown}\n\\usepackage{amsthm}\n\\usepackage{caption}\n\\usepackage{subcaption}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\newcommand{\\indicator}{{\\bf 1}}\n\\newcommand{\\pramod}[1]{{\\color{red}\n\\footnotesize[Pramod: #1] }}\n\\newcommand{\\xw}[1]{{\\color{green}\n\\footnotesize[Xuechao: #1] }}\n%\\theoremstyle{definition}\n\\newtheorem{definition}{Definition}\n\\newtheorem{theorem}{Theorem}\n\\newtheorem{lemma}{Lemma}\n%\\let\\proof\\relax\n%\\let\\endproof\\relax \n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 10}\n\\cfoot{\\thepage}\n\n\\title{Lecture 10: Sharding: Scaling Storage, Computation and Communication}\n\\author{Principles of Blockchains, Princeton University,  \\\\ Professor:  Pramod Viswanath \\\\ Scribe:  Ranvir Rana}\n%\\date{March 2, 2021}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nBitcoin security relies on full replication: all nodes store the full ledger, validate the full ledger and communicate the full ledger to each other. The security of Bitcoin is tied crucially to the replication and we see that there is an inherent trade-off between security and efficiency. Sharding aims to ameliorate, or entirely eliminate, this tradeoff: Can a blockchain be both secure and efficient in storage, communication, and computation requirements? Such are the goals of this lecture. \n\\end{abstract}\n\n\\section{Introduction}\n\nBitcoin uses {\\em full replication}: everyone stores every block, everyone validates/computes on every block and everyone communicates every block. Thus the number of participants does not change the load per node (in terms of storage, compute, communication); i.e., the total load of the network grows linearly with the number of participants in the blockchain. \n\nMore nodes joining the network implies greater participation which comes with the need for greater throughput; however, if every node replicates the complete ledger, the waste in resources (and hence the cost of a transaction) increases with the increasing number of nodes. This additional resource burden is a negative network effect; not desirable in distributed systems relying on a big network for security. \n\nMany distributed systems scale their ``load\" with an increasing number of nodes. %Such scaling with the increase in the number of nodes is termed as {\\em horizontal scaling}. \nConsider BitTorrent protocol for file-sharing:  if more nodes join the network, the number of nodes storing a file of interest increases. Thus a single file request can be routed to a single node with lower probability, hence decreasing the load per file-request. \nThe property of the distributed system where the performance (in BitTorrent's case, the number of files that can be distributed) scales {\\em linearly with the number of participating nodes} is called {\\em horizontal scaling}. This is in contrast to {\\em vertical scaling}, where the performance is improved to the best possible for a fixed number of nodes (and associated peer to peer network); this was the focus of the previous two lectures, improving throughput  and latency for a fixed underlying physical network. \n\nBlockchains have a different requirement from simple file-sharing systems in addition to being Byzantine fault tolerant: it needs to maintain consensus on ledger order, i.e.,  every node should agree on the location of any particular transaction in the ledger. \nIntuitively, if you need to decrease the ``load\" per node per transaction, you need nodes to not  see all transactions. But how can a node agree on the order of all transactions if it hasn't seen all transactions? The fact that some protocols can achieve horizontal scaling seems surprising!  Horizontal scaling is achieved using an idea called {\\em sharding}; the idea, with origins in distributed database theory, is to split the  database  into subsets with  each  subset  stored by a different subset of nodes. Thus full replication is averted. A principled approach to sharding in blockchains, and full horizontal scaling in blockchains is the focus of this lecture; we begin with the following first order approach to sharding in blockchains. \n\n\n\n\\noindent {\\bf First order approach to Sharding. }\nSuppose the ledger can be split into $K$ exclusive and exhaustive non-intersecting subsets; this is natural when the ledger is composed of ``independent\" applications which do not interact with each other and no transaction crosses the application boundaries. Later in the lecture, we will eliminate this assumption by allowing {\\em   cross-shard} transactions. \nThe simplest idea is to let each of  $K$ applications   be managed as independent blockchains. The ledger is split into $K$ non-interacting sub-ledgers called shards. However the total number of participating nodes, $N$ is shared across the blockchains; in sharding, each node participates in maintaining only one of the shards. In this first order approach, each shard runs its own consensus protocol independent of other shards, e.g., we maintain  $K$ blockchains (managed by the longest chain protocol) in parallel, with each blockchain  maintained by $N/K$ nodes. Since a node maintains only one shard, it maintains only a $1/K$ fraction of the ledger (also denoted as the ``state\" of the blockchain); thus the maintenance (storage, computation/validation, and communication) costs are a fraction  $1/K$  of the overall ledger. In principle, $K$ can increase linearly with $N$, while ensuring each shard is maintained by a constant number of nodes; thus optimal horizontal scaling is achieved.  This increase in efficiency comes with  {\\em reduced security}: the overall security is limited by the security of any one of the shards and  an adversary can tamper with the state by attacking just one shard. Attacking a single shard is easier than if a single   blockchain was maintaining all the applications; this is because  the attacker needs to only compete with $N/K$ nodes instead of $N$ nodes (in the PoW longest chain protocol, the adversary congregates all its mining effort on one of the shards while honest mining is split among the shards).  In summary, the first order approach provides an order $K$ horizontal scaling, but by decreasing security by a factor of $K$. How to provision horizontal scaling with no security repercussions is the topic of this lecture. \n\n% Hence we need to dig deeper into the scaling solutions offered by distributed systems: We will discuss a key technique used to engineer distributed systems that scale better than replication: {\\em coding}. Consider the following use cases where coding provides storage, communication or computation scaling.\n\n%\\noindent {\\bf Scaling Using Coding}\n%Suppose we want to design a crash fault-tolerant distributed storage system that can handle crashes from a certain fraction of nodes. If the number of nodes increases, so does the number of nodes that can fail. Let us design a system that can handle $f=0.25n$ faults; if we were to simply replicate data across nodes, we would need to copy the data to $f+1=0.25n+1$ nodes, a number increasing with $n$. A more efficient solution is to slice the data into $n/2$ slices, erasure code it to $n$ slices, and store each slice on a different node. This protocol tolerates $f=O(n)$ faults with a file being replicated only twice.\n\n%We can find similar examples of using coding for scaling networks and computation. In network coding, a node combines the received packets to generate a coded packet; the destination node on receiving the coded packets combines them to decode it. Decoding a packet is possible even if a subset of them arrive; network coding achieves similar performance as routing (low replication) but with higher resiliency of network edge failures. Similarly, computation on such coded data can be done via Lagrange coded computing which uses the Lagrange Polynomial to substitute any computation. In all these cases, errors were random/benign. In our case, we also need byzantine resistance and consensus to work. \n\n%First, we scale storage alone. We do this using a simple example of distributed storage via erasure coding discussed above. We observe that classical blockchains are implementing replication coding, an inefficient way to store information. Can we use more efficient error-correcting codes to achieve the same security?. This idea leads to {\\bf Polyshard}, a sharding system with storage scaling but no compute/communication scaling. In Polyshard, rather than storing and processing one uncoded shard, each node stores and computes on a coded shard of the same size generated by linearly mixing uncoded shards, using the well-known Lagrange polynomial. Every computational step can be regarded as a Lagrange polynomial; thus, coding provides sufficient redundancy while providing resilience against malicious actors that can be considered errors for the error-correcting code. The fact that we can run computation of the coded ledger allows us to run transactional ledgers using coding. Therein lies the main drawback of Polyshard, computations have to be encoded as a Lagrange polynomial. However, the degree of the polynomial can be huge if the state transition function is complex (say a smart contract); thus, Polyshard is practical as for as computation scaling is concerned only of the Lagrange polynomial is linear. In case of an attack (or claim of an attack) at the stage of coded block dispersal, the nodes need to coordinate to verify the coded blocks' consistency. This coordination involves collecting almost all of the coded blocks for different shards; thus, communication fails to scale. How to fix these problems? We consider two broad approaches used in the sharding literature to scale all three resources: communication, computation, and storage. All of these approaches use uncoded shards, just like the strawman approach.\n\n\\section{Multiconsensus architecture}\nConsider the following extension of the first order approach: this time, the allocation of which node maintains which shard is uniformly random. In the first version, the random allocation is managed  by a {\\em cryptographically secure oracle} which all nodes have access to; further any node can verify if a fellow participant is managing the shard that it rightfully should (according to the oracle).   The key impact of this modification is that adversaries can no longer congregate in a single shard (with the aim of attacking it); the intuition is that if majority exists in the overall set of nodes, then the random node to shard allocation engine transfers this property to each shard thus maintaining the original security level.\n\nThe random reallocation is enabled by a node to shard allocation engine (N2S). The \ncryptographically secure random allocations of N2S can be maintained by a separate service or as part of the blockchain.  \\href{https://eprint.iacr.org/2016/1067.pdf}{RandHound} is a state of the art distributed randomness generator, external to the blockchain. An intra-blockchain N2S assigns nodes to shards using a (shared) distributed randomness, generated using a  consensus engine {\\em shared across all shards} and commonly referred to as a ``beacon\" consensus engine. The beacon only contains state commitments and N2S allocation metadata. Since N2S allocation metadata mostly involves validator ids and state-commitments are mostly cryptographic hashes posted at large intervals of time (a hash per 10,000 shard transactions for example), the load on a beacon chain is minimal compared to transactions payload on a shard. This makes the ``beacon\" consensus engine lightweight and thus we can ask all nodes to maintain it. \n\nWhile this solution seems a straightforward way to achieve horizontal scaling, the corresponding security and level of scaling are quite limited:\n\\begin{itemize}\n    \\item First, the N2S allocation inherently requires each node to have an {\\em identity}. So this sharding procedure cannot be permissionless, a departure from {\\sf Bitcoin}'s design.\n    \\item Second, for the random allocation to preserve the fraction of honest hashing power in {\\em each} shard (so global majority of honest hash power translates to majority honest hash power in each shard and hence provide security of consensus in each shard), the number of nodes per shard has to be substantial. This limits the number of shards $K$ as a function of the number of nodes $N$, see Figure~\\ref{fig:shardingrandom}.  \n    \\item Third, the architecture is not secure against an {\\em adaptive} adversary, which can corrupt miners {\\em after} they have been allocated to a shard; an adversary can readily implement this attack in practice by allowing miners to advertise their shard allocations on the public Internet, allowing for collusion (i.e., corruptions) inside one of the shards. This is especially problematic as only a small fraction of nodes need to collude to attack a shard (a majority of the $\\frac{N}{K}$ nodes in each shard).  A standard method to avoid such an attack is to regularly {\\em reallocate} the N2S allocations; the idea is that by the time allocated nodes can coordinate and collude, a reallocation is conducted. Security is provided by  rotation among the shard allocations only if such rotations are fast enough;  the faster the rotation, the more the overhead of the N2S procedure (the overhead scales linearly with the number of the nodes $N$), diminishing the horizontal scaling effect. \n\\end{itemize}\nEach of these three limitations is resolved in a full sharding solution, described next. \n\\begin{figure}\n     \\centering\n     \\includegraphics[width=10cm]{figures/multiconsensus_shardMajority.pdf}\n    \\put(-285,120){\\rotatebox{90}{$P_{secure}$}}\n    \\put(-140,15){N}\n   \\caption{Probability that every shard is secure (i.e., honest supermajority in each of the $K=10$ shards) as a function of the number of users $N$ under different adversarial models (10\\%, 20\\%, 25\\% and 30\\% net adversarial fraction)}\n   \\label{fig:shardingrandom}\n \\end{figure}\n\n\n\\section{Uniconsensus architecture}\nRather than relying on a small subset of nodes to maintain a shard, the uniconsensus architecture relies on the consensus amongst all nodes to maintain each shard; this significantly improves multiconsensus architecture's security properties. This is done by having every node participate in a single main consensus engine, as the word ``uniconsensus\" connotes. While every node participates in the main consensus engine, each node picks a shard of its choice to mine shard blocks (self-allocation). The single consensus engine only maintains a {\\em log of the hash of shard blocks} and hence is scalable. Its light size allows every node to maintain the consensus engine. But how to couple the shard blocks with the main consensus engine, and how to ensure this coupling is adversary-resistant? This is achieved using the same idea we have seen in the past three lectures, scaling fairness (Lecture 7), scaling throughput (Lecture 8) and scaling latency (Lecture 9): many-for-one mining of a superblock and cryptographic sortition into constituent sub-blocks. \n\nThe data structure of a uniconsensus architecture consists of two types of block structures: a {\\em proposer} blocktree consisting of {\\em proposer} blocks responsible for the single consensus engine and $K$ shard ledgers consisting of shard blocks. The proposer blocks are organized into a blocktree by a PoW based Nakamoto longest chain consensus protocol. Proposer blocks also contain hash-pointers to shard blocks which are used to order shard blocks in each shard using the longest chain of the Proposer blocktree. Shard blocks  are identified with their respective shards via their $ShardID$. The shard blocks contain shard transactions and as with transaction blocks in {\\sf Prism} (Lectures 8 and 9), do not contain any blocktree pointers. This lack of pointers is because the ordering of shard blocks is inferred solely from their order in the main consensus engine (the longest chain of the proposer blocktree) -- exactly as in {\\sf Prism}. The sole job of shard block mining is adversary resistance and plays no role in shard block ordering. This data structure is depicted in Figure \\ref{fig:uniconsensus}, where the shard ledger is constructed by ordering shard blocks according to the order of their corresponding hash pointers in the proposer chain.\n\n\\begin{figure}\n     \\centering\n     \\includegraphics[width=10cm]{figures/bitcoin_uni.pdf}\n   \\caption{Data structures in the Uniconsensus architecture. }\n   \\label{fig:uniconsensus}\n\\end{figure}\n\nSecurity relies on the fact that every miner mines proposer blocks and not solely shard blocks; We ensure this via {\\em many-for-one mining} and {\\em sortition}. Proposer and shard blocks are mined {\\em simultaneously} using a $2$-for-1 PoW sortition algorithm. A mining node creates a superblock comprising a potential shard block (for a shard of the node's choice) and a potential proposer block and mines a nonce on a header comprising of hash commitments of both the blocks. If the hash of this superblock falls between $0$ and $\\tau_1$ (proposer block mining difficulty), then it is treated as a proposer block, else if it falls between $\\tau_1$ and $\\tau_2$ (a shard specific variable) it is treated as a shard block for the identified shard. This ensures that adversaries cannot focus their mining resources selectively on mining either proposer or shard blocks. Moreover, the potential shard block's shard-id is fixed during the mining process, ensuring that a single mining attempt only creates a shard block for one shard (of the miner's choice). The shard block mining difficulty is periodically adjusted for each shard to ensure a constant shard block generation rate for each shard. This $2$-for-one PoW sortition is shown in Figure \\ref{fig:sortition}.\n\n\\begin{figure}\n     \\centering\n     \\includegraphics[width=10cm]{figures/sortition1.pdf}\n   \\caption{Uniconsensus architecture: $2$-for-one PoW sortition.}\n   \\label{fig:sortition}\n\\end{figure}\n\nIt is straightforward to see that the uniconsensus architecture scales the resource usage. Any node only maintains the proposer blocktree and a shard ledger of its choice; the node will not maintain the shard ledgers of the rest $K-1$ shards. Maintaining only a fraction $\\frac{1}{K}$ of the overall ledger improves efficiency and enables scaling with the number of nodes since most of the storage, computation, and communication resources of the blockchain are used up in maintaining transactions.\n\nAn honest consensus majority is no longer needed in each shard to preserve safety; hence uniconsensus architecture is safe against a fully adaptive adversary. Consider a shard with less than a majority of honest nodes; the shard's adversarial nodes cannot change the log of shard blocks without violating the consensus engine's safety. This is prohibitively difficult since everyone maintains the consensus engine. \n\nAn important distinction from multiconsensus is that each node is free to join a shard of its choice; an N2S allocation is not required since an honest majority within a shard is no longer required. This architecture guarantees the order of transactions in the shards. Shard nodes perform shard block execution and sanitization of invalid transactions once the order is finalized. \nWe summarize how the uniconsensus architecture overcomes the limitations of multiconsensus architecture:\n\\begin{enumerate}\n    \\item {\\bf Identity-free sharding}. No N2S allocation is needed, hence no need to have an  on-chain validator/miner identity. \n    \\item {\\bf Small number of nodes per shard}. There is no need for honest majority within a shard, hence the constraints established in Figure \\ref{fig:shardingrandom} do not apply.\n    \\item {\\bf Adaptive adversary resistance}. Destroying honest majority in a shard is no longer an attack; this achieves resistance to safety violations by corrupting a shard. Moreover the mapping of miner-identity to shard-id  does not exist on-chain, weakening the targeting capabilities of adaptive adversaries. \n\\end{enumerate}\n\nUniconsensus architecture allows nodes to self-allocate. While this adds to the freedom of nodes to choose a shard of their choice and removes the node's shard allocation from public knowledge, it allows a liveness attack. An adversary can concentrate its mining power on one shard and drown out honest shard blocks. The fraction of honest blocks to the adversarial blocks is significantly reduced due to a large fraction of adversarial nodes in the shard. This adversarial concentration can throttle the throughput of honest transactions in the shard under attack, leading to a loss in liveness. A dynamic self-allocation (DSA) algorithm like \\href{https://arxiv.org/abs/2005.09610}{Free2Shard} can be used to prevent  such liveness attacks. DSA lets honest users allocate themselves to shards in response to adversarial action without the use of a central authority. An intuitive way as to how DSA works is by allowing honest nodes to choose to relocate themselves to shards that have low throughput (perhaps due to liveness attack); such relocation is further incentivized by higher transaction fees due to the low throughput. \n\n\\section{Bootstrap and State-commitment}\n\nIn both the above architectures, honest nodes need to relocate themselves to new shards.  When a node joins a new shard, it has to download the state of the shard -- this relocation causes scaling deterioration, which worsens with increasing rate of relocation.   Thus, an important question is how to {\\em efficiently} relocate to the new shard; this problem is similar to bootstrapping in a blockchain. One option is to process the whole ledger; however, doing so would  nullify any scaling benefits from sharding since a node will now have to process the ledger of all shards eventually. A more efficient way to deal with this issue is to download the latest state of that shard. However, the bootstrapping node  cannot trust  a shard-node to provide the correct state. This highlights the need for {\\em trusted} state-commitments. State-commitments are {\\em accumulators} of a ledger's state, which are agreed upon to be correct by everyone in the network. The bootstrapping node can download the state and verify its correctness using the state-commitments. We discuss the details of the accumulator used for state commitments and how they are generated next.\n\n\\subsection{Accumulator for State-commitments}\nIn the simplest sense, a ledger's state consists of $(account, value)$ tuples. We need to design an accumulator for these tuples. Since the state-commitments need agreement over the network, there needs to be a one-to-one mapping (within cryptographic bounds) from state to state-commitment. \n\nThe most common accumulator we have used throughout the course is the root of a Merkle tree. Unfortunately  a Merkle tree's root cannot be used for state-commitments: while each node has the same state, the nodes can order the tuples differently while creating a Merkle tree, leading to different roots breaking the one-to-one mapping. The key is to  use an {\\em ordered} Merkle tree with order defined by account number; this way, the one-to-one mapping is preserved. However there are performance limitations to using an ordered Merkle tree for state: it is very costly to add or remove an account from an ordered Merkle tree. Adding an account will lead to insertion in the middle, a very expensive operation if the Merkle tree is large. Hence, ordered-Merkle trees  are not used for state-commitments. \n\nThe dynamic nature of the ledger state with insertions and deletions of accounts warrants the use of a {\\em sparse} Merkle tree. A sparse Merkle tree is a Merkle tree with a fixed but very large number of leaves; there exists a distinct leaf in the tree  \nfor every possible output from a cryptographic hash function (every possible account number). It can be simulated efficiently because the tree is sparse (i.e., most leaves are empty). Moreover, insertion and deletion of accounts is computationally simple since a distinct leaf already exists. The sparse Merkle tree is constructed with the value of a leaf being the balance in that account (leaf id = account id) if it exists or null if it does not exist. This sparse Merkle tree with  only two accounts  is illustrated in Figure \\ref{fig:sparseMT}. In practice, a compressed form of sparse Merkle trees called {\\em Merkle Patricia Trie} (MPT) is used;  MPT has similar insertion and deletion complexity (O(1)) as a sparse Merkle tree. \n\n\\begin{figure}\n     \\centering\n     \\includegraphics[width=10cm]{figures/smt1.pdf}\n   \\caption{State-commitment using a sparse Merkle tree.}\n   \\label{fig:sparseMT}\n\\end{figure}\n\nA state commitment consists of the root of a Merkle Patricia Trie of a shards execution state. It is generated at regular intervals (termed epochs) on the ledger. The root is posted on the beacon chain (multiconsensus  architecture) or the main consensus engine (uniconsensus architecture).  \n\n\\subsection{Generation and agreement on state commitments}\nThe entire process of state commitments discussed so far assumes that state commitments are honest. In practice, a Byzantine-fault-tolerant way of posting state-commitments needs to be established for both architectures. This is the focus of the following discussion. \n\n\\subsubsection{Multiconsensus}\nState-commitment generation is particularly straightforward for the multiconsensus architecture due to the strong underlying assumptions that the nodes have identity and that each shard has an honest majority. Under this assumption, a state-root is generated by any node and signed by a majority of the shards nodes making it a state-commitment. The state-commitment can be assumed to be correct since each shard is assumed to have an honest super-majority. Better yet, a state-commitment can just be treated as a regular transaction on the shard with deterministic validation rules within the ledger (execution state at that point in the ledger must match the state-commitment). State-commitments are periodically posted on the beacon chain to make it easy for incoming nodes from different shards to obtain the latest state commitment. Posting state-commitments on beacon chain is fine since state-commitments are very small in size (size of a cryptographic hash output). \n\n\n\\subsubsection{Uniconsensus}\nState-commitment generation for the uniconsensus architecture is a bit more nuanced, stemming from the fact that we no longer suppose identity of the nodes or that each shard has an honest majority. Moreover, we also assume that not all transactions included in the ledger are valid; this is because validation is decoupled from ordering, i.e.,  transaction validation is conducted by the {\\em sanitization} process after the order of transactions has been agreed upon. One cannot query the whole network to verify the state-commitment since it will defeat the purpose of sharding (all nodes will have to process all shards). Thus protocols that don't rely on a majority of nodes being honest to run a verifiable computation are needed. The solution below incorporates two new ideas: (1){\\em interactivity}  among the nodes generating the state-commitment and (2) relying on honest nodes to detect  {\\em fraud} in the broadcasts,  instead of the standard approach of proving the veracity of a broadcast. \n\nFraud-proof based state-commitments follow a ``assume correct if not proven wrong within a time-frame\" approach. The state-commitments are generated by specific parties in a shard called {\\em commitment leaders} and their broadcasts scrutinized for fraud by honest shard nodes.  If a fraud is found, then the proof of fraud is posted by one of the honest nodes (called challenger) on the main consensus engine: proposer chain. If no fraud proof is posted on the proposer chain within a time-frame, the state-commitment is assumed to be honest. This process is depicted in Figure \\ref{fig:uni_sc_1}. \n\nSince we aim to keep the proposer chain light (recall that every node maintains the proposer chain), the fraud proof has to be light. Consecutive state-commitments summarize thousands of transactions and we do not want the consensus engine to process all those transactions to verify a fraud-proof. Ideally we want the incorrect computation of state to be proven using just one transaction (or better yet, just one {\\em bytecode}). The pinning  down of the fraud proof of incorrect computation to one transaction is achieved by a logarithmic search across all transactions, described next. \n\n\\begin{figure}[h]\n\n\\begin{subfigure}{0.3\\textwidth}\n\\includegraphics[width=0.9\\linewidth]{figures/uniconsensus_sc_1.pdf} \n\\caption{Commitment-leader and challenger}\n\\label{fig:uni_sc_1}\n\\end{subfigure}\n\\begin{subfigure}{0.65\\textwidth}\n\\includegraphics[width=0.9\\linewidth]{figures/uniconsensus_sc_2.pdf}\n\\caption{Interactive fraud proof}\n\\label{fig:uni_sc_2}\n\\end{subfigure}\n\n\\caption{State-commitment in uniconsensus architecture}\n\\label{fig:uni_sc_all}\n\\end{figure}\n\n%The protocol for pinning down fraud-proof to one transaction is described briefly below:\nA {\\em logarithmic fraud search} mechanism consists of two parties: A commitment-leader and a challenger, each belonging to the same shard. Suppose the commitment-leader is adversarial, and   posts a state-commitment of the shard on the consensus engine. On seeing an invalid state-commitment, a challenger posts a challenge stating that the computation is incorrect. The following sequence of interactions summarizes the protocol once a fraud is detected and challenged. \n\\begin{itemize}\n    \\item The commitment-leader posts intermediate states for the challenged state. \n    \\item The challenger responds with a number indicating the first intermediate state when the challenger's view differs from the leader.\n    \\item The game continues to the next round with the leader posting intermediate states for the smaller challenged state and the challenger responding according to the previous step. \n\\end{itemize}\n\nThe interactions end when the conflict is resolved down to one transaction, i.e., the search for the single transaction is complete. The identified transaction is posted on the consensus engine to decide if a fraud has occurred or not. An example of this transaction search is illustrated in Figure \\ref{fig:uni_sc_2}. Once the fraud has been detected and the incriminating transaction found, this specific transaction is excised from the ledger and consensus is regained. In certain designs, the commitment-leader is penalized for this fraud: this penalty can be outside the blockchain in a PoW setting. We will shortly see the permissioning mechanisms of Proof of Stake (PoS) where the penalization can be handled {\\em within} the blockchain (e.g., via ``slashing a collateral transaction required to be posted by the commitment-leaders\"). The  fraud-proof mechanism together with the ability to penalize adversarial behavior incentivizes commitment-leaders to behave  according to the protocol. \n\n\\section{Cross-shard transactions}\n\nWe have assumed so far that the state can be split into $K$ subsets that do not interact with one another. While this setup appropriately models a large class of applications, it is interesting to resolve sharding to the fullest extent, by supporting cross-shard interactions. This is the focus of this section. For ease of understanding we will use the following example throughout  this section: We want a cross-shard transaction to send funds $(x_A,x_B)$ from input shards A, B to $(y_C,y_D)$ in output shards C, D. A fundamental question in enabling cross-shard transactions is the following: How do validators in shards C and D ensure that funds $(x_A,x_B)$ exist in shards A and B?\n\nScalability requires that nodes maintaining a shard do not need to know the state of  other shards. Thus nodes in output shards cannot directly verify whether the funds are available in input shards. However, an important observation is that each shard as a whole is safe and live in multiconsensus, and there are protocols that ensure safety and liveness of  state commitments in uniconsensus (as discussed above). Thus, each shard (or their state commitments) can be thought of as {\\em crash tolerant} and the following  commit/abort protocols can be used for successful  communication between shards. \n\nA required property for cross-shard transactions is {\\em atomicity}: %(look up ACID for database transactions): \nif a transaction is committed (aborted) in one shard, then it should be  committed (aborted) in all participating shards. In the context of our example, if funds $x_B$ do not exist in shard B, the transaction should not be executed in shard A, C and D respectively. Atomicity is simple to state,  yet subtle to ensure. Consider the following  one-stage cross-shard transaction protocol that appears tailor-made for ensuring atomicity: \n\\begin{itemize}\n    \\item Input shards (A and B in our example) update their state by locking funds $x_A$ and $x_B$ respectively for this cross-shard transaction $tx$. Their latest state commitments $S1_A$ and $S1_B$ can be used to prove that funds $x_A$ and $x_B$ are locked and cannot be used in shards $A$ and $B$ anymore. \n    \\item Proof of lock of funds $x_A$ and $x_B$ for transaction $tx$ is posted on shards $C$ and $D$ respectively. This proof is a simple merkle-proof from state commitments $S1_A$ and $S1_B$  available to both the output shards. On validating a correct merkle proof, shards $C$ and $D$ release funds $y_C$ and $y_D$ respectively.\n\\end{itemize}\nUnfortunately, this single stage protocol violates atomicity in the following scenario: suppose funds $x_B$ are not available in shard $B$. When this transaction is initiated, shard $A$ will lock $x_A$ and this will be reflected in state commitment $S1_A$.  However, shard $B$ will not lock $x_B$ since those funds do not exist. Since a proof of lock from both input shards is not available, output shards $C$ and $D$ will not release funds $y_C$ and $y_D$. The fund $x_A$ is locked forever, thus $tx$ was committed in shard $A$ and aborted in the rest of the shards; breaking atomicity. \n\n\nTo ensure atomicity, there must be a way to unlock the funds if one of the input shards fails to lock. To this end, the protocol above is generalized to multiphase commits: In particular,  two-phase commitment protocols work as follows:\n\\begin{itemize}\n    \\item Phase 1:\n    \\begin{itemize}\n        \\item A transaction manager TM is assigned to read state commitments across shards; usually a TM is the spending party/ies.\n        \\item If the input funds $x_A,x_B$ are available in shard A and B, respectively, both shards update their state to lock the funds if available. % (equivalent to send \"accept\" message in 2PC literature)\n        \\item If an input fund in shard $A$ is not available, the shard updates its state to mark fund $x_A$ unavailable by adding a {\\em receipt of unavailability} to its state.  %(equivalent to send \"reject\" message in 2PC literature) \n    \\end{itemize}\n    \\item Phase 2:\n    \\begin{itemize}\n        \\item If the TM sees that funds are locked in all input shards as per state commitments $S1_A$ and $S1_B$, it sends a proof of lock to output shards to generate $(y_C,y_D)$.  %(Called a \"commit\" message in 2PC literature)\n        \\item If the TM sees that funds are unavailable in one of the input shards as per state commitments $S1_A$ and $S1_B$, it sends a rollback transaction to all input shards which consists of proof of {\\em receipt of unavailability} in one of the input shards. The rollback transaction reclaims locked funds in the input shards. \n    \\end{itemize}\n\\end{itemize}\n\nThis two-phase commitment protocol ensures that all the input funds of the transaction are either spent or unspent; this in turn guarantees atomicity. There will never arise a case where some input funds are spent, and some are not spent. Consider the case discussed above; funds $x_B$ are not available in shard $B$. When this transaction is initiated shard $A$ will lock $x_A$ and it will be shown in state commitment $S1_A$, however, shard $B$ will not lock $x_B$ but post {\\em receipt of unavailability} in the state commitment $S1_B$. The TM can now send a rollback transaction to shard $A$ to unlock $x_A$. Hence the transaction would have been aborted in all the participating shards.\n\n\\begin{figure}\n     \\centering\n     \\includegraphics[width=10cm]{figures/2pc_1.pdf}\n   \\caption{Cross-shard two-phase commitment.}\n   \\label{fig:2pc}\n\\end{figure}\n\n\\section*{References}\n\nScaling blockchains horizontally has been an active area of research for quite some time. Most of the existing sharding solutions have utilized multiconsensus architectures: A good starting point to understanding a concrete sharding protocol that utilizes multiconsensus architectures is \\href{https://loiluu.com/papers/elastico.pdf}{Elastico}, \\href{https://eprint.iacr.org/2018/460.pdf}{rapidchain}\nand \\href{https://eprint.iacr.org/2017/406.pdf}{Omniledger}. Practical manifestations of multiconsensus include \\href{https://ethereum.org/en/eth2/shard-chains/}{Ethereum 2.0} and \\href{https://polkadot.network/technology/}{Polkadot}. Please refer to \\href{https://eprint.iacr.org/2016/1067.pdf}{Randhound} for detailed information on randomness generation used for N2S allocation in many of these protocols. \n\nVarious new horizontal scaling proposals utilize uniconsensus including\n\\href{https://arxiv.org/abs/2005.09610}{Free2Shard},\n\\href{https://arxiv.org/abs/1611.06816}{Aspen},\n\\href{https://near.org/downloads/Nightshade.pdf}{Nightshade}, and \\href{https://arxiv.org/abs/1905.09274}{Lazyledger}. The concrete uniconsensus protocol described in these lecture notes is derived from Free2Shard; it also contains DSA algorithms that can be used to solve the liveness issue. \n\nMany partial scaling protocols have been developed that scale one or more of the three resources:  \\href{https://www.zilliqa.com/}{Zilliqa} scales computation by partitioning validation and \\href{https://arxiv.org/abs/1809.10361}{Polyshard} scales storage by using coded storage and computation. \n\nDetailed information on state roots and Merle Patricia Tries are in the  \\href{https://ethereum.github.io/yellowpaper/paper.pdf}{Ethereum Yellow paper}. Free2Shard explains the interactive fraud-proof game in brief; a comprehensive description is in  \\href{https://people.cs.uchicago.edu/~teutsch/papers/truebit.pdf}{Truebit} and \\href{https://www.usenix.org/conference/usenixsecurity18/presentation/kalodner}{Arbitrum}. The Atomix and  Omniledger protocols provide  concrete examples of cross-shard transactions that use two-phase commits.\n\n\\end{document}\n\n\n\\section{Machine problem on sharding}\n\n\\begin{itemize}\n    \\item Accumulator: MPT\n    \\item State-root\n    \\item Light state-commitment proofs foreign shards\n\\end{itemize}",
    "lecture_06.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\usepackage{markdown}\n\\usepackage{amsthm}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\newcommand{\\pramod}[1]{{\\color{red}\n\\footnotesize[Pramod: #1] }}\n\\newcommand{\\xw}[1]{{\\color{green}\n\\footnotesize[Xuechao: #1] }}\n%\\theoremstyle{definition}\n\\newtheorem{definition}{Definition}\n\\let\\proof\\relax\n\\let\\endproof\\relax \n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 6}\n\\cfoot{\\thepage}\n\n\\title{Lecture 6:   Safety of Bitcoin}\n\\author{Principles of Blockchains, Princeton University,  \\\\ Professor:  Pramod Viswanath \\\\ Scribes: Suryanarayana Sankagiri and Xuechao Wang}\n%\\date{February 11, 2021}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nIn this lecture, we introduce a mathematical model of the Nakamoto consensus protocol, with the aim of formally analyzing the protocol's {\\em safety}, an important security property. To this end, we introduce the common prefix property, which is closely related to the  $k$-deep confirmation rule. We discuss different strategies that an adversary can adopt in order to violate the common prefix property. Assuming all communication is instantaneous, we see that the private attack is  the worst-case attack; we see that there is a tradeoff between $k$ and probability of error (i.e., safety of a block being violated).  In particular, the error probability decays to zero as $k$ increases, as long as honest miners control a majority of the mining power. When network delays are bounded away from zero, many more attacks are possible and thus the honest miners need to possess more than a simple majority of the mining power for the safety of Bitcoin: we characterize the exact fraction of honest mining power that is both necessary and sufficient for safety of Bitcoin (in the limit of $k$ large). Crucially,  this analysis is in the {\\em synchronous} network setting, where all messages are delivered to every node within a fixed propagation delay. The longest chain protocol is unsafe when the network deviates from the synchronous setting. \n\\end{abstract}\n\n\\section*{Introduction} \nThe last few lectures described the Bitcoin design, which is considered the prototypical blockchain system. In any blockchain system, the system's security is paramount. All aspects of the system are analyzed assuming there is an adversary that co-ordinates multiple peers so as to disrupt the system. For simplicity, we often talk of \\textit{the adversary} as a single party with considerable powers vis-a-vis other honest parties (e.g., more information, more computation power, control over the network).  \n\nThere are many different security measures in Bitcoin that are designed to protect honest users from an adversary. Of these, many are simple sanity checks that honest users perform. This includes verifying the proof-of-work, verifying signed transactions and validating transactions against the current UTXO set. An adversary that tries to cheat by violating any of these can easily be identified and its messages (blocks/transactions) ignored.\n\nIn contrast, attacks at the level of the Nakamoto consensus protocol are of a different nature. Firstly, it is not always evident to honest players that an adversary is attacking the protocol. Secondly, even if players identify that the protocol is under attack, it is difficult to act against it in a consistent manner.   Due to these reasons, the protocol's security analysis is more nuanced. This lecture focuses on the security of the Nakamoto consensus protocol, which is analyzed via a formal mathematical model. \n\nThe first aspect of the model is to model the mining process as a stochastic process in which new blocks appear at random intervals of time. This mathematical model serves as a basis for theoretical security guarantees. We shall see that the security guarantees are probabilistic in nature, with the randomness factor coming  from the mining process.\n\n\\section*{Mining as a Poisson process}\nThe times at which a new block is mined is modeled as a Poisson process with rate $\\lambda$. Here the average inter-block time,  $\\frac{1}{\\lambda}$, is set based on the target difficulty in the PoW mining operation; for Bitcoin $\\frac{1}{\\lambda} = 10$ minutes.  A Poisson process is one in which new events (or arrivals) occur at random intervals  following the  exponential distribution. Moreover, the intervals between any two events are independent of, and statistically identical to,  each other. Recall that an exponential random variable $X$ with parameter $\\lambda$ has distribution \n\\[\\mathbb{P}(X \\geq t) = \\exp(-\\lambda t) \\ \\forall t \\geq 0.\\]\nAlso recall that a Poisson random variable $Y$ with parameter $\\lambda$ has distribution \n\\[\\mathbb{P}(Y = k) = \\exp(-\\lambda) \\frac{\\lambda^k}{k!} \\ \\forall k \\geq 0.\\]\nIn a Poisson process, the number of events in an interval of length $T$ is a Poisson random variable with parameter $\\lambda T$. Moreover, the number of events in disjoint intervals of time are independent. If we consider small intervals ($\\lambda T \\ll 1$), there is one event in the interval with probability $\\lambda T$ and none otherwise. Thus, a Poisson process can be emulated by  counting the occurrence of heads in a sequence of (independent) coin tosses, with the probability of heads being very small. We now see why the mining process has such a property.\n\nImagine that the number of miners in the system and the total computing power at their disposal is constant over some period of time. Assume that each of the miners' computers are mining incessantly, and that is the only computation they are performing. It is then reasonable to say that the total number of hashes being computed (equivalently, the total number of nonces being tried out) per unit time is roughly constant. Say, a billion hashes are computed every second. \n\nFurther, suppose that the difficulty level of the hash puzzle for proposing a block is very high. E.g., say that the first thirty-five zeros must be zero for a block to be valid. The probability that a particular nonce will meet this criterion is $2^{-35} \\approx 3 \\times 10^{-11}$. Thus, the probability that the hash puzzle will be solved by \\textit{any miner} in a given second is $0.03$, a small number (we assumed that a billion hashes are computed every second). Whether or not a proof-of-work hash is found in a particular second has no bearing on whether one will be found in the next second. The reason for this is that the hash function is essentially a random oracle; the hash values for different inputs are independent of each other. Thus, the mining process is well modeled as a Poisson process.\n\nIn modeling the mining process as a Poisson process, we focus only at the times at which new, valid blocks are created. The Poisson process model holds irrespective of the number of miners, their individual computation power, whether different miners are working on the same block or different blocks, and when different users receive newly mined blocks. The parameter $\\lambda$ of the mining process, called the \\textbf{mining rate}, is equal to the average number of blocks mined per unit time. In Bitcoin, $\\lambda$ is $1/(600 \\text{s})$, i.e., one block every 600 seconds (ten minutes). In Ethereum (which also has the same Nakamoto consensus protocol), the rate is much faster: $\\lambda$ is $1/(13 \\text{s})$.\n\nWith variations in total computing power, the fixed mining rate assumption does not hold precisely. In reality, the total computation power does not change suddenly; this is especially true for a mature system like Bitcoin, which already has many miners actively participating. Thus, over a small period of time, the rate is roughly constant. Adjusting the difficulty parameter at regular intervals helps keep the mining rate at the same level. Therefore, for this lecture, we shall assume that the mining rate of the protocol is a constant $\\lambda$ throughout. More nuanced models with variable mining rates exist in the \\href{https://eprint.iacr.org/2016/1048.pdf}{literature}. % (take a look at the abstract of the linked paper).\n\nWe now proceed to specify some other important modeling assumptions about the protocol. Some aspects of the model may deviate from reality by giving the adversary some extra power. By doing so, we are guaranteed that the statements on the system's security are guaranteed to hold even in practice.\n\n\\section*{Nakamoto consensus protocol model} \nWe assume that there is a single adversary and many different honest parties participating in the protocol. The adversary's computing power is a fraction $\\beta$ of the total computing power of all users in the system. Among honest users, the computing power is divided roughly equally with each user controlling a very small fraction. This implies that typically, consecutive honest blocks are mined by different users. Such a model gives the adversary more power than a setting with a smaller number of honest users with considerable mining power. This will be made clear when we discuss the effect of network delay. Let the fraction of ``hash power\" of the adversary be $\\beta$, and assume that $\\beta < 1/2$. This means that the adversary mines blocks as a Poisson process of rate $\\beta \\lambda$, while honest users mine blocks at a rate of $(1-\\beta) \\lambda$. Further, these processes are independent of each other.\n\nIn reality, parties store all blocks that they hear of, including blocks that fork away from the current longest-chain. Their \\textit{ledger} consists of blocks in the longest chain. For the sake of modeling, assume that each honest player only stores a single blockchain at all times--the longest chain that they have heard until that time. Let $\\mathcal{C}^h_i$ denote the chain held by party $h$ at time $i \\in \\mathbb{R}^+$. \n\nIf an honest party hears of multiple chains with the same (maximum) length, we assume that they choose one of them arbitrarily as $\\mathcal{C}^h_i$. This choice is made by the adversary. Note that this implies an honest user may swap its chain when it hears of an equally long chain, not just a strictly longer one. It also implies that if two honest parties both hear of two chains of equal (maximum) length, then the two parties may adopt different chains. This tie breaking power is another example of giving the adversary extra powers than what may exist in reality. \n\nThe \\textit{prefix} of a chain is a sub-chain consisting of the first few blocks. More formally, we say that chain $\\mathcal{C}_1$ is a prefix of chain $\\mathcal{C}_2$ if all blocks in $\\mathcal{C}_1$ are also present in $\\mathcal{C}_2$. (By default, we assume that a chain is a sequence of blocks from the genesis down to any other block.) We denote this by $\\mathcal{C}_1 \\preceq \\mathcal{C}_2$. We define the notation of the prefix of a chain as follow.\n\\begin{itemize}\n    \\item For a chain $\\mathcal{C}$, let $\\mathcal{C}^{\\lfloor k}$ be the  prefix chain obtained by dropping the last $k$ blocks. In case $\\mathcal{C}$ has less than or equal to $k$ blocks, let $\\mathcal{C}^{\\lfloor k}$ be the genesis block.\n    %\\item For some user $h$ and some time $i$, let $\\mathcal{C}^h_i[0:s]$ denote the portion of the chain consisting of blocks mined before time $s \\leq i$. For $s = i-k$, this involves dropping blocks in the last $k$ units of time.\n\\end{itemize}\n\nRecall the $k$-deep confirmation rule in Bitcoin: a node treats all but the last $k$ blocks in its longest chain as \\textit{confirmed}. In our notation, the blocks in  $\\mathcal{C}^{h \\lfloor k}_i$ are confirmed by user $h$ at time $i$. %A similar, practical rule is to confirm all blocks except those received in the last $k$ units of time. These two rules are nearly equivalent (up to a scaling of the parameter $k$).\nOnce we confirm a block, we also confirm all the transactions in it. Note that the confirmation rule is \\textit{locally} applied by each user; therefore, a transaction confirmed by one user needn't be confirmed by another. However, it is desirable that a transaction confirmed by one user is soon confirmed by all other users, and remains confirmed forever after. In blockchains, this desirable property is called a \\textit{safety property}.\n\n\\section*{Formal definitions of safety}\nWe now formally define safety of the Nakamoto consensus protocol. We give two definitions: the first is a statement about the entire duration of the protocol (a global/extensive statement), while the second concerns just one particular block (a local/intensive statement). \n\n\\begin{definition}[Common Prefix Property]\nFor a blockchain protocol, the $k$-common prefix property holds during an execution of the protocol if any block that is committed by one honest user appears in every honest user's chain thereafter.\nMathematically, for all pairs of times $i_1 \\leq i_2$, for all pairs of honest users $h_1, h_2$, \n\\[\\mathcal{C}^{\\lfloor k}_1 \\preceq \\mathcal{C}_2\\]\nwhere $\\mathcal{C}_1 \\equiv \\mathcal{C}^{h_1}_{i_1}$, $\\mathcal{C}_2 \\equiv \\mathcal{C}^{h_2}_{i_2}$.\n\\end{definition}\n\n\\begin{definition}[Individual block safety]\nIn an execution, a block $B$ present in some honest user's chain is safe if, after it has been committed by any honest user, it remains a part of all honest user's chains. Mathematically, if block $B$ is committed by some user $h$ at time $t$, then for all $t' \\geq t$, for all honest users $h'$, $b \\in \\mathcal{C}^{h'}_{t'}$\n\\end{definition}\n\nNote that the two statements are very similar in form. In fact, the former subsumes the latter. For simplicity of exposition, we focus on the latter property alone.\n\nThe above statements are merely definitions of a desired security property. Whether or not such a property holds (or with what probability it holds) requires further calculations. A security guarantee/theorem would be of the form that the $k$-common prefix property holds with  probability approaching one, as $k$ approaches infinity.  Such security guarantees are given under some assumptions: assuming a fixed mining rate, a bound on the adversary's computing power, and a bound on the network delay. Crucially, these guarantees are given assuming the adversary can act arbitrarily; in other words, we do not assume anything about the adversary's strategy at all. To get a sense of how the adversary can disrupt safety, we take a look at some possible adversarial actions. In particular, we will focus on an adversary trying to disrupt the individual safety of a fixed block $B$.\n\n%\\paragraph{Liveness} \\textcolor{red}{TODO}\n\n\n\n\n% With these parameters set, whether or not the private attack will be successful depends only on the randomness of the mining process. We say that the private attack is successful (from block $B$) if it overturns $k$ or more honest blocks (built below block $B$). For this to happen, over some long-enough interval, the adversarial users must mine more blocks than honest ones. For simplicity, suppose the private attack is launched right from the beginning, i.e., launched from the genesis block. With $\\beta < 1/2$, the adversary must be lucky (mine blocks quicker than expected), or the honest users must be unlucky (mine blocks slower than expected), or both. If not, the attack cannot succeed.\n\n% The number of honest blocks in the first $T$ units of time, $X_T$, is random with distribution $\\textsf{Poisson}((1-\\beta)\\lambda T)$, which has mean $(1-\\beta)\\lambda T$. The same holds for adversarial blocks (denoted by $Z_T$), but with $1-\\beta$ replaced by $\\beta$. The Chernoff bound on Poisson random variables states that if $X \\sim \\textsf{Poisson}(\\lambda)$, then\n% \\begin{align}\n% \\mathbb{P}(X \\geq \\lambda + x) &\\leq \\exp(-x^2/2(\\lambda + x)) \\label{eq:upper_bound} \\\\\n% \\mathbb{P}(X \\leq \\lambda - x) &\\leq \\exp(-x^2/2(\\lambda + x))\\label{eq:lower_bound}\n% \\end{align}\n% Let $\\epsilon \\triangleq 1 - 2\\beta$. Using $\\eqref{eq:upper_bound}$ for $Z_T$ with $x = (1/2 - \\beta)\\lambda T$ gives\n% \\[\\mathbb{P}(Z_T \\geq 0.5\\lambda T) \\leq \\exp(-\\epsilon^2 \\lambda T/4)\\]\n% Using $\\eqref{eq:lower_bound}$ for $X_T$ with $x = (1/2 - \\beta)\\lambda T$ gives\n% \\[\\mathbb{P}(X_T \\leq 0.5\\lambda T) \\leq \\exp(-\\epsilon^2 \\lambda T/4(1 + 2\\epsilon)) \\leq \\exp(-\\epsilon^2 \\lambda T/12)\\]\n\n% Thus, the probability that $Z_T$ exceeds $X_T$ for any value of $T$ greater than $T_0$ is bounded above by (due to the union bound)\n% \\begin{align*}\n%     \\sum_{T=T_0}^{\\infty} \\mathbb{P}(Z_T \\geq X_T) &\\leq \\sum_{T=T_0}^{\\infty} \\mathbb{P}(Z_T \\geq 0.5 \\lambda T) + \\mathbb{P}(X_T \\leq 0.5 \\lambda T) \\\\\n%     &\\leq \\sum_{T=T_0}^{\\infty} \\exp(-\\epsilon^2 \\lambda T/12) + \\exp(-\\epsilon^2 \\lambda T/4)\n%      = C(\\epsilon, \\lambda) \\exp(-\\epsilon^2 \\lambda T_0/12)\n% \\end{align*}\n% where $C(\\epsilon, \\lambda)$ is some constant that depends on $\\epsilon$ and $\\lambda$. What value of $T_0$ should we choose? We should choose a value such that $k$ honest blocks take more than $T_0$ time to appear. Let $T_0$ be such that $\\lambda T_0 = k$, which implies $(1-\\beta) \\lambda T_0 < k$. The probability that $X_{T_0} \\geq k$ is bounded by $\\exp(-\\beta^2 \\lambda T_0/8)$. \n% Thus, the probability of a private attack with parameter $k$ is bounded by $\\exp(-\\beta^2 \\lambda T_0/8)$ $+ C(\\epsilon, \\lambda) \\exp(-\\epsilon^2 \\lambda T_0/12)$. replacing $\\lambda T_0$ by $k$ shows that the probability of this happening decays exponentially with $k$.\n\n% However, private attacks are not the only strategy the adversary can employ. We will see other attacks  in later lectures and study their impact on security. %However,   one can show that the private attack is actually the worst case attack in term of success probability for the longest chain protocol. The logic is to show that for a fixed sample path in the probability space, if any other attack succeeds, then the private attack also succeeds. \n% We can also calculate the exact success probability of the private attack. Details of the proof and the calculation can be found in the Appendix. \n% Nakamoto \\cite{nakamoto2008bitcoin} himself/herself made a subtle mistake in the calculation, which was first pointed out in \\cite{rosenfeld2014analysis}.  \n% \\begin{figure}\n%     \\centering\n%     \\includegraphics[width=10cm]{figures/private.png}\n%     \\caption{Private attack with $\\beta = 0.3$}\n%     \\label{fig:my_label}\n% \\end{figure}\n\n% %\\textit{Now for some intuition on why the rule works. Bring up the Poisson model and argue intuitively that if $\\beta < 50\\%$ then in the large k limit (k-deep confirmation) security holds, based on the private attack formulation.}\n\n\\section*{Private attack}\n Consider a simple model of the blockchain system with all users split into two groups: many honest users  and a singe adversarial user. The adversarial user is  trying to re-write the last $k$ blocks in the ledger by performing a private attack. Assume that the total mining rate is fixed at $\\lambda$. We suppose that the adversarial fraction of hash power is $\\beta$ (for \n ``bad\"); the honest fraction of hash power is $1-\\beta$. \n \nSuppose the adversary wishes to violate the safety of a block $B$. To do so, the adversary must ensure that block $B$ is first confirmed by some (or all) honest users, and then, at some time in the future, must dislodge $B$ from the longest chain,  i.e., it must create a fork from a block preceding $B$, and must eventually produce a chain of length equal to or longer than the longest chain containing $B$, after $B$ has been confirmed. \n\nOne possible attack is the private attack, introduced in Lecture 3, which we investigate here in more detail. Let $B'$ be the parent of block $B$. One option is for the adversary to mine a conflicting block on $B'$ immediately after block $B'$ is mined. It keeps mining in private, creating an ever-increasing chain. The honest users, unaware of the private chain, continue to mine following the longest chain rule, below $B$. In the private attack, the adversary does not contribute to the chain the honest nodes are mining on. %At some time $t$ after block $B$ is mined, let the private chain at time $t$ be called $\\mathcal{C}^{\\mathcal{A}}{t}$, and the longest honest chain be called $\\mathcal{C}^{\\mathcal{H}}{t}$. \nNote that the honest and adversarial chains are independent of each other and distributed as Poisson processes with rate $(1-\\beta)\\lambda$ and $\\beta\\lambda$, respectively. \n\nWhen should the adversary reveal its chain to the honest users? Suppose it reveals its private chain while it is shorter than the longest honest chain. The honest users will simply ignore the adversary's chain, and it will not produce any effect. Thus, the adversary must reveal its chain only when it is at least as long as the honest chain. What happens if the adversary reveals its chain too early, i.e., before block $B$ gets $k$-deep? It would still end up displacing $B$, but then it's actions do not lead to a safety violation! Thus, the adversary must also wait until the honest chain is long enough (see Figure~\\ref{fig:privateattack}). \n\n \\begin{figure}\n   \\centering\n     \\includegraphics[width=15cm]{figures/privateattack.png}\n     \\caption{Private attack on block $B$ with $k=5$.}\n     \\label{fig:privateattack}\n \\end{figure}\n\n\\section*{Analysis of the private attack under zero delay}\nSuppose now that the network delay $\\Delta = 0$. So any node mined successfully by an honest node reaches all other nodes instantaneously. One immediate effect of this is that the honest nodes always have access to the latest mined block and thus can always mine on the tip of the longest public blockchain (by potentially  switching their mining upon receiving a new block).  \nDenote the time intervals between the honest and adversarial blocks in the chains of length $k+1$, following block $B'$ by $(T_0^h, T_1^h, \\ldots T_k^h)$ and $(T_0^a, T_1^a, \\ldots T_k^a)$ respectively (see Figure~\\ref{fig:privateattack}, where $k=5$). Then the private attack is successful exactly when the total time to mine $k+1$ blocks by the adversary is faster than the time the honest miners take to mine their $k+1$ blocks, i.e., \n$$\n\\sum_{i=0}^k T_i^h > \\sum_{i=0}^k T_i^a.\n$$\nNote that the times are all independent of each other and $T_0^h, \\ldots ,T^h_k$ are identically distributed as exponential random variables with mean  $\\frac{1}{(1-\\beta)\\lambda}$ and $T_0^a, \\ldots ,T^a_k$ are identically distributed as exponential random variables with mean  $\\frac{1}{\\beta\\lambda}$. By the law of large numbers, \n$$\n\\frac{1}{k+1} \\sum_{i=0}^k (T_i^h - T_i^a) \\rightarrow  \\frac{1}{(1-\\beta)\\lambda} - \\frac{1}{\\beta\\lambda}. \n$$\nThe limiting value is positive (i.e., the private attack is successful) exactly when \n$$\n\\frac{1}{(1-\\beta)\\lambda} >  \\frac{1}{\\beta\\lambda}, \n$$\nor simply $\\beta > \\frac{1}{2}$, i.e., the adversary controls a majority of the hash power. This calculation shows that in the limit of $k$ very large, the safety of any block $B$ in the longest chain of Bitcoin will continue to remain in the longest chain with probability approaching one. In general there is a tradeoff between a confirmation depth of $k$ and the resulting safety of a block $B$ that has $k$ blocks mined under it. The probability of ``deconfirmation\", i.e., the block $B$ gets dislodged from the longest chain can be calculated as follows (here $s > 0$ is a parameter to be chosen later): \n\\begin{align}\nP(\\sum_{i=0}^k (T_i^h - T_i^a) > 0) &= P(s \\sum_{i=0}^k (T_i^h - T_i^a) > 0) = \n P(e^{s \\sum_{i=0}^k (T_i^h - T_i^a)} > 1) \\\\\n&\\leq E[e^{s \\sum_{i=0}^k (T_i^h - T_i^a)}] = E[\\Pi_{i=0}^k e^{s(T_i^h - T_i^a)}] = \\Pi_{i=0}^k E[e^{s(T_0^h - T_0^a)}] \\\\\n&= \\left (\\frac{\\beta\\lambda}{\\beta\\lambda + s}\\right )^{k+1} \\left (\\frac{(1-\\beta)\\lambda}{(1-\\beta)\\lambda - s}\\right )^{k+1},\n\\end{align}\nbecause of the factorization of the moment generating function of independent random variables. % (each of which is the difference of independent exponential random variables). \nChoosing $s = \\frac{(1-2\\beta)\\lambda}{2}$ minimizes the exponent and we see that the probability of deconfirmation of a block $B$ is upper bounded by $e^{-c(k+1)}$ where the {\\em  exponent} is given by:\n$$\nc = -\\log_e(4\\beta(1-\\beta)) > 0. \n$$\nSo the probability of deconfirmation decays exponentially in $k$, as also  illustrated  in Figure~\\ref{fig:illustrateprivateattack}. % \\xw{Eqn. (3) is an upper-bound of the error probability, while Figure~\\ref{fig:illustrateprivateattack} plots the exact probabilities.} \\pramod{yeah, but this is the \"correct\" error exponent, so it is also tight. if we want to be precise we can mention this.} \nTurns out this calculation was also conducted by Nakamoto themself, albeit somewhat incorrectly, which is  included in Figure~\\ref{fig:illustrateprivateattack} as a comparison. \n\n\\begin{figure}\n    \\centering\n  \\includegraphics[width=10cm]{figures/private.png}\n     \\caption{Private attack with $\\beta = 0.3$.}\n     \\label{fig:illustrateprivateattack}\n \\end{figure}\n\n\n%\\pramod{how about mentioning the pre-mining attack? Do we do it in the appendix?}\n\n\\section*{Private attack is the worst-case attack}\nPrivate attacks, when successful, enable double-spends and constitute a particularly serious threat. However, they are not the only possible attack on the safety of the blockchain. Another canonical attack, known as the {\\em balance} attack is the following, illustrated in Figure~\\ref{fig:balance-attack}. Here the three honest blocks are denoted by $B_1^h, B_2^h, B_3^h$ and the adversarial blocks are denoted by $B_1^a, B_2^a, B_3^a$. The adversary mines and releases blocks in such a way as to {\\em balance} the heights of two chains; by such a balancing action, the adversary succeeds in switching the honest miner actions across two chains never letting any one chain stabilize. While this attack does not enable a double-spend directly, it is still a serious safety threat since the ledger keeps changing and entries never stabilize. In Figure~\\ref{fig:balance-attack}, the six blocks are released in the order of $B_1^h, B_2^h, B_1^a, B_2^a, B_3^h, B_3^a$ and the longest chain switches from the left to the right and then back to the left.  \n\n\\begin{figure}\n    \\centering\n  \\includegraphics[width=14cm]{figures/balanceattack.png}\n     \\caption{Illustration of a balance attack. }\n     \\label{fig:balance-attack}\n \\end{figure}\n \nThe balance attack is also only an instance of the large space of adversarial actions. For instance,  an attacker could launch a balance attack to {\\em split} the honest mining power among the two chains (thus reducing the rate of growth of each one) and then launching a fatal private attack. In general, the space of adversary strategies is very vast, growing over time, and is parameterized by two quantities: where to mine the adversary blocks, and when to publish the adversary blocks. \n However,  in the special case when the network delay is zero, it turns out that whenever any attack on safety is successful, the private attack is also successful. This is true for each instance of the when and where the honest and adversarial mining actions occur (i.e., for every {\\em sample-path} of the underlying Poisson mining processes). Suppose the attack is launched on the block just below the genesis block (left block on the first level in Figure~\\ref{fig:balance-attack}; here $k=2$). Consider two random variables $A_k, H_k$ which represent the number of blocks mined by  the adversary and the honest nodes respectively during an attack on the safety of the $k$-deep confirmation rule. There are two main observations. \n \\begin{itemize}\n     \\item The total number of blocks  mined is $A_k + H_k$ must be at least $2k+2$ since to launch a safety attack at least two chains of length $k+1$ must be present: one of the chains of length $k+1$ must have been present to confirm the block $B$ and another chain of length $k+1$ must be present to deconfirm the block $B$ by switching the longest chain. So $A_k + H_k \\geq 2k+2$. \n     \\item We note that two honest nodes can never be mined at the same level of the blockchain; this is because the network delay is zero and miners instantaneously learn of any newly mined block  and all honest nodes have full consensus on the longest chain. Since honest nodes mine on the tip of the longest chain, there could not be parallel mining by the honest nodes at the same level. So to have two chains with both length at least $k+1$, it must be that the adversarially mined blocks must be larger in number than the honest ones: $A_k \\geq H_k$.  \n  \\end{itemize}\n  From the above two observations we conclude that $A_k \\geq k+1$, i.e., the the adversary has already successfully mined at least $k+1$ blocks by the time of the safety attack on the $k$-deep confirmation rule. For the same sample path, the adversary could have used its blocks to launch a private attack. %Figure~\\ref{fig:private-balance} illustrates the private attack the adversary could have launched instead of the attack in Figure~\\ref{fig:balance-attack}. \n \n%\\begin{figure}\n%    \\centering\n%  \\includegraphics[width=14cm]{figures/balanceattack.png}\n%     \\caption{The balance attack from Figure~\\ref{fig:balance-attack} also allows a private attack to succeed. }\n%     \\label{fig:private-balance}\n% \\end{figure}\n\n\n\n\\section*{Safety analysis under bounded network delay}\nWe have supposed the network delay is zero in the analysis above, a simplification to model the practical Bitcoin setting: inter-block arrival rate is ten minutes on average, while block propagation delay in the Internet is of the order of a few seconds on average. Empirical measurements on the Bitcoin network show that  blocks reach a very large fraction of participants within ten seconds. We will make the supposition that there is a finite amount of time $\\Delta$ within which all blocks reach all participants definitively; this is the so-called $\\Delta$-synchronous network model. Further we will suppose that the adversary reserves the right to deliver the blocks to different participants at a time of its choosing (this includes potentially reordering blocks) as long as the $\\Delta$-synchrony condition is met. \n\nThe main impact of the propagation delay is that the most recently mined blocks take time to reach the honest nodes and thus they are mining on {\\em stale} blocks, that are no longer the tip of the longest chain. Successful mining is now potentially wasteful, because the mining was based on a parent block that has already been extended. In other words there is {\\em natural forking}, even without adversarial intervention. In Bitcoin the inter-block arrival time is ten minutes, so it is very unlikely that honest nodes will mine on stale blocks. But in other blockchains such as Ethereum (which also uses the same longest chain protocol) where the inter-block arrival time is fourteen seconds, natural forking is more prevalent. What fraction of honest mining power is ``wasted\" due to this natural forking? The term $(1-\\beta) \\lambda \\Delta$ (the product of $(1-\\beta)\\lambda$, the rate at which honest blocks are mined and $\\Delta$, the network delay) is the expected number of blocks that are being mined ``in parallel\", of which only one of the blocks will succeed in extending the longest chain. Thus the rate of growth of the honest chain is now reduced by a fraction $\\frac{1}{1 + (1-\\beta)\\lambda \\Delta}$ to \n$$\n\\frac{(1-\\beta)\\lambda}{1 + (1-\\beta)\\lambda \\Delta}. \n$$\nIn the Appendix we will mathematically justify this statement under the limit of a very large number of honest miners (each with infinitesimally small mining power). Now an adversary launching a {\\em private attack} is successful if its rate of growth (of a private chain) is larger than that of the (reduced) growth rate of the honest chain:\n\\begin{equation}\n    \\beta \\lambda > \\frac{(1-\\beta)\\lambda}{1 + (1-\\beta)\\lambda \\Delta}.\n    \\label{eq:miningthreshold}\n\\end{equation}\n Figure~\\ref{fig:threshold} illustrates the minimum hash power adversary needs  to succeed in its private attack.  %\\pramod{Plot only blue curve in the figure and shade the area under the curve by the color blue.}\n\n\\begin{figure}\n     \\centering\n     \\includegraphics[width=10cm]{figures/threshold.png}\n   \\caption{Minimum hash power needed by the adversary to succeed in its private attack. It turns out that this is also the security threshold for the adversary to successfully launch any safety attack. }\n   \\label{fig:threshold}\n \\end{figure}\n\nAs we have seen earlier, the private attack is only one of the possible strategies adopted by the adversary. When the network delay $\\Delta =0$, we have seen that the private attack is the worst-case attack in a very general setting: for every sample path of the mining process and for every confirmation depth $k$, the private attack is successful whenever any attack is successful. Unfortunately this is not true as seen in the example in Figure \\ref{fig:counterexample}. \n%\\pramod{show the example of when a balance attack is successful but the  private attack is not.}\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width =10cm]{figures/counterexample.jpg}\n    \\caption{Attacks aimed to create a fork with length 2}\n    \\label{fig:counterexample}\n\\end{figure}\n\n\nNevertheless, it turns out that the private attack is still a worst-case attack in the sense of the  minimum required honest hash power while ensuring safety against all attacks (this safety is with probability approaching one, in the  limit of $k$ approaching infinity). So the condition in Equation~(\\ref{eq:miningthreshold}) derived for the success of the private attack also holds for {\\em any attack}. Some  intuition for why this could be true is provided next.  %\\pramod{any chance of explaining this intuitively using Nakamoto blocks and the figures from our paper?} \\xw{I don't think this is true. Even for large $k$, there could be mixing strategy that beats the private attack. For example, try balancing attack first, then do private attack after failing to balance.} \\pramod{I didnt mean the worst-case in a sample path sense.}\n\n\n\\section*{Nakamoto blocks}\n\nThe entire blocktree, consisting of both honest and adversarial blocks (public or private), can be arbitrary under a general attack where the adversary can make public blocks at multiple time instances. However, what we can observe is that by partitioning the complex blocktree into sub-trees, each rooted at a honest block and consisting otherwise entirely of adversarial blocks, one can view the general attack as initiating {\\em multiple} adversarial sub-trees to race with a single fictitious chain consisting of only honest blocks (Figure \\ref{fig:blocktree_partition}). \n\n\n\\begin{figure}\n     \\centering\n     \\includegraphics[width=12cm]{figures/blocktree_partition.jpg}\n   \\caption{By blocktree partitioning, a general attack is represented as multiple adversarial chains simultaneously racing with a fictitious honest chain. Note that this fictitious chain is formed by only the honest blocks, and may not correspond to the longest chain in the actual system. However, the longest chain in the actual system must grow no slower than this fictitious chain. }\n   \\label{fig:blocktree_partition}\n\\end{figure}\n\nThe growth rate of each of these adversarial sub-trees is upper bounded by the growth rate of the adversarial chain used in the private attack.  Therefore, if the private attack is unsuccessful, we know that the growth rate of each of the adversarial trees must be less than that of the fictitious honest chain. A  \\href{https://arxiv.org/pdf/2005.10484.pdf}{recent paper} shows that under this  condition, there must exist honest blocks, which are called {\\em Nakamoto blocks}, each having the property that {\\em none} of the past adversarial trees can {\\em ever} catch up after the honest chain reaches the block (Figure \\ref{fig:nakamoto_block}). These Nakamoto blocks serve to stabilize the blockchain: when each such block enters the blocktree, complex as it may be, it is guaranteed that the entire prefix of the longest chain  up to that block remains immutable in the future\\footnote{Thus, Nakamoto blocks have a god-like permanence, they exist, but nobody knows which block is a Nakamoto block.}. When Nakamoto blocks occur and occur frequently, the safety of the protocol is guaranteed.\n\n\\begin{figure}\n     \\centering\n     \\includegraphics[width=10cm]{figures/nakamoto_block.jpg}\n   \\caption{Race between the adversarial trees and the fictitious honest chain. While there may be multiple adversarial trees simultaneously racing with the honest chain, the growth rate of each tree is bounded by the growth rate of the adversarial chain in the private attack. An honest block is a Nakamoto block when all the previous adversarial trees  never catch up with the honest chain past that block. To simplify notations, $\\lambda_{ag} = \\beta \\lambda$ and $\\lambda_h = (1-\\beta)\\lambda$.}\n   \\label{fig:nakamoto_block}\n\\end{figure}\n\n\n\\section*{Importance of synchronous network}\nThe main point from the safety analysis of this lecture is that the longest chain protocol is safe as long as the adversarial hash power is small enough, as a function of the mining rate and worst-case network delay. It is important that the worst-case network delay be finite: in a  purely asynchronous network (no guarantees whatsoever on the network delays), the adversary can mine alternate chains and share them separately with different subsets of honest nodes thus breaking consensus. It is interesting to consider a network scenario that is in-between: the network delays are finite but unknown -- after an unspecified time (known as the {\\em global stabilization time} (GST)), all messages are guaranteed to be delivered to all the nodes within bounded time. Such a  model is known as the partially synchronous network model and in this case, safety can be violated because $k$  could be smaller than GST (unlike GST, $k$ is a finite and prespecified quantity). However, after GST the consensus returns to all the honest nodes.  In later lectures we will study consensus protocols that guarantee safety even under partially synchronous network settings. \n\n\n\n\\section*{Appendix}\n\n\\noindent {\\bf Growth rate of honest chain under network delay} \nSuppose that a certain honest block $B$ is mined by a miner $P$ at time $t$ and $B$ is the first block at level $\\ell$. In the worst case, $B$ is not received by the remaining honest miners until time $t + \\Delta$. Since the network has an very large number of honest miners (each with infinitesimal mining powers), it is very unlikely that $P$ will mine another block before time $t + \\Delta$. Since other miners have not seen $B$, their block will still be mined at the same level as $B$ (with a parent block at the level $\\ell -1$). We assume the honest mining process is a Poisson process with rate $(1-\\beta)\\lambda$, then on average $(1-\\beta)\\lambda\\Delta$ honest blocks are mined in the time interval $[t, t + \\Delta]$. These blocks will not increase the length of the longest chain as they are all at level $\\ell$. The first block mined after $t + \\Delta$ will increase the length of the longest chain by one. Thus on average, only $1$ out of $1 + (1-\\beta)\\lambda\\Delta$ blocks will increase the length of the longest chain. Thus the growth rate of the longest chain is $\\frac{(1-\\beta)\\lambda}{1 + (1-\\beta)\\lambda\\Delta}$.\n\nAlternatively, the inter-arrival time of the Poisson process is an exponentially random variable with mean $1/((1-\\beta)\\lambda)$. Hence the average time taken to mine a block at a new level and send it to all other miners (in the worst case) is $1/((1-\\beta)\\lambda) + \\Delta$. Only when this block is received by the other miners, can the length of the longest chain grow. Therefore, the length of the longest chain grows by one with time $1/((1-\\beta)\\lambda) + \\Delta$ on average, which gives the growth rate $\\frac{1}{1/((1-\\beta)\\lambda) + \\Delta} = \\frac{(1-\\beta)\\lambda}{1 + (1-\\beta)\\lambda\\Delta}$.\n\n\\input{Problem_sets/Lec6_PS}\n\n\n\\end{document}\n1) what do we mean by security: define safety and liveness\n1a) focus on safety; next lecture has liveness\n1b) can only have probabilistic guarantee\n1c) common prefix property\n\n2) delta = 0\n2a) what are some possible attacks?\n2b) double spend versus never converging\n2c) Xuechao's figure. proving pre-mined private attack is worst-case for delta = 0 (this is a 3-page proof, perhaps we should just refer to the paper)\n\n2d) error exponent calculation. show that the slope depends on lambda-a - lambda-h\n\n4) non-zero delta. Show that balancing is worse than private attack.\n4a) mean-based calculation for backbone (loner calculation)\n4b) mean-based calculation for nakamoto block.\n\n5) end with a note on liveness.",
    "lecture_15.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\usepackage{markdown}\n\\usepackage{amsthm}\n\\usepackage{caption}\n\\usepackage{subcaption}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\usepackage{xspace}\n\\newcommand{\\indicator}{{\\bf 1}}\n\\newcommand{\\pramod}[1]{{\\color{red}\n\\footnotesize[Pramod: #1] }}\n\\newcommand{\\xw}[1]{{\\color{green}\n\\footnotesize[Xuechao: #1] }}\n\\newcommand{\\gerui}[1]{{\\color{blue}\n\\footnotesize[Gerui: #1] }}\n%\\theoremstyle{definition}\n\\newtheorem{definition}{Definition}\n\\newtheorem{theorem}{Theorem}\n\\newtheorem{lemma}{Lemma}\n%\\let\\proof\\relax\n%\\let\\endproof\\relax \n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 15}\n\\cfoot{\\thepage}\n\n\\newcommand{\\bba}{\\ensuremath{BBA^*}\\xspace}\n\\newcommand{\\ba}{\\ensuremath{BA^*}\\xspace}\n\\newcommand{\\coinfixedtozero}{\\text{Coin-Fixed-To-0}\\xspace}\n\\newcommand{\\coinfixedtoone}{\\text{Coin-Fixed-To-1}\\xspace}\n\\newcommand{\\coingenuinelyflipped}{\\text{Coin-Genuinely-Flipped}\\xspace}\n\n\n\\title{Lecture 15: Permissionless Blockchains based on BFT Protocols: Algorand }\n\\author{Principles of Blockchains, University of Illinois,  \\\\ Professor:  Pramod Viswanath \\\\ Scribe:  Gerui Wang}\n\\date{March 18, 2021}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nIn the previous lecture, we saw BFT protocols that provide consensus with {\\em finality}, i.e., deterministic safety guarantees. However, the protocols we saw (e.g., Hotstuff) were for a fixed number of participants. In this lecture, we study how to use a BFT protocol (such as Hotstuff) in the context of a permissionless blockchain. We pay particular attention to participation determined by PoS, and security against adaptive adversaries. We study  Algorand, a BFT protocol that is very efficient in throughput and latency and  is  especially suited to operation in a permissionless setting via Proof of Stake (PoS), providing resistance against an adaptive adversary. \n\\end{abstract}\n\n\n% \\paragraph{Model}\n% Peer-to-peer network with gossiping (for simplicity, perhaps use point-to-point, all-to-all network). Lock-step synchronous, bounded delay of gossiping. Digital signatures and PKI. Hash functions.\n\n% Talks about selecting a committee first, then about player replaceability: change committee each step here (although the above paper doesn't talk about it).\n\n% \\section*{Introduction}\n\n% In the previous lectures, we have introduced longest chain style consensus (Nakamoto's longest chain) and classical BFT consensus (HotStuff, Streamlet). In this lecture, we will introduce Algorand, a consensus protocol that is different from these protocols. In Algorand, blocks are generated round by round sequentially, each by a multivalue Byzantine agreement, named \\ba. The name Algorand, comes from the usage of algorithmic randomness to select a set of verifiers (known as \\emph{committee}) who participates in \\ba and are in charge of constructing the blocks. Algorand doesn't use PoW or probabilistic confirmation as Nakamoto does, and it differs from classical BFT consensus in that a committee of players, rather than all players, participate in \\ba. The committee selection uses cryptographic sortition and supports {\\em player-replaceability}: it can select a new, randomly and independently selected committee not only each round of \\ba, but also within each step inside \\ba (as in Hotstuff, the \\ba requires multiple steps). This mechanism withstands an adaptive adversary who can corrupt all members of a committee, because the next committee is a new one and not affected by the corruption.\n% \\subsection*{Algorand's features}\n% \\begin{enumerate}\n%     \\item \\textbf{Adaptive adversary.} Algorand withstands $1/3$ fraction of adaptive Byzantine corruption, where the adversary can instantaneously corrupt any player it wants, at any time it wants.\n%     \\item \\textbf{Secret cryptographic sortition and secret credentials are used in committee selection.} A random quantity $Q^r$ that is deduced from the previous block $B^{r-1}$ is used to derive a secret credential $\\sigma_i$ for player $i$, which determines whether player $i$ is included in a committee. Only player $i$ itself gets to learn the credential and its role (inside the committee or not), hence the adversary cannot corrupt a specific committee member without learning the credential. When player $i$ fulfills its role by sending a message, the credential is attached to the message, so its role becomes publicly known. Now the adversary can corrupt the player immediately, but it will be too late for the adversary to affect this player since its role is already fulfilled and the message is already sent.\n%     \\item \\textbf{Player-replaceability between rounds and steps.} Since there are multiple round to produce multiple blocks, and protocol \\ba is a multi-step protocol, we also require the protocol steps to be player-replaceable: each step can be executed by a totally new set of players. To achieve player-replaceability, we produce new credentials for each step to ensure that the committee for each step is randomly and independently selected. Even if the adversary corrupts previous committees, it won't affect future committees since randomly selected committees will most probably have empty intersection.\n% \\end{enumerate}\n\n% For the remaining of this lecture, we will consider binary consensus within  Algorand, and show how it achieves player-replaceability. Then we extend the Algorand consensus to handle multivalues.  We conclude by discussing  how to incorporate PoS and the forensics properties of Algorand. \n\n\\section*{From Permissioned to Permissionless: Committee Selection}\nConsider a very large number $n$ of nodes, but with variable (unknown) participation level, i.e., not all the nodes may be online. This is a bit more constrained than the truly permissionless setting, where $n$ itself is unknown. \nA simple way to  convert a permissioned BFT protocol to a permissionless one is to simply select a committee of fixed size ($N$) and run a BFT protocol (e.g., HotStuff) to reach consensus on a new block. The randomness of committee election comes from the previous block. Now, as long as 2/3 of this random committee is {\\em online and honest}, the BFT protocol is safe and live. Due to the randomness in the committee election, we need to allow some slack in the condition on the   fraction of honest players. For example, we can achieve 2/3 honest supermajority of committee when the honest fraction is 0.7. Given the committee size $N$, the random variable of honest committee member $X$ follows Binomial distribution Binomial($N,0.7$). And figure~\\ref{fig:1} shows the probability $P(X> 2N/3)$, and we can see as $N$ grows larger, the probability approaches 1.\n\\begin{figure}[htb]\n    \\centering\n    \\includegraphics[width=0.5\\textwidth]{figures/11}\n    \\caption{Probability of honest supermajority for fixed committee size $N$.}\n    \\label{fig:1}\n\\end{figure}\n\nHowever, it is difficult to elect a  fixed committee size in a distributed verifiable manner.  But it is easy to do a random committee size, using hash functions (like we did in Lecture 12). Each player (honest or malicious) runs a lottery with a small probability of being elected. So now $N$ is also random, but with a fixed expectation. For instance, there are 700K honest players and 300K malicious (Byzantine) players in total, and let $E[N]=1000$. Then the lottery's probability of being elected is 0.001 for every player. And $X$ follows Binomial(700K,0.001) and $Y$ follows Binomial(300K,0.001) ($Y$ is the random variable of malicious committee member).\n\nFor a committee with a random size, besides requiring $X> 2E[N]/3$, which ensures that honest players can make progress (liveness), we also need $X+2Y<4E[N]/3$ which ensures the committee has 2/3 honest supermajority (safety). Now, we can re-plot the probability in figure~\\ref{fig:2} and we see again that the probability of a random committee leading to a secure BFT protocol approaches 1 rapidly.\n\n\\begin{figure}[htb]\n    \\centering\n    \\includegraphics[width=0.5\\textwidth]{figures/12}\n    \\caption{Probability of liveness and honest supermajority for a random committee size $N$. Total players $n=1,000,000$ and honest fraction $0.7$.}\n    \\label{fig:2}\n\\end{figure}\n\n%Point out that one can simply select a committee of fixed size ($N$) and run BFT (e.g., Hotstuff). This is a simple blockchain (no forking). Draw a figure. Then as long as 2/3 of this committee is online and honest, all is good.  \n\n%Calculate  probabilities of this happening as a function of committee size (law of large numbers), assuming overall 2/3 is honest. Plot the probability as a function of committee size: $P(X > 2N/3)$ as a function of $N$, where $X$ is Binomial($N,2/3$). \n\n%The trouble is picking fixed committee size in a distributed verifiable manner. But easy to do a random committee size, using hash functions. Come up with a specific mechanism using VRFs So now $N$ is also random  (like we did in lecture 12). Now replot the prob of honest supermajority in committee. %general, don't need to talk about credential\n\nThis form of random committee selection is illustrated in figure~\\ref{fig:blockchain1}. However, insecurity arises due to vulnerability to adaptive adversaries.  The  vulnerability is of two kinds: (a) the  committee selection is known ahead of time and thus an adaptive adversary can corrupt the committee beforehand;  (b) even within a committee, individual nodes have specific roles in the context of the BFT protocol and can get corrupted during the BFT operation.  \nAlgorand addresses both these problems by: (a) novel committee selection that is robust to an  adaptive adversary (using secret credentials);  (b) novel BFT consensus that is robust to adaptive adversary even within substeps of the protocol, as depicted in figure~\\ref{fig:blockchain2}. How these are implemented  is the topic of the next two sections. \n\n\\begin{figure}[htb]\n    \\centering\n    \\begin{subfigure}[b]{0.45\\textwidth}\n         \\centering\n         \\includegraphics[width=\\textwidth]{figures/cs1}\n         \\caption{Simple committee}\n         \\label{fig:blockchain1}\n     \\end{subfigure}\n     \\hfill\n     \\begin{subfigure}[b]{0.45\\textwidth}\n         \\centering\n         \\includegraphics[width=\\textwidth]{figures/cs2}\n         \\caption{Algorand}\n         \\label{fig:blockchain2}\n     \\end{subfigure}\n     \\caption{Simple committee selection vs Algorand committee selection}\n    \\label{fig:two-blockchain}\n\\end{figure}\n\n\\section*{Player Replaceability and Secret Committee Election}\n%secret credentials, VRF. \n\nThe existence of an adaptive adversary requires each substep of a BFT protocol to be assigned to a totally new committee, which is independently and randomly selected among all players. This property is called \\emph{Player Replaceability}. In addition, since an adversary can corrupt the committee as soon as it knows their identities, we require the committee election to be held \\emph{secretly}. In this section, we show how Algorand achieves these requirements.\n\nSuppose the block $B^{r-1}$ associated with round $r-1$'s is available on the blockchain, and we are running a BFT protocol to determine block $B^r$. Assume that we can obtain a random quantity $Q^r$ from the last block $B^{r-1}$, which will be used to generate the randomness. The BFT protocol for block $B^r$ involves multiple steps, and we denote the step counter by $s$. Algorand elects different committees for each step, as seen below. \n\nIn any committee selection stage, player $i$ uses a quantity known as \\emph{credential} ($\\sigma$)  to secretly determine whether it has been selected. Relying on the random quantity $Q^r$ that is deduced from block $B^{r-1}$ (assuming round $r-1$'s block $B^{r-1}$ available on the blockchain), the credential $\\sigma_i^{r,s}$ is a unique signature on $r,s,Q^r$ and if $H(\\sigma_i^{r,s})<p$ ($H$ is a hash function, $p$ is a threshold) then player $i$ is selected as a committee member.  The unique secret signature is generated using  VRFs we have introduced in Lecture 12: $VRF(r,s,Q^r,sk_i)<p$ where $sk_i$ is the secret key for VRF. \nThe threshold $p$ is chosen  to have a suitable expected committee size.\n\nWhen its time to act in step $s$ arrives, $i$ propagates $\\sigma_i^{r,s}$ with its message so that other players can verify its inclusion in the committee. Although the adversary may corrupt it, the message cannot be stopped from reaching other honest players. Moreover, the adversary has no more control on the rest of the protocol than he has by corrupting a random player: the committees of all future steps will be randomly and independently selected.\n\n%Let $\\kappa$ be the expected committee size and usually we have $\\kappa\\ll n$. In protocol \\bba, we just need to change the quantity $2t+1$ to $t_H\\approx 2 \\kappa/3$. Since the committee selection is randomized, we need to have some room for quantity $t_H$ and it should be less than the optimal $2 \\kappa/3$.\n\n\\paragraph{Ephemeral keys.} Although the adversary cannot predict beforehand which users will be in the committee, it would know their identities after seeing their messages, and could then corrupt all of them and oblige them to certify a fake block. To prevent this, players use ephemeral keys: public/secret key pairs that are single-use-only, and once used, are destroyed. Only credentials $\\sigma$ are signed by the long-term public/secret key pairs, and any other message is signed by ephemeral key pairs. \n\nTo generate an ephemeral key pair for a player-round-step triple $(i,r,s)$ %such that player $i$ is elected in committee in round $r$, step $s$, \nplayer $i$ first generates a master key pair, then it uses the master key pair to generate the ephemeral key pairs for multiple rounds and steps, after which it destroys the master secret key and publicizes the master public key. At round $r$, step $s$, if player $i$ is elected as a committee member, it uses the ephemeral key for $(i,r,s)$ to sign messages, and then destroys the ephemeral secret key. Ephemeral keys are different from the key evolving scheme (KES) we saw in Lecture~12 in that the ephemeral keys are generated by a master key pair, rather than evolving from the previous ephemeral key pair. Since it's very unlikely to be elected as a committee member, a player does not necessarily need to keep keys for every round and step as it does in KES. In this situation, using ephemeral keys is more suitable and more efficient than using KES. \n\n\\section*{Algorand: Single Round BFT Consensus Protocol}\n%BBA, KES, Multiple value BA. Notice that safety is still probabilistic but the guarantees are very very good, so essentially finality. \nWe start with a probabilistic binary BFT consensus protocol that doesn't have player replaceability (but naturally allows its  addition, as we see later).  This protocol targets $n=3t+1$ players and $t$-Byzantine fault tolerance.  Each player $i$ holds a binary value $b_i$ as input, on which they want to reach agreement. During the protocol, they keep updating their local binary value $b_i$.  \n At the end of the protocol, honest players should output the same value $b$, that is, there is a value $b$ such that $b_i=b$ for all honest player $i$. If all honest players hold the same input, that is, there is a value $b$ such that initially $b_i = b$ for all honest players, then at the end they should output $b$, that is, $b_i = b$ still holds for all honest players.% their binary value $b_i$. \n\n\nThe protocol proceeds in synchronous steps, where messages are guaranteed to be delivered within a step. So the protocol is designed for a {\\em synchronous} network, like the longest chain protocol. Each step follows the  paradigm below:\n\n\\begin{center}\n\\begin{tabular}{|c|c|}\n\\hline\n    Start of a step & End of a step \\\\\n\\hline\nEvery player & Every player\\\\\n    propagates $b_i$ & updates $b_i$ based on the received messages\\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\n\\subsection*{Intuition} \n\nThe key idea in the Algorand protocol lies in the way  \\emph{player $i$ updates $b_i$}. \nDenote $\\#_i(v)$ to be  the number of players from which $i$ has received the value $v$,  possibly including $i$ itself.  The  update rule is the following: \n\\begin{quote}\n    If $\\#_i(0)\\ge 2t+1$, then player $i$ sets $b_i=0$. Symmetrically, if $\\#_i(1)\\ge 2t+1$, then $i$ sets $b_i=1$.\n\\end{quote}\nThe above update rule stipulates that if more than $2t+1$ players hold 0 (or 1), of which $t+1$ must be honest, then player $i$ sets $b_i$ to 0 (or 1). Notice that the two conditions  $\\#_i(0)\\ge 2t+1$ and  $\\#_i(1)\\ge 2t+1$ never happens together in one step, since only Byzantine players vote twice and  there are at most $t$ of them.\n\nAn obvious issue with the above step is what if  $\\#_i(0)< 2t+1$ and  $\\#_i(1)< 2t+1$? This condition implies there has not been a $2/3$ majority of a value yet. To deal with this situation, we use a cryptographic primitive called \\emph{common coin}. Assume in each step there is a new randomly and independently selected bit $c$ shared with all players (we will show how to implement it later). The usage of the common coin is straightforward: each player sets $b_i=c$ when enough of the players have not had consensus. Hence, the updating of $b_i$ becomes:\n\\begin{enumerate}\n    \\item If $\\#_i(0)\\ge 2t+1$, then $i$ sets $b_i=0$.\n    \\item Else, if $\\#_i(1)\\ge 2t+1$, then $i$ sets $b_i=1$.\n    \\item Else, $i$ sets $b_i=c$.\n\\end{enumerate}\nThe intuition is to run this step  sufficiently many times, say $m=100$ times, and let player $i$ output its local value $b_i$. The following analysis shows that with sufficient iterations of this step, consensus is achieved among honest players with finality. \n\n\\paragraph{Analysis} The core step has the following properties,\n\\begin{itemize}\n    \\item[(A)] If, at the start of a step, the honest players are in agreement on a bit $b$, (i.e., if $b_i = b$ for all honest player $i$), then they remain in agreement on $b$ by its end.\n    \\item[(B)] If the honest players are not in agreement (on any bit) at the start of a step, then with probability $1/2$, they will be in agreement (on some bit) by its end.\n%    \\item[(C)] If all honest players started with the same initial binary value $b$ (i.e, if the honest players were originally in agreement on a bit $b$), then they will continue to agree on $b$.\n\\end{itemize}\nProperty (A) is easy to see since there are at least $2t+1$ honest players and they propagate their agreed values. The explanation for property (B) is that when honest players are not in agreement, they can be in either condition 1 and 3 (sets $b_i=0$ and $b_i=c$) or condition 2 and 3 (sets $b_i=1$ and $b_i=c$). In either case, coin $c$ is equal to the bit with probability $1/2$. Thus, despite initial values, by running this  step $m$ times, honest players will reach an agreement with probability $1-(1/2)^{m}$. However, this is not a consensus protocol, since honest players are not aware whether they are in agreement or not (even after $m$ steps) and when to terminate. The next section constructs a BFT consensus protocol, utilizing this basic step, to  solve this problem.\n\n\\subsection*{Consensus on a binary value}\n\nAlgorand's binary BFT consensus protocol is an ever-running loop that runs three steps in turn. The protocol is shown in figure~\\ref{fig:bba}.  We also use a counter $s$ (starting with $s=1$) to represent how many steps it has executed. So the first step has counter $s=1,4,\\ldots$; the second step $s=2,5,\\ldots$; and the third step $s=3,6,\\ldots$. \n\n\\begin{figure}[thb]\n    \\centering\n    \\includegraphics[width=\\textwidth]{figures/Algorand}\n    \\caption{Algorand consensus on a binary value}\n    \\label{fig:bba}\n\\end{figure}\nThe first and second steps in the figure have the aforementioned property (A). They also ensure that, once the agreement has already been reached on some bit, an honest player can learn this is the case, output the bit, and terminate. This is formally described as property (C).\n\\begin{itemize}\n    \\item[(C)] If, at the first or second step, an honest player $i$ outputs, then agreement will hold at the end of the step.\n\\end{itemize}\nAs already mentioned, the third step has property (A) and (B). From these properties, we can show that this is a Byzantine consensus protocol. (A) and (C) ensure that no honest player outputs different values, and (A) and (B) ensures that they eventually reach agreement and output a value.\n\n\\subsection*{Adding player replaceability and secret committee election}\nTo add the committee into the protocol, we give the eligibility to propagate messages to the committee. Notice that updating local value $b_i$ is still done by all players. The communication complexity is $O(nN)$ since each committee member sends messages to all players.\n\nTo enable player replaceability and secret committee election, players calculate credentials as introduced in the previous section. Once player $i$ calculates its credential for round $r$, step $s$: $\\sigma_{i}^{r,s}$, it learns its role (whether in committee), and can prove its role by appending the credential to its messages in this step. \nIn short, within a step: \n\\begin{center}\n\\begin{tabular}{|c|c|}\n\\hline\n    Start of a step & End of a step \\\\\n\\hline\n    \\textbf{Committee member} &  \\textbf{Every player}\\\\\n    propagates $b_i$ & updates $b_i$ based on the received messages\\\\\n    appends credential $\\sigma_{i}^{r,s}$ &\\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\nIn the protocol illustrated in Figure~\\ref{fig:bba}, we simply need to replace the quantity $2t+1$ by $2 E[N]/3$, since now the random committee has expected size $E[N]$ rather than $n=3t+1$.\n\n\\subsection*{Implementing common coin}\nHere we show how to implement the common coin in the third step. The common coin is generated in a separate step where a player  receives messages from many players, denoted by a set $SV$. The player picks the smallest credential hash from $SV$, hashes the credential with the step counter $s$, and uses the least significant bit as the coin $c$. Formally,\n\\begin{quote}\n    Letting $SV$ be the set of players from whom it has received a valid message, and letting $l={\\arg\\min}_{j\\in SV} H(\\sigma_j)$. $i$ uses $\\texttt{lsb}(H(\\sigma_j,s))$ as the common coin, where $H$ is a hash function and $\\texttt{lsb}$ is the least significant bit.\n\\end{quote}\n\n\\paragraph{Analysis.} If player $l$ whose credential hash is smallest is honest, then this procedure implements the common coin. Player $l$ is honest with probability $2/3$. Hence, this procedure generates a correct common coin for all players with probability 2/3. Therefore, the property (B) becomes ``with probability $1/3$ (rather than 1/2), honest players will be in agreement''. The protocol terminates within constant steps in expectation.\n\n\\subsection*{Multivalue consensus}\nHere we present the intuition on extending binary value to multivalue Algorand consensus. \nFirst, we need to elect a leader for each round $r$ who should build and propagate a valid block $B^r$. The ``potential leader'' election is the same as in the committee election, except with a much smaller threshold to elect just a few dozen players as potential leaders. \nThen (possibly multiple) potential leaders propagate their blocks. Each player chooses the leader whose credential hash is the smallest from potential leaders, and vote for the block hash twice: only when receiving more than $2/3$ first votes should it send the second vote. After these two steps (block proposing and two-round voting), each player either (a) receives a valid block $B^r$ from the leader and enough votes for its hash, or (b) no valid block has enough votes for its hash.\n\nThen, player $i$ starts the binary protocol with initial value $b_i=0$ in condition (a) or $b_i=1$ in condition (b). In the binary protocol, players also attach the block hash to their messages as additional information in condition (a), to make sure they hold the same block. The two-round voting also ensures that if two honest players start with condition (a), then they receive the same block $B^r$. If the binary protocol outputs value 0, it means block $B^r$ (which is known to all players) is finalized. Otherwise, if the output is value 1, it means an empty block $B^r_{\\epsilon}$ is finalized.\n\nNotice that the aforementioned block proposing and two-round voting steps are also committee-based and player-replaceable. Therefore, the whole Algorand protocol is committee-based and player-replaceable.\n\n\n\\section*{Conclusion}\n\nPutting the steps together, we have Algorand consensus where players agree on block $B^r$ for round $r$. To build the Algorand Blockchain, the consensus protocol is executed round by round to generate block $B^1,B^2,\\ldots$ sequentially, where block $B^{r+1}$ contains a hash pointer to parent block $B^r$. Each round has $O(nN)$ communication and terminates in constant expected steps, as shown in previous sections.\n\nWe can also turn Algorand into a proof-of-stake (PoS) blockchain, if we involve the stake held by a public key into the committee/leader election (more stake, higher chance to be elected).% then we end up with a PoS and permissionless blockchain. \nSince there is no forking at all in Algorand,  none of the key grinding and nothing-at-stake attacks that we saw in the longest chain version of PoS (Lecture 12) arise here. So the individual block security of Algorand guarantees security of the whole blockchain. \nOne weakness is that the security of Algorand is under a synchronous network setting, where messages are delivered within a step. \n\n\n\\paragraph{Forensics.} Algorand is designed for $n=3t+1$ players of which $t$ are Byzantine. If the Byzantine players are beyond $t$, they can deviate from the protocol and create a safety violation. Unlike HotStuff or Streamlet, there exists a safety attack that does not leave cryptographic evidence and malicious actors are not held accountable. For instance, in the second step, if all honest players agree on $b=0$ at the start of the step, but more than $1/3$ fraction of players are Byzantine and do not send any vote, then every honest player won't receive $2/3$ fraction of votes for $b = 0$, and they will switch their local value to $b = 1$ by the end of this step. This can result in a safety violation. Nevertheless, since the Byzantine players don't send any message at all, there is no cryptographic evidence to hold them accountable. This statement holds for Algorand with or without committee elections and player replaceability. Whether there is a BFT protocol that is efficient and has player replaceability (so that it can be used as a core consensus engine inside a PoS permissionless blockchain) with strong forensic support is an open question. \n\n% \\section*{Warmup: The Binary BA Protocol \\bba}\n% Let us start with a probabilistic binary Byzantine agreement named \\bba and not concern about player replaceability for now. This protocol targets $n=3t+1$ players and $t$-Byzantine fault tolerance. Each player $i$ holds a binary value $b_i$ on which they want to reach agreement. The protocol proceeds in synchronous steps, where messages are guaranteed to be delivered within a step. Each step follows this paradigm:\n\n% \\begin{center}\n% \\begin{tabular}{|c|c|}\n% \\hline\n%     Start of a step & End of a step \\\\\n% \\hline\n%     Propagates $b_i$ (including itself)& Updates $b_i$ based on the received messages\\\\\n% \\hline\n% \\end{tabular}\n% \\end{center}\n\n% \\subsection*{A Straw-man Step}\n% Before going to \\bba, we wish to show an intuition about \\emph{how player $i$ updates $b_i$}. Since the assumption of Byzantine players is $n/3$, it is not hard to have the following idea ($\\#_i(v)$ denotes the number of players from which $i$ has received the value $v$):\n% \\begin{quote}\n%     If $\\#_i(0)\\ge 2t+1$, then $i$ sets $b_i=0$. Symmetrically, if $\\#_i(1)\\ge 2t+1$, then $i$ sets $b_i=1$.\n% \\end{quote}\n% The above step says, if more than $2t+1$ players hold 0 (or 1), of which $t+1$ must be honest, then player $i$ sets $b_i$ to 0 (or 1). Notice that the two conditions  $\\#_i(0)\\ge 2t+1$ and  $\\#_i(1)\\ge 2t+1$ never happens together in one step, since there are at most $t$ Byzantine players who vote twice.\n\n% An obvious question with the above step is what if  $\\#_i(0)< 2t+1$ and  $\\#_i(1)< 2t+1$? This condition means there is not a $2/3$ majority of a value yet. To deal with this situation, we need a cryptographic primitive called \\emph{common coin}. Assume in each step there is a new randomly and independently selected bit $c$ magically appears in the sky. (We will show how to implement it later.) The usage of the common coin is straightforward: each player sets $b_i=c$. Hence, the straw-man step becomes:\n% \\begin{enumerate}\n%     \\item If $\\#_i(0)\\ge 2t+1$, then $i$ sets $b_i=0$.\n%     \\item Else, if $\\#_i(1)\\ge 2t+1$, then $i$ sets $b_i=1$.\n%     \\item Else, $i$ sets $b_i=c$.\n% \\end{enumerate}\n\n% \\paragraph{Analysis} This straw-man step has the following properties,\n% \\begin{itemize}\n%     \\item[(A)] If, at the start of a step, the honest players (at least $2t+1$) are in agreement on a bit $b$, (i.e., if $b_i = b$ for all honest player $i$), then they remain in agreement on $b$ by its end.\n%     \\item[(B)] If the honest players are not in agreement (on any bit) at the start of a step, then with probability $1/2$, they will be in agreement (on some bit) by its end.\n% %    \\item[(C)] If all honest players started with the same initial binary value $b$ (i.e, if the honest players were originally in agreement on a bit $b$), then they will continue to agree on $b$.\n% \\end{itemize}\n% A brief explanation for property (B) is that when honest players are not in agreement, they can be in either condition 1 and 3 (sets $b_i=0$ and $b_i=c$) or condition 2 and 3 (sets $b_i=1$ and $b_i=c$). In either case, coin $c$ is equal to the bit with probability $1/2$. Thus, despite initial values, by running this straw-man step sufficiently many times, honest players will reach an agreement with overwhelming probability.\n\n% \\subsection*{3 Steps of \\bba}\n% A problem with running the straw-man step a large number of times is that honest players are not aware when they are in agreement and can terminate early. To solve this problem, \\bba uses 3 different types of steps, modified from the straw-man step.\n% \\begin{itemize}\n%     \\item \\coinfixedtozero Step. The common coin is replaced by a fixed bit 0.\n%     \\item \\coinfixedtoone Step. The common coin is replaced by a fixed bit 1.\n%     \\item \\coingenuinelyflipped Step. The common coin is the genuinely random coin.\n% \\end{itemize}\n% As already mentioned, \\coingenuinelyflipped step enables reaching agreement with probability $1/2$. The first two steps, \\coinfixedtozero and \\coinfixedtoone, ensure that, once the agreement has already been reached on some bit, an honest player can learn this is the case, and terminate with the bit.\n\n% We also have the following property of \\coinfixedtozero and \\coinfixedtoone step.\n% \\begin{itemize}\n%     \\item[(C)] If, at \\coinfixedtozero or \\coinfixedtoone step, an honest player $i$ outputs, then agreement will hold at the end of the step.\n% \\end{itemize}\n% A brief explanation is, taking \\coinfixedtozero as an example, if an honest player $i$ outputs, players can be in either condition 1 or 3, since there are at most $t$ Byzantine players who vote twice so condition 2 is unreachable. Hence, at the end of \\coinfixedtozero,  honest players reach agreement on value 0.\n\n% \\subsection*{Description of \\bba}\n% Protocol \\bba is a 3-step loop that consists of \\coinfixedtozero, \\coinfixedtoone, and \\coingenuinelyflipped step. It uses a counter $s$, representing how many steps it has executed. The protocol is shown in Appendix, Table~\\ref{tab:bba}. From the aforementioned properties (A), (B), and (C), we can show that \\bba is a Byzantine agreement protocol. (A) and (C) ensure that no honest player outputs different values, and (B) ensures that they eventually reach agreement and output a value.\n\n\n% \\section*{Player-replaceability: selecting committees using sortition}\n% The advantage of protocol \\bba is player-replaceability, that is, each step can be assigned to a totally new committee, which is independently and randomly selected among all players. Given a committee of a step, we change the protocol's paradigm to:\n\n% \\begin{center}\n% \\begin{tabular}{|c|c|}\n% \\hline\n%     Start of a step & End of a step \\\\\n% \\hline\n%     \\textbf{Committee member} &  \\textbf{Every player}\\\\\n%     propagates $b_i$ (including itself)& updates $b_i$ based on the received messages\\\\\n% \\hline\n% \\end{tabular}\n% \\end{center}\n\n% In the committee selection, player $i$ uses a quantity \\emph{credential} $\\sigma$ to secretly determines whether it is selected. Relying on a random quantity $Q^r$ that is deduced from block $B^{r-1}$ (assuming round $r-1$'s block $B^{r-1}$ available on the blockchain), the credential $\\sigma_i^{r,s}$ is the unique signature on $r,s,Q^r$ and if $H(\\sigma_i^{r,s})<p$ ($H$ is a hash function, $p$ is a threshold) then player $i$ is selected as a committee member.  \\footnote{Or using the VRF output and proof derived from $r,s,Q^r$.}\n% The threshold $p$ should be chosen properly to have a suitable expected committee size.\n% When its time to act in step $s$ arrives, $i$ propagates $\\sigma_i^{r,s}$ with its message so that other players can verify its inclusion in the committee. Although the adversary may corrupt it, the message cannot be stopped from reaching other honest players. Moreover, the adversary has no more control on the rest of the protocol than he has by corrupting a random player: the committees of all future steps will be randomly and independently selected.\n\n% Let $\\kappa$ be the expected committee size and usually we have $\\kappa\\ll n$. In protocol \\bba, we just need to change the quantity $2t+1$ to $t_H\\approx 2 \\kappa/3$. Since the committee selection is randomized, we need to have some room for quantity $t_H$ and it should be less than the optimal $2 \\kappa/3$.\n\n% \\paragraph{Ephemeral keys.} Although the adversary cannot predict beforehand which users will be the committee, it would know their identities after seeing their messages, and could then corrupt all of them and oblige them to certify a fake block. To prevent this, players use ephemeral keys: public/secret key pairs that are single-use-only, and once used, are destroyed. Only credentials $\\sigma$ are signed by the long-term public/secret key pairs, and any other message is signed by ephemeral key pairs.\n\n\n\n% \\section*{Extending \\bba to multi-valued Byzantine agreement \\ba}\n% Here we present the intuition on extending \\bba to multi-valued Byzantine agreement \\ba. For the full protocol \\ba, you can refer \\cite{chen2019algorand}.\n\n% We need to elect a leader for each round $r$ who should build and propagate a valid block $B^r$. The ``potential leader'' election is the same as committee election, except with a different threshold. Then (possibly multiple) potential leaders propagate their blocks. Each player chooses the leader whose credential hash is the smallest, and vote for the block hash for two rounds. After these block proposing and two-round voting steps, each player either (a) receive a valid block $B^r$ from the leader and enough votes for its hash, or (b) no valid block has enough votes for its hash.\n\n% Player $i$ starts protocol \\bba with initial value $b_i=0$ in condition (a) or $b_i=1$ in condition (b). The two-round voting ensures that if two honest players start with $b_i=0$, then they receive the same block $B^r$. If protocol \\bba outputs value 0, it means block $B^r$ is finalized. Otherwise, if the output is value 1, it means an empty block $B^r_{\\epsilon}$ is finalized.\n% % Classic paper by R. Turpin and B. Coan. (perhaps not related here).\n\n% % Graded consensus in 2019 paper: Algorand: A secure and efficient distributed ledger.\n\n% Notice that the aforementioned block proposing and two-round voting steps are also player-replaceable. Therefore, the whole Algorand protocol is player-replaceable.\n\n% \\section*{Proof-of-Stake (PoS)} The Algorand described in this lecture is a permissioned one. If we involve the stake held by a public key into the committee/leader selection (more stake, higher chance to be selected), then we end up with a PoS and permissionless blockchain.\n\n% \\section*{Forensics and Accountability} \\bba is designed for $n=3t+1$ players of which $t$ are Byzantine. If the Byzantine players are beyond $t$, they can deviate from the protocol and create safety violation. Unlike HotStuff or Streamlet, their misbehavior doesn't leave a cryptographic evidence and they are not held accountable. In \\coinfixedtoone step, if all honest players agree on $b=0$ at the start of the step, but more than $1/3$ fraction of players are Byzantine and do not send any vote, then every honest player won't receive $2/3$ fraction of votes for $b = 0$, and they will switch their local value to $b = 1$ by the end of this step. This breaks property (A) and can result in a safety violation. Nevertheless, since the Byzantine players don't send any message at all, there is no cryptographic evidence to hold them accountable.\n\n% \\section*{Appendix}\n% \\begin{table}[!th]\n%     \\caption{Protocol \\bba}\n%     \\label{tab:bba}\n%     [\\coinfixedtozero Step] Each player $i$ propagates $b_i$.\n%     \\begin{itemize}\n%         \\item[1.1] If $\\#_i(0)\\ge 2t+1$, then $i$ sets $b_i=0$. Outputs 0 and do not change $b_i$. That is, for future steps, propagates 0.\n%         \\item[1.2] If $\\#_i(1)\\ge 2t+1$, then $i$ sets $b_i=1$.\n%         \\item[1.3] Else, $i$ sets $b_i=0$.\n%     \\end{itemize}\n%     [\\coinfixedtoone Step] Each player $i$ propagates $b_i$.\n%     \\begin{itemize}\n%         \\item[2.1] If $\\#_i(1)\\ge 2t+1$, then $i$ sets $b_i=1$. Outputs 1 and do not change $b_i$. That is, for future steps, propagates 1.\n%         \\item[2.2] If $\\#_i(0)\\ge 2t+1$, then $i$ sets $b_i=0$.\n%         \\item[2.3] Else, $i$ sets $b_i=1$.\n%     \\end{itemize}\n%     [\\coingenuinelyflipped Step] Each player $i$ propagates $b_i$. %and $\\sigma_i$ (the credential of $i$ of this step, used to compute the common coin).\n%     \\begin{itemize}\n%         \\item[3.1] If $\\#_i(0)\\ge 2t+1$, then $i$ sets $b_i=0$.\n%         \\item[3.2] If $\\#_i(1)\\ge 2t+1$, then $i$ sets $b_i=1$.\n%         \\item[3.3] Else, $i$ sets $b_i$ to the common coin $c$.%letting $SV$ be the set of players from whom it has received a valid message, and letting $l={\\arg\\min}_{j\\in SV} H(\\sigma_j)$. $i$ sets $b_i=\\texttt{lsb}(H(\\sigma_j,s))$, where $H$ is a hash function and $\\texttt{lsb}$ is the least significant bit.\n%     \\end{itemize}\n% \\end{table}\n\n% \\subsection*{Implement the common coin}\n% %\\gerui{Explain a player's credential $\\sigma_i$: its signature on a random quantity $Q_r$ that is from the last block, public visiable to all.}\n% Here we show how to implement the common coin in \\coingenuinelyflipped step. In \\coingenuinelyflipped step, a player should receives messages from many players, denoted by $SV$. It picks the smallest credential hash from $SV$, hash the credential with the step counter $s$, and use the least significant bit as the coin $c$. Step 3.3 becomes\n% \\begin{itemize}\n%     \\item[3.3] Else, letting $SV$ be the set of players from whom it has received a valid message, and letting $l={\\arg\\min}_{j\\in SV} H(\\sigma_j)$. $i$ sets $b_i=\\texttt{lsb}(H(\\sigma_j,s))$, where $H$ is a hash function and $\\texttt{lsb}$ is the least significant bit.\n% \\end{itemize}\n\n% \\paragraph{Analysis} If player $l$ whose credential hash is smallest is honest, then this procedure implements the common coin. Player $l$ is honest with probability $2/3$. Hence, the property (B) for \\coingenuinelyflipped step is:\n% \\begin{itemize}\n%     \\item[(B)] If the honest players are not in agreement (on any bit) at the start of a step, then with probability $1/3$, they will be in agreement (on some bit) by its end.\n% \\end{itemize}\n\n\\nocite{micali2018byzantine}\n\\nocite{chen2019algorand}\n\\nocite{sheng2020bft}\n\\bibliography{references}\n\\bibliographystyle{unsrt}\n\\end{document}\n\n\n\n\n\n\n\nhttps://medium.com/xinfin/xinfin-partners-with-stanford-university-for-treehacks-2019-5ca7388b4c4c \n\nhttps://www.coindesk.com/r3-corda-now-has-a-bridge-to-public-blockchains-with-arrival-of-ethereum-based-xdc",
    "lecture_14.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\usepackage{markdown}\n\\usepackage{amsthm}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\newcommand{\\indicator}{{\\bf 1}}\n\\newcommand{\\pramod}[1]{{\\color{red}\n\\footnotesize[Pramod: #1] }}\n\\newcommand{\\xw}[1]{{\\color{green}\n\\footnotesize[Xuechao: #1] }}\n%\\theoremstyle{definition}\n\\newtheorem{definition}{Definition}\n\\newtheorem{theorem}{Theorem}\n\\newtheorem{lemma}{Lemma}\n%\\let\\proof\\relax\n%\\let\\endproof\\relax \n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 14}\n\\cfoot{\\thepage}\n\n\\title{Lecture 14: Blockchain protocols with finality: Streamlet and HotStuff}\n\\author{Principles of Blockchains, University of Illinois,  \\\\ Professor:  Pramod Viswanath \\\\ Scribe:  Xuechao Wang}\n\\date{March 16, 2021}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nSo far, we have seen the longest chain protocol (module 1) and its variants (module 2). These protocols all favor liveness, but are not safe under network partition. In this lecture (as a beginning of module 3), we study a different family of blockchain protocol called Byzantine fault tolerant (BFT) protocols, which guarantee deterministic safety (aka. finality). We study two BFT protocols, Streamlet and HotStuff, the former is simple, and the latter has state-of-art performance.\n\\end{abstract}\n\n\\section*{Introduction}\n\nSo far we have focused on the longest chain consensus protocol (module 1) and modifications to scale performance (module 2). The major advantage of the protocol is its very strong liveness property: the protocol is live even with minuscule honest hash power:  a single honest miner has a chance to succeed in the PoW lottery and get to propose a block, thus extending the longest chain regardless of the network synchrony. The protocol guarantees  security  for a majority honest hash power, but with two caveats: \n\\begin{itemize}\n    \\item {\\em Probabilistic Safety Guarantee}: the safety of the confirmed blocks is provided in terms of the {\\em probability} of deconfirmation (``error\").  \n    \\item {\\em Synchronous Network Operation}: honest nodes crucially need to synchronize at periodic intervals on the state of the longest chain, so that they can work on extending the common longest chain, avoiding forking. \n\\end{itemize}\nIn summary:\n\\begin{quote}\n    The longest chain protocol prioritizes liveness over  safety.\n\\end{quote} \nIn some applications, safety is very important, especially deterministic guarantees (known as ``finality\") for a confirmed ledger entry,  e.g., financial applications. In such a case, there is not much respite the longest chain protocol (and any of the modifications we saw in the past module) will offer. In this lecture, we will study  blockchain protocols that offer finality, and even if the network is not synchronous. This is the goal of this lecture.  The protocols we see are the culmination of a sequence of works in a family of  BFT (Byzantine fault tolerant) protocols, studied in computer science since the 1980s.  \n\n\\section*{BFT Protocol Setup}\nWe instantiate the  BFT protocol with a {\\em fixed} set of participating nodes (referred by $N$). The participating nodes have a fixed identity (public key), known to all participants. This is a departure from the  permissionless blockchains supported by the longest chain protocol; we will discuss how to adapt the BFT protocols to the permissionless setting next lecture. \n\nThe protocol proceeds in {\\em rounds}, denoted by integers, much like the PoS longest chain protocols we studied in Lecture 12. Unlike the PoS protocols, here a {\\em single} proposer is elected in each round.\nThe proposer should be chosen and verified in a distributed manner. In a permissioned system, we can do the proposer election in two simple ways: (a) A round robin fashion, e.g., round $i$'s proposer is the node $(i~ {\\rm mod}~N$); (b) Using a distributed pseudo-random function or a hash function $H: \\{0,1\\} \\rightarrow [N]$, round $r$s proposer is computed as $H(r)$.\n\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=\\textwidth]{figures/streamlet.png}\n    \\caption{(a)Proof-of-stake longest chain protocol from Lecture 12; (b)Streamlet;(c)HotStuff.}\n    \\label{fig:hotstuff}\n\\end{figure}\n%\\pramod{lets replace the word leader by proposer, because this is the terminology we have used throughout. talk about the leader election process, how a single leader is elected. you can talk about pacemaker here and any/all good ideas, both in theory and in practice. ideally proposer election should be random, not known even to the proposer, for good permissionless protocols. talk about this issue (VRF).  }\n\n%In the implementation of HotStuff, The details of electing a proposer are encapsulated in an abstraction called a {\\it pacemaker}, that needs to provide two guarantees: Infinitely often, all nodes spend a certain period of time jointly in a epoch, and a unique correct proposer is elected for the epoch. A naive way to achieve the pacemaker properties is by doubling the time each node spends in each epoch until a decision is made. In each epoch, proposers can be rotated deterministically, they are elected via a distributed pseudorandom function, or they use a randomized back-off protocol. \\pramod{I moved this material here, but you will likely need to rewrite.}\n\n\\section*{Streamlet}\n\n\\subsection*{Streamlet protocol}\n\n\\noindent {\\bf Chain rule.} Streamlet protocol works as follows. In every round:\n\\begin{itemize}\n    \\item The rounds designated proposer proposes a new block extending from the longest notarized chain it has seen (if there are multiple, break ties arbitrarily). The notion of  ``notarization\" is defined below.\n    \\item Every node votes for the first proposal they see from the rounds proposer, as long as the proposed block extends from (one of) the longest notarized chain(s) that the voter has seen. A vote is a signature on the proposed block.\n    \\item When a block gains votes from more than $2N/3$ distinct nodes, it becomes notarized. A chain is notarized if its constituent blocks are all notarized.\n\\end{itemize}\n\nWe call the set of  distinct votes on a notarized block a {\\it quorum certificate} (QC). This choice of quorum size to be more than $\\frac{2N}{3}$ makes sure that at most one block per round can be notarized as long as the number of malicious nodes is less than $N/3$. This is because the intersection of two quorums has size at least $N/3$ (see Figure~\\ref{fig:quorum}) and only malicious nodes will potentially equivocate.\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.3\\textwidth]{figures/quorum.png}\n    \\caption{The intersection of two quorums must be greater than $N/3$.}\n    \\label{fig:quorum}\n\\end{figure}\n\n\n\\noindent {\\bf Confirmation rule.} Since at most one block per round can be notarized, can we simply confirm notarized blocks? Unfortunately this is insecure,  because two blocks in different rounds can be both notarized at the same height of the blockchain as seen by the following example.\n\n\n\\noindent {\\bf Confirming a 1-deep notarized block is insecure.} Let $f < N/3$ be the number of malicious nodes. In Figure~\\ref{fig:streamlet1}, a malicious proposer from round 3 proposes block $B_3$, but it only sends $B_3$ to $x$ honest nodes, where $2N/3 -f<x<2N/3$. If all $f$ malicious nodes keep their votes on $B_3$ private, then $B_3$ will not be notarized in the view of any honest node. Suppose the proposer of round 4 is honest, then it will propose a block $B_4$ at the same height as $B_3$. Every honest node votes for $B_4$ , and it gets notarized. After that, all $f$ malicious nodes release their votes on $B_3$ and make $B_3$ notarized. Since $B_3$ and $B_4$ are conflicting (not on a chain), confirming either one of them will lead to a safety violation. So notarization does not mean confirmation.\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.3\\textwidth]{figures/streamlet1.png}\n    \\caption{Two blocks at the same height can be both notarized.}\n    \\label{fig:streamlet1}\n\\end{figure}\n\n\\noindent {\\bf Confirming a $k$-deep notarized block is also insecure.} In the longest chain protocol, we have also seen that confirming the tip of the chain is not secure. The solution in the longest chain protocol is to confirm according to the $k$-deep rule, with sufficiently large $k$. The natural question is  whether  the $k$-deep confirmation rule (confirming the $k$-deep block in the longest notarized chain) is secure in Streamlet? Unfortunately, this is not the case:  during asynchrony, the adversary can play the trick in the previous attack (Figure~\\ref{fig:streamlet1}) at every height to create two equally long chains of arbitrary length. Recall that we assume the adversary can delay each message arbitrarily when the network is asynchronous. In Figure~\\ref{fig:streamlet2}, at each height, the adversary makes sure that only $x$ honest nodes vote for the block (with an odd round number) in the chain above, where $2N/3 -f<x<2N/3$. And after the conflicting block (with an even round number) in the chain below gets notarized, the adversary releases $f$ private votes to make the block above notarized. Because of this {\\em balance attack}, the $k$-deep rule is still not safe in Streamlet. \n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.7\\textwidth]{figures/streamlet2.png}\n    \\caption{A balance attack.}\n    \\label{fig:streamlet2}\n\\end{figure}\n\n\\noindent {\\bf Confirming a 2-deep notarized block with  consecutive round numbers is insecure.} Note that in this balance attack, there are no blocks with consecutive round numbers in a chain. Then how about confirming the notarized chain up to the second last block when there are two adjacent blocks with consecutive round numbers at the tip? Note that we cannot confirm the last block in the chain because of the attack in Figure~\\ref{fig:streamlet1}. With this confirmation rule, no block is confirmed in Figure~\\ref{fig:streamlet2}, so there is no safety violation for this attack. However, a different  attack is fatal; see   Figure~\\ref{fig:streamlet3}. Here the adversary conducts an analogous attack on blocks $B_3$ and $B_4$ to make them both notarized.  A malicious proposer from round 5 places the block $B_5$ as a child of $B_4$, and makes sure that only $x$ honest nodes vote for $B_5$, where $2N/3 -f<x<2N/3$. $B_6$ is proposed as a child of $B_3$ and every honest node will vote for it. After $B_6$ is notarized, all $f$ malicious nodes release their votes on $B_5$ and make $B_5$ notarized. In this case, we  see that $B_4$ and $B_5$ are notarized as  a chain; so $B_4$ is in a 2-deep notarized chain with consecutive round numbers and will be confirmed. However confirming $B_4$ will lead to a safety violation, because some honest nodes may adopt $B_3$ and $B_6$ as the longest notarized chain.\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.4\\textwidth]{figures/streamlet3.png}\n    \\caption{Two blocks with consecutive round numbers are not enough for secure confirmation.}\n    \\label{fig:streamlet3}\n\\end{figure}\n\n\\noindent {\\bf Confirming a 3-deep notarized block with consecutive round numbers is secure.} Since the rule with two blocks in a row does not work, let us try one more time: {\\em three blocks in a row}. If in any notarized chain, there are three adjacent blocks with consecutive round numbers, we confirm the prefix of the chain up to the second of the three blocks. It turns out this one is safe! Suppose one honest node sees three notarized blocks $B_5,B_6,B_7$ from rounds $5,6,7$ in a chain (see Figure~\\ref{fig:streamlet4}), to prove safety we argue that no block can be notarized at the same height as $B_6$. For the contradiction, suppose there is a notarized block $B$ from round $X$ conflicting $B_6$. Due to the fact that at most one block can be notarized per round, we know $X>7$ or $X<5$.\n\n\\begin{itemize}\n    \\item {\\bf Case 1:} $X < 5$. Since block $B$ is notarized, it means that more than $N/3$ honest nodes, denoted by the set $S$, voted for block $B$ and not only so, at the time of the voting (that is, during round $X < 5$), they must have observed block $B_3$ notarized. Now the honest nodes in $S$ will not vote for block $B_5$ during round 5, since it fails to extend a longest notarized chain seen, which is block $B_3$ or longer. Since $f < N/3$, this means that block $B_5$ can never get notarized in an honest node's view, which leads to a contradiction.\n    \\item {\\bf Case 2:} $X > 7$. Since block $B_7$ is notarized, more than $N/3$ honest nodes (denoted the set $S$) must have seen a notarized block $B_6$ by the time they vote for block $B_7$ (i.e., by the end of round 7). As a result, in round $X > 7$, the set $S$ of nodes must have seen block $B_6$ notarized and will not vote for block $B$, since block $B$ now fails to extend the longest notarized chain seen (which is block $B_6$ or longer). Since $f < N/3$, this means that block $B$ can never get notarized in an honest node's view, which leads to a contradiction.\n\\end{itemize}\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.7\\textwidth]{figures/streamlet4.png}\n    \\caption{Streamlet confirmation example. In this example, the prefix of the top chain up to the round-6 block is considered confirmed.}\n    \\label{fig:streamlet4}\n\\end{figure}\n\nTherefore, we can conclude that this three-block confirmation rule is safe. Note that the above proof holds, no matter what the actual network delays are, and even if honest nodes rounds are not synchronized (as long as the local round numbers are monotonically increasing). Of course, if the network is partitioned and honest nodes messages are being held up, then we cannot guarantee progress. As explained next, liveness ensues in Streamlet during ``periods of synchrony\", i.e., during a period of time in which messages between honest nodes are delivered within a known bound $\\Delta$.\n\n\nIf we set the round duration to be the maximum round-trip delay ($2\\Delta$), then when an honest proposer proposes its block at the beginning of a round. This should allow sufficient time for all the honest nodes to get their votes in and notarize the block. Therefore, if the adversary has less than $1/3$ of all nodes, it does not have the power to stop chain growth. Formally it can be shown that once there are 5 consecutive rounds of honest proposers, a new honest block will be confirmed.\n\n\\subsection*{Performance of Streamlet}\n\n\\noindent {\\bf Communication complexity of Streamlet.} Streamlet requires nodes to {\\em echo} received messages (blocks or transactions) to everyone else. Let the block size be $B$ bits and vote size by $V$ bits. In each round, there are $N$ senders, $N$ receivers, and on each link one block and $N$ votes (due to echoing) are sent. The total communication adds up to $N^2(B+NV) = N^2 B + N^3 V$ bits per block, even in the case of an honest proposer. If $N$ is large (i.e., we want the protocol to be scalable), $N^3 V$ is the dominating term in the communication complexity.  Furthermore,  Streamlet requires echoing for its security guarantees (thus necessarily incurring $N^3$ communication complexity); this is best seen via the  example below (see Figure~\\ref{fig:streamlet_live}).\n\nConsider a blockchain system with $N=7$ nodes $\\{a,b,c,d,e,x,y\\}$; suppose   nodes $x$ and $y$ are Byzantine. By round $r$, all honest nodes share the same view of the world. Then, $x$ is chosen to be the proposer of round $r$. During the first half $\\Delta$ of round $r$ it sends its block proposal $B$ only to nodes $a,b,c$ and $y$. In the second half of the round, $a,b$ and $c$, follow the protocol and vote for $B$, sending their signature to all other nodes. The other Byzantine node, $y$, on the other hand, sends its vote only to $a$. At this point the round ends and no further votes on $B$ will be cast. It is clear that at this point $a$ has collected 5 ($> 2N/3$) votes for $B$ (from $a,b,c,x,y$) while any other honest node collected only 4 of them. This leads to $B$ being notarized only by $a$.\nIf there are no vote echoes, in the following rounds $a$ does not vote for any proposal that does not extend $B$. If $a$ and $y$ cease to participate, liveness is compromised. When $a$ becomes the leader, it proposes to extend $B$ but no one else votes for it, because they dont know it is notarized. Therefore, the chain stops growing.\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.7\\textwidth]{figures/streamlet_live.png}\n    \\caption{Liveness is compromised if there is no message echoing in Streamlet.}\n    \\label{fig:streamlet_live}\n\\end{figure}\n\nSince we have to use at least $N-1$ messages to spread the block among all nodes, the best communication cost we can expect would be $O(N)$ per block. We say a blockchain protocol achieves {\\it linearity} if the communication complexity  is linear in the number of nodes. Obviously, Streamlet is far from achieving linearity due to broadcasting and echoing. \n\n\\noindent {\\bf Latency of Streamlet.} To guarantee liveness, Streamlet makes an assumption that rounds operate in lock-step with $2\\Delta$ duration. Under the ``normal path\" (i.e., no adversary and no forking), the confirmation latency of Streamlet is two rounds ($4\\Delta$ in time duration). If there are $f < N/3$ malicious nodes, Streamlet still guarantees liveness whenever there are 5 consecutive honest proposers. This happens on an average once every $1/(2/3)^5 \\approx 7.6$ rounds, about $15\\Delta$. Recall that Bitcoin latency is $O(\\log_e(\\frac{1}{\\epsilon})\\frac{1}{\\lambda\\Delta})\\Delta$, where $\\epsilon$ is the confirmation error probability and $\\lambda\\Delta \\ll 1$ for security. So compared to Bitcoin, Streamlet achieves much better latency: small constant and finality (i.e., deterministic confirmation).\n\nHowever, BFT protocols can actually achieve even better latency by having non lock-step rounds.\nStreamlet foregoes an important property of asynchronous consensus protocols, called {\\it responsivity}: the ability to advance at the speed of the actual network delays without waiting for maximal network delays.\n\n\\noindent {\\bf External client support.} In Streamlet, the votes are not recorded on the blockchain itself. Therefore, while Streamlet creates a total-order on transactions, the question of how an external client (who is not in the permissioned committee) can verify the correctness of the ledger and confirm a transaction is not addressed. \n\n% three subsections. \n\n% 1) Describe the Protocol. \n\n% 2) Describe the confirmation rule and intuition for the rule. Why k-deep doesnt work and we need consecutive slot leader blocks, and why we need 3 in a row for security. \n\n% 3) Performance of Streamlet.  \n% (a) Latency (b) Communication complexiity. \n\n% \\pramod{you can use some of the material below, but good to write in a  logical manner (like you did for lecture 12), as opposed to bullet points. The main point is that complexity is bad and is not responsive. we will move the citation to the blog post to the references section at the end.}\n\n% In a \\href{https://dahliamalkhi.github.io/posts/2020/12/what-they-didnt-teach-you-in-streamlet/}{recent blog} written by Dr.~Dahlia Malkhi (CTO of Facebook's Diem),  the following gaps left by Streamlet are explored. \\pramod{move all citations to the end of the notes.}\n% \\begin{itemize}\n%     \\item Streamlet incurs $O(n^3)$ message complexity per block.\n%     \\item Streamlet makes a strong and unnecessary synchrony assumption.\n%     \\item Streamlet's votes are not on chain, so external clients cannot verify the correctness of the log.\n% \\end{itemize}\n\n\n\\section*{HotStuff}\n\nHotStuff is the consensus protocol behind Facebook's Diem project. HotStuff is very similar to Streamlet, but it achieves both linearity and responsiveness. Now that we have seen Streamlet in detail, it is straightforward to extend the protocol into HotStuff. \n%Actually, it is not hard to turn Streamlet into HotStuff. \n%We point out that HotStuff is proposed earlier than Streamlet, so HotStuff is not an optimized version of Streamlet. We present them in this order just because Streamlet is simpler.\n%\\pramod{we will talk about the history of which came first and the order of inventions in the references section at the end of the notes. for now, the goal is to propose modifications to the protocol above to improve complexity and responsivity.  }\n\n\\noindent {\\bf HotStuff highest QC.} \nIn HotStuff, a block is linked to its parent using the QC itself (on-chain), so everyone can verify it has been notarized (see Figure~\\ref{fig:hotstuff}(c)).\nEvery node keeps the QC with the highest round number (HighQC) it knows of. As in Streamlet, a proposer proposes a block extending highQC, while a node votes for a proposal if it extends the branch of its highQC. But an important difference is that a node only sends the vote to the proposer of the next round. Therefore, in HotStuff, the communication cost per block is $NB + NV$; thus HotStuff has linear complexity.\n\n% \\begin{figure}\n%     \\centering\n%     \\includegraphics[width=\\textwidth]{figures/HotStuff.png}\n%     \\caption{HotStuff blockchain.}\n%     \\label{fig:hotstuff}\n% \\end{figure}\n\n\\noindent{\\bf HotStuff finalization rule} is the same as in Streamlet: whenever three alternating blocks whose rounds are consecutive are formed, the middle block of the three blocks becomes finalized (along with all blocks in the chain to the genesis).\n\n\\noindent{\\bf HotStuff round synchronization.} HotStuff does not require round synchronization. A proposer can propose a new block immediately after it receives a new QC, i.e., the actions in HotStuff are event driven rather than time driven as in Streamlet. The protocol can make progress at the speed of the actual network delays, so HotStuff is responsive. By doubling the time each node spends in each round until a decision is made, liveness is guaranteed.\n\n\n\\section*{Protocol Forensics}\nIn the Streamlet and HotStuff protocols we have seen that there is a fixed number of  participants and their identities (through their public keys) are fixed and known as well. Can these identities be used to provide some incentives for honest behavior? In particular, if the nodes that collude to launch a safety attack can  be identified with cryptographic integrity, such {\\em forensics} would provide a strong  disincentive to malicious behavior. Indeed, a single honest node can detect at least $\\frac{N}{3} + 1$ malicious actors (without a need to collaborate with any other node), for both the Streamlet and  HotStuff blockchain protocols. \n\nSuppose an honest node sees a safety breach.  \nThen there must be more than $\\frac{N}{3}$ nodes, each of which must have either voted on two blocks with the same round number or voted on two blocks with depth and round number ordering reversed; see Figure~\\ref{fig:streamletfork}.  Both of these conditions  are observable by the honest node; further an intersection of the QC of the conflicting blocks yields cryptographic evidence of the malicious actors.  \n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=\\textwidth]{figures/streamlet_forensics.png}\n     \\caption{Safety breach in Streamlet/HotStuff. When an honest node observes these two conflicting notarized blocks (in red), at least $N/3+1$ malicious nodes can be detected by taking the intersection of the corresponding two QCs.}\n     \\label{fig:streamletfork}\n \\end{figure}\n\n%\\pramod{need a figure here for each of the two types of attacks. left: round numbers same. right: round number and depth reversed.}\n\n\\section*{Conclusion}\n\n In this lecture, we have  upgraded  probabilistic safety in the longest chain protocol to deterministic safety (known as {\\em finality}); but this improvement has  come at two costs:\n \\begin{itemize}\n     \\item there is a fixed number of  participants and their identities (through their public keys) are fixed and known as well, which does not suit the permissionless nature of blockchains we have discussed so far. In the next lecture (Lecture 15) we study a blockchain protocol, also based on the BFT family, that suits a permissionless architecture and is robust to adaptive adversaries just like the PoW longest chain  protocol.  \n     \\item liveness is weakened in the pursuit of strengthening security guarantee to a finality: substantial honest participation is needed now, unlike the longest chain protocol that allowed dynamic participation and even a single honest miner ensured liveness.   How to have both finality (deterministic safety) and dynamic availability (liveness even under varying participation levels of honest nodes) is the topic of the lecture after next (Lecture 16). \n \\end{itemize} \n \n \\section*{Reference}\nWe have presented  \\href{https://arxiv.org/pdf/1803.05069.pdf}{HotStuff} as  an optimized version of Streamlet. We present them in this order  because Streamlet is simpler, although HotStuff predates Streamlet by a few years.  Our presentation is inspired by a \\href{https://dahliamalkhi.github.io/posts/2020/12/what-they-didnt-teach-you-in-streamlet/}{ blog post}, co-authored  by Dr.~Dahlia Malkhi (one of the inventors of HotStuff); the blog post compares Streamlet and HotStuff sharply and presents a clean way to morph Streamlet back into HotStuff.\n\n\\end{document}",
    "lecture_04_new.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\usepackage{caption}\n\\usepackage{subcaption}\n\\let\\proof\\relax\n\\let\\endproof\\relax\n\\usepackage{amsthm}\n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 4}\n\\cfoot{\\thepage}\n\n\\title{Lecture 4:  Peer to Peer Network and Bitcoin system}\n\\author{Principles of Blockchains, Princeton University,  \\\\ Professor:  Pramod Viswanath \\\\ Scribes: Soubhik Deb, Ranvir Rana, \\\\Suryanarayana Sankagiri and Xuechao Wang}\n%\\date{February 4, 2021}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nIn this lecture, we cover the networking and system aspects of Bitcoin. We first introduce the notion of peer-to-peer networks, of which a blockchain is an example. We describe how messages are broadcast to all users in such a network. We specify the details of the networking layer in Bitcoin and also discuss two interesting ways of improving the networking layer protocols. The first, called \\textsf{Perigee}, is a technique to reduce the delay in propagating messages. The second, called \\textsf{Dandelion}, reduces the extent to which an eavesdropper can track messages to its source. In the second part of this lecture, we cover some aspects regarding transactions in Bitcoin. Transactions give semantic meaning to the decentralized ledger enabled by a blockchain. We discuss how Bitcoin gets its monetary value and how money is transferred from one user to another. We highlight the different safety checks that users can perform to prevent any form of cheating. This leads to the notion of validating a block. We argue that validating blocks is a storage and computation intensive process. and show how Bitcoin can support light clients that perform a limited extent of validation. Finally, we take a high-level view and discuss how a blockchain can act as a distributed computer, running arbitrary programs termed as smart contracts.\n\\end{abstract}\n\n\\section*{Basic primitives and random network construction}\nIn blockchain systems, the basic network-layer operation is to {\\em broadcast} messages. By broadcast, we mean that a user sends some information/message to all other users in the system. There are two basic blockchain elements being broadcast:\n\\begin{itemize}\n    \\item data values that are to be recorded on the ledger\n    \\item blocks\n\\end{itemize}\n\nIn a decentralized system such as a blockchain, the network should have\n\\begin{itemize}\n    \\item Robustness from a single point of failure: No centralized server;  \n    \\item Robustness from censorship: No centralized server; \n    \\item Robustness from nodes going offline, high churn rate; \n\\end{itemize}\nAdditional desirable properties include\n\\begin{itemize}\n    \\item a message that is broadcast should reach all users as quickly as possible\n    \\item a message that is broadcast should not be traceable back to its origin (for the sake of anonymity/privacy)\n\\end{itemize}\nThe need for robustness implies that we do not want a client-server relationship; we settle for a peer-to-peer (P2P) network where each node has identical behavior.\n%A distributed system's security is closely tied to its network assumption; hence it is essential to design the network to mirror these assumptions. We understand p2p networking using the Bitcoin network as a reference.Examples of a P2P network include Napster and  BitTorrent. \n\nConsider a set of users in a P2P network. An \\textit{overlay network} depicts the connections between nodes, and is represented as a graph. It abstracts out the physical network switches and routers and defines virtual links between nodes. Two nodes that are connected by a link can exchange messages directly. Those that are not connected by a link must find a path connecting them on this overlay network in order to communicate messages.\n\nOverlay networks can be split into two base categories: structured and unstructured. Structured overlay networks, like \\href{https://en.wikipedia.org/wiki/Chord_(peer-to-peer)}{CHORD}, assign an identifier to each node and uses that to construct well-defined routing rules. These networks are excellent for routing sending point to point messages, a use case not required for Bitcoin. Structured networks are suitable for broadcast, too; any message transmission takes $O(\\log N)$ hops on CHORD with $O(\\log N)$ connections per node.\n\nOn the other hand, unstructured networks like $d$-regular graphs have no node identifiers; a node connects to $d$ other nodes randomly. While routing point to point messages takes $O(\\log N)$ hops, it's impractical since finding the path from point A to point B involves many peer queries. On the other hand, broadcast is very efficient using gossip and takes $O(\\log N)$ hops. Thus, the number of hops required is the same as the structured network with the added benefit of $O(1)$ peer connections. Hence, the Bitcoin network uses an unstructured $d$-regular overlay network. \n\nHow does broadcast take only $O(\\log N)$ steps? We first need to understand the gossip-flooding-based broadcast protocol. The flooding protocol mimics the spread of an epidemic. Once a node is ``infected\", it infects its peers and forever stay's infected. It is easy to see that the spread of information will happen exponentially; hence the information will take $O(\\log N)$ hops to spread to all nodes. To formally understand the spread, we note that $d$-regular graphs with $d\\geq 3$ are an \\textit{expander graph} for large sizes ($|V|$) with high probability. An expander graph is a connected but sparse graph ($|E|=O(|V|)$) with the following property: $|\\partial A| \\geq \\epsilon|A|$ for any connected sub-graph $A$ with $|A|<0.5|V|$. Here, $|\\partial A|$ refers to the number of vertices outside $A$ with at least one neighbor in $A$. A gossip message originates with $A(0)$ as the broadcasting node with $|A(0)|=1$, in the next hop, it will spread to $\\partial A(0)$ with $|A(1)|\\geq (1+\\epsilon)|A(0)|$. This recursion continues and we have $|A(k)|\\geq(1+\\epsilon)^kA(0)$. Thus, the number of steps to reach half the number of nodes is logarithmic in the number of nodes. It can be shown that the other half of the nodes can also be covered in $O(\\log N)$ time.\n\n\n%Engineering issues (peer discovery, bootstrap, churn). Implementation connections (to the lab experiment). Validation of tx, blocks. How does that impact networking? What about skipping validation and doing cut-through routing? Compact blocks. (RR)\n\n\\section*{Bitcoin P2P network: A systems view}\nIn Bitcoin, peers connect to each other and communicate using the TCP protocol. The codebase allows for eight outgoing connections and up to 117 incoming connections. The network has a high churn rate (rate at which users enter/leave the system); hence, the node must be ready to connect to new peers. Moreover, to ensure that the peers we are connecting to are chosen randomly, the node keeps a large list of nodes running Bitcoin in the form of their (IP, port) tuple and establishes a connection to one of them randomly when a slot opens up.  \n\nHow does a node bootstrap its list of peers? This happens by connecting to a set of DNS seed nodes. The seed nodes are not heavily decentralized; hence completely relying on the peer list provided by them is not advisable. On connecting to the initial set of peers, a node asks its neighbors for their peer list using {\\tt getAddr} and {\\tt Addr} messages. The node keeps refreshing its peer list regularly by exchanging peer lists with its peers. \n\nTransmission of all block and transactions happen through the inventory message {\\tt inv}, on receiving an {\\tt inv} message the node checks if it has the block or the transaction in its local storage. If not, it sends the {\\tt getData} message to fetch those blocks and transactions from the peer. Since block sizes are relatively large, block transmission can optionally happen in 2 stages. On receiving the {\\tt inv} message, the node may ask for headers first using {\\tt getHeaders} and ask for complete blocks only if a header chain is established. This header-first block transmission increases queries but can decrease the net bandwidth usage. It may also prevent nodes from accepting PoW invalid blocks since the node can check from the header whether PoW is valid. \n\nWe saw in the previous lecture that some nodes might be malicious. A question that may arise is: what stops malicious nodes from flooding the network with invalid blocks and transactions (i.e., with invalid PoW and/or signatures)? Such flooding will saturate the network and increase transmission delay to unacceptable levels. Such an attack is prevented by a simple design decision, forward message to peers only after validating the message; i.e., a node sends an {\\tt inv} block message to its peers only after validating the block. If the adversary creates an invalid block, the block will not be propagated beyond one honest node. Additionally, nodes maintain their peers' reputation using some predefined heuristics; if a peer misbehaves (say by sending a transaction with invalid signatures), its reputation is downgraded and after a certain lower threshold is disconnected.  \n\nAs a side effect, forward after validation structure increases the net delay in broadcasting a block across the network. Several ``trusted\" relay networks have been established for speeding up propagation. Once a block is validated by a peripheral node in a relay network, it is gossiped to all other nodes before performing local validation since the inter-node communication is trusted. An example is FRN (fast relay network); it creates a hub and spoke model with trusted servers as hubs. \n\nAnother proposal to speed up propagation is using compact blocks. Note that a transaction is broadcast in the network twice. Once when the transaction is generated and the second time as a transaction is a block. We can remove this redundancy by introducing compact blocks. For nodes enrolled for compact block relaying, their peers guess the transaction the node has received while forwarding a new block and only send a compact block containing the original block contents sans the guessed transactions. Any mismatch in guessing is resolved later using a {\\tt getblktxn} message. \n\n\\section*{Random Geometric Graphs}\nIn the random network topology, each node in the peer-to-peer (P$2$P) network $G$ chooses $c$ other nodes uniformly at random from the set of all nodes in the network $G$ and sets them as its neighbors. Thus, whenever a node $n$ needs to broadcast a message, it transmits the message to these $c$ neighbors who in turn relays the message to their own neighbors. While the result graph is a expander with low diameter, the shortest path taken for routing a message from the source to the destination is sub-optimal in the sense that the length of this shortest path could be much worse than the {\\em geodesic} shortest path (see Fig~\\ref{fig:random-topology}). Furthermore, the random network topology fails to take into account the heterogeneities present in the internet: different users could have different bandwidth and processing power, non-uniformity in mining power that make a difference to networking efficiency. \n\n{\\sf Perigee} is a recent P2P protocol that aims to create a random {\\em geometric} graph topology; this way the shortest path on the connectivity graph is also the shortest {\\em geographic} (geodesic)  path. There are two types of neighbors for a node $n$: (a) \\textit{outgoing neighbors}: the set of neighbors to whom the node $n$ sends and receives messages; (b) \\textit{incoming neighbors}: the set of neighbors from whom message is only received. {\\sf Perigee} is a decentralized algorithm  for selecting the set of outgoing neighbors with the objective to minimize the time it requires for a broadcast message to reach $90\\%$ of the nodes in the network. The overarching idea of {\\sf Perigee} is to update the set of outgoing neighbors by exploiting the information gathered by interacting with the current set of outgoing neighbors while exploring new connections in the network; this is done by making a connection to the classical \\href{https://epubs.siam.org/doi/abs/10.1137/S0097539701398375}{multi-armed  bandit problem} in statistical decision making theory.\n\nIn {\\sf Perigee}, a node $n$ in proceeds in a round-by-round basis under the following steps:\n\\begin{enumerate}\n    \\item A round comprises of $M$ unique messages that has been broadcast in the network. Let these $M$ messages in round $r$ be represented by $\\mathcal{M}^r$ and $\\Gamma^r$ represent the set of outgoing neighbors in round $r$. For each message $m \\in \\mathcal{M}^r$, the node $n$ records the timestamp $t^m_{\\text{nbr}}$ when that message $m$ was received from each of its outgoing neighbor $\\text{nbr} \\in \\Gamma^r$. The node $n$ also records the earliest timestamp $t^m_{\\text{earliest}}$ when it received the message $m$. Note that it is possible that the node $n$ received the message $m$ for the first time from a non-outgoing neighbor.\n    \\item At the end of the round, the node $n$ assigns score to each of its outgoing neighbors based on the timestamps it recorded in step $1$. Towards that end, the node $n$ first determines $t^m_{\\text{nbr}} - t^m_{\\text{earliest}}$ for each outgoing neighbor $\\text{nbr} \\in \\Gamma^r$ and message $m \\in \\mathcal{M}^r$. Now, the node $n$ employs a scoring method to assign scores to each outgoing neighbors. There are two flavors of scoring methods. \n    \\begin{itemize}\n        \\item \\textit{Scoring each outgoing neighbor individually.} For each outgoing neighbor $\\text{nbr} \\in \\Gamma^r$, the score is computed as $90\\textsuperscript{th}$ percentile of the set $\\{t^m_{\\text{nbr}} - t^m_{\\text{earliest}} \\vert m \\in \\mathcal{M}^r\\}$. This scoring approach  reflects a preference to retain an outgoing neighbor from which messages are received relatively earlier. Thus, lower the score for a neighbor $\\text{nbr}$, higher is the preference to retain that neighbor in the next round. Therefore, assuming  $k$ out of $\\mid \\Gamma^r \\mid$ outgoing neighbors are to be retained for the next round, the node $n$ retains the outgoing neighbors that are among the $k$ lowest scorers.\n        \\item \\textit{Scoring groups of neighbors jointly.} In contrast to previous approach, the idea behind joint scoring is to assign the score to a group of neighbors $\\Gamma_{\\text{retain}}$. First, set $\\Gamma_{\\text{retain}} = \\phi$ and determine the outgoing neighbor $\\text{nbr} \\in \\Gamma^r$ that has the lowest $90\\textsuperscript{th}$ percentile of the set $\\{t^m_{\\text{nbr}} - t^m_{\\text{earliest}} \\vert m \\in \\mathcal{M}^r\\}$ and include it in $\\Gamma_{\\text{retain}}$. Then, score each $\\text{nbr} \\in \\Gamma^r \\setminus \\Gamma_{\\text{retain}}$ by computing the $90\\textsuperscript{th}$ percentile of the set \\[\\{ \\min(t^{m}_{\\text{nbr}} - t^{m}_{\\text{earliest}}, \\min(\\{t^{m}_{\\text{nbr}'} - t^{m}_{\\text{earliest}} \\mid \\text{nbr}' \\in \\Gamma_{\\text{retain}}\\})) \\mid m \\in \\mathcal{M}^r\\}.\\] Include the $\\text{nbr} \\in \\Gamma^r \\setminus \\Gamma_{\\text{retain}}$ with the lowest score in $\\Gamma_{\\text{retain}}$. Essentially, we are determining the outgoing neighbor in  $\\Gamma^r \\setminus \\Gamma_{\\text{retain}}$ that best complements the existing neighbors in $\\Gamma_{\\text{retain}}$ to minimize the time required for the node $n$ to receive $90\\%$ of the messages. Assuming  $k$ out of $\\mid \\Gamma^r \\mid$ outgoing neighbors are to be retained for the next round, this process is continued until $\\mid \\Gamma_{\\text{retain}} \\mid = k$.\n    \\end{itemize}\n    This step describes the process for retaining $k$ outgoing neighbors from $\\Gamma^r$ by \\textbf{exploiting} the information gathered from interacting with neighbors in round $r$. The retained outgoing neighbors are included into $\\Gamma_{r+1}$.\n    \\item  Next, the node $n$ does \\textbf{exploration} by selecting uniformly at random $\\mid \\Gamma^r \\mid - k$ nodes from the set of all nodes in the network that are not in $\\Gamma^r$ and are included in $\\Gamma^{r+1}$. \n\\end{enumerate}\n\\begin{figure}[ht]\n\\centering\n\\begin{subfigure}{.5\\textwidth}\n  \\centering\n  \\includegraphics[width=.75\\linewidth]{figures/random_topology.pdf}\n  \\caption{Random network topology}\n  \\label{fig:random-topology}\n\\end{subfigure}%\n\\begin{subfigure}{.5\\textwidth}\n  \\centering\n  \\includegraphics[width=.75\\linewidth]{figures/perigee.pdf}\n  \\caption{Perigee}\n  \\label{fig:perigee}\n\\end{subfigure}\n\\caption{Observe that, for Perigee, shortest path follows much closer to the geodesic shortest path.}\n\\end{figure}\n\n\n\n\\section*{Network Anonymity and Privacy}\nIn a blockchain system, the blockchain data structure is visible to all participants. In the context of a cryptocurrency, the blockchain contains every transaction in the history of the currency. More generally, it can contain sensitive data of users, which should not be made public. Indeed, this is a necessary feature of blockchains if it is to be publicly verifiable ledger. How then can one obtain privacy in blockchains?\n\nFor the sake of privacy, Bitcoin originally proposed using pseudonymous identifiers. Each user participates in the system via one or more psuedonym, each of which is linked to a public key. This paradigm has been adopted by most cryptocurrencies today. Anybody observing the blockchain learns only the transaction patterns of each pseudonym. As long as these pseudonyms cannot be linked to the owner's human identity, privacy is preserved. However, multiple studies have shown that such a system is vulnerable to de-anonymization attacks, particularly in the presence of side information. % \\cite{narayanan2009anonymizing,backstrom2007wherefore,fistful,androulaki2013evaluating,ober2013structure}.\n\nHere, we focus on a specific class of de-anonymization attacks wherein an adversary who observe traffic flowing over the P2P network can obtain some information about the users. In most cryptocurrencies, new transactions are spread over the network according to some pre-specified flooding protocol (typically a gossip algorithm). If an adversary observes this traffic at a fine enough time resolution -- e.g., by setting up a supernode that connects to many nodes -- it can often link transactions (and hence the pseudonym of the sender) to the IP address that originated the transaction. The IP address can then be associated to a human identity by other means. We then discuss an alternate networking protocol called \\textbf{Dandelion} which provides theoretical privacy guarantees.\n\n\\subsection*{A mathematical model}\nWe first discuss a mathematical model for the network de-anonymization problem. The model involves the protocol by which messages are spread in the network, and a model of the adversary that collects information about this process and tries to identify the source of the message. Typically, the underlying network is modeled as a graph $G = (V,E)$. Here, $V$ denotes the set of all nodes participating in the blockchain system and $E$ is the set of edges representing TCP connections between nodes. As a simplification, we consider the problem of de-anonymizing a single message (transaction/block) sent by a particular node $v^* \\in V$. When modeled as above, the problem of de-anonymization boils down to guessing $v^*$ given some observations of how the message has spread. \n\n%Although messages sent in the network include both transactions, for this portion we will be concerned only with transactions. This is because we want to link the The source of the transactions\n\nIn the context of de-anonymization, there are two main adversarial models: \\emph{eavesdropper adversaries} and \\emph{botnet (spy-based) adversaries}. Eavesdropper adversaries run a supernode that connects to all (or a substantial subset) of nodes in the network (Figure \\ref{fig:eavesdropper}).\n From the perspective of an honest node, the eavesdropper looks just like any other node. Honest nodes therefore relay transactions normally, allowing the eavesdropper to collect timestamps and other metadata. Combined with information about the graph topology, this metadata can be used to infer the source of a particular transaction. One important property of eavesdropper nodes is that they typically do not relay messages; they only collect communications relayed by other nodes. \n\nBotnet or spy-based adversaries (Figure \\ref{fig:botnet}) \n instead consist of a set of corrupt, colluding nodes that participate in the network normally, both accepting \\emph{and} relaying information. We let $p$ denote the fraction of spies in the network, and let $V_A, V_H \\subseteq V$ denote the set of adversarial and honest nodes, respectively. As the name suggests, this adversarial model is motivated by a botnet that spawns cryptocurrency nodes. The key difference compared to the eavesdropper adversary is that each botnet node may have limited visibility into the network (e.g., if it only connects to a few peers rather than the entire network), and botnet adversaries may inject packets into the network. \n\n\\begin{figure}\n\\begin{minipage}{0.5\\textwidth}\n\\centering\n    \\includegraphics[width=1.2in]{figures/eavesdropper}\n    \\caption{Eavesdropper adversary. A well-connected supernode eavesdrops on relayed communications.}\n    \\label{fig:eavesdropper}\n\\end{minipage}\n\\hspace{0.1in}\n\\begin{minipage}{0.5\\textwidth}\n    \\centering\n    \\includegraphics[width=1.2in]{figures/botnet}\n    \\caption{Botnet adversary. Red nodes represent  corrupt ``spy nodes\", which use observed metadata to infer the transaction source.}\n    \\label{fig:botnet}\n\\end{minipage}\n\\end{figure}\n\nAs discussed in the sections above, many cryptocurrencies---including Bitcoin---broadcast content using a gossip protocol called \\emph{diffusion}. Under diffusion, each node transmits the message to each of its neighbors with independent, exponentially-distributed delays. The problem of detecting the source of a diffusion process over a graph is well-studied. An \\href{https://ieeexplore.ieee.org/abstract/document/5961801}{early work}  who studied this problem in a so-called \\emph{snapshot model}. Under this model, the diffusion process is allowed to spread in the network until some time $T$. At this time, the adversary gets to observe which nodes have the message, and which do not. The authors showed that one can reliably infer the source of a diffusion process, even as $T$ grows to infinity.\n\nThe de-anonymization algorithms suggested in this and other works revolve around the notion of \\textit{centrality} or symmetry; because diffusion spreads content symmetrically on the underlying network, the message (roughly) spreads in a disc over the graph, with the true source at the middle of that disc. The above results imply that an adversary with partial global oversight can infer the shape of the disc and identify the central node with non-negligible probability. These results suggest that diffusion is poorly-suited to protecting users' anonymity at the network level, which motivates the need for alternative spreading protocols that protect users' anonymity.\n\n\\subsection*{Dandelion}\nThe key idea that emerges from the analysis of diffusion is that one must break the symmetry of the message spreading (aka gossiping) protocol in order to prevent the adversary from accurately guessing the message.  The {\\sf Dandelion} P2P networking protocol, which incorporates this idea, has two phases: a \\textit{stem phase} (aka anonymity phase) and a \\textit{fluff plase} (aka diffusion phase). In the stem phase, each node propagates each message along a randomly chosen direction. After a random number of hops, the stem phase ends. Then, in the fluff phase, the transaction is broadcast via diffusion to the rest of the graph. As mentioned, the stem phase provides the anonymity guarantees, while the latter fluff phase helps propagate the message to all users without much delay.\n\n\nThe {\\sf Dandelion} protocol is explained in more detail below. {\\sf Dandelion} proceeds in asynchronous epochs; each node advances its epoch when its internal clock reaches a random threshold (in practice, this will be on the order of minutes). Within an epoch, the main algorithmic components of {\\sf Dandelion} are:\n\\begin{enumerate}\n    \\item \\textbf{Anonymity graph:} The random walk takes place on an overlay of the P2P graph called the anonymity graph. This overlay should be chosen either as a random cycle graph (i.e., a 2-regular graph) or a 4-regular graph. This 4-regular graph is embedded in the underlying P2P graph by having each node choose (up to) two of its outbound edges, without replacement, uniformly at random as {\\sf Dandelion} relays. This does not produce an exact 4-regular graph, but an approximation.Each time a node transitions to the next epoch, it selects fresh {\\sf Dandelion} relays.\n    \\item \\textbf{Forwarding of a nodes own transactions:} Each time a node generates a transaction, it forwards the transaction in stem phase along the same randomly-selected outbound edge on the anonymity graph. If the anonymity graph is a cycle, there is only one outbound edge per node; otherwise, the node must choose one of its two outbound edges.\n    \\item \\textbf{Relaying of other nodes transactions} Each time a node receives a stem-phase transaction from another node, it either relays the transaction or diffuses it. The choice to diffuse transactions is pseudo-random, and is computed from a hash of the nodes own identity and epoch number. Note that the decision to diffuse does not depend on the transaction itselfin each epoch, a node is either a diffuser or a relay node for all relayed transactions. If the node is not a diffuser in this epoch (i.e.,it is a relayer), then it relays transactions pseudo-randomly; each node maps each of its incoming edges in the anonymity graph to an outbound edge in the anonymity graph (with replacement). This mapping is selected at the beginning of each epoch, and determines how transactions are relayed.\n    \\item \\textbf{Robustness mechanism} Each node tracks, for each stem-phase transaction that it sends or relays,whether the transaction is seen again as a fluff-phase transaction within some random amount of time. If not, the node starts to diffuse the transaction\n\\end{enumerate}\n\n% \\subsection*{Guarantees on Dandelion}\n% The key theoretical result concerning {\\sf Dandelion} provides upper bounds on both the \\textit{precision} and the \\textit{recall} with which an adversary can estimate the source of a message. \\textit{define precision, recall.}\n\n\n\\section*{Basic requirements for a banking system} \nIn any currency/banking system, there are some basic requirements that the system must provide for. We list them here:\n\\begin{enumerate}\n    \\item There should be a unit of currency/money.\n    \\item There should be a standard way of keeping accounts, i.e., keeping track of how much money each person owns, and transferring money between accounts. \n    \\item No user should be able to create new money from thin air. Put differently, there should be a fixed amount of money in the system at any given time, and new money should be introduced in a systematic manner.\n    \\item A user should not be able to spend more money than he/she owns. There should be a way to verify whether or not this happens.\n    \\item One user should not be able to spend someone else's money (at least, not without their permission).\n\\end{enumerate}\nLet us see how the Bitcoin system provides these features.\n\n\\section*{Bitcoin and Satoshi}\nThe basic unit of currency in the Bitcoin system is, simply, Bitcoin. The smallest denomination of a Bitcoin is called a Satoshi. It is equal to $10^{-8}$ Bitcoins. All transactions must be some integer multiple of a Satoshi. Just as all other currencies in the world have exchange rates, there is an exchange-rate between Bitcoin and the dollar. As of today, February 9 2021, one Bitcoin is worth $48,000$ US dollars. Due to various factors (including greed and speculation), the exchange rate between Bitcoin and dollars is very volatile. Whether Bitcoin should be thought of as a currency (like the US Dollar) or a store of value (like the precious metal, gold) has been debated widely; the mainstream view is that Bitcoin is a combination of both. Economically valuing Bitcoin, both in the short and long terms, is an active area of research. In this lecture we will see aspects of the Bitcoin system that helps understand the economic aspects of Bitcoin, both as a currency and a store of value. \n\n\\section*{Transactions}\nIn ordinary parlance, the term \\textbf{transaction} refers to an exchange of something of value. In the context of Bitcoin and cryptocurrencies, a transaction is simply a message that specifies the transfer of money from one entity to another. In fact, transactions are the data-values that get recorded on the blockchain. The blockchain as a ledger is therefore an ordered list of transactions. From this publicly verifiable ledger, any user can detect whether transactions are made according to certain rules or not, thereby lending credibility to the ledger and the currency.\n\nIn Bitcoins, transactions have a well-defined structure, which we elaborate upon below. One can take a look at the structure of real Bitcoin transactions \\href{https://www.blockchain.com/explorer}{here}.\n\n\\paragraph{Addresses}\nNaively, in a currency system, there should be some notion of an account; a transaction notes the transfer of money from one account to another. In Bitcoin, the notion of accounts is replaced with that of \\textit{addresses}. Bitcoins are allocated to addresses, and these addresses are also used to decide where Bitcoins will be sent to, in a transaction. What exactly is an address and how is one generated? In Bitcoin, an address is simply the hash of a public key. Recall the notion of digital signatures, and that of public and private keys. New pairs of keys, and thus new addresses can be generated at will by a single user.\n\nOne idiosyncrasy of Bitcoin is the following. In order to receive coins, a user needs to only publish its address, not its public key. However, to spend coins, a user must also reveal its public key. This is explained below.\n\n\\paragraph{Transaction inputs and outputs}\nA transaction in a Bitcoin is a statement that records a transfer of money from one address to another. More broadly, a transaction records a transfer of money from one set of addresses to another. Every transaction has a set of \\textit{transaction inputs} and \\textit{transaction outputs}. Each transaction input states the amount of Bitcoin being spent by a particular address. Each transaction output states the amount of Bitcoin being received by a particular address. In a transaction, the total money being spent should add up to the total money being received. %We shall see the reason for allowing multiple transaction inputs and outputs shortly.\n\n\\paragraph{Signatures on transactions}\nEach transaction must be signed by all the users that are spending money. This is a basic safety feature that prevents others from spending one's money without authorization. As mentioned above, each address has a one-to-one correspondence with a public key, which in turn has a one-to-one correspondence with a private key. A user that wishes to spend Bitcoins associated with a particular address creates a transaction appropriately, and then signs the transaction using the corresponding private key. It then broadcasts the transaction along with the corresponding public key. Anyone who that sees a signed transaction can verify whether it was signed by the person owning the address (and thereby, the coins in the address). Thus, signatures help other users validate transactions. More generally, if a transaction spends Bitcoins from multiple addresses, there must be signatures corresponding to each of these addresses.\n\n\\paragraph{UTXOs} So far, we have seen how transactions are used to transfer money from one address to another. What prevents a user (i.e., an address) from spending more money than it has? One method would be to keeping track of the balance of each address, adding or deducting its value as money is received/spent from the address. Bitcoin adopts a different approach; here, every transaction input must be a transaction output of an earlier transaction. Linking transaction inputs to past inputs provides a proof that the address indeed has sufficient money to spend. \n\nWhen a new transaction output is created, we say that it is \\textit{unspent}. At some time in the future, it gets consumed as part of transaction input, at which point it is \\textit{spent}. A valid transaction must only include \\textit{unspent transaction outputs} (UTXOs) as its inputs. While honest users will always ensure this, a dishonest user can try to \\textit{double-spend} its money. In order to prevent this, honest users must keep track of the set of UTXOs at all times, and must validate every new transaction in the blockchain against this set. We elaborate more on this in later sections. The above method of validating transactions is called the \\textbf{UTXO model}. A more natural technique would be the \\textbf{account-based model}, where the balance is maintained for each address. This latter model is adopted in other cryptocurrencies such as Ethereum (and also in regular banks).\n\nWe now see why a Bitcoin transaction allows for multiple transaction inputs and outputs. First, let us consider the need for multiple outputs. Suppose a particular user owns a single Bitcoin address, to which it has received 2 Bitcoins in a particular transaction. Even if it wants to spend a fraction of that money (say, 1 Bitcoin), it must spend the only UTXO it has, which is of 2 Bitcoins. In such a case, it creates two transaction outputs, one to the address it actually wants to send the money to, and the other to itself (the change). The latter output could be to the original address, or to a new address. Next, let us consider the case of multiple inputs. Suppose an address (i.e., user) has received 1 Bitcoin each in two different transactions, and it would now like to pay 2 Bitcoins to another address. It can then include two transaction inputs in a single transaction in order to pay this amount.\n\n\\paragraph{Cryptocurrency wallets} In reality, keeping track of UTXOs, and measuring them up for each transaction is difficult. In addition, a single user ought to spawn new addresses regularly, for the sake of maintaining anonymity. These addresses (and the corresponding keys) must be generated carefully, without revealing even a hint of the private key. Further, they must be stored securely. All these functionalities are taken care of by a \\textit{cryptocurrency wallet}. Wallets are simply software that perform a lot of these tasks in the back-end, allowing users to transact in Bitcoin as one would using a bank account. Using a wallet requires trusting the software of the wallet. In principle, one can participate in the cryptocurrency system without the use of a wallet, but most users use a wallet.\n\n\\paragraph{Transaction fees} We mentioned above that the total value in a transaction's inputs must add up to the total value in its outputs. In reality, the sum of values in the output is slightly lower than the inputs. The remaining amount, called the \\textbf{transaction fees}, is claimed by the miner of the block that includes this transaction. The transaction fees are an incentive for a miner to include a particular transaction in the block being mined. Transactions with higher fees get included faster in the blockchain, while those with lower fees get added later. The fees vary with time, and are often calculated automatically by wallets according to a  particular fee rate, measured in Satoshi per kilobyte. You can learn more about transaction fees and fee rates  \\href{https://en.bitcoin.it/wiki/Miner_fees}{here}. Roughly speaking, fees are of the order of ten dollars per transaction.\n\n\\paragraph*{Coinbase transactions}\nThe preceding discussion is on how money is exchanged by users in the Bitcoin system. How is money introduced in the system in the first place? The answer is simple: new Bitcoins are generated with every new block. Every block includes a special transaction, called the coin-base transaction, in which the miner gets for itself a fixed number of Bitcoins. Initially, the rewards were $50$ BTC per block. Every $210,000$ blocks mined, or about every four years, the reward given to Bitcoin miners for processing transactions is cut in half. So far, there have been three halvings, and the current reward is $6.25$ BTC per block. Block rewards will continue till the year $2140$, after which there will be no new Bitcoin introduced in the system. The total volume of currency that will be ever be used is capped at $21$ million, of which around $18.5$ million coins are already in circulation. Coinbase transactions, along with transaction fees, are an additional incentive mechanism for Bitcoin users to actively participate by mining. In the initial years of Bitcoin, coinbase transactions formed the major component of the rewards; with time, the contribution of transaction fees is catching up. \n\nFigure \\ref{fig:bitcoin_halving} shows how the Bitcoin block reward decreases by half every four years. We are currently at 6.25 Bitcoins per block. The figure also shows the total number of Bitcoins in circulations. The halving scheme ensures that the total number of Bitcoins ever produced will taper off to a total of $21$ million Bitcoins.\n\nFigure \\ref{fig:block_rewards} shows the same metric as in Figure \\ref{fig:bitcoin_halving}, but the reward is now measured in dollars instead of Bitcoin. This figure is useful to understand the incentives for mining. The block rewards (along with the transaction rewards) must offset the cost of mining. As more users join the system with time, a particular miner must compute more hashes (and thus must spend more on electricity) to mine a block. Block rewards (in terms of dollars) have gone up too, providing an incentive for users to mine in spite of the increasing difficulty. There is a subtle balance between the various economic factors that govern the level of mining power in the Bitcoin system.\n\\begin{figure}[p]\n    \\centering\n    \\includegraphics[width = 0.8\\textwidth]{figures/bitcoin_halving.png}\n    \\caption{Bitcoin block reward in bitcoins. Figure sourced from \\href{https://www.coindesk.com/bitcoin-halving-explainer}{here}}\n    \\label{fig:bitcoin_halving}\n\\end{figure}\n\n\\begin{figure}[p]\n    \\centering\n    \\includegraphics[width = 0.8\\textwidth]{figures/block_reward.jpg}\n    \\caption{Bitcoin block reward in dollars. Figure sourced from \\href{https://www.cmcmarkets.com/en/learn-cryptocurrencies/bitcoin-halving}{here}}\n    \\label{fig:block_rewards}\n\\end{figure}\n\n%\\pramod{please put a figure of how bitcoin's block reward scheme changes over time. give some numbers as examples.}\n\n\\paragraph*{Transaction mempool}\nWhenever one user wants to pay another using Bitcoin, it generates an appropriate transaction, signs it, and broadcasts it through the entire network. Ultimately, the transaction is simply a message (a string of bits) in a particular semantic form. The size of a message is  a few kilobytes; the exact size depends on the number of transaction inputs and outputs. The transaction is propagated across the Bitcoin network using the diffusion protocol. Miners keep looking out for new transactions and add them to their memory, called the \\textbf{mempool} (they do so after verifying the signature on the transaction). At any given point in time, a miner is working on a particular block, which contains some transactions from its mempool. A miner can include new transactions from its mempool into its working block at will (or even remove them). As such, it would like to include as many transactions as possible in order to maximize its sum total transaction rewards. However, there is an upper bound on the total size of a block. Thus, a miner prioritizes blocks with a higher transaction fee rate, i.e., a higher fee with a smaller size. A transaction with a high enough transaction fee is included immediately by all miners into their working block. The lucky miner who finds the proof-of-work first gets to ``claim\" the reward; again the claim on the reward is only honored when the block is confirmed, i.e., buried deep enough in the longest chain. \n\nNote that there is a certain latency between the transaction first being issued and the transaction being confirmed on the blockchain. The first factor behind the latency is that it takes time for a newly issued transaction to be included in any block; this latency can be reduced by increasing the mining fee. The second factor is that it takes time for a block that includes the transaction to be buried deep enough. Here, a user may trade-off latency with security (in Bitcoin). Other blockchain designs, which we explore in future lectures, may not have this trade-off.\n\n\\section*{Validating a block}\n\n\\paragraph{The state of the system} In the above discussion, we covered many important points explaining how Bitcoin enables a money-exchange system. One issue that was skirted is, how do users verify that a single coin is not spent twice? In the context of Bitcoin, this issue boils down to verifying that a transaction's inputs have not been spent already. As such, the only way to verify this is to keep track of the set of UTXOs (unspent transaction outputs) at all times. This set is often referred to as the \\textbf{state} of the system. Note that these outputs are for those transactions that are already in the blockchain, and have not been spent in the blockchain. Thus, the state changes  every time the longest-chain grows (or more generally, changes). It is important to note that the state is separate from the mempool, but is linked in the following way. Honest users build a block from transactions in the mempool. However, they only choose those transactions that are valid, and they check the validity using the information in the state. In an account-based model, the state would simply be the roster of all account balances. More generally, the state of a blockchain system contains a summary of all the entries in the ledger thus far, which can be used to validate new entries. \n\nFigure \\ref{fig:utxo_size} shows the number of UTXOs in the Bitcoin system as a function of time. Clearly, it has grown many-fold since the beginning, and it will continue to grow as Bitcoin becomes more popular. With each UTXO being a few hundred bytes, the size of the UTXO set is now over $5$ GB. As such, this might seem like a moderate amount which can be easily stored. However, each node must perform many read, write and delete operations on this set. Thus, the set must be stored in the memory (preferably, on-chip memory) rather than on the disk. Given this requirement, the UTXO size is too large for regular devices to store; it requires specialized hardware. The large UTXO size is another dimension of the scalability challenge. %\\pramod{point out that this growing in size over time. give some numbers to get an idea of the current size. }\n\\begin{figure}[htbp]\n    \\centering\n    \\includegraphics[width = 0.8\\textwidth]{figures/UTXO_size.png}\n    \\caption{Number of UTXOs over time in Bitcoin. Figure sourced from \\href{https://www.blockchain.com/charts/utxo-count}{here}}\n    \\label{fig:utxo_size}\n\\end{figure}\n\n\\paragraph{Validating blocks} When a miner receives a new block, it must perform certain sanity checks, of which two are important. First, it checks whether the proof-of-work meets the required threshold. Second, it checks whether the transactions in the block are consistent with the state. This means that it must check whether every input in every transaction belongs to the state or not. If it does, the miner accepts the block, removes the relevant transactions from its mempool, and also updates the state. Updating the state involves deleting spent transaction outputs and adding the newly generated ones. While constructing a new block to mine on, the same validation steps are taken preemptively.\n\n\\paragraph{Light nodes and stateless clients}\nStoring the state of the system and validating each transaction in every block requires storage and computation power. Bitcoin allows for light nodes/clients, who can participate in the system with much lesser computation and storage power. A light client merely verifies the proof of work on blocks. It may further selectively verify the validity of transactions, especially those that concern itself. As such, a light client does not store the state of the system which prevents it from validating transactions.\n\nThere are proposals to augment the functionality of light nodes, by creating so-called \\textbf{stateless nodes}. These nodes can validate transactions/blocks without storing the full state at all times. They merely download the requisite state information to validate a block, one block at a time, and then delete it once the block is validated. In order to do so securely, the state is stored in the form of an accumulator, which we discussed in Lecture 2. The stateless client option is being pursued vigorously by Ethereum. See, e.g., the discussion \\href{https://ethresear.ch/t/the-stateless-client-concept/172}{here}. A fully functional stateless client for Bitcoin, which makes use of Merkle tree accumulators, has been built by the \\href{https://www.media.mit.edu/projects/utreexo/overview/}{UTREEXO project}.\n\n\\section*{Smart contracts}\nSo far, we have seen how blockchains can be used to implement a currency system. Essentially, the blockchain as a ledger records payments from one party to another, thereby keeping tab of all parties' balances. Transactions are simply messages recording the transfer of money. However, blockchains are much more versatile; they can also be used to run \\textit{smart contracts}. Smart contracts are programs that are run by the peers in the blockchain system. The notion of a transaction is broadened to include these pieces of code as well. Smart contracts come into play when two parties want to exchange money subject to some terms and conditions. In the physical world, they would draw up a contract. A trusted third party/authority would be needed to ensure that both parties follow the contract. When run on a blockchain, smart contracts eliminate the need for a single trusted third-party. Instead, the decentralized trust of the blockchain (in other words, the honest majority of the system) ensures that the contract gets executed correctly.\n\nIn this lecture, we only focus on smart contracts in Bitcoin, which are rather limited in scope. Ethereum, a subsequent cryptocurrency, allows for much more diverse programs as smart contracts; we will learn about that in a later lecture.\n\n\\paragraph{Scripts in Bitcoin}\nSmart contracts are simply called scripts in Bitcoin. To understand scripts, we need to broaden our understanding of transactions from merely statements recording the transfer of money. As we saw before, a transaction consists of inputs and outputs, with outputs recording the transfer of Bitcoins to some address. What we did not mention before is that every transaction output includes a script, consisting of \\textit{opcodes}, which specify conditions that must be satisfied in order to spend the coins mentioned in the output. The default condition is that the spender of the output must provide a public key that hashes to the pertinent address, and must sign the message with the corresponding private key. Earlier, we presented this as a sanity check; however, this is explicitly specified as a script in every regular transaction.\n\nBitcoin scripts also allow for additional conditions, such as requiring that the transaction is not spent until a particular time, requiring that a transaction is spent by a particular time, requiring a message that is signed by multiple private keys, etc.\nAn interesting and useful script that emerges from a combination of these conditions is that of a hashed timelock contract (HTLC). HTLCs are useful in setting up escrow funds. If Alice wants to pay Bob in exchange for some other good, then Alice would like to pay Bob only after she is guaranteed to get the good from Bob, and Bob would like to release the good only after he is guaranteed to be paid by Alice. An HTLC enables such terms to encoded as a smart contract on a blockchain. You can learn more about HTLCs \\href{https://www.investopedia.com/terms/h/hashed-timelock-contract.asp}{here}. A full list of opcodes used in the Bitcoin script is given \\href{https://en.bitcoin.it/wiki/Script}{here}.\n\n\\section*{Reference material}\n\n{\\sf Perigee} is a recent P2P protocol that adapts the network topology to a random geometric network, presented in ``\\href{https://dl.acm.org/doi/abs/10.1145/3382734.3405704}{Perigee: Efficient Peer-to-Peer Network Design for Blockchains},\" \nMao, Deb, Venkatakrishnan and Kannan, PODC 2020. %{\\sf Perigee} uses ideas from the \\href{https://epubs.siam.org/doi/abs/10.1137/S0097539701398375}{multi-armed  bandit}  problem in theory of statistical  decision making. \n\n{\\sf Dandelion} networking was invented in ``\\href{https://dl.acm.org/doi/abs/10.1145/3084459}{Dandelion: Redesigning the Bitcoin Network for Anonymity},\" Fanti, Venkatakrishnan and Viswanath, Sigmetrics 2017. \n\n\n\\input{Problem_sets/Lec4_PS}\n\\end{document}",
    "lecture_18.tex": "\\documentclass[a4paper]{article}\n\\usepackage[a4paper]{geometry}\n\\usepackage[english]{babel}\n\\usepackage[utf8x]{inputenc}\n\\usepackage{listings}\n\\usepackage{fancyhdr}\n\\usepackage{makecell}\n\\usepackage{threeparttable}\n\\usepackage{subfig}\n\\usepackage{graphicx}  \n\\newsavebox{\\measurebox}\n\\pagestyle{fancy}\n\\usepackage{tabularx} \n\\usepackage{multirow}\n\\usepackage{amsfonts}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 18}\n\\newcommand{\\POM}{$\\mathsf{POM}\\ $}\n\\usepackage{float} \n\\usepackage{amsmath}\n\\usepackage[colorlinks=true, allcolors=blue]{hyperref}\n\\usepackage{listings}\n\\usepackage{url}\n\\usepackage{graphicx}\n\\graphicspath{ {./figures/} }\n\\newcommand{\\h}{\\textsf{H}}\n\\usepackage{amsthm}\n\\newtheorem{lemma}{Lemma}[]\n\\newcommand{\\cmt}{\\textsf{cmt}}\n\\newcommand{\\prove}{\\textsf{Prove}}\n\\newcommand{\\verify}{\\textsf{Verify}}\n\\newcommand{\\sn}{\\textsf{sn}}\n\\newcommand{\\adpk}{\\textsf{addr}_{\\textsf{pk}}}\n\\newcommand{\\adsk}{\\textsf{addr}_{\\textsf{sk}}}\n\\newcommand{\\adpknew}{\\textsf{addr}^{\\text{new}}_{\\textsf{pk}}}\n\\newcommand{\\adsknew}{\\textsf{addr}^{\\text{new}}_{\\textsf{sk}}}\n\\newcommand{\\adpkold}{\\textsf{addr}^{\\text{old}}_{\\textsf{pk}}}\n\\newcommand{\\adskold}{\\textsf{addr}^{\\text{old}}_{\\textsf{sk}}}\n\\newcommand{\\tx}{\\textsf{tx}}\n\\newcommand{\\rt}{\\textsf{rt}}\n\\newcommand{\\info}{\\textsf{info}}\n\\newcommand{\\pf}{\\textsf{proof}}\n\\newcommand{\\pramod}[1]{{\\color{red}\n\\footnotesize[Pramod: #1] }}\n\\newcommand{\\peiyao}[1]{{\\color{blue}\n\\footnotesize[Peiyao: #1] }}\n\n\\title{Lecture 18: Data Privacy via Zero Knowledge Cryptography\t}\n\\author{\nPrinciples of Blockchains, University of Illinois, \\\\ \nProfessor: Pramod Viswanath \\\\ \nScribe: Peiyao Sheng \n and Viswa Virinchi Muppirala\\\\\n}\n\\date{March 30, 2021}\n\n\n\\begin{document}\n\\maketitle\n\n\\begin{abstract}\n   The transactions and ledger in the blockchain designs we have seen are in plain text and world-readable. This property was crucially used to {\\em validate} transactions before adding them to blocks and for blocks to be accepted into the ledger. However, there is a need to avoid representing transactions in plain text, e.g., in financial applications such as cryptocurrencies. Although banks and credit card companies inherently see the identities of participants in all transactions, the ledger themselves are not openly readable to other parties. How to provide strong identity management between relevant parties (i.e., merchants and customers), while cutting out unnecessary information leakage to middlemen is a pressing problem.  In this lecture, we \n    summarize a powerful cryptographic technique for providing transaction privacy at the blockchain layer known as zk-SNARKs. The key idea behind zk-SNARKs is to encrypt transactions in such a way that users can verify their validity without learning anything about the contents of the transaction. zk-SNARKs are the technical foundation of the privacy-preserving cryptocurrency Zcash whose architecture is the focus of this lecture. \n\\end{abstract}\n\n\\section*{Introduction}\nBitcoin employs the UTXO format of state/ledger management, where transactions consist of a list of inputs and outputs;  outputs specify the recipients' public keys and inputs refer to previous outputs -- see  Figure~\\ref{fig:utxo}. One key property of the Bitcoin network is pseudonymity;  the public key is the only information associated with each account. A single user can create multiple public keys to protect privacy. However, the relationship {\\em between} transactions leads to information leakage. Based on the public keys of inputs and outputs of a transaction, we can link  transactions into a  graph; see Figure~\\ref{fig:spill}. Now if the identity of one  public key is accidentally divulged, the identities of other public keys connected to it in the graph are also potentially traceable.\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=\\textwidth]{figures/tx_graph.png}\n    \\caption{Typical transaction graph for a day \\cite{fleder2015bitcoin}.}\n    \\label{fig:spill}\n\\end{figure}\n\n\\paragraph{Trusted third-party mixer.} \nOne possible solution to this problem is to employ a third-party mixer (also known as a ``laundry service\"). Consider a set of outputs from a list of transactions, when creating a new transaction with some of the outputs, UTXO system requires the sender to specify which outputs will be used. The laundry service essentially exchanges the coins (the public keys) of various users so that the public keys can't be traced using a transaction graph. However, this requires peers to trust a centralized third-party who can trace or even steal the coins. \n\n\\paragraph{Decentralized laundry system.}  As a second step, we can consider removing the trusted party for the laundry system to get a decentralized privacy service that is  directly {\\em integrated} into the UTXO format. Imagine there is a special UTXO transaction with an input and an output. Instead of directly pointing to some previous output for input, we attach a proof to the input. The proof is valid when it can convince everyone that the input coin is owned by the sender and has not been spent. Besides, the proof {\\em will not} reveal which output the input relates to.\n\n\nThe property of not revealing connections between inputs and outputs can be achieved by {\\em zero-knowledge proofs} (discussed in detail below). \nOne of the more efficient cryptographic methods to generate such proof is zk-SNARK\\cite{ben2014succinct}, which stands for ``zero-knowledge, succinct and non-interactive arguments of knowledge\", and it generates proofs that are short and easy to verify. Combining the zk-SNARK cryptographic tool within the UTXO framework,  Zcash\\cite{sasson2014zerocash} extends Bitcoin's protocol by adding new types of transactions that provide a separate privacy-preserving currency, in which transactions reveal neither the payment's origin, destination, or amount. The new transactions also support both split and aggregation of the coins. Zcash uses zk-SNARK to generate efficient proofs which replace the traditional links between inputs and outputs. The proof is used to show that (1) the sender holds the secret keys corresponding to {\\em some} of the public keys of previous outputs (the list of outputs is called {\\em hiding set}); (2) and the amount spent is no more than the total amount of these outputs it holds.\nThis helps in hiding both the user identity and the value of coins transferred.  In this lecture, we  study the Zcash architecture in detail and its integration atop the Bitcoin stack (see Figure~\\ref{fig:utxo}).\n\n% %Zerocoin lacks in performance and needs a double-discrete-log proof to redeem funds. \n%\\pramod{this is not understandable Peiyao. The reader has no idea of what ``double-discrete-log proofs\" are. Can you find a way to state the ideas at a reasonable level and then point out that the complexity is poor?}\n%This creates a large overhead on the blockchain and makes it less usable. Moreover it neither gives a mechanism to split or aggregate zerocoins nor lets the users transact in zerocoin. \n\n\n\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.8\\textwidth]{figures/txs.png}\n    \\caption{Left: UTXO structure where the unspent outputs from previous transactions are referred by inputs of a later transaction. Right: Zcash transaction structure with zero knowledge proof.}\n    \\label{fig:utxo}\n\\end{figure}\n\n\n\n\\section*{Zero-knowledge Model}\nThe zk-SNARK cryptographic tool is best  introduced in the context of  a basic model of a ``zero-knowledge proof system\" that will be used to formalize the setting and guarantees of zero knowledge proofs. \n\n\\paragraph{Language and NP.}\nA language $L$ is a set of statements such that $L(x) = 1$  if $x\\in L$. Example: if $x$ is a number, $L$ can be an indicator of whether the number is composite. \nAnd NP is defined to be the class of languages $L$ that have a polynomial time verifier $V$ such that \n\n$$L(x)=1 \\iff \\exists w,\\ s.t.\\ V(x,w)=1$$\n\nwhere $w$ is a polynomial sized witness, who can be used by a verifier given input $x$ to determine whether $L(x) = 1$. Example: $x$ is an integer, $L$ is testing for composite. We can find a witness here to be the prime factorization of $x$, and the verifier can testify whether the product of $w$ equals to $x$ in polynomial time.\n\n\\paragraph{Prover and Zero-knowledge.}\nNow consider a language $L$ in NP, e.g. the composite testing problem. Assume there is a {\\em prover} who has found a witness $w$ (the prime factorization of $x$) and wants to prove to a verifier. But the verifier only has access to $x$, so the prover's task is to convince the verifier that $x$ is composite ($L(x) = 1$). The prover can  send $w$  over and now the verifier can directly compute $V(x, w)$.  However, this way the verifier has direct access to  the witness. In the zero knowledge system, the prover wants to generate a {\\em zero-knowledge proof}, using which the verifier will  learn nothing  about the specific witness $w$, while still completing the verification. \n\nTo understand how zero knowledge proofs are even possible, consider the following discrete logarithm example. Given $x$, a prover wants to prove she knows a witness $w$ such that $g^w = x$, where $g$ is a generator of a cyclic group with prime order $q$. With $w$ and $x$, a verifier is easy to verify the fact, however, to achieve zero-knowledge, the verifier only has access to $x$ and should learn nothing about $w$ during the verification process. The proving process is described as below:\n\\begin{enumerate}\n    \\item The prover picks a random $v\\in \\mathbb{Z}_q^{*}$, and sends the verifier $t = g^v$.\n    \\item The verifier picks a random $c\\in \\mathbb{Z}_q^{*}$ and sends it back to the prover.\n    \\item The prover computes $r=v-cw$ and returns $r$ to the verifier.\n    \\item Finally the verifier checks whether the condition $t=g^rx^c$ holds.\n\\end{enumerate}\nWhen prover really knows $w$, its easy to verify the correctness (Completeness). And it can be proved that another party who does not know $w$ can construct such proofs with negligible probability (Soundness). And as we can see, during the proof and verification process, witness $w$ is wrapped with random numbers so the verifier still learns {\\em nothing} about the witness, hence the term ``zero knowledge\". Besides this example, we can construct zero knowledge proofs for many other problems. The remarkable fact is that all languages in NP have zero knowledge proofs. \\cite{goldreich1986prove}.  In this lecture we  treat zero knowledge proofs as a black box interface (represented by the zk-SNARK cryptographic library) and learn how to invoke it appropriately.\n\n\n\n\n%\\pramod{zk seems like magic from the above description. we need to give some intuition for  how zk is even remotely possible. even a high level intuition and an example will go a long way in educating the reader (and ourselves).}\\pramod{Now you can state the punchline, which is all NP languages have zk proofs.} \n\n\\paragraph{Efficiency.}  \nThe performance of the cryptographic tools (e.g., how long it takes to generate the proof or verify the proof, how large is the proof size) are critical to practical usage.  \nWe denote the execution time required to run $V(x,w)$ by $T$; this is the baseline complexity of verification. We consider four metrics of complexity of zero knowledge proof systems. \n\\begin{itemize}\n    \\item  {\\em Prover complexity}. Efficient provers can generate proofs in expected time $O(T \\log T)$. The complexity is only marginally more compared to the baseline. \n    \\item  {\\em Verification complexity and proof size}. A desirable characteristic of such proof systems is succinctness, informally meaning that the proof size is small and thus can be verified efficiently. Succinct proof sizes of  constant or logarithmic compared to the statement size are possible and  thus can be validated in expected time $O(1)$ or $O(\\log T)$. Although the complexity is sublinear, the constants are large and verification is not that efficient for practice usage (e.g., in Zcash). \n    \\item {\\em Interactivity of verification}. Most zero knowledge protocols are interactive, including the example we discussed above. However, noninteractive proofs are most attractive for blockchain applications. Although a generic  technique  to convert interactive protocols into noninteractive protocols while retaining security properties exists (the \\href{https://en.wikipedia.org/wiki/FiatShamir_heuristic}{Fiat-Shamir heuristic}), it works under ideal conditions (including needing a random oracle model) and a more tailored approach is  of interest in practice. %\\pramod{point out how interactive proofs can be much less complex and some intuition for how they work and why they can be more efficient.}\n    \\item {\\em Setup assumptions}. Many zero knowledge protocols depend on a ``trusted setup\", e.g. zk-SNARKs. Specifically, the parameters necessary to generate and verify the proofs must be computed by a trusted party. Otherwise, the protocol could be reverted and the money can be generated in the air. To improve on this, protocols like zk-STARKs (Zero-Knowledge Scalable Transparent ARguments of Knowledge) utilize publicly verifiable randomness instead of trusted setup to create trustlessly verifiable computation systems. The engineering of these theoretical cryptographic concepts into practical libraries is presently being actively pursued. \n    %\\pramod{explain trusted setup. players need common randomness and need to generate in a distributed manner, etc. Need to be as detailed as possible on what this is. here you will talk about zk-SNARK and zk-STARKs.} \n\\end{itemize} \n\n\n\n\\section*{From Zero Knowledge Proof Systems to Zcash}\\label{sec:def}\nWe connect anonymity in Bitcoin to zero knowledge proof systems by first  defining new data structures and addressing mechanisms  on top of Bitcoin architecture.\n\\begin{enumerate}\n    \\item \\textbf{Address.} Same as Bitcoin, there are two types of addresses, public key address $\\adpk$ and secret key address $\\adsk$. \n    \\item \\textbf{A coin in Zcash} We define a coin $c$, which has the same role as a transaction output of Bitcoin, with the following attributes,\n    \\begin{itemize}\n        \\item[-] Coin commitment $\\cmt(c)$\n        \\item[-] Coin value $v(c)$\n        \\item[-] Coin serial number $\\sn(c)$\n        \\item[-] Coin address $\\adpk(c)$\n        %\\item[-] Trapdoor random values $\\rho, r, s$\n    \\end{itemize}\n    The commitment of a coin can be thought of a hash of all the data contained in the coin and serial number can be thought of as an output of a pseudo-random generator. %Figure ~\\ref{fig:coin} shows how the attributes of a coin are generated.\n    %\\begin{figure}\n    %    \\centering\n    %    \\includegraphics[height = 7 cm]{figures/Zcash_coin.png}\n    %    \\caption{The attributes and the block diagram of how they're generated are shown here}\n    %    \\label{fig:coin}\n    %\\end{figure}\n    A collision-resistant hash function like the SHA256 compression function is used to generate all the addresses and the coin attributes. \n    % Let $\\lambda$ denote the security parameter. We use collision-resistant pseudorandom functions family $PRF = \\{ PRF_x : \\{0,1\\}^* \\rightarrow \\{0,1\\}^{O(\\lambda)}\\}_x$ where $x$ is the seed. In our case the secret key will act as the seed. We derive\n    \\item \\textbf{Pour transaction structure.} A pour transaction is a transaction that contains two inputs and two outputs. Compared to Bitcoin transactions, the pour transaction consumes the input coins by revealing their serial numbers, but does not reveal any other information such as the values of the input or output coins, or the addresses of their owners. All the publicly visible information of the transaction can be denoted as $$\\tx:=(\\rt, \\sn_1^{\\text{old}}, \\sn_2^{\\text{old}}, \\cmt_1^{\\text{new}}, \\cmt_2^{\\text{new}}, v_{\\text{pub}}, \\info, \\pf)$$ where \\rt\\ is the Merkle root, the inputs are serial numbers of two old coins, the outputs are commitments of two new coins. $v_{\\text{pub}}$ is the fraction of the input value that may be publicly revealed (optional) , \\info\\ a transaction string (optional) and \\pf\\ is used to prove the ownership of the old coins and the validity of the transaction. The pour transaction takes two coins as inputs and outputs so that it can implement both split and aggregation of the coins. If two coins can be split or aggregated in a pour transaction, multiple coins can be split or aggregated in multiple pour transactions. The details of these properties will be discussed below.\n\\end{enumerate}\n\n\\section*{Zcash Framework}\nWe begin by formalizing the transaction linkage problem that the UTXO state management system of Bitcoin faces. We would like to design a {\\em pour transaction} that creates two new coins from  two old coins without revealing the information of the coins (especially the public keys).\n\n\\paragraph{First Attempt: use commitment}. \nThe first attempt is to create the transaction only with the commitments of coins, i.e. a pour transaction contains\n$(\\cmt_1^{\\text{old}}, \\cmt_2^{\\text{old}}, \\cmt_1^{\\text{new}}, \\cmt_2^{\\text{new}}, \\pf)$. And the proof should imply \n\\begin{enumerate}\n    \\item [(1)] the one who provides the proof has access to the old and new coins\n    \\item [(2)] the coins satisfy $v(c_1^{\\text{old}}) + v(c_2^{\\text{old}}) \\ge v(c_1^{\\text{new}}) + v(c_2^{\\text{new}})$\n    \\item[(3)]it has access to $\\adsk(c_1^{\\text{old}})$ and $\\adsk(c_2^{\\text{old}})$.\n\\end{enumerate}\n\nWe can state this problem formulation as an NP statement, black-boxing   the zero knowledge proof generation process. The statement contains:\n\\begin{itemize}\n    \\item $x = (\\cmt_1^{\\text{old}}, \\cmt_2^{\\text{old}}, \\cmt_1^{\\text{new}}, \\cmt_2^{\\text{new}})$; \n    \\item $L(x)$ is an indicator of whether $x$ is a valid pour transaction. $L(x)=1$ if $x$ is a valid pour transaction;\n    \\item we define the witness $w = (c_1^{\\text{old}}, c_2^{\\text{old}}, c_1^{\\text{new}}, c_2^{\\text{new}}, \\adsk(c_1^{\\text{old}}), \\adsk(c_2^{\\text{old}}))$.\n\\end{itemize}   Given $x$ and $w$, a verifier $V(x,w)=1$ if the following conditions are true:\n\\begin{itemize}\n    \\item [-] $(\\cmt(c_1^{\\text{old}}), \\cmt(c_2^{\\text{old}}), \\cmt(c_1^{\\text{new}}), \\cmt(c_2^{\\text{new}})) = x$\n    \\item [-] $v(c_1^{\\text{old}}) + v(c_2^{\\text{old}}) \\ge v(c_1^{\\text{new}}) + v(c_2^{\\text{new}})$\n    \\item [-] $\\adpk(c_1^{\\text{old}})$ matches $\\adsk(c_1^{\\text{old}})$ and $\\adpk(c_2^{\\text{old}})$ matches $\\adsk(c_2^{\\text{old}})$\n\\end{itemize}\nIt is easy to see that $L(x)=1\\iff V(x,w)=1$.\n\nThe methodology is to convert these statements into {\\em algebraic circuits} and the proof is generated by ``circuit satisfiability\". The proof is an encrypted tuple $\\pi = [g^H, g^Z]$, where $H$ and $Z$ are polynomials computed during the proving phase, and there is a verifying key $vk = g^T$. We recall in the example of the discrete logarithm  above, the proving process did not reveal the information of the witness since it is hard to revert the logarithm. An example construction can be found in this \\href{https://medium.com/@VitalikButerin/quadratic-arithmetic-programs-from-zero-to-hero-f6d558cea649}{post} for further reading. %\\pramod{this is a great place to connect to the original intuition on how zk proofs are even possible in the first place.}\nNow anyone in the blockchain who has access to $w$ can generate the proof without revealing any information related to $w$, and anyone who has access to $x$ can verify the validity of the transaction. But this method has a vulnerability that the commitment is still traceable.\n\n\\paragraph{Second Attempt: use two types of commitments} An idea to improve on the previous formulation is to use two types of commitments. The first is normal commitment \\cmt\\ and the second is a unique serial number \\sn\\  (generated by a pseudo-random generator).  In a transaction, we use serial numbers to represent old coins and commitments to represent new coins, i.e., the transaction includes $(\\rt, \\sn_1^{\\text{old}}, \\sn_2^{\\text{old}}, \\cmt_1^{\\text{new}}, \\cmt_2^{\\text{new}}, \\pf)$, where \\rt\\ specifies the Merkle-tree root of the commitments of outputs in the ledger. The witness is still the same, $w = (\\rt, c_1^{\\text{old}}, c_2^{\\text{old}}, c_1^{\\text{new}}, c_2^{\\text{new}}, \\adsk(c_1^{\\text{old}}), \\adsk(c_2^{\\text{old}}))$. And again $L(x)=1\\iff V(x,w)=1$, $V(x,w)=1$ if the following conditions are true:\n\nFor $i\\in \\{1,2\\}$\n\\begin{itemize}\n    \\item [-] The commitments $\\cmt_i$ of $c_i^{\\text{new}}$ appear on the ledger, verified using the Merkle-tree root $\\rt$, i.e., $\\cmt(c_1^{\\text{new}}) \\in \\rt \\land \\cmt(c_2^{\\text{new}}) \\in \\rt$.\n    \\item [-] The address secret key ${\\adskold}_{,i}$ matches the address public key of $c_i^{\\text{old}}$ %through ${\\adpkold}_{,i} = \\mathcal{H}({\\adskold}_{,i}\\|00\\|0)$\n    % \\item [-] The serial number $\\sn^{\\text{old}}_i$ matches that of $c_i^{\\text{old}}$ through $\\sn_i^{\\text{old}} = \\mathcal{H}({\\adskold}_{,i}\\|01\\|\\rho_i^{\\text{old}})$.\n    % \\item [-] The coin $c_i^{\\text{old}}$ is well formed through $\\cmt_i^{\\text{old}} =$ \n    \\item [-] $(\\sn(c_1^{\\text{old}}), \\sn(c_2^{\\text{old}}), \\cmt(c_1^{\\text{new}}), \\cmt(c_2^{\\text{new}})) = (\\sn_1^{\\text{old}}, \\sn_2^{\\text{old}}, \\cmt_1^{\\text{new}}, \\cmt_2^{\\text{new}})$\n    \\item [-] $v(c_1^{\\text{old}}) + v(c_2^{\\text{old}}) \\ge v(c_1^{\\text{new}}) + v(c_2^{\\text{new}})$. \n\\end{itemize}\n\nSimilar to the previous formulation, those who have $w$ can generate the proof and who have $x$ can verify the validity. However, compared to the previous method, there is no direct connection between old coins and new coins since they use different types of commitments. The only concern is that without the connection, how can we know which previous output is being spent? To solve this problem, we record all serial numbers appearing in previous transactions as a {\\em nullifier set} and conduct an additional check to see whether the input serial number is already in the nullifier set.\n\n\n\\section*{Zcash Protocol: Putting it all together}\nThe key  modification of Bitcoin made by Zcash  is the introduction of pour transactions. Different from a normal UTXO transaction, the inputs and outputs of a pour transaction are replaced by the commitments and serial numbers to break the link between old and new coins.\n\n\\paragraph{Create a pour transaction.} \nBased on the second solution, the full structure of a pour transaction (as  defined earlier) contains $(\\rt, \\sn_1^{\\text{old}}, \\sn_2^{\\text{old}}, \\cmt_1^{\\text{new}}, \\cmt_2^{\\text{new}}, v_{\\text{pub}}, \\info, \\pf)$. To create a pour transaction, the sender needs to have the following information (see Figure~\\ref{fig:tx_gen}):\n\\begin{itemize}\n    \\item [-] Old coins $c_1^{\\text{old}}, c_2^{\\text{old}}$;\n    \\item [-] Secret keys of old coins $\\adsk(c_1^{\\text{old}}), \\adsk(c_2^{\\text{old}})$;\n    \\item [-] New values $v_1^{\\text{new}}, v_2^{\\text{new}}$; \n    \\item [-] Public value $v_{\\text{pub}}$ s.t. $v_1^{\\text{old}} + v_2^{\\text{old}} \\ge v_1^{\\text{new}} + v_2^{\\text{new}} + v_{pub}$;\n    \\item [-] New addresses $\\adpk(c_1^{\\text{new}}), \\adpk(c_2^{\\text{new}})$.\n\\end{itemize}\n\n\\begin{figure}\n\\centering\n\\begin{minipage}{.5\\textwidth}\n  \\centering\n  \\includegraphics[width=.8\\linewidth]{figures/tx_generator.png}\n  \\captionof{figure}{Generate a pour transaction.}\n  \\label{fig:tx_gen}\n\\end{minipage}%\n\\begin{minipage}{.5\\textwidth}\n  \\centering\n  \\includegraphics[width=.7\\linewidth]{figures/zk-SNARK.png}\n  \\captionof{figure}{Generate a zk-SNARK proof.}\n  \\label{fig:proof_gen}\n\\end{minipage}\n\\end{figure}\nIn a real system, a transaction generator can be called by a sender given required information to generate a pour transaction and the new coins. Then the new coins will be sent to the recipients off chain and the transaction will be posted on chain.  \n\n\\paragraph{Generate a  zk-SNARK proof.}  zk-SNARK is a cryptographic  zero knowledge, succinct and a non-interactive verification method. When a prover knows the witness for an NP-statement, they can produce a short proof that can be verified by anyone without revealing the witness. The NP-statements we will encounter in Zcash are going to be satisfiability statements such as ``the hash function matches this particular value for this particular input''. As a library, there are three polynomial time algorithms during the proving process, $\\textsf{KeyGen}$, $\\prove$ and $\\verify$. $\\textsf{KeyGen}$ is the trusted setup which generates proving and verifying keys, $pk$ and $vk$ respectively once and for all. The function $\\prove$ takes $pk$, the witness $w$ and the public input $x$ to output a short proof $\\pi = \\prove(pk,w,x)$. The function $\\verify$ takes $vk$, the public input $x$ and the proof $\\pi$ and outputs a Boolean value $\\verify(vk,x,\\pi)$.\n\n\n\n\n\\paragraph{Incentives in Zcash.} Zcash is a fork of Bitcoin main chain, and still follows the same basic protocol with an added privacy-preserving service. So the incentives in Zcash are identical  to that in the Bitcoin protocol, including both mining rewards and  transaction fees. Since the zk proof verification process is efficient, the increased  verification time is not significant (especially given the slow mining rate in Bitcoin). \n\n\n\\section*{References}\n Zerocoin~\\cite{6547123} extends Bitcoin to provide a decentralized laundry system using zero knowledge proofs. Zero-knowledge proofs allow users to periodically convert their bitcoins into zerocoins of fixed denominations and later provide a proof that they own one of the zerocoins to recover their bitcoins. However, the proof used by Zerocoin is not efficient, which creates a large overhead on the blockchain and makes it less usable. Moreover, it neither gives a mechanism to split or aggregate zerocoins nor lets the users transact in zerocoin, routine day-to-day transactions are still conducted in Bitcoin.\n\nThe Zcash architecture discussed in this lecture was originally proposed in \\href{https://eprint.iacr.org/2014/349}{this manuscript}. A more informal description is presented \\href{https://z.cash/technology/}{here}. The zk-SNARK library is described informally \\href{https://z.cash/technology/zksnarks/}{here}. \n\n\n\\bibliographystyle{plain}\n\\bibliography{references}\n\n\\end{document}",
    "lecture_03.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\n\\let\\proof\\relax\n\\let\\endproof\\relax\n\\usepackage{amsthm}\n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 3}\n\\cfoot{\\thepage}\n\n\\title{Lecture 3:  Proof of Work and Nakamoto Consensus}\n\\author{Principles of Blockchains, Princeton University,  \\\\ Professor:  Pramod Viswanath \\\\ Scribes: Suryanarayana Sankagiri and Xuechao Wang}\n\\date{February 2, 2021}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract} This lecture covers the {Nakamoto consensus protocol}. Coupled with the blockchain data structure, the protocol realizes a decentralized ledger, allowing multiple parties to write to it in a consistent manner. Moreover, the protocol is such that it is robust against an adversary that tries disrupt it; the honest parties continue to have a consistent, ever-growing ledger. In the context of this protocol, we introduce the terms {mining}, {Proof of Work}, {longest-chain rule} and {$k$-deep rule}. We also discuss what it means for such a decentralized ledger to be secure.\n\\end{abstract}\n\nIn the last lecture, we saw that the blockchain data structure enables a tamper-evident and tamper-resistant ledger but with a caveat: only a single party has the privilege to write into the ledger. Other parties may merely read the ledger and verify whether or not it is consistent. To create a decentralized ledger, we showed that the following three questions must be answered.\n\\begin{enumerate}\n    \\item Who are the set of users that can participate in and how are they chosen? \n    \\item When and which block does a user get to append and how do others verify this rule in a decentralized manner?\n    \\item Where does a user append the block? In principle, a block can be appended to any other block in the view of the user. \n\\end{enumerate}\nIn this lecture we see how Bitcoin (and many other cryptocurrencies that followed) answers these questions via the \\textbf{Nakamoto consensus protocol}.\n\n\\section*{Intuition behind Nakamoto consensus}\nThe Nakamoto consensus protocol, first introduced in the Bitcoin whitepaper, can be described briefly as follows. At any given time, there are a certain number of users that are actively participating in writing to the decentralized ledger, one block at a time. These users can change with time; new users can join in this task of their own free will, without anyone's permission. At regular intervals, a user is chosen at random among the ones currently present to propose the next block. This user creates a block with new data, and the hash pointer of the last block in the blockchain. In effect, it appends the new block to the end of the blockchain, thereby extending the ledger. It then signs this block and broadcasts it to all other users in the system. Other users receive this block, perform some checks on it, and adopt it into (their local copy of) the ledger. The process repeats indefinitely. The process is initialized from a \\textbf{genesis block}, which is known to all users right from the beginning.\n\nHow can such a system be realized? In particular, how can one randomly pick a user to propose the next block, especially when the number of users is variable? Nakamoto's idea was to use a simple concept called \\textit{proof-of-work}, described next. This concept is a salient feature of many blockchain systems, and arguably the most important novelty of Bitcoin. It provides an answer to the first two questions above. \n\nWhat other aspects go into the creation of a new block? Firstly, the miner must include new data-values that have not been included in the ledger so far. This aspect of the protocol will be covered in the coming lectures. Secondly, it must include the hash pointer of a block that is already on the ledger:   the new block should point to the last block currently on the ledger. Formally called the \\textit{longest-chain rule} for block proposal, this is another salient feature of the Nakamoto consensus protocol. It answers the third question above. This seemingly innocuous rule has important implications for the security of the protocol, which become clear when we consider adversarial behavior, i.e., users who do not follow this rule.\n\n\\section*{Proof-of-work and mining}\nHash puzzles are a game in which one tries to find a {\\sf nonce} (an integer) such that \n$$\nH({\\sf nonce}, {\\sf data}) <  T, \n$$\nwhere $T$ is the {\\em target  } difficulty level. \nHere, {\\sf data} is some pertinent string; every new piece of data defines a new hash puzzle. If the the target $T$ is small, one needs to try out many different nonces in order to solve the puzzle. For each nonce, one most re-compute the hash function. Every hash computation takes some non-zero time. The exact time depends on the length of the data string; for the sake of estimates, we can assume it to be a few nanoseconds on a modern computer. A party that has solved such a hash puzzle must clearly have tried a large number of nonces and computed hashes with each one of them. Thus, it must have put in a lot of `work' , i.e., computation time. It simply cannot guess a nonce that solves the puzzle in a short time (except with small probability, purely by luck). We say that a nonce that solves the hash puzzle (in conjunction with the pertinent data) serves as a '\\textbf{proof-of-work}' (PoW for short). \n\n%Note that the actual amount of time it takes for a person to solve the hash puzzle is random; only its expected value can be controlled by the threshold. To speed things up, the person can perform this task in parallel on multiple computers (or get a faster computer).\n\nNow imagine multiple parties competing to solve the same hash puzzle the earliest. As we saw, there is no real strategy; they must simply try random nonces and re-compute the hash each time with a different nonce. Since multiple parties are working towards the same puzzle, it will get solved faster. This is because the search for different nonces is now split among different computers which work in parallel. Which party solves the puzzle the first? A priori, this cannot be determined; the winner of this race is random, beyond the control of the competing parties. At best, a party can improve its chances by buying a better computer which computes hashes faster. Even so, it is unlikely that one party has much more computing power than all the others combined. Thus, multiple parties have a reasonable chance of winning the race. Moreover, the winner changes from one hash puzzle to another.\n\nThe process of searching for a nonce that solves the hash puzzle is called \\textbf{mining}. The precious resource being mined here is the right nonce, i.e., the proof-of-work. Just as one must keep digging (mining) until one strikes gold, one must keep computing hashes with random nonces until one solves the puzzle. The parties competing to solve the hash puzzle are called \\textbf{miners}. In the Nakamoto consensus protocol, what is the gold that the miners get upon solving the hash puzzle? In a nutshell, they get to propose a new block. Before we specify the details, let us note that such a system has the properties described in the previous section, i.e., new blocks are proposed at some regular intervals of time (with some random fluctuations), and that the proposer is randomly chosen among the currently active users.\n\nWe now elaborate on how hash puzzles are used in the context of blockchains. In blockchains operating with the Nakamoto consensus protocol, each block contains a nonce (this is simply a special field in the block). The \\textbf{block header} consists of the Merkle root of data in the block, the hash pointer to the previous block, the nonce, the timestamp of the block, and perhaps some other meta-data relevant to the application. A block is considered \\textit{valid} only if the hash of its block header is less than some pre-specified target  (more on how this target is chosen later). In Bitcoin, the target is set such that a new block is expected every ten minutes. Note that the hashes are computed only on the block header and not on the whole block data, which makes it more efficient to compute them.\n\nAt any given time, each miner $m$ creates a block $B_m$ with some data, and includes the hash pointer of the latest known block (i.e., the block at the end of the ledger) into $B_m$. For different miners $m$, $B_m$ may contain identical data, or may differ. All miners search for nonces to solve the hash puzzle. The first successful miner immediately broadcasts its block, with the proof-of-work nonce to other users. We say that a \\textit{new block is mined}; let this block be $B$. These other users first check the proof-of-work (simply check whether the new block's header that they receive has a small enough hash). If this criterion is satisfied, they then create a new block, $B'_m$, locally, with fresh data and a hash pointer pointing to $B$. We say that the miners mine on top of $B$. The process then repeats. This completes the description of the mining process in a proof-of-work system.\n\n\\section*{Forks and the longest-chain rule}\nNote that the mining rate is different from the rate at which the ledger grows. Ideally, each new block should lead to the growth of the ledger. However, this is not always the case. For example, it is possible that a miner mines a valid block but does not publish it; in this case, the ledger does not grow (this is dishonest behavior, but we must account for it nevertheless). It is also possible that two valid blocks are mined with the same parent block, in which case the ledger grows only by one block. This can happen if the second hash puzzle is solved before the pertinent miner heard of the previous block. After all, it takes a non-zero amount of time for a block to be communicated across the network, especially if the block has a lot of data.\n\nIn general, the set of blocks mined at any given point in time form a directed tree, rather than a single chain. We say that the blockchain has \\textbf{forked} when a single block has two or more children blocks. We saw how forks might occur due to communication delays or adversarial behavior in the previous paragraph. As such, there could be many forks over time. What then should the users consider as `the ledger'? The \\textbf{longest-chain rule} states that the longest chain among all published blocks should be treated as the ledger. Thus, users should build a new block and append it to the longest chain that they currently know of. When there are ties (i.e., there are two or more chains of equal length, that fork at some level), one favors the branch of the fork where the blocks' hashes are the smallest.\n\n\\section*{Adversarial users}\nThe description so far describes the salient aspects of the  Nakamoto consensus protocol. (Some more details will be covered in the next  lecture). All users are expected to follow the protocol exactly. In reality, there may be some who deviate from the protocol; they are \\textbf{adversarial users} (aka corrupt/malicious users). Those who do follow the protocol are called honest parties. What might be the aim of the adversarial parties? In general, their aim is to disrupt the system in any possible way. Here, we describe one possible attack on the append-only property of the ledger, called the \\textbf{private attack}.\n\nIn the private attack, a group of adversarial users mine new blocks, but keep these blocks privately to themselves; they do not broadcast these blocks throughout the network. Honest users are simply unaware of these private blocks, and continue to mine as if these blocks never existed. In effect, the adversarial users have created a fork in the blockchain, but one that only they can see. Suppose, due to randomness in the mining process, the adversarial users get lucky and build a few (say, five) private blocks in quick succession. During the same interval, say the honest users only mine three blocks. In such a case, the private (adversarial) chain is longer than the public (honest) chain. Now, the adversarial users release their private chain to all other users. By the longest-chain rule, these honest users must give up their chain and adopt the adversarial chain. In effect, the last three blocks have been erased from the ledger.\n\n\\begin{figure}[htbp]\n    \\centering\n    \\includegraphics[width=10cm]{figures/private_attack.png}\n    \\caption{An Illustration of the private attack}\n    \\label{fig:private_attack}\n\\end{figure}\n\nFigure \\ref{fig:private_attack} illustrates the fork in the blockchain when a private attack is launched. The dashed blocks are the privately held blocks of the malicious users, while the solid blocks are publicly seen blocks mined by honest users. \n\n\nSuccessfully executed private attacks can wreck havoc with the trust in the blockchain. This is best illustrated with a {\\em double-spend} action enabled by the private attack. Suppose a transaction ({\\sf tx}) is embedded in a block $B$ (see Figure~\\ref{fig:doublespend}): say, the transaction encodes payment of seven Bitcoins to {\\sf Tesla} (which recently announced plans to accept Bitcoins for their cars).  Upon seeing the {\\sf tx} embedded in a block on the longest chain, suppose {\\sf Tesla} decides to release the car to the source of the transaction (thus ``confirming\" or completing the transaction {\\sf tx}). Then an adversary seeing that the  {\\sf tx} has been confirmed could launch a private attack: release two or more blocks it has been mining in private. Now the block $B$ is no longer in the longest chain and the transaction {\\sf tx} no longer in the ledger maintained by the participants. Now the source of the transaction is free to double-spend the seven Bitcoins; this is a fatal attack  demolishing any trust embodied by the blockchain. One way to address this is to {\\em delay} confirming the transaction; this is described next. \n\n\\begin{figure}[htbp]\n    \\centering\n    \\includegraphics[width=8cm]{figures/doublespending.png}\n    \\caption{An Illustration of the double spend attack.}\n    \\label{fig:doublespend}\n\\end{figure}\n\n\n\\section*{The $k$-deep confirmation rule}\nIn the Nakamoto consensus protocol, occasional changes at the end of the ledger is impossible to avoid. We discussed above how malicious users can coordinate and launch a private attack, which effectively re-writes the last  block of the ledger. Even if we assume that there are no adversarial users, we have seen that forks can occur because of network delay. Wherever there are forks, there is the possibility that the longest-chain may switch, which would mean that the last portion of the ledger is re-written. \n\nThe solution around this is simple and intuitive. Users should treat a block as \\textbf{confirmed} only if it is {\\em buried deep enough under other blocks}. Put differently, only if some $k$ blocks are built directly below a block $B$ should the block $B$ be confirmed. Confirming a block means that the portion of the ledger up to that block is now immutable. It is not advisable to confirm very recent blocks as they may be over-written, due to forks in the blockchain. \n\nThe \\textbf{$k$-deep confirmation rule}, mentioned above, reflects the belief that any change in the longest-chain are towards the end of the chain. The prefix of the longest chain at some time $t$, i.e. the chain obtained by dropping the last $k$ blocks, continues to remain a prefix of the longest chain at future times too. Note that for any finite value of $k$, it is not guaranteed with absolute certainty that this will be true. If the adversarial users invest in a lot of computing power, block communication among honest users, or simply get very lucky, they could even overturn a deeply buried block. However, the larger the value of $k$, the more unlikely it is that this happens. In lecture 6, we show that the probability with which this happens decreases exponentially with $k$, so long as the honest miners control a majority (i.e., more than 50\\%) of the hash power.\n\n%\\textit{Talk about confirmation. Point out that there is no finality.At best probabilistic guarantee. When should we decide to confirm? This is the first time this concept is showing up in our lecture, so we need to motivate it. }\n\n\\section*{Variable mining difficulty}\nA key requirement of deployed PoW blockchains is to adapt to the immense variation in mining power. For example, the mining power of Bitcoin increased exponentially by an astonishing factor of $10^{14}$ during its decade of deployment. This is a reflection of the growing popularity of Bitcoin; many people have invested a lot of computational resources into it over time. If Bitcoin had continued to use the same difficulty for the hash puzzle, then the average inter-block time would have fallen from the original $10$ minutes to $6$ picoseconds. By adjusting the difficulty threshold of Bitcoin, using a difficulty adjustment algorithm, the average inter-block time is kept constant over the course of a long duration of time.\n\nThe threshold below which the hash puzzle output lies in successful PoW mining is the {\\em target} of a block. The {\\em difficulty} of each block is measured in terms of how many times the block is harder to obtain than using the initial target of the system that is embedded in the genesis block. The {\\em chain difficulty} of a chain is the sum of difficulties of all blocks that comprise the chain, then each block in the chain {\\em covers} an interval of chain difficulty. We also refer the chain difficulty of a block as the chain difficulty of the chain ending at this block. There are three core ideas to the Bitcoin difficulty adjustment algorithm: (a) vary the difficulty target of block mining based on the average inter-block time from the previous epoch (of $2016$ blocks), (b) use the {\\em heaviest} chain (calculated by the sum of the block difficulties) instead of the longest chain to determine the ledger, and (c) allow the difficulty to be adjusted only mildly every epoch (by an upper bound of a factor of $4$). While this appears to be a simple and intuitive algorithm, minor seemingly-innocuous variants turn out to be dangerously insecure.\n\nConsider a simpler algorithm using only (b), i.e., simply let the miners choose their own difficulty and then use (b) the heaviest chain rule. At a first glance, this rule appears kosher - the heaviest chain rule seems to afford no advantage to any miner to manipulate their difficulty. However, this lack of advantage only holds in expectation, and the variance created by extremely difficult adversarial blocks can thwart a confirmation rule that confirms deeply-embedded blocks, no matter how deep, with non-negligible probability proportional to the attacker's mining power. We give a simple calculation here. Suppose honest miners are adopting the initial mining difficulty as defined in the genesis block, with expected inter-block time being 10 minutes. Let 10 minutes be our unit of time and the initial difficulty be the difficulty unit, hence on average it take $k$ units of time to mine a honest chain with $k$ blocks. See Figure ~\\ref{fig:bahack0} for illustration. Suppose the adversarial mining power is half of the honest mining power (or $1/3$ of total mining power). To mine a heavier chain, the adversary only needs to mine one block which is as difficult as $k$ honest blocks, within $k$ unit of time. Then the adversarial mining process follows a Poisson point process with rate $1/2k$, and the number of adversarial blocks mined in $k$ unit of time follows the Poisson distribution ${\\sf Poiss}(1/2)$. Hence the success probability of this attack would be\n$$\\mathbb{P}(\\rm attack~succeeds) = \\mathbb{P}({\\sf Poiss}(1/2)\\geq 1) = 1 - e^{-1/2} \\approx 39.3\\%,$$\nwhich is a constant independent of $k$, therefore any $k$-deep confirmation rule will fail.\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=9cm]{figures/Bahack0.png}\n    \\caption{A simple attack if allowing miners to choose their own difficulty. The adversary mines one block which is as difficult as $k$ honest blocks.}\n    \\label{fig:bahack0}\n\\end{figure}\n\nNow consider a more detailed rule involving only (a) and (b). It turns out that there is a difficulty raising attack \\cite{bahack2013theoretical}, where the adversary creates an epoch filled with timestamps extremely close-together, so that the difficulty adjustment rule from (a) will set the difficulty extremely high for the next epoch, at which point, the adversary can utilize the high variance of the mining similar to the aforementioned attack. Now we describe this attack in detail. Note that the adversary can put any timestamp in its private blocks, so the difficulty of the second epoch in its private chain can be arbitrary value as long as the adversary completes the first epoch. Let $B$ with difficulty $X$ be the first block of the second epoch in the private chain, then $B$ has chain difficulty $2016 +X$. See Figure ~\\ref{fig:bahack} for illustration. To mine an honest chain with chain difficulty $2016 +X$, on average it takes $2016 + X$ unit of time. On the other hand, considering the same adversary, it takes on average $4032$ unit of time for it to complete the first epoch in its private chain. Therefore, to succeed in this attack, the adversary needs to mine the block $B$ within $ X - 2016$ unit of time, which happens with probability:\n$$\\mathbb{P}(\\rm attack~succeeds) = \\mathbb{P}({\\sf Poiss}(\\frac{X-2016}{2X})\\geq 1) = 1- e^{-\\frac{X-2016}{2X}} \\approx 1 - e^{-1/2} \\approx 39.3\\%,$$\nif $X \\gg 2016$. Note that the success probability is independent of the length of the public longest chain, hence any $k$-deep confirmation rule will fail again.\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=10cm]{figures/Bahack.png}\n    \\caption{The difficulty rising attack. The adversary raises the difficulty to extremely high in the second epoch by faking timestamps.}\n    \\label{fig:bahack}\n\\end{figure}\n\nThis more complex attack is only thwarted using the full protocol that employs (a), (b) and (c) together. Formally, the Bitcoin difficulty adjustment algorithm is as follows: Consider a chain of $v$ blocks with timestamps $(r_1 \\ldots r_v)$. For fixed parameters $\\tau$ (= 4  in Bitcoin), $\\Phi$ the length of an epoch in number of blocks (= 2016 in Bitcoin), $\\Lambda_0$ the expected duration of an epoch (= 2 weeks in Bitcoin). The target calculation function $D: \\mathbb{Z}^* \\rightarrow \\mathbb{R}$ is defined as\n\n\\begin{align*}\n    D(\\epsilon) &= T_0,\\\\\n    D(r_1 \\ldots r_v) &= \\left\\{ \\begin{array}{ll}\n         \\frac{1}{\\tau}T& \\text{if } \\frac{\\Lambda}{\\Lambda_0}T < \\frac{1}{\\tau}T  \\\\\n         \\tau T&  \\text{if } \\frac{\\Lambda}{\\Lambda_0}T > {\\tau}T \\\\\n         \\frac{\\Lambda}{\\Lambda_0}T & \\text{ otherwise}\n    \\end{array}\\right.\n\\end{align*}\nwhere $T_0$ is the initial target as defined in the genesis block, and $\\Phi' , \\Lambda,$ and $T$ correspond to the last block, duration, and target of the last completed epoch, respectively, i.e., $\\Phi' = \\Phi \\lfloor v/\\Phi \\rfloor$, $\\Lambda = r_{\\Phi'} - r_{\\Phi' -\\Phi}$ and $T = D(r_1 \\ldots r_{\\Phi'-1})$. A full and beautiful analysis of Bitcoin rule is provided in \\cite{full2020}.\n\n%\\section*{Sybil resistance}\n\n%\\section*{Skeleton}\n%Bitcoin is permissionless, so anyone can participate in the block creation process. Which user gets to propose a block and when is decided through a mining process. The user always appends a new block as the leaf of the longest chain in the block tree data structure it has locally. This rule is also referred to as the longest chain rule. \n\n%The points (1) and (2) are best explained jointly through a process called mining. Mining allows everyone to participate through a proof of work process. The main point of mining is to have roughly one block produced every $T$ seconds (where $T$ is slow enough so that the generated block can be broadcast over the network to everyone). \n\n%Explain the mining process. Mining simply cannot be faked because of hash functions. Permissionless and at the same time prevents spam (sybil resistance). \n\n%Show how the threshold has dramatically varied over the lifetime of Bitcoin. Explain the variable difficulty mining rule. Point out the subtleties of the rule (and justify some of the choices that were made). \n\n%Explain the longest chain rule. If there are two chains of equally long length, then ties can be broken arbitrarily (although the rule says to stick to the chain that you had first). \n\n\\section*{Bitcoin is Permissionless}\nIn Bitcoin, participants can generate a new (secret key, public key) pair for themselves at any point in time. Thus, a single user can pretend to be multiple different people. In fact, doing so is encouraged for privacy reasons. Such a system is called a \\textbf{permissionless system}. However, creating multiple identities in Bitcoin does not truly increase one's representation in the system; that is determined by the mining (computation) power, which can only be grown by a capital investment. If the system were such that an adversary could gain advantage by creating multiple identities, then such an attack is called a \\textbf{Sybil attack}.  Bitcoin inherit the    \\textbf{Sybil-resistance} property from PoW mining. Thus the PoW mining process simultaneously achieves multiple goals in  Bitcoin: (a) Sybil-resistance; (b) Randomized block proposer election; (c) Adjusting the average inter-block duration time.  \nIn some other blockchain designs, there are external mechanisms to ensure that each entity only has a single key. Such a system is said to be {\\em permissioned}. These blockchains will also have separate mechanisms for items (b) and (c). We will see some of these designs in later lectures. \n\n\\bibliographystyle{plain}\n\\bibliography{references}\n\n\\input{Problem_sets/Lec3_PS}\n\n%\\section*{Appendix}\n%In this appendix, we prove that the private attack is one of the optimal adversary strategies in terms of probability of success when the adversary tries to create a fork from the {\\bf genesis} in the zero network delay case (this is an idealization of the Bitcon parameter setting of mining rate of one block very ten minutes, which is much much smaller than network propagation delay).\n\n%\\noindent {\\bf Optimality} \n\n%\\noindent Security model: There is zero delay among honest nodes so {\\bf honest blocks always appear on different heights}. If there is more than one longest chain, then the adversary controls how the honest partys mining power is split across the multiple longest chains.\n%We assume the adversary launches the attack from the genesis block and starts mining at the same time as honest nodes (i.e., no pre-mining phase). We say the attack succeeds when the adversary at some time creates a fork from the genesis and both chains are of equal length at least $k$.\n%In Nakamoto's private attack, the adversary simply mines a chain from the genesis privately and releases the private chain when the private chain exceeds the honest chain and the honest chain has length at least $k$.\n%\\begin{proof}\n%We use a random 0-1 string $w^{(n)} \\in \\{0,1\\}^n$ to represent the randomness in the attack. $w^{(n)}_i = 0$ means that the honest nodes mine the $i$-th block and the honest block will be placed to one of the two chains according to the longest chain rule. If there is a tie, tie breaking can be in favor of the adversary. $w^{(n)}_i = 1$ means that the adversary mines the $i$-th block and the adversary can take arbitrary action (eg., keep it private, publish it, or even drop it). For any fixed $k$, given an adversarial strategy $S$, if the adversary can create a fork with length at least $k$ under string $w^{(n)}$, we call $w^{(n)}$ a $S$-bad string. Note that if $S$ is a randomized strategy, then we consider the worst case. Let $q_n^{S} = P(w^{(n)} \\text{ is a } S\\text{-bad string})$. Let $S^*$ be the private attack. We will prove $q_n^{S} \\leq q_n^{S^*}$ for any $S$.\n%\\begin{align}\n%     q_n^{S} = &P(w^{(n)} \\text{ is a } S\\text{-bad string}) \\nonumber\\\\\n%  \\leq  &P(\\exists k \\leq m \\leq n/2, \\text{such that \\# of 0's $\\leq$ \\# of 1's in the first $2m$ bits in $w^{(n)}$}) \\nonumber\\\\\n%  = &P(w^{(n)} \\text{ is a } S^*\\text{-bad string}) = q_n^{S^*}. \\label{eqn:bound}\n%\\end{align}\n\n%Note that for any strategy $S$, if $w^{(n)}$ a $S$-bad string, then both $\\overline{w^{(n)}0}$ and $\\overline{w^{(n)}1}$ are $S$-bad strings. So we have $q_n^{S} \\leq q_{n+1}^{S}$, then by Monotone Convergence Theorem, $\\lim q_n^{S}$ exists and we write it as $q^{S}$, which is the success probability of strategy $S$. Applying limit on (\\ref{eqn:bound}), we get $q^{S}\\leq q^{S^*}$ for any $S$, which concludes the proof.\n\n%\\end{proof}\n\n%\\noindent {\\bf Calculation of $q^{S^*}$} \n\n%Let $\\beta$ be the fraction of adversarial mining power. We will compute $q^{S^*}$ as a function of $k$ and $\\beta$.\n\n%Nakamoto \\cite{nakamoto2008bitcoin} also calculates the success probability of private attack. However, Nakamoto assumes that when the honest chain has length $k$, the length of the private chain will follow a Poisson distribution with expected value $k\\beta/(1-\\beta)$, which is not correct. \n%Let $Z$ be the length of the private chain at the time when the length of the honest chain reaches $k$, then the distribution of $Z$ should be\n%\\begin{equation}\n%    P(Z=m) = \\binom{k-1+m}{m}(1-\\beta)^k \\beta^m,\n%\\end{equation}\n%for $m = 0,1,2,\\cdots$. One can check that $E[Z] = k\\beta/(1-\\beta)$.\n\n%From random walk theory, the probability that the private chain can catch up the honest chain from $s$ block behind is $(\\frac{\\beta}{1-\\beta})^s$ when $\\beta<1/2$. So we have \n%\\begin{align}\n%    q^{S^*} &= \\sum_{m=0}^{k} \\binom{k-1+m}{m}(1-\\beta)^k \\beta^m (\\frac{\\beta}{1-\\beta})^{k-m} + \\sum_{m=k+1}^{\\infty} \\binom{k-1+m}{m}(1-\\beta)^k \\beta^m  \\nonumber\\\\\n %           &= 1 - \\sum_{m=0}^{k} \\binom{k-1+m}{m}[ (1-\\beta)^k \\beta^m - (1-\\beta)^m \\beta^k ]. \\label{eqn:q_S}\n%\\end{align}\n\n\\end{document}",
    "lecture_19.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\usepackage{markdown}\n\\usepackage{caption}\n\\usepackage{subcaption}\n\\usepackage{amsthm}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\newcommand{\\indicator}{{\\bf 1}}\n\\newcommand{\\pramod}[1]{{\\color{red}\n\\footnotesize[Pramod: #1] }}\n\\newcommand{\\xw}[1]{{\\color{green}\n\\footnotesize[Xuechao: #1] }}\n%\\theoremstyle{definition}\n\\newtheorem{definition}{Definition}\n\\newtheorem{theorem}{Theorem}\n\\newtheorem{lemma}{Lemma}\n\\newtheorem{remark}{Remark}\n\n\\newcommand{\\singlechain}{\\Pi_{\\texttt{single}}}\n\\newcommand{\\multichain}{\\Pi_{\\texttt{multi}}}\n\\newcommand{\\mchain}{\\texttt{chain}}\n\\newcommand{\\chain}{\\texttt{SemChain}}\n\\newcommand{\\finalization}{\\texttt{Finalization}}\n\\newcommand{\\lists}{\\mathcal{L}}\n\\newcommand{\\depth}{\\texttt{index}}\n\n%\\let\\proof\\relax\n%\\let\\endproof\\relax \n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 19}\n\\cfoot{\\thepage}\n\n\\title{Lecture 19: Privacy for Smart Contracts}\n\\author{Principles of Blockchains, University of Illinois,  \\\\ Professor:  Pramod Viswanath \\\\ Scribe:  Soubhik Deb}\n\\date{April 1, 2021}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nThe previous lecture showed how to bring  privacy to the data in the blockchain. Using cryptographic tools of zero knowledge, privacy was afforded to transactions, and yet readily allowing for verification of the validity of the transaction. In this lecture we study the problem of how to bring such strong privacy to the data in a more general state management system: an account based system managing smart contracts (e.g., Ethereum).  The privacy construction of the previous lecture was specific to UTXO and it is especially challenging to generalize it to the smart contract platform; this is the  focus of this lecture. \n\\end{abstract}\n\n\n\n% 1. UTXO model and zcash privacy recap. Point out that this is a complete solution, but specific to UTXO. Need to have figures for UTXO model and tx therein (borrow from previous lecture if needed). Now say that we move away from UTXO to account based model (leave a pointer to EVM and programmable contracts -- will be covered in a separate lecture). What are privacy issues in account based model? \n\n% 2)  Discuss why previous lecture solutions dont solve the issues in the account based model. Divide the different privacy issues in account model and highlight the specific ones we will solve in this lecture. The others will be covered in a later lecture (Kachina). Ideally we can use figures here too. \n\n% 3) Privacy Bridge.  the ideas. what privacy  guarantees can you get. \n\n% 4) How to build a system around this idea. Putting it on EVM for example. \n\n% 5) what privacy features you cannot get. conclusion. \n\n\n\n\\section*{Introduction}\n\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=0.4\\textwidth]{figures/utxo.pdf}\n    \\caption{UTXO model was introduced in Bitcoin. However, it leads to information leakage. Zcash employs zk-SNARKs to shield the information on the payment's origin, destination, or amount in a payment transaction.}\n    \\label{fig:utxo-zcash}\n\\end{figure}\nIn the previous lecture, we learnt how Zcash can be used to provide privacy in an UTXO state management system. The UTXO model of state/ledger management system consists of  transactions (which contain a list of inputs and outputs):  outputs specify the recipients' public keys and inputs refer to previous output. However, simply using the UTXO model leads to information leakage via which one can link transactions into a graph. Zcash provides an architectural framework to remove this information leakage by ensuring that a payment transaction doesn't reveal the payment's origin, destination, or the amount; see Figure~\\ref{fig:utxo-zcash} for an illustration. \n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.5\\textwidth]{figures/degree.pdf}\n    \\caption{Bitcoin offers neither privacy nor programmability. It avails simple scripts that can be used for writing only the payment transactions. On the other hand, Zcash offers complete privacy but no programmability. In contrast to that, Ethereum offers high degree of programmability but no privacy. Currently, there is no deployed blockchain ecosystem that offers both privacy and programmability.}\n    \\label{fig:degree}\n\\end{figure}\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.9\\textwidth]{figures/privacy_account_based.pdf}\n    \\caption{An entity buys Ether from a cryptocurrency exchange such as Coinbase. Then, using smart contract, it successfully executes an arbitrage opportunity that involves exchanging Ether for ZKS and ZKS for COMP in Uniswap and then, COMP for Ether in Sushiswap. After that, the entity exchanges the Ether for USD in Coinbase. However, Coinbase has full access to the real-world identity of this entity (through the ``know your customer\" (KYC) process). }\n    \\label{fig:user-privacy-account-based}\n\\end{figure}\nThe simple-state environment in the UTXO model makes it difficult, if not impossible, for programming on-chain complex computation that requires some state information or requires multiple parties (see Figure~\\ref{fig:degree}). This lack of programmability in UTXO model leads to the introduction of account-based model in Ethereum. To facilitate this programmability in Ethereum, applications involving complex computations are defined in smart contracts which are then executed in Ethereum Virtual Machine (EVM). This feature has enabled numerous financial instruments like decentralized exchanges, arbitrage, flash loans in decentralized finance (DeFi), tokenization and games  in Ethereum. However, in contemporary account-based blockchain ecosystems, all details inside a transaction are public and thus, afford  no privacy.  For example,  suppose an account buys Ether from a cryptocurrency exchange, like Coinbase, and uses it to execute an arbitrage opportunity (see Figure \\ref{fig:user-privacy-account-based}). Next the account  converts the Ether to a fiat currency such as USD. Since all the details inside the transactions in Ethereum are public, therefore, the real-world identity of the entity that obtained the arbitrage opportunity is known to the cryptocurrency exchange. \n\n\nHaving studied Zcash in previous lecture, a natural question is whether we can use zk-SNARKs to shield the internal details of the transactions in an account-based ecosystem like Ethereum. A successful design will then provide {\\em both} privacy and programmability. Before answering this question, we first need to delineate what is meant by the privacy of a transaction. Internally, a transaction is composed of different components:  sender address, recipient address, value of the transaction, tokens exchanged, liquidity pool whose service is availed, timestamps, etc. Therefore, privacy of a transaction can imply that a certain combination of above components like senders' and recipients' addresses is shielded whereas rest are visible to the public (see  Figure~\\ref{fig:spectrum}). In this lecture, we  explore a construction that guarantees the aforementioned level of privacy,  termed as {\\bf user privacy}. This construction would still reveal the information regarding the value of the transaction and tokens exchanged but shield the identities of the accounts involved in the transaction.  \n\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.6\\textwidth]{figures/spectrum.pdf}\n    \\caption{In the first case, every detail about the transaction is revealed to the public. This is the current state of privacy in Ethereum and other smart-contract based blockchain ecosystems. A limited amount of privacy can be achieved by shielding only the senders' address and recipients' address in the transaction. Complete privacy is obtained when all the components of a transaction are shielded yet this transaction is still verifiable.}\n    \\label{fig:spectrum}\n\\end{figure}\n\n\n\n\\section*{Key Idea}\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.95\\textwidth]{figures/key_idea.pdf}\n    \\caption{A node makes an account in a privacy-preserving blockchain like Zcash (with limited programmability) and exchanges fiat currency for some tokens. Then, the node utilizes the hiding set to create an account in the account-based ecosystem. For example, in case of Ethereum, hiding set can be utilized to open a contract account for a smart contract. Using the hiding set, masks the linking between the account in Zcash and the contract account in Ethereum. Now, the node can use this smart contract to engage in various trades like arbitrage, swaps, payment transactions, etc., in Ethereum. When the node wants to convert the tokens in its possession in Ethereum back to fiat currency like USD, it can first use the hiding set to transfer its assets to another account in Zcash. Note that using hiding set breaks any link between the account in Zcash and the contract account in Ethereum. Then, the node can exchange the tokens for fiat currency in a cryptoexchange. A similar strategy can be employed by the node for masking the links between different transactions done from its accounts in Ethereum.}\n    \\label{fig:key-idea}\n\\end{figure}\n\nThe key idea to achieve user privacy in an account-based blockchain ecosystem is to use the privacy-preserving blockchain like Zcash as an anchor. Specifically, a participating node must have an account in Ethereum to engage in payment transactions, trading activities in DeFi, etc. There are two possible ways an account can avail of to transact in a privacy-preserving manner:\n\\begin{itemize}\n    \\item the node can go to a cryptoexchange and exchange  fiat  for the token in the privacy-preserving blockchain, say Zcash. Then, the node can employ the {hiding set}  in Zcash to insert liquidity in the account in Ethereum. Using the hiding set removes any linkage between the account in Zcash that obtained token from the cryptoexchange and the account in Ethereum.\n    \\item the node can avail of a flash loan from liquidity pools like \\href{https://aave.com/}{Aave} in one account in Ethereum. Then, the node can move this asset to an account in  Zcash and then, use the {\\em hiding set} in Zcash to again move this asset back to another account in Ethereum.\n\\end{itemize}\nIn both cases, the trades engaged on Ethereum  are visible to either the cryptoexchange or the liquidity pool. However, these entities have no way to link the trades with the accounts that were used by the node for obtaining liquidity. In fact, if a node doesn't want other nodes to link the transactions done from its accounts, the node can use the hiding set in Zcash to break those links in the same manner as above (see Figure~\\ref{fig:key-idea}).\nNote that other parties (cryptoexchanges, liquidity pools) can observe the transactions conducted in Ethereum but  have no way to determine the actual identity of the node that participated in these transactions. This provides user privacy.\n\n\n\n\\section*{Construction}\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.9\\textwidth]{figures/zcash.pdf}\n    \\caption{In a privacy-preserving blockchain like Zcash, some of the input and output UTXOs in a transaction can be shielded and some of the other input and output UTXOs can be public.}\n    \\label{fig:zcash}\n\\end{figure}\nIn Zcash, the addresses and values of some of the input UTXOs and output UTXOs in a transaction can be ``shielded\" and thus, their privacy is maintained. However, in the same transactions, some of the other input and output UTXOs can be public. We will employ this feature for constructing a {\\em privacy bridge} to smart contracts (see Figure~\\ref{fig:zcash}).\n\n\\begin{figure}[h]\n     \\centering\n     \\begin{subfigure}[b]{\\textwidth}\n         \\centering\n         \\includegraphics[width=0.4\\textwidth]{figures/new_blockchain.pdf}\n         \\caption{Each block can contain three types of transactions - privacy-preserving transactions, bridging transactions and programmable transactions.}\n         \\label{fig:new_blockchain}\n     \\end{subfigure}\n     \\hfill\n     \\begin{subfigure}[b]{\\textwidth}\n         \\centering\n         \\includegraphics[width=0.75\\textwidth]{figures/bridging_transactions.pdf}\n         \\caption{Pictorial illustration of the two types of bridging transactions: the first one decreases the assets/tokens in the account of the smart contract and atomically outputs  shielded UTXOs in the privacy-preserving side, the second one involves spending unspent UTXOs in the privacy -preserving side and outputting a public output that increments the account of the smart contract in the programmability-side. Both these transactions must be executed atomically.}\n         \\label{fig:bridging-transaction}\n     \\end{subfigure}\n        \\caption{A privacy bridge based blockchain ecosystem.}\n        \\label{fig:new-blockchain-description}\n\\end{figure}\n\n\nThe privacy bridge comprises of a blockchain that has a privacy-preserving side and a programmability-side. A node has an address in the privacy-preserving side and follows a UTXO model. Transactions within the privacy-preserving side, that is, all senders and recipients of the transaction being addresses in the UTXO model of the privacy-preserving side, are guaranteed  privacy.   We refer to such transactions as ``privacy-preserving transactions\" (see Figure~\\ref{fig:new_blockchain}). On the other hand, if a node wants to employ programmability for executing complex transactions, then, it can transfer funds from the privacy-preserving side to smart contracts in the programmability-side using ``bridging transactions\". Now, within the programmability-side, the node can use smart contracts  to create ``programmable transactions\" for executing complex strategies. Note that these programmable transactions do not hide  details such as the addresses of the smart contracts that are in its senders or recipients list, the tokens that are exchanged or the value, etc.  There are two types of bridging transactions (see  Figure~\\ref{fig:bridging-transaction}): \n\\begin{itemize}\n    \\item the first type decrements the token in the account in the programmability-side and outputs a shielded UTXO in the privacy-preserving side which updates the coins held by the transaction. Note that the source account of the privacy-preserving transaction is kept private. \n    \\item the second type involves spending UTXO in the privacy-preserving side and incrementing the tokens in the smart contract on the programmability-side that is specified in the output of the bridging transaction.\n\\end{itemize}\nThese bridging transactions are implemented in the same way as described at the beginning of this section (see Figure~\\ref{fig:zcash}). Therefore, even if the transactions executed by the smart account in the programmability-side are all public, the accounts in the privacy-preserving side to which the assets have been transferred to are not publicly revealed by the bridging transaction. Note that the bridging transactions are executed atomically. Consequently,  in each block, miners can include three types of transactions: privacy-preserving transactions, bridging transactions and programmable transactions (see Figure~\\ref{fig:new_blockchain}). \n\n\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=0.9\\textwidth]{figures/privacy_helps.pdf}\n    \\caption{Privacy bridge preserves the privacy of the addresses in the privacy-preserving side that funded and received assets from the smart contract in the programmability-side.}\n    \\label{fig:privacy-helps}\n\\end{figure}\n\nIn summary, the smart contract can execute any arbitrage strategy in the programmability side, but the bridging transactions do not reveal the addresses of the account in the privacy-preserving side that deposited funds in the smart contract or the addresses in the privacy-preserving side to which the smart contract transferred its assets (see Figure~\\ref{fig:privacy-helps}). Hence, nobody, not even the cryptocurrency exchanges like Coinbase, can link the accounts in the privacy-preserving side to the transactions in the programmability-side.\n\n\n\n\n\n\\section*{References}\n\nIn this lecture we saw a simple technique to harness the Zcash architecture on UTXOs to  smart contract platforms. This bridging technique brings user privacy, but the actual contents of the transaction (such as the amounts) are public. A more general technique would shield such data; even more generally, perhaps all data on the blockchain could be encrypted and yet be validated by the  participants. Such a broad goal is tantamount to true \\href{https://en.wikipedia.org/wiki/Homomorphic_encryption}{homomorphic encryption}, which refers to computing on encrypted data without the need for any secret key,  a grand goal of cryptography.  Several recent works have attempted to build such general privacy preserving architectures: \\href{https://eprint.iacr.org/2018/962.pdf}{{\\sf zexe}}, \\href{https://eprint.iacr.org/2019/191}{{\\sf Zether}}, \\href{https://github.com/eth-sri/zkay}{{\\sf zkay}}, \n\\href{https://eprint.iacr.org/2020/543}{{\\sf kachina}}, and this is an active area of research and development.\n\n\\href{https://eprint.iacr.org/2018/962.pdf}{{\\sf zexe}}  is a ledger-based system where users can execute offline\ncomputations while hiding all information about the computations and subsequently produce transactions, attesting to the correctness of these computations which can be validated in constant time.  \\href{https://eprint.iacr.org/2019/191}{{\\sf Zether}} is a smart contract in Ethereum that\nkeeps the account balances encrypted and exposes methods to deposit, transfer and withdraw\nfunds to/from accounts through cryptographic proofs.  \\href{https://github.com/eth-sri/zkay}{{\\sf zkay}} is a language formalism which introduces privacy types for Solidity. \n\\href{https://eprint.iacr.org/2020/543}{{\\sf kachina}} is a  framework for deploying privacy-preserving smart contracts under  the Universal Composition (UC) model.\n\n%need to summarize, in 1-2 sentences, these papers. \n \n\n\n\n\n\n\n\n\n\n\n\n\\end{document}",
    "lecture_09.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\usepackage{markdown}\n\\usepackage{amsthm}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\newcommand{\\indicator}{{\\bf 1}}\n\\newcommand{\\pramod}[1]{{\\color{red}\n\\footnotesize[Pramod: #1] }}\n\\newcommand{\\xw}[1]{{\\color{green}\n\\footnotesize[Xuechao: #1] }}\n%\\theoremstyle{definition}\n\\newtheorem{definition}{Definition}\n\\newtheorem{theorem}{Theorem}\n\\newtheorem{lemma}{Lemma}\n%\\let\\proof\\relax\n%\\let\\endproof\\relax \n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 9}\n\\cfoot{\\thepage}\n\n\\title{Lecture 9:  Scaling Latency}\n\\author{Principles of Blockchains, Princeton University,  \\\\ Professor:  Pramod Viswanath \\\\ Scribe:  Xuechao Wang}\n%\\date{February 23, 2021}\n\\date{\\today}\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nIn this lecture, we see that there is a fundamental tradeoff between latency and security in {\\sf  Bitcoin}.  We study  the {\\sf  Prism} protocol, a simple variant of which was introduced in the previous lecture,  which further separates voter blocks from proposer blocks. By having multiple parallel chains for voting, {\\sf Prism} decouples latency from security and achieves fast confirmation.\n\\end{abstract}\n\n\\section*{Bitcoin Latency}\n\nIn {\\sf Bitcoin}, when a transaction has been included in a block, it will be confirmed only after the block is buried $k$-deep in the longest chain. Furthermore, to ensure confirmation with high probability, $k$ must be large. The average latency of confirmation is then the product of $k$ and average inter-block arrival time;  again just like the throughput, the latency in {\\sf Bitcoin} is also limited by security. How bad is this tradeoff? We study this next. \n\n%\\subsection*{Analysis of Bitcoin latency}\n\nAs in the analysis of throughput, our analysis starts with the case when the network delay is zero, i.e.,  $\\Delta = 0$. In this case,  the largest  probability of deconfirmation (``error probability\") $\\varepsilon$ is achieved by the private attack (see Lecture 6). Further, we have seen that the error probability decays exponentially in the  depth $k$ of the  confirmation rule: \n$$ \\varepsilon = e^{-ck}, \\quad \\quad c = -\\log_e(4\\beta(1-\\beta)); \n$$ \nhere $\\beta$ is the fraction of the hash power of the adversary. Suppose that the target difficulty of the mining puzzle is set such that the average time to succeed in mining a block is $\\frac{1}{\\lambda}$. Then we know that themaximum average inter-block time  is $1/(1-\\beta)\\lambda$, which is met when the adversary does not participate in mining (see Lecture 8). Therefore, the latency of {\\sf Bitcoin} is given by\n\\begin{equation*}\n    \\tau_{LC} = \\frac{k}{(1-\\beta)\\lambda} = \\frac{1}{c(1-\\beta)\\lambda}\\log_e(\\frac{1}{\\varepsilon}) = O(\\frac{1}{\\lambda} \\log_e(\\frac{1}{\\varepsilon})), \n\\end{equation*}\nwhere the constant hidden in the $O(\\cdot)$ only depends on $\\beta$. We can see that the latency depends on the error probability $\\varepsilon$, i.e., security. For example, we can compute that $\\tau_{LC} \\approx 66/\\lambda$ when $\\beta = 0.3$ even for a modest setting of $\\varepsilon = 10^{-3}$; {\\sf Bitcoin} has $\\frac{1}{\\lambda}$ of 10 minutes, so the latency works out to  11 hours! We plot the tradeoff between latency and security of {\\sf Bitcoin} against the private attack (which is the worst-case attack   for  $\\Delta = 0$) in Figure \\ref{fig:tradeoff}; indeed the latency is terrible even for modest requirements on the security parameter $\\varepsilon$. \n\n\\begin{figure}\n\\begin{center}\n\\includegraphics[width=0.8\\textwidth]{figures/security_latency.png}\n\\end{center}\n\n\\caption{Bitcoins latencysecurity tradeoff for different $\\beta$ assuming $\\Delta = 0$. We set $\\lambda$ to be 6 blocks per hour, as in Bitcoin.}\n\\label{fig:tradeoff}\n\n\\end{figure}\n\nFor the general case $\\Delta > 0$, we have seen in Lecture 6 that the private attack is no longer the worst case attack in terms of success probability. Nevertheless, the private attack still provides a {\\em lower bound} on the error probability and a corresponding lower bound on the latency for a given error probability. Both these quantities   only get worse as $\\Delta$ increases, due to the resulting forking.  From a practical point of view, {\\em upper bounds} on the error probability (and latency) are most interesting; an upper bound on latency provides practical guidance for a user of {\\sf Bitcoin} when to consider a transaction confirmed with a desired level of confidence. A   \\href{https://arxiv.org/pdf/2011.14051.pdf}{recent work} reports such upper bounds which are fairly close to the lower bounds implied by the private attack. For example, when the adversary controls 10\\% of the total mining power and the block propagation delays are within $\\Delta = 10 {\\rm ~seconds}$, a Bitcoin block can be confirmed with less than $10^{-3}$ error probability after 5 hours 20 minutes, or with less than $10^{-10}$ error probability after 12 hours 15 minutes. Figure~\\ref{fig:tradeoff1} illustrates the security-latency tradeoff as implied by the lower and upper bounds. \n\n\\begin{figure}\n\\begin{center}\n\\includegraphics[width=0.8\\textwidth]{figures/security_latency1.png}\n\\end{center}\n\\caption{Bitcoins latencysecurity tradeoff for $\\beta = 0.1$ when $\\Delta >0$. We set $\\lambda$ to be 6 blocks per hour as in Bitcoin and $\\Delta = 10$ seconds. The lower bound on  latency is derived from the private attack, while the upper bound is borrowed from  \\href{https://arxiv.org/pdf/2011.14051.pdf}{this work}.}\n\\label{fig:tradeoff1}\n\n\\end{figure}\n\n%1) tradeoff between latency and security. exact analysis using the private attack for Delta = 0. For Delta > 0, we can use private attack again to see the tradeoff. But this is not the worst case, so need to do more work -- but there are strong upper and lower bounds which essentially show that the private attack tradeoff is also the worst-case. (new work of Dongning, et al). \n\n%\\section*{Hybrid Consensus}\n% we will not discuss in this lecture. moved to \"Beyond Bitcoin\" module where we combine BFT and longest chains anyway. \n\n\\section*{Prism: Fast Confirmation}\n\nLecture 8 introduced {\\sf Prism 1.0} with two types of blocks: {\\em transaction} blocks and {\\em proposer} blocks. These two blocks decouple the security and payload (data) aspects of the longest chain protocol. Within the security aspect (embodied by the proposer block in {\\sf Prism 1.0}) there is a further subdivision of two properties. First, the block {\\em proposes}, i.e., acts as a leader for the ``round\". Second, the block   adds confidence to the ancestor blocks along the chain to the genesis (as embodied by the   $k$-deep confirmation rule), i.e., acts as a ``voter\" to the ancestor blocks.   Each block votes for all ancestor blocks through the parent link relationships. Continuing the deconstruction principle  in {\\sf Prism 1.0}, we can further decouple the role of voting from the proposer blocks by having separate voter blocks. But how to organize the voter blocks? The full Prism protocol answers this question.\n\n\n\\begin{figure}\n\\begin{center}\n\\includegraphics[width=\\textwidth]{figures/Prism_main.pdf}\n\\end{center}\n\n\\caption{Factorizing the blocks into three types of blocks: proposer blocks, transaction blocks and voter blocks.}\n\\label{fig:prism}\n\n\\end{figure}\n\nJust as in {\\sf Prism 1.0}, the \\textit{proposer} blocktree in {\\sf Prism} anchors the blockchain.  Each proposer block contains a list of reference links to \\textit{transaction} blocks that contain transactions, as well as a single reference to a parent proposer block. Honest nodes mine proposer blocks following the longest chain rule in the proposer tree.\nWe define the \\emph{level} of a proposer block as its distance from the genesis proposer block, and the \\emph{height} of the proposer tree as the maximum level that contains any proposer blocks. To determine the ordering of proposer blocks (and thus transaction blocks and transactions), we elect one \\textit{leader} proposer block from each level. The sequence of leader blocks up to the height of the proposer tree is called the  \\textit{leader sequence}, and is determined by the \\emph{voter} chains. Note that the leader blocks do not need to follow the chain structure of the proposer blocks because otherwise deadlock may occur if conflicting blocks (i.e., two proposer blocks not on one chain) are determined as leader blocks. \n\nIn {\\sf Prism}, there are $m$ voter chains, where $m \\gg 1$ is a fixed parameter chosen by the system designer. The larger the $m$, the more parallel the voting process and hence the shorter the latency of confirmation. In general $m$ is chosen as large as network bandwidth and memory management issues are manageable. For example, $m=1000$ is chosen in the \\href{https://arxiv.org/pdf/1909.11261.pdf}{full-stack implementation}  of Prism. New voter blocks are mined on each voter chain according to the longest chain rule. A voter block votes for a proposer block by containing a reference link to that proposer block, with the requirements that: (1) a vote is valid only if the voter block is in the longest chain of its voter tree; (2) each voter chain votes for one and only one proposer block at each level; (3) each voter block votes for all the proposer levels that have not been voted by its parent. The leader block at each level is the one that has the largest number of votes among all the proposer blocks at the same level (ties can be broken by the hash of the proposer blocks). The elected leader blocks then provide a unique ordering of the transaction blocks to form the final ledger. \n\n{\\sf Prism} also uses cryptographic sortition to prevent the adversary from focusing its mining power on a specific type of blocks or on a specific voter chain. A miner first forms a ``superblock\" containing $m+2$ parts: a transaction block, a proposer block and a voter block on the $i$-th voter tree ($1\\leq i \\leq m$). We say a superblock is successfully  mined if \n\\begin{equation}\n    Hash({\\sf nonce}, {\\sf superblock}) < T_{\\rm tx} + T_{\\rm prop} + m T_{\\rm v}. \n\\label{eq:sortition}\n\\end{equation}\nFurther, every successfully mined superblock is identified as a transaction block, a proposer block or a voter block based on the hash output: \n\\begin{itemize}\n    \\item identify the superblock as a proposer block if the hash output is less than $T_{\\rm prop}$; \n    \\item identify the superblock as a transaction block if the hash output is in the range $[T_{\\rm prop}, T_{\\rm tx} + T_{\\rm prop})$;\n    \\item identify the superblock as a voter block on the $i$-th voter tree ($1\\leq i \\leq m$) if the hash output is in the range $[T_{\\rm tx} + T_{\\rm prop} + (i-1) T_{\\rm v}, T_{\\rm tx} + T_{\\rm prop} + i T_{\\rm v} )$;\n\\end{itemize}\n    Due to the random output nature of hash functions, the probability a superblock is identified as a proposer block, a transaction block or a voter block on the $i$-th voter tree ($1\\leq i \\leq m$) is proportional to $T_{\\rm prop}$, $T_{\\rm tx}$ and $T_{\\rm v}$, respectively. See Figure \\ref{fig:sortition} for an  illustration. We set the transaction target difficulty $T_{\\rm tx}$ easy, as in {\\sf Prism 1.0}; this allows for a lot of transaction blocks to be mined in parallel (up to the limits of how much the network capacity can handle). The proposer and each voter chain target difficulty ($T_{\\rm prop}$ and $T_{\\rm v}$, respectively) are set high, as in {\\sf Bitcoin} for security; this ensures that the proposer block sequence  and each voter chain grow slowly enough that forking is not an issue (i.e., the growth rate $\\lambda$ is much smaller than $\\frac{1}{\\Delta}$, the network delay).  \n\nThe {\\sf Prism} protocol is similar to other ideas we have seen in terms of applying the decoupling principle ({\\sf Prism 1.0}, {\\sf Fruitchains}, and {\\sf Bitcoin-NG} all employed this principle to different degrees). However, it is different in a special way: \n\\begin{quote}\nThe actual confirmed sequence of proposer blocks may never form a chain.\n\\end{quote}\nThis means  that the miner can no longer validate a block {\\em before} mining because the confirmed proposer blocks may not form a chain and the miner cannot know the current state of the ledger given a proposer parent block. So {\\sf Prism} decouples the process of mining blocks from validating transactions. Note that given a confirmed leader sequence of proposer blocks, the ordering of transaction blocks is uniquely determined. This gives us a total ordering of transactions, and enables us to determine the validity of each individual transaction by executing them following this ordering. For example, among transactions that try to spend the same coin, only the first is considered valid. This process is called ledger sanitization and is executed after the ledger has stabilized (i.e., confirmed). %Next, we explain why {\\sf Prism} achieves low confirmation latency. \n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width =13cm]{figures/sortition1.png}\n    \\caption{Superblock containing a transaction block, a proposer block and $m$ voter blocks is ``$(m+2)$-for-one\" mined; the resulting  cryptographic sortition identifies the type of the block as the winner of the mining process.}\n    \\label{fig:sortition}\n\\end{figure}\n\n\\subsection*{Fast confirmation rule in Prism}\n\nThe parallel chain structure of the voting scheme in {\\sf Prism} enables low confirmation latency. The high-level idea is that votes accrue only sequentially in Bitcoin, whereas in {\\sf Prism}, votes accrue in {\\em parallel}. Thus, since voting blocks are created in parallel, for a fixed amount of security, confirmation can occur in  a much shorter amount of time;   this  reduces the  latency. By how much is the latency reduced and how to arrive at a principled confirmation rule that is secure and yet affords fast latency? This is discussed next. \n\nWe look at the confirmation latency of {\\sf Prism} in a simple case, where a single honest proposer block $B_p$ at level one is mined at time $0$. %For simplicity, we assume network delay $\\Delta = 0$. \n In {\\sf Prism}, $B_p$ can be confirmed if no other proposer block at level one can receive more votes than it. But this is not operational, since the confirmation event depends on the future. One naive solution would be: we confirm $B_p$ if it receives more than $m/2$ votes from the voter blocks that are at least $k$-deep in their voter chains. If we choose $k$ as large as in Bitcoin, then this confirmation rule is safe  because all these votes are permanent in the voter chains with high probability by the safety of Bitcoin. But this requires waiting long enough for the vote to be $k$-deep in each of the chains, leading to latency even worse than that of Bitcoin.  \n \n The key point is that one does not have to wait until each of the votes stabilize (i.e., are buried $k$-deep in their respective chains, with a large value of $k$). Even if each vote is ephemeral (because $k$ is small, for instance $k=2 ~{\\rm or}~3$) the {\\em averaging} of all votes ensures that the overall vote is secure. This is due to the law of large numbers; a similar concept is {\\em boosting} in machine learning where many low precision classifiers are combined to create a high precision classifier. This phenomenon is best described in the context of a simple attack, that is analogous to Nakamoto's private attack on the {\\sf Bitcoin} protocol. \n \n% \\pramod{bring in section 4.1.1 material here. also do a plot of error prob as a function of m.}\n\n\\begin{figure}[h]\n\\begin{centering}\n\\includegraphics[width=0.8\\linewidth]{figures/example_1.pdf}\n\\caption{(a) Transaction block is referred to by an isolated honest proposer block. (b) Transaction block is referred to by a non-isolated proposer block but on the next level there is an isolated proposer block.\nNote that since $H_2$ is honest, it refers to all unconfirmed transaction blocks, i.e., \\texttt{TB}.}\n\\label{fig:example_1}\n\\end{centering}\n\\end{figure}\n\n\nConsider a situation when a transaction block \\texttt{TB} is referred to by an honest proposer block $H$ which is currently isolated at its level, i.e. no other public proposer block exists at the same level. See Figure \\ref{fig:example_1}(a). \nThis case is quite common since the mining rate of the proposer blocks is chosen such that there is little forking in the proposer tree. Block $H$ will start collecting votes, each of which is on the longest chain of its respective voter tree. Over time, each of these votes will become deeper in its voter chain. An attack by the adversary is to mine a private proposer block $A$ at the same level, and on each of the voter trees fork off and mine a private alternate chain and send its vote to the block $A$. After leader block $H$ is confirmed, the adversary continues to mine on each of the voter alternate chains to attempt to overtake the public longest chain and shift the vote from $H$ to $A$. If the adversary can thereby get more votes on $A$ than on $H$, then its attack is successful.\n\n\nThis attack can be viewed as the $m$-chain analog to Nakamoto's private attack on {\\sf Bitcoin}, where instead of having one race between the honest chain and the private chain we have $m$ such races.  In fact, Nakamoto's calculations on the success probability of an attack on a single chain can help us determine how deep we need to wait for the votes to become to confirm the proposer block $H$. At tolerable adversary power $\\beta = 0.3$, the reversal probability in a single chain is $0.45$ when a block is $2$-deep. With $m=1000$ voter chains and each vote being $2$-deep, the expected number of chains that can be reversed by the adversary is $450$. The probability that the adversary got lucky and can reverse more than half the votes, i.e. $500$, is about $10^{-3}$. Hence to achieve $\\epsilon = 10^{-3}$, we only need to wait for $1000$ votes each $2$-deep. This incurs much shorter latency than the $24$ block depth needed for {\\em each} vote to be reversed with probability $10^{-3}$. This reduction in latency is conceptually similar to averaging many unreliable  classifiers to form a strong aggregate classifier:  the more voter chains there are, the less certainty of permanence each individual vote needs to be, thereby reducing confirmation time. This gain comes without sacrificing security: each voter chain is operating slowly enough to tolerate $\\beta$ adversarial hash power. \n\n\n\n\n\\noindent {\\bf Fast confirmation rule.} How to convert the intuition of fast latency of {\\sf Prism} to a principled confirmation rule? Note that the confirmation rule would have to be secure under all possible attacks, not just the specific private attack described above. \nThe key idea is to confirm at a time $t^*$ such that if there is no competing proposer block appears at level one before $t^*$, then no other proposer block can accumulate more than $m/2$ votes anymore after $t^*$, with high probability.\nAn observation from the longest chain protocol is that a prefix of the longest chain will stabilize as the chain grows longer, i.e. as time passes (because the chain grows with time). \nTherefore, in {\\sf Prism}, since each voter chain adopts the longest chain rule, the fraction of votes that have stabilized is also monotonically increasing in time. \nBy the law of the large numbers, when $m \\rightarrow \\infty$, if at a certain time each vote has stabilized with probability $1/2$, then no other \nproposer blocks can realistically accumulate more than $m/2$ votes anymore, so that we can confirm the block. Then we can have the following time-based confirmation rule.\n\n\n\\noindent{\\bf Tentative Confirmation rule}.  We confirm $B_p$ at time $t^*$ if there is no competing proposer block, where $t^*$ is the solution of the equation $h(t) = 1/2$ and $h(t)$ is a function that calculates the fraction of stabilized votes (or equivalently the effective vote from one voter chain) at time $t$. We derive $t^*$ and a closed form expression for $h(t)$ in the appendix, depending only on the mining rate $\\lambda$ and tolerable adversary hash power fraction  $\\beta$.   For instance, when $\\beta = 0.3$, we can numerically calculate $t^* \\approx 3/\\lambda$, so the confirmation time is a small factor of the average inter-block arrival time. \n\n\nHowever, time is not observable in a proof-of-work blockchain because the timestamp may not be accurate or even be faked in an adversarial block. But time can be estimated from the growth of the voter chains. Fortunately, the large number of voter chains in {\\sf Prism} makes this estimation accurate even for short time periods because of the law of large numbers. The total mining rate of all voter chains is $m\\lambda$, so on average $m\\lambda t$ voter blocks are mined within $t$ unit of time. This conversion from time to block is accurate for large $m$, so finally we can have the following block-based confirmation rule that is observable.\n\n\\noindent{\\bf Final confirmation rule}. We confirm $B_p$ when $mt^*\\lambda$ voter blocks are mined and there is no competing proposer block. Again $t^*$ only depends on the mining rate $\\lambda$ and the tolerated adversary hash power fraction $\\beta$.  \nWhen $\\beta = 0.3$, we know that  $t^* \\approx 3/\\lambda$ and we confirm the proposer block when $3m$ voter blocks are mined. \n\n\\subsubsection*{Non-isolated Proposer Block}\n\nConsider now the case when the transaction block \\texttt{TB} is referred to by an honest proposer block $H_1$ which is not isolated at its level, i.e. $H_1$ is matched by an adversarial public proposer block $A_1$ (the competing proposer block could also be honest). This matching could persist for $L$ levels until reaching a level when there is an isolated honest proposer block. See Figure \\ref{fig:example_1}(b) for the special case of $L=1$. \nLet us separately consider the life cycle of an honest transaction vs. a double-spent one.\n\n\\noindent \\textbf{Honest transaction.}\nA naive approach for confirming \\texttt{TB} would be to wait until we can definitively confirm $H_1$ or $A_1$.\nHowever, this may be slow because of adversarial attacks that try to balance votes.\nA key insight is that for honest (non-double-spent) transactions, we do not need to know \\emph{which} of $H_1$ and $A_1$ is confirmed---only that one of them will be confirmed.\nThis weaker form of \\emph{list confirmation} works because if $A_1$ eventually gets confirmed, a later honest proposer block can still refer to \\texttt{TB}. \nTo confirm an honest transaction at level $i$, we need two events: (1) list confirmation of all levels up  to $i$; (2) an isolated honest proposer at level $i$.\nOnce we have list-confirmed a set of proposer blocks at level $i$ referring \\texttt{TB} (e.g., either $H_1$ or $A_1$ will be the leader), we know that no other block can be the leader at that level.\nHowever, list confirmation alone is not enough for honest transaction confirmation if the transaction is not present in all ledgers. \nIn that case, we also need to wait for an isolated honest proposer level, where the proposer block will include \\texttt{TB} in the ledger. \nOnce this isolated honest proposer level is confirmed \\emph{and} all the preceding levels are list-confirmed, we can be sure that \\texttt{TB} will appear in the final ledger. \nThe confirmation latency is thus the maximum of two parts:\n\n\\textit{(1) List confirmation.} We fast confirm that the adversary cannot produce a private block $A$ with more votes than the votes of public blocks $H_1$ and $A_1$. \nThe logic is similar to the case of isolated honest proposer block discussed above, viewing the situation as a race between honest nodes voting for the public blocks $H_1$ or $A_1$ and adversary voting for $A$. \nAdversarial actions (e.g., presenting $H_1$ to half the honest nodes and $A_1$ to the other half) can cause the number of votes to be evenly split between $H_1$ and $A_1$, which can slow down list confirmation, albeit not significantly.\n\n\\textit{(2) Isolated honest proposer level.}\nIn Figure \\ref{fig:example_1}(b), if we wait until level $2$, we see an isolated public proposer block $H_2$ which can be fast confirmed. \nAt this point, we know that the final leader sequence at levels $1,2$ is either $H_1,H_2$ or $A_1,H_2$, both of which contain our honest transaction since $H_2$ refers to all previous unconfirmed transaction blocks. \n\n\n\\noindent \\textbf{Double-spent transaction.}\nTo confirm double-spent transactions, we need stronger conditions than those listed above: namely, instead of list confirmation, we need \\emph{unique block confirmation}, confirming which block at a proposer level will be the ultimate leader.\nThis is achieved once list confirmation occurs \\emph{and} one of the list-confirmed blocks can be reliably declared the winner. \nIf one of the public proposer blocks $H_1$ or $A_1$ gathers many more votes than the other block, then we can fast confirm a unique leader, even for double-spent transactions.\nHowever, other adversarial attacks (such as balancing the votes on $H_1$ and $A_1$) can cause the number of votes to be evenly split between $H_1$ and $A_1$, so we cannot fast confirm a leader block.\nIn this case, we must wait until every vote on $H_1$ and $A_1$ stabilizes, in which case either $H_1$ or $A_1$ is confirmed and only one of the double-spent transactions is accepted. \nA content-dependent tie breaking rule can be used to break ties after votes are stabilized.\n\n\n\n\\subsection*{Scaling latency via Prism}  \n\nThe latency of {\\sf Prism} $\\tau_{Prism}$ under the ``normal path\" (i.e., single proposer block for a level) is \n\\begin{equation*}\n    \\tau_{\\rm Prism} = O(\\frac{1}{\\lambda}),\n\\end{equation*}\nwhich is independent of the error probability $\\varepsilon$ when we choose $m$ to be large enough, and the constant hidden in the $O(\\cdot)$ only depends on $\\beta$. \nIn comparison to Bitcoin, {\\sf Prism} achieves faster confirmation because it only needs to wait until the effective vote $h(t)$ is greater than 0.5. We can apply the law of large numbers horizontally (in space) to conclude that the majority of the voter chains have voted for a proposer block irreversibly, and hence we can confirm the block with high probability. \nWhile in Bitcoin there is only one chain, so we have to wait until $h(t)$ is $1-\\varepsilon$ to guarantee a small deconfirmation probability $\\varepsilon$, where the law of large numbers is applied vertically (in time) as we have seen in Lecture 6. The comparison between Bitcoin and {\\sf Prism} latency is in Figure \\ref{fig:prismlatency}.\nIn summary, by having many voter chains, {\\sf Prism} gets rid of the $\\log_e(\\frac{1}{\\varepsilon})$ term in Bitcoin latency, i.e., decouples latency from security and achieves fast confirmation.\n%\\pramod{can you plot $\\tau_{\\rm Prism}$ here as a function of $\\beta$? This will be related to $t^*$ but note that is in the appendix and we dont want readers to go there. Do this plot with different values of $m$ and compare with longest chain.}\n\n\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width =10cm]{figures/prism_latency.png}\n    \\caption{Comparison between Bitcoin and {\\sf Prism} latency under various values of $\\beta$. We set $\\lambda$ to be 6 blocks per hour and the error probability $\\epsilon = 10^{-3}$. This also justifies the choice of $m$ in the \\href{https://arxiv.org/abs/1909.11261}{implementation of {\\sf Prism}}.}\n    \\label{fig:prismlatency}\n\\end{figure}\n\n\n\n\\section*{References}\n\nAn analysis of the  latencysecurity tradeoff covering all possible attacks by the adversary has been conducted in \\href{https://arxiv.org/pdf/2011.14051.pdf}{this paper}  for the longest chain protocol. \n\nScaling latency of the PoW longest chain protocol has been an active research topic in the last a few years,  with limited success. Besides \\href{https://arxiv.org/pdf/1810.08092.pdf}{{\\sf Prism}}, another protocol, called \\href{https://eprint.iacr.org/2020/675.pdf}{Ledger-combiners}, also uses parallel-chains for achieving low latency. Ledger combiners run multiple instances of the longest chain protocol in parallel;  the confirmation is conducted at the transaction level instead of the block level: if a transaction appears in a large fraction of all the parallel chains, then it can be confirmed with high probability. For conflict-free transactions, confirmation can be accelerated to a constant multiple of block time with negligible error probability (similar to {\\sf Prism}'s guarantee on the single proposer block case).\n\nIn this lecture, we have seen that {\\sf Prism}'s latency does not depend on the security parameter ($\\varepsilon$), that was a dominant term in Bitcoin's latency. Achieving fast consensus among a {\\em fixed} set of parties (also known as the {\\em permissioned} setting) is a classical topic in computer science, studied under the rubric of  called Byzantine Fault Tolerant (BFT) consensus. Recent advances have solidified the decades-old research on BFT protocols; two protocols \\href{https://eprint.iacr.org/2020/088.pdf}{Streamlet} and \\href{https://dl.acm.org/doi/pdf/10.1145/3293611.3331591}{Hotstuff}  have  latency that is a small constant multiple of the worst case network delay $\\Delta$.  We will study these protocols in Module 3 of this course, where we also discuss how to merge them with the permissionless setting of the PoW longest chain protocol. \n\n\\section*{Appendix}\n\n\\subsection*{Derivation of $t^*$}\nTo derive $t^*$, we first define the following random variables and events: \n\\begin{itemize}\n    \\item For $1 \\leq i \\leq m$, let $H_i(t)$ ($A_i(t)$) be the number of honest (adversarial) blocks mined on the $i$-th voter tree before time $t$. \n    \\item Let $V_i(t)$ be the event that the $i$-th voter chain has voted for $B_p$ by time $t$ and remains voting for $B_p$ after time $t$.\n    \\item Let $G_i(t)$ be the event that $H_i(\\tau) > A_i(\\tau)$ for any $\\tau \\geq t$. \n\\end{itemize}\n\nBecause of the cryptographic sortition used in {\\sf Prism} mining, $H_i(t)$ and $A_i(t)$ ($1 \\leq i \\leq m$) are independent Poisson random variables, $H_i(t) \\sim {\\sf Poiss}(\\beta\\lambda t)$ and $A_i(t) \\sim {\\sf Poiss}((1-\\beta)\\lambda t)$, where $\\beta$ is the fraction of adversarial mining power and $\\lambda$ is the mining rate on an individual voter chain. Let $\\mathcal{V}(t) = \\sum_{i=1}^m \\indicator_{V_i(t)}$, where $\\indicator$ is the indicator function, i.e., $\\indicator_{V_i(t)} = 1$ if $V_i(t)$ occurs, otherwise 0. Then we want $\\mathcal{V}(t^*) \\geq m/2$. However, the event $V_i(t)$ depends not only on honest and adversarial mining process, but also on the adversarial strategy that is aiming to disrupt the voter chain. So we define the good event $G_i(t)$, which is independent of the adversarial strategy. Next, we prove the following important claim:\n$$G_i(t) \\subseteq V_i(t).$$\n\nTo prove this claim, the logic is very similar to our analysis that the Nakamoto private attack is the worst attack. Since $H_i(t) > A_i(t)$, we know there is at least one honest block on the $i$-th voter chain at time $t$. Hence, by the voting rule in {\\sf Prism}, either this honest voter block or one of its ancestors should vote for $B_p$. And further because we have $H_i(\\tau) > A_i(\\tau)$ for all $\\tau > t$, the voter block that votes for $B_p$ will never be displaced from the $i$-th voter chain after time $t$, i.e., the event $V_i$ occurs. Now when have\n\\begin{equation}\n\\label{eqn:bound}\n    \\mathcal{V}(t) = \\sum_{i=1}^m \\indicator_{V_i(t)} \\geq \\sum_{i=1}^m \\indicator_{G_i(t)},\n\\end{equation}\na lower bound on $\\mathcal{V}(t)$, that is independent of the adversarial strategy. Therefore, we can confirm $B_p$ if $\\sum_{i=1}^m \\indicator_{G_i(t)} \\geq m/2$. However, now the problem is that each event $G_i(t)$ is not observable at time $t$ because the adversarial blocks may be private and also the event depends on future. \n\nThis problem can be solved by setting $m$ to be large. Note that for $1 \\leq i \\leq m$, the events $G_i$'s are independent and identical. Hence $\\indicator_{G_i}$'s are i.i.d. random variables. By the law of large numbers\n\\begin{equation}\n\\label{eqn:lln}\n    \\frac{1}{m} \\sum_{i=1}^m \\indicator_{G_i(t)} \\rightarrow \\mathbb{E}[ \\indicator_{G_1(t)}] = \\mathbb{P}(G_1(t)),\n\\end{equation}\nas $m \\rightarrow \\infty$.\n\nLet $h(t) \\triangleq \\mathbb{P}(G_1(t))$. If we set $t^*$ to be the solution of the equation $h(t) = 0.5$, then combing Eqn. (\\ref{eqn:bound}) and (\\ref{eqn:lln}), we get what we want: $\\mathcal{V}(t^*) \\geq m/2$.  Therefore, we can think of $h(t)$ as a measure of the effective vote from one voter chain. When $B_p$ receives a vote, there is some probability that the vote will be reversed and $h(t)$ takes this into consideration.\n\nNow the only remaining question is how to calculate the effective vote $h(t)$. The numbers of adversarial blocks and honest blocks mined in the time interval $(0, t)$ follow Poisson distributions with mean $\\beta \\lambda t$ and $(1-\\beta)\\lambda t$, respectively. If the number of adversarial blocks is no less than the number of honest blocks at time $\\tau+t$, then $G_1(t) = 0$; otherwise, from simple random walk theory, the probability that the number of adversarial blocks will ever catch up the honest from $z$ blocks behind is given by $(\\frac{\\beta}{1-\\beta})^z$ when $\\beta < 1/2$. (Exactly the same fact has been used by Satoshi in \\href{https://bitcoin.org/bitcoin.pdf}{Bitcoin white paper}.)  Thus, there is a closed form expression for $h(t)$: \n\\begin{equation}\n    h(t) =  \\sum_{k = 0}^{\\infty} e^{-(1-\\beta)\\lambda t} \\frac{((1-\\beta)\\lambda t)^k}{k!} \\cdot \\sum_{n=0}^{k} e^{-\\beta\\lambda t} \\frac{(\\beta\\lambda t)^n}{n!} \\big (1-(\\frac{\\beta}{1-\\beta})^{k-n} \\big).\n\\end{equation}\nwhich is simply a function of $\\lambda$ and $\\beta$; see Figure~\\ref{fig:vote}. \n\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width =10cm]{figures/effective_vote.png}\n    \\caption{Effective vote $h(t)$ over time.}\n    \\label{fig:vote}\n\\end{figure}\n\n\n\\end{document}\n",
    "lecture_13.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\usepackage{markdown}\n\\usepackage{caption}\n\\usepackage{subcaption}\n\\usepackage{amsthm}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\newcommand{\\indicator}{{\\bf 1}}\n\\newcommand{\\pramod}[1]{{\\color{red}\n\\footnotesize[Pramod: #1] }}\n\\newcommand{\\xw}[1]{{\\color{green}\n\\footnotesize[Xuechao: #1] }}\n%\\theoremstyle{definition}\n\\newtheorem{definition}{Definition}\n\\newtheorem{theorem}{Theorem}\n\\newtheorem{lemma}{Lemma}\n\\newtheorem{remark}{Remark}\n\n\\newcommand{\\singlechain}{\\Pi_{\\texttt{single}}}\n\\newcommand{\\multichain}{\\Pi_{\\texttt{multi}}}\n\\newcommand{\\mchain}{\\texttt{chain}}\n\\newcommand{\\chain}{\\texttt{SemChain}}\n\\newcommand{\\finalization}{\\texttt{Finalization}}\n\\newcommand{\\lists}{\\mathcal{L}}\n\\newcommand{\\depth}{\\texttt{index}}\n\n%\\let\\proof\\relax\n%\\let\\endproof\\relax \n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 13}\n\\cfoot{\\thepage}\n\n\\title{Lecture 13: Transaction Ordering and Fairness}\n\\author{Principles of Blockchains, University of Illinois,  \\\\ Professor:  Pramod Viswanath \\\\ Scribe:  Soubhik Deb}\n\\date{March 11, 2021}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nConsensus in blockchains this far refers to an ordered sequence of blocks. We have not paid attention to the  ordering of the transactions within a block, which is left to the miner who assembles the block. The ordering is important because the fees associated with the transactions and the value of the native tokens at different points in the ledger  can depend on the ordering. The importance of fair ordering is  underscored by massive {\\em frontrunning} attacks on the popular blockchain {\\sf Ethereum}. A fair ordering of transactions would mean that if one transaction was transmitted before another one, then this ordering would be maintained in the final ledger.  In this lecture, we demonstrate a clean adaptation of the longest chain protocol to incorporate  fair transaction ordering. We  discuss how to quantify the level of fairness of the ordering (different nodes can see different ordering due to network delays, be they natural or through adversarial action) and show that the adaptation only adds a modest extra latency to the $k$-deep confirmation rule while guaranteeing high confidence of fair ordering.   \n\\end{abstract}\n\n\n\n\\section*{Introduction}\nIn centralized financial (CeFi) markets, the ordering in which market orders are executed in the exchanges plays a crucial role in making a profit or loss of millions or potentially, billions of dollars. However, such high-stakes also incentivizes adversarial actors to engage in manipulating the execution ordering of these market orders. Such practices are termed as \\textbf{frontrunning}. See Fig.~\\ref{fig:frontrunning} for an illustration of a frontrunning attack.\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.75\\textwidth]{figures/frontrunning.pdf}\n    \\caption{Suppose that the share price for some arbitrary company is increasing. After observing the buy order of the honest trader, the adversary creates its own buy order and gets it somehow executed before the former in the exchange. An adversarial trader could do so via bribing, self-dealing, being privy to inside information, etc. Now, the adversarial trader can sell these shares to the honest trader at a profit.}\n    \\label{fig:frontrunning}\n\\end{figure}\nFrontrunning is strictly monitored and prohibited in the centralized stock exchanges and past incidents of frontrunning have resulted in fines worth millions of dollars by SEC and FBI. \n\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.95\\textwidth]{figures/frontrunning_real_world_example.pdf}\n    \\caption{A bot sitting in the {\\sf Ethereum} executed couple of token swaps atomically using a smart contract. The smart contract takes advantage of the arbitrage in the exchange rate between Ether (native token in {\\sf Ethereum}) and NFTX token (an ERC20 token) in two different DEXes, Uniswap and Sushiswap. Seeing the increasing demand for NFTX in Sushiswap, the smart contract employs frontrunning to swap Ether for NFTX in Uniswap and then sells these NFTX tokens in Sushiswap at a profit. In terms of the exchange rate between Ether and USD at the above timestamp, the bot executing this frontrunning made a profit of greater than \\$900 in a single atomic pair of transactions.}\n    \\label{fig:frontrunning-real-world}\n\\end{figure}\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.95\\textwidth]{figures/transaction_fees.pdf}\n    \\caption{Ever since DeFi came into the mainstream in the summer of $2020$, there has been an exponential increase in transaction fees in {\\sf Ethereum}, primarily, due to frontrunning.}\n    \\label{fig:transaction-fees}\n\\end{figure}\n% are included\n\nWith the rising prominence of the decentralized finance (DeFi) industry, similar order manipulation via frontrunning has become very lucrative. Unlike in CeFi, this phenomenon has been exacerbated in DeFi due to the lack of any trusted authority that can regulate financial malpractices in the decentralized setting. As the order in which transactions are included in a block in the blockchain depends on the discretion of the miner of that block, the miners are generally incentivized to arrange those transactions earlier that earn them the most transaction fees. So, a client can pay a large transaction fee to have a frontrunning transaction ordered earlier in the blockchain. On the other hand, the clients that are victims of such frontrunning attacks have no way to know, verify and get redressal from such a nefarious ordering event. This has given rise to  rampant order manipulation in DeFi as indicated by  bots embedded inside public blockchains (e.g., {\\sf Ethereum}) and generating frontrunning transactions. According to one estimate, these frontrunning bots in {\\sf Ethereum} have proved to be very successful and have extracted a profit of more than \\$300 million since January 2020. Fig.~\\ref{fig:frontrunning-real-world} illustrates a real-world example of frontrunning attack in DeFi in which a frontrunning bot takes advantage of the arbitrage in the exchange rates between different decentralized exchanges (DEX) to make a substantial profit. The immediate externality from frontrunning attacks in DeFi is in the dramatic increase in the transaction fees (known as ``gas\"), as evident from Fig.~\\ref{fig:transaction-fees} for {\\sf Ethereum}. The increase in transaction fee occurs because there can be multiple competing bots trying to frontrun the {\\em same} transaction: a frontrunning bot  iteratively bids up its transaction fees in order for its frontrunning transaction to get ordered in a block by the miner ahead of the transactions  of any of its competing bots or the original transaction which is being targeted for frontrunning. Additionally, there can be many failed transactions (because they ran out of gas) and reverted transactions from frontrunning which can occupy valuable space in the blockchain. Thus, these frontrunning attacks have resulted in negative externalities in {\\sf Ethereum}:  network congestion in the peer-to-peer network and reduced block space usage in the chain.   The frontrunning attacks have also contributed to the miner reaping as much profit (known as ``miner-extractable value\") in the form of transaction fees as possible from ordering-for-profit. \n \n\nOne possible solution is to impose a fixed  fee that is agnostic to the actual value of that transaction (this is the essence of EIP-1559, a recent improvement proposal for {\\sf Ethereum}). However, a   frontrunning bot can simply collude with a miner in an off-chain market and get its frontrunning transaction ordered earlier. So the challenge remains: can one design a fair-ordering consensus protocol  that is provably secure  against manipulation of transaction ordering? Of specific interest is a simple transaction ordering strategy  that can be readily incorporated alongside  the longest chain protocol. Such is the goal of this lecture. \n\n \n%  in a block depends on the discretion of the proposer of the block. For instance, a node in the blockchain typically orders the transactions based on the transaction fees. However, the miner can manipulate the order of transactions within the block according to another heuristic. This incentivizes the miners to engage in \\textbf{frontrunning} whereby they can suitably order the transactions that makes them highest profit. See Fig.~\\ref{fig:frontrunning} for an illustration.\n\n\n\n\n\n% Consider the following example of   {\\bf front-running} bots in  {\\sf Ethereum}: \n% \\begin{quote}\n%     if someone is about to buy a large amount of ETH (short form of ether, the native token in {\\sf Ethereum}) on a cryptocurrency exchange, to such an extent that it would drive the price higher, one way to cash in would be to buy ETH right before the large purchase goes through and then sell immediately after. This entails the front-running bot to place higher gas price on its transaction of buying ETH. By placing a  higher gas price, even if the transaction corresponding to the large purchase is received by most nodes earlier than the front-running transaction placed by the bots, the miner has an incentive in having front-running transaction ordered earlier.\n% \\end{quote}\n%  Nodes have no way to verify whether such a nefarious ordering event occurred. Also, without careful design, a heuristic used by a node for ordering transactions in its block can be susceptible to ordering manipulation by the clients. \n% According to \\href{https://explore.flashbots.net/}{one estimate}, these front-running bots in {\\sf Ethereum} have proved to be very successful and have extracted a profit of more than \\$300 million since Jan 2020. Without any regulatory oversight in the permissionless blockchain, such manipulation of transaction  ordering  can lead to market instability and unfairness. Therefore, the question is can one design a fair-ordering consensus protocol  that is provably secure  against manipulation of transaction ordering? Of specific interest is a simple transaction ordering strategy  that can be readily incorporated along the longest chain protocol. Such is the goal of this lecture. \n\n\n%\\subsubsection*{Brief Recap}\n%Let $\\Delta$ secs be the network delay. We assume that time is discretized into rounds of $\\Delta$ seconds each and transactions that arrive in the same round receive the same timestamp. Let $f$ be the per round mining rate and $\\beta$ be the fraction of the hashing power that the adversary can control without the compromising the system security, assuming rest of the nodes follow the protocol. $\\kappa$ denotes the security parameter. The standard properties of PoW  blockchain are as follows. (1) $T$-common-prefix implies that the chains of two honest nodes differ by at most the last $T$ blocks; This allows nodes to confirm their local chain except for the last $T$ blocks. (2) $(T, \\mu)$-chain-quality implies that for any $T$ consecutive blocks, at least $\\mu$ fraction are honestly mined; \n\n%\\pramod{(1) At this point it is important to discuss some intuition on how to do transaction ordering, i.e., blocks need to ``vote\" on the transaction ordering. \n\n%(2) Then set up the basic protocol where blocks are colored and within a color order the same transactions. \n\n%(3) Now do an example of transactions ordered in time, different for different nodes. This is like how Sreeram did in his lecture in the class. \n\n%(4) Then use that example to show how the tx get ordered in different blocks in the chain. I think the best way to explain the protocol is through an example. Use the example to explain all the corner cases (batching, etc). \n\n%(5) Finally ask how to evaluate how good the ordering is and what guarantees one can make. This is the time to discuss various possible ordering metrics and which one is good (batch-order fairness). \n\n%(6)Then use this metric to state the main theorem, in words: ordering confidence is broken with prob exponentially decaying in m, where m is the epoch size. Brief hint on why some metrics dont work is okay -- Condorcet paradox is  way too tangential to this lecture. }\n\n\\section*{Fair Ordering Protocol}\n\n\n\\begin{figure}\n    \\centering\n     \\begin{subfigure}[b]{0.25\\textwidth}\n         \\centering\n         \\includegraphics[width=\\textwidth]{figures/voting_1.pdf}\n         \\caption{Voting in longest chain protocol.}\n         \\label{fig:voting-1}\n     \\end{subfigure}\n     \\hfill\n     \\begin{subfigure}[b]{0.25\\textwidth}\n         \\centering\n         \\includegraphics[width=\\textwidth]{figures/voting_2.pdf}\n         \\caption{$k-$deep confirmation.}\n         \\label{fig:voting-2}\n     \\end{subfigure}\n     \\hfill\n     \\begin{subfigure}[b]{0.25\\textwidth}\n         \\centering\n         \\includegraphics[width=\\textwidth]{figures/voting_3.pdf}\n         \\caption{Proposal by consensus.}\n         \\label{fig:voting-3}\n     \\end{subfigure}\n        \\caption{Pictorial illustration of the key idea in how to incorporate a simple transaction ordering strategy in longest chain protocol.}\n        \\label{fig:transition}\n\\end{figure}\n\n\n\n% \\begin{figure}\n%     \\centering\n%     \\includegraphics[width=0.8\\textwidth]{figures/basic_protocol.pdf}\n%     \\caption{Key idea demonstrating how blocks can be used as an intermediary for reconciling the preferences of the ordering of the transactions among different nodes. In this example, the same set of transactions $\\{Tx_1, Tx_2, Tx_3, Tx_4\\}$ is contained in each block in the epoch of $m=5$ blocks, where $m$ is a system parameter.  As evident from the vote count, under majority-voting rule, the ordering in the fair-ordered ledger will be: $Tx_1 \\rightarrow Tx_2 \\rightarrow  Tx_3 \\rightarrow Tx_4$.}\n%     \\label{fig:basic-protocol}\n% \\end{figure}\n\n\n\nIn the longest chain protocol, each node has its own preference on how the transactions should be ordered. The obvious question is how to reconcile all of these individual preferences  to get one consistent ordering of transactions across all the honest nodes (we will call it fair-ordered ledger) from the fair-ordering protocol? Recall that as there are Byzantine adversaries in the system who can report fake ordering of transactions to the fair-ordering protocol, adequate security guardrails have to be present while reconciling views from different nodes so that Byzantine adversaries do not manipulate the ordering. Furthermore,  the nodes participating in the longest chain protocol are pseudonymous (no fixed identity) and the participation level is varying. \n\n\\noindent {\\bf Key idea}. It is clear that the direct collection of preferences on the ordering of transactions from each node for reconciling all these preferences is not practical --  the associated communication and storage complexities would be horrendous. However, the blocks in the longest chain can serve as  natural intermediaries to sample from, and reconcile,  the diverse ordering preferences. To be precise, when a block $B$ is mined by an honest miner, the miner orders the transactions inside the block according to its own preferences of the ordering of those transactions. Now, when another miner extends the chain from $B$ we have seen that this miner action can be viewed as   casting a ``vote\" of confirmation of the ordering of transactions proposed in block $B$; see Fig.~\\ref{fig:voting-1}. When there are $k$ votes, i.e., $B$ is buried $k$-deep in the longest chain, we can confirm the proposed ordering of transactions; see  Fig.~\\ref{fig:voting-2}.  Unfortunately, all the descendant blocks of $B$ are voting on the same specific ordering of the transactions in block $B$, authored by the proposer of block $B$. \n\nThe key idea to get around this unilateral proposition of ordering of transactions is the following:  have multiple descendant blocks (say, a sequence of $m$ blocks) come together and propose an ordering of transactions by consensus; see Fig.~\\ref{fig:voting-3}. With $m$ sufficiently large, using chain-quality property of longest chain protocol (see Lecture 7), other nodes can be confident that the majority of the blocks in this sequence of $m$ blocks have been mined by honest miners with high probability. Now, the ordering between any pair of transactions $Tx_1$ and $Tx_2$ in the fair-ordered ledger in any honest node is inferred based on whether ``$Tx_1$ is ordered before $Tx_2$\" or ``$Tx_2$ is ordered before $Tx_1$\" in the majority of the $m$ blocks. The ordering of transactions obtained by consensus among the epoch of $m$ blocks is confirmed after all these $m$ blocks are $k-$deep, that is, $k$ votes have been cast for this ordering. For notational purpose, if $Tx_1$ is ordered before $Tx_2$, then it is represented by $Tx_1 \\rightarrow Tx_2$.\n\n\n\n\n\n% Extending this idea, for any pair of transactions, if a large number of blocks contains an ordering between those two transactions, then the ordering which is preferred (``voted\") in majority of the blocks can be considered to be the ordering between those two transactions in the fair-ordered ledger. For any pair of transaction $Tx$ and $Tx'$ included in a ordering, let $Tx \\rightarrow Tx'$ represent that $Tx$ is ordered before $Tx'$ in that ordering. Referring to Fig.~\\ref{fig:basic-protocol}, the same set of transactions $\\{Tx_1, Tx_2, Tx_3, Tx_4\\}$ are ordered within each block in an epoch of $m$ blocks (which is represented by the same color). In each of the blocks in the next epoch, a different set of transactions will ordered (represented by different color). By employing majority-voting rule among these $m$ blocks in an epoch, the ordering between any two transactions that is preferred by majority among these $m$ blocks is determined as the ordering between those two transactions in the fair-ordered ledger.\n\n% \\begin{figure}\n%     \\centering\n%      \\begin{subfigure}[b]{0.75\\textwidth}\n%          \\centering\n%          \\includegraphics[width=\\textwidth]{figures/transaction_ordering.pdf}\n%          \\caption{For illustration purpose, consider the preferred transaction ordering in five honest nodes. Observe that these nodes, being honest, have ordered the transactions according to the timestamps in which they received these transactions locally.}\n%      \\label{fig:transaction-ordering}\n%      \\end{subfigure}\n%      \\hfill\n%      \\begin{subfigure}[b]{0.75\\textwidth}\n%          \\centering\n%          \\includegraphics[width=\\textwidth]{figures/final_transaction_ordering.pdf}\n%          \\caption{Ordering the transactions in the fair-ordered ledger. Due to the circular ordering of $Tx_2 \\rightarrow Tx_3 \\rightarrow Tx_4 \\rightarrow Tx_5 \\rightarrow Tx_6 \\rightarrow Tx_2$, these transactions are ordered together in a batch in the fair-ordered ledger.}\n%          \\label{fig:final-transaction-ordering}\n%      \\end{subfigure}\n%         \\caption{Pictorial representation of the key idea.}\n%         \\label{fig:key-idea}\n% \\end{figure}\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.95\\textwidth]{figures/transaction_ordering.pdf}\n    \\caption{Consider a set of transactions $\\{Tx_1, Tx_2, Tx_3, Tx_4, Tx_5, Tx_6, Tx_7\\}$. Observe that the same set of transactions are received at different nodes in different orders and at different times. For the sake of convenience, we have illustrated the order and time in which this set of transactions are received for only five honest nodes and one adversarial node. Let the epoch required for reaching a consensus on proposing an ordering of transactions be of size $m=6$. In the blocks mined by the honest nodes $1,2,3,4$ and $5$, the transactions are arranged in the order that they received those transactions locally. On the other hand, an adversarial node can disregard the order in which the transactions are received locally and arrange the transactions in the block it mined in any arbitrary order that suits its needs, like, arranging transactions in the order of decreasing transaction fees.}\n    \\label{fig:transaction-ordering}\n\\end{figure}\nAs mentioned earlier, each node could have its own preference on how to order a set of transactions. The honest nodes deduce their preference of the ordering among these transactions from the order in which they received those transactions locally from the peer-to-peer (p2p) network. Owing to network delay or  adversarial behavior in the network, different nodes might receive the same set of transactions from the p2p network in different orders and at different times; see Fig.~\\ref{fig:transaction-ordering}. These differences get reflected in the order in which the transactions are arranged in each of the $m$ blocks in the epoch that are used for reaching consensus on their proposed ordering. Furthermore, a Byzantine adversary can arrange the transactions in arbitrary order in the block it mines so as to influence the final ordering obtained from consensus. However, owing to chain-quality property of the longest chain protocol, this ability of the adversary to do order-manipulation can be made negligible.\n\n\n\n% Under the aforementioned idea of obtaining the ordering of transactions via consensus among $m$ blocks,  that are mined by these nodes. Referring to Fig.~\\ref{fig:final-transaction-ordering}, for epoch of size $m=5$, assume that the nodes $1,2,3,4$ and $5$ illustrated in Fig~\\ref{fig:transaction-ordering} mine the blocks in the epoch that contain ordering among the transactions in the set $\\{Tx_1, Tx_2, Tx_3, Tx_4, Tx_5, Tx_6, Tx_7\\}$.\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.75\\textwidth]{figures/final_transaction_ordering.pdf}\n    \\caption{Pictorial representation of obtaining a fair-ordered ledger from the blockchain.}\n    \\label{fig:final-transaction-ordering}\n\\end{figure}\n\nAfter all the $m$ blocks in the epoch are $k-$deep, majority rule can be employed in order to reach consensus on the ordering on the transactions among the $m$ blocks. Observe that, in Fig.~\\ref{fig:transaction-ordering}, $Tx_1$ is preferred before other transactions in $5$ out of $6$ blocks in the epoch. So, in the fair-ordered ledger, $Tx_1$ will be ordered before other transactions. As for other transactions, $Tx_2 \\rightarrow Tx_3$, $Tx_3\\rightarrow Tx_4$, $Tx_4 \\rightarrow Tx_5$, $Tx_5 \\rightarrow Tx_6$ and $Tx_6 \\rightarrow Tx_2$ in majority of the blocks. However, this results in a paradoxical circular ordering. To circumvent this, one idea is to order all these transactions in a paradoxical ordering together in one batch in the fair-ordered ledger as illustrated in Fig.~\\ref{fig:final-transaction-ordering}. Continuing ordering in this epoch-by-epoch manner using majority-voting rule and batching, a consistent fair-ordered ledger is obtained at each honest node in the system. \n\n\n\n\n\n\\noindent {\\bf Pipelining}. In the fair-ordering protocol presented above, all the blocks within an epoch order the {\\em same set} of transactions. This  reduces the transaction throughput by a factor of $m$, the epoch size. What is required is that each transaction should be ordered in a ``streaming\" fashion. This can be accomplished by mandating that when a transaction is ordered in a block for the first time, this transaction must be included in the ordering of the transactions of the next $m-1$ descendent blocks. Thus, each transaction has its own epoch of $m$ blocks where it is included in the ordering; see Fig.~\\ref{fig:streaming}.\n\nHow to order the transactions in the fair-ordered ledger whose epochs are overlapping?  For example, in Fig.~\\ref{fig:streaming}, notice that the epoch for transactions $Tx_1, Tx_2, Tx_3, Tx_4$ and the epochs for transactions $Tx_5, Tx_6$ are not the same but overlapping. We address this by requiring the protocol to construct $m$ {\\em semantic chains}. Each of these semantic chains is constructed by appending the transaction orderings from the blocks with same color. For example, semantic chain $\\texttt{SemChain}_1$ (represented by orange color) is constructed in a streaming fashion by appending the transaction orderings in the orange-colored blocks. Now, as earlier, majority rule is employed in order to reach consensus on the ordering on the transactions among the $m$ semantic chains. \n\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=\\textwidth]{figures/streaming.pdf}\n    \\caption{Transforming the fair-ordering protocol into a streaming protocol. In the longest chain, all blocks whose depth from the genesis modulo $m$ are the same are assigned the same color. Each of the $m$ semantic chains is constructed by appending the transaction ordering from the blocks with the same color. Observe that each transaction appears only once in each semantic chain. Majority rule is then employed to achieve a consensus on the ordering of the transactions in the fair-ordered ledger.}\n    \\label{fig:streaming}\n\\end{figure}\n\n\n\\section*{Fair Ordering Guarantees}\nThe fair-ordering protocol described above outputs a globally-consistent ordering of transactions but how fair is this ordering and how to evaluate that fairness? What guarantees does this fair-ordered protocol make against any possible order manipulation by a Byzantine adversary? \nThe ordering is fair as long as a majority of the $m$ block proposers are honest; this is simply because the overall ordering is based on the majority of the individual $m$ orderings. The fraction of honest miner blocks in the longest chain is known as {\\em chain quality} $CQ$; see Equation~3 in Lecture~7. Now with PoW mining rate set slow enough, $CQ > \\frac{1}{2}$ when $\\beta < \\frac{1}{3}$.  The chain quality condition gets more accurate as $m$ increases, with the  fair-ordering protocol guarantees batch-order fairness for $\\beta < \\frac{1}{3}$ with probability approaching $1$.\n\nWe have proposed batch order fairness as the metric to state the ordering guarantees. A detailed discussion about other possible metrics is in the appendix. \n\n\n\\noindent {\\bf Increasing the adversarial threshold}. The {\\sf Fruitchains} protocol was proposed in Lecture~7 to improve the chain quality to its optimal level;  a natural question is how to adapt the fair-ordering protocol here to the {\\sf Fruitchains} setting. We do this by not having blocks of $m$ different colors composing an epoch; instead now fruits of $m$ different colors would compose an epoch (see Fig.~\\ref{fig:fruitchain}).  Now, each of the $m$ semantic chains would be constructed by appending the ordering of transactions contained in fruits of same color.\n%Recall that with high probability, chain quality in Fruitchain is approximately given by $1-(1+\\epsilon)\\beta$ for some $\\epsilon > 0$. Then, for $\\beta < \\frac{1}{2}$, chain quality of $\\frac{1}{2}$ is achieved which implies that batch-order fairness is guaranteed. A similar construction can be done for Prism 1.0 where fruits will be instead replaced by transaction blocks \\cite{bagaria2019prism}.\n\n\n\\noindent {\\bf Reducing confirmation latency}. In Lecture~9 we have studied the {\\sf Prism} protocol to incorporate multiple voting chains to significantly drop the latency of confirmation, which can be used in conjunction with the  fair-ordering protocol;  see Fig.~\\ref{fig:prismify}.  %Using fast confirmation policy in Prism, we can reduce the latency in confirming the blocks and consequently, reduce the time taken for outputting the fair-ordered ledger. Another technique to reduce confirmation latency for achieving ordering in the fair-ordered ledger is to use multiple parallel longest chains. See Fig.~\\ref{fig:multi} for an illustration. Now, each of the longest chain can be interpreted as a semantic chain in itself. An additional feature of this modification is that it provides a methodology to combine multiple independent chains in a fair way.\n\n\n\n\n\n\\begin{figure}\n    \\centering\n     \\begin{subfigure}[b]{0.85\\textwidth}\n         \\centering\n         \\includegraphics[width=\\textwidth]{figures/fruitchain.pdf}\n         \\caption{Each of the $m$ semantic chains will be constructed by appending the transaction ordering from the fruits with the same color.}\n         \\label{fig:fruitchain}\n     \\end{subfigure}\n     \\hfill\n     \\begin{subfigure}[b]{0.85\\textwidth}\n         \\centering\n         \\includegraphics[width=\\textwidth]{figures/prismify.pdf}\n         \\caption{Multiple voter chains are used to reduce the latency for confirmation of blocks.}\n         \\label{fig:prismify}\n     \\end{subfigure}\n    %  \\hfill\n    %  \\begin{subfigure}[b]{0.9\\textwidth}\n    %      \\centering\n    %      \\includegraphics[width=\\textwidth]{figures/multi.pdf}\n    %      \\caption{Parallel longest chains are used to reduce the latency for confirmation of blocks. Now, each of the $m$ semantic chains is a longest chain. This modification also provide a methodology to combine multiple independent chains in a fair way.}\n    %      \\label{fig:multi}\n    %  \\end{subfigure}\n     \\caption{Improvements on the fair-ordering protocol.}\n\\end{figure}\n\n\n\n\\section*{Zero-Block Confirmation}\nZero-block confirmation has been a topic of interest from the early days of Bitcoin, and touted as an important step towards the practicality of Bitcoin for day-to-day purchases. With zero-block confirmation property, {\\em a node can confirm a transaction without even seeing a single mined block that contains the transaction}. To motivate the gravity of its importance, consider the following payment scenario: Alice wishes to buy a coffee from Carol's Coffee, using Bitcoin, which uses an underlying Nakamoto-style PoW blockchain. Alice pays 0.00001 Bitcoin for her coffee. However, for Alice's transaction to be confirmed by the network, it could take several PoW blocks to make sure the transaction is buried sufficiently deep in the chain. This could be in the order of hours, which makes Bitcoin based payment systems untenable for practical transactions. Now, it is possible that Carol's Coffee can immediately accept Alice's transaction and Alice can get her coffee quickly. But in the longest chain protocols like Bitcoin, ordering of transactions within a block is unilaterally decided by the miner of the block. So, Alice can soon after send a double spending transaction and an adversarial miner can order this double spending transaction from Alice before the transaction made by Alice to Carol's Coffee.\n\n\n\nAs described in previous sections, the fair-ordering protocol replaces this unilateral decision-making on the ordering of transactions with a consensus-based proposal on the ordering of transactions. As a consequence, the fair-ordering protocol guarantees the powerful zero-block confirmation property. \n\n\n\n\n\n\n\\section*{References}\n\\href{https://arxiv.org/abs/1904.05234}{Flash Boys 2.0} was the first major work which brought attention to the phenomenon of frontrunning that is prevalent in DeFi. This work documented and quantified the widespread and rising deployment of arbitrage bots in blockchain systems, specifically in decentralized exchanges (DEXes). These two articles titled as  \\hyperlink{https://medium.com/@danrobinson/ethereum-is-a-dark-forest-ecc5f0505dff}{``Ethereum is a dark forest\"} and \\hyperlink{https://samczsun.com/escaping-the-dark-forest/}{``Escaping the dark forest\"} present interesting real-world case studies on the severity of frontrunning in {\\sf Ethereum}. The ubiquity of frontrunning bots necessitated the requirement for a new consensus property called {\\em fair-ordering} for distributed systems. \\hyperlink{https://eprint.iacr.org/2020/269.pdf}{KZGJ} and  \\hyperlink{https://www.usenix.org/conference/osdi20/presentation/zhang-yunhao}{ZSCZA} formalized the definition of fair-ordering in the context of Byzantine consensus and constructed protocols to achieve them.  \\hyperlink{https://eprint.iacr.org/2021/139.pdf}{KDK} introduced the first consensus protocol that achieves fair-ordering in permissionless setting.\n\n\n\n\n%\\bibliographystyle{unsrt}\n%\\bibliography{references}\n\n\n\\appendix\n\\section*{Possible Definitions for a Fair Ordering of Transactions}\n \nAn honest node in the blockchain system derives fair-ordered ledger from the longest chain. In order to mitigate manipulation of the order of these transactions, first we need to state a suitable definition for a fair transaction ordering that the ledger must satisfy. We briefly explain multiple candidate definitions that would illustrate the nuances of defining fair transaction ordering. \n\\begin{itemize}\n    \\item \\textbf{Send-order-fairness}. A strawman approach for ordering transactions would be based on the timestamps \\textbf{when} the transactions were broadcast by the clients in the peer-to-peer network.  For instance, if a transaction $Tx$ was sent by a client before another transaction $Tx'$ (possibly by another client), then $Tx$ should appear before $Tx'$ in the fair-ordered ledger of all honest nodes. However, this approach has a big problem: there needs to be a trusted way to timestamp a transaction at the client side. This would require some third-party trusted execution environments, e.g., Intel SGX which doesn't align with the vision of permissionless setting.  \n    \\item \\textbf{\\href{https://arxiv.org/abs/2007.08303}{Time relative fairness} or \\href{https://www.usenix.org/conference/osdi20/presentation/zhang-yunhao}{ordering linearizability}}.  This definition requires that if all honest nodes receive a transaction $Tx$ before any honest node receives $Tx'$, then $Tx$ will be ordered before $Tx'$ in the fair-ordered ledger of all honest nodes. In other words, if the \\textbf{latest} receive time for $Tx$ at any honest node is before the \\textbf{earliest} receive time for $Tx'$ at any honest node, then $Tx$ should be ordered earlier. See Fig.~\\ref{fig:linearizability} for an illustration. However, this definition is not sufficient to mitigate the aforementioned frontrunning attacks as it enforces no guarantees on transactions whose receive times are globally interleaved. To be more precise, an adversarial transaction that attempts to front-run an honest user transaction, is most likely to end up getting interleaved with the user transaction in its receive times at different nodes.  Consequently, for most practical frontrunning scenarios, this definition would be vacuous and not particularly useful.\n    \\item \\textbf{\\href{https://www.swirlds.com/downloads/SWIRLDS-TR-2016-01.pdf}{Median fairness}}. Under this definition, if the median of the set of receive times for $Tx$ at all nodes is smaller than the median of the set of receive times for $Tx'$ at all nodes, then $Tx$ should be ordered before $Tx'$ in the fair-ordered ledger of all honest nodes. See Fig.~\\ref{fig:median-fairness} for an illustration. Although this definition takes into consideration aforementioned interleaving, however, a protocol guaranteeing median fairness would be vulnerable to order manipulation due to even a single adversarial node reporting a flipped receive timestamp to the protocol. To be precise, consider two transactions $Tx$ and $Tx'$ and five nodes, node $A$, $B$, $C$, $D$ and $E$, where $E$ is the adversary that is Byzantine in nature. $Tx$ is received by nodes $A$, $\\cdots$ , $E$ at rounds $1$, $1$, $4$, $4$, $2$ while $Tx'$ is received by the nodes at rounds $2$, $2$, $5$, $5$, $3$. Now, all nodes have received $Tx$ before $Tx'$ and consequently, $median(Tx) < median(Tx')$. However, the adversarial node $E$ could falsely report its receive times for $Tx$ to be round $3$ and that for $Tx'$ to be round $2$. Now, $median(Tx) = median(1,1,4,4,3) = 3 > median(Tx') = median(2,2,5,5,2) = 2$. Thus, even a single Byzantine adversary is able to invert the ordering of transactions $Tx$ and $Tx'$ by reporting false receive times.   \n    \\begin{figure}\n    \\centering\n     \\begin{subfigure}[b]{0.45\\textwidth}\n         \\centering\n         \\includegraphics[width=\\textwidth]{figures/lineraizability.pdf}\n         \\caption{For ordering linearizability. The receive time for transactions $Tx$ and $Tx'$ at each honest node are depicted by blue-colored and orange-colored dots, respectively.}\n         \\label{fig:linearizability}\n     \\end{subfigure}\n     \\hfill\n     \\begin{subfigure}[b]{0.45\\textwidth}\n         \\centering\n         \\includegraphics[width=\\textwidth]{figures/median_fairness.pdf}\n         \\caption{For median-fairness. The receive time for transactions $Tx$ and $Tx'$ at each node are depicted by blue-colored and orange-colored dots, respectively.}\n         \\label{fig:median-fairness}\n     \\end{subfigure}\n        \\caption{ Pictorial representation for ordering linearizability and median fairness.}\n        \\label{fig:order-}\n\\end{figure}\n    \\item \\textbf{receive-order-fairness}. Intuitively, recalling the aforementioned example of frontrunning, a sound definition for fair ordering of transactions must ensure that if a transaction $Tx$ is \\textbf{received before} the transaction $Tx'$ by a \\textbf{large fraction} of nodes in the blockchain system, then $Tx$ must be \\textbf{ordered before} $Tx'$ in the fair-ordered ledger of an honest node. See Fig~\\ref{fig:gamma-receive-order-fairness} for an illustration of this intuition. However, due to \\href{https://en.wikipedia.org/wiki/Condorcet_paradox}{Condorcet paradox}, receive-order-fairness is impossible to achieve. To understand this impossibility result, assume that there are currently $N$ nodes -  node $1$, node $2$, $\\cdots$, node $N$, in the system. Suppose that the node $1$ received transactions in the order $[Tx_1, Tx_2, \\cdots, Tx_N]$ and any node $n \\neq 1$ received transactions in the order  $[Tx_n, \\cdots, Tx_N, Tx_1, \\cdots, Tx_{n-1}]$. Observe that for any pair of consecutive transactions $Tx_n, Tx_{n+1},$ $n \\in [1, 2, \\cdots, N-1]$, there are $N-1$ nodes that received $Tx_n$ before $Tx_{n+1}$. Also, there are $N-1$ nodes that received $Tx_{N-1}$ before $Tx_1$. This means that any consensus protocol satisfying receive-order-fairness must order $Tx_1$ before $Tx_2$, $Tx_2$ before $Tx_3$, $\\cdots$, $Tx_{n-1}$ before $Tx_n$ and $Tx_n$ before $Tx_1$, which is a contradiction. Thus, despite transitive ordering of the transactions at each node, the collective final ordering is non-transitive and paradoxical.   \n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.98\\textwidth]{figures/ordering_manipulation.pdf}\n    \\caption{Suppose the transaction $Tx$, broadcast by client $A$ at time $t_1$, is received by a large fraction of nodes at $t'_1$ before client $B$ broadcasts the transaction $Tx'$ at $t_2$. Then, when the blocks containing transactions $Tx$ and $Tx'$ are confirmed at $t_{confirm}$, $\\gamma-$receive-order-fairness specifies ordering $Tx$ before $Tx'$ in the fair-ordered ledger of an honest node.}\n    \\label{fig:gamma-receive-order-fairness}\n\\end{figure}\n    \\item \\textbf{\\href{https://link.springer.com/chapter/10.1007/978-3-030-56877-1_16}{Batch-order-fairness}}. This definition states that if a transaction $Tx$ is \\textbf{received before} the transaction $Tx'$ by a large fraction of nodes in the blockchain system,  then the fair-ordered ledger will order $Tx$ \\textbf{no later} than $Tx'$. Observe that this definition is a relaxation on receive-order-fairness. Referring to the example given in receive-order-fairness, the paradoxical orderings due to Condorcet paradox can be sidestepped by ordering all the transactions in the paradoxical orderings together in the same batch and, thus, ordering them together in the fair-ordered ledger. \n    % Note that transactions inside a batch can still be totally ordered by a higher-layer compiler; their ordering just wont be taken into account for unfairness. Also note that, for any pair of transactions $tx$ and $tx'$ that doesn't satisfy the antecedent of the definition of $\\gamma-$batch-order-fairness,  this definition doesn't dictate any requirement on their ordering except that a protocol guaranteeing $\\gamma-$batch-order-fairness must ensure consistent ordering  between $tx$ and $tx'$ in the transaction ledger of all honest nodes. \n\\end{itemize}\n\n\n\n\n% Leveraging on this, in the next section, we will present protocols for permissionless system that guarantees $\\gamma-$batch-order-fairness for ordering of transactions.\n\n\n\n\\end{document}",
    "lecture_08.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\usepackage{markdown}\n\\usepackage{amsthm}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\newcommand{\\pramod}[1]{{\\color{red}\n\\footnotesize[Pramod: #1] }}\n\\newcommand{\\xw}[1]{{\\color{green}\n\\footnotesize[Xuechao: #1] }}\n%\\theoremstyle{definition}\n\\newtheorem{definition}{Definition}\n\\newtheorem{theorem}{Theorem}\n\\newtheorem{lemma}{Lemma}\n%\\let\\proof\\relax\n%\\let\\endproof\\relax \n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 8}\n\\cfoot{\\thepage}\n\n\\title{Lecture 8:  Scaling Throughput in Bitcoin}\n\\author{Principles of Blockchains, Princeton University,  \\\\ Professor:  Pramod Viswanath \\\\ Scribe:  Xuechao Wang}\n%\\date{February 18, 2021}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nIn this lecture, we see why security inherently limits the mining rate and hence the throughput (transactions per second) of Bitcoin. Scaling the throughput while maintaining the high security of Bitcoin has been a major research topic of the past few years. In this lecture, we look at three major efforts with increasing success: {\\sf GHOST} (changes the fork choice rule in mining), {\\sf Bitcoin-NG} (a single successful miner can propose multiple blocks in sequence), and {\\sf Prism} (separates proposer blocks from transaction blocks, and yet mines them together via cryptographic sortition). {\\sf GHOST} is vulnerable to a balance attack that reduces its throughput back to Bitcoin levels. {\\sf Bitcoin-NG} is vulnerable to bribing attacks by an {\\em  adaptive} adversary, again restricting its throughput back to Bitcoin levels. {\\sf Prism}, closely related to {\\sf Fruitchains} from the previous lecture, retains the high security of Bitcoin and achieves throughput restricted only by the underlying network capacity. \n\\end{abstract}\n\n\n\\section*{Bitcoin's throughput is security limited}\nThe only key parameters in Bitcoin are: mining difficulty (decides the mining rate $\\lambda$) and block size ($B$). In practice, $\\lambda$ is set to be 0.1/minute (i.e., one block every ten minutes is mined on average) and $B$ is roughly 1 MB (approximately 2000 transactions). So the throughput of Bitcoin (assuming only honest miners) is very low:\n$$\n(1-\\beta)\\lambda B \\approx 4 \\mbox{ transactions/second}, \n$$\nrepresenting a data rate of roughly 16 Kbps. We observe that the underlying network speeds are far larger: e.g., 100 Mbps is an inexpensive cable modem speed: so clearly, the network is not limiting Bitcoin's throughput. We can try increasing the two parameters $\\lambda, B$ to directly increase throughput: \n\\begin{itemize}\n\\item  Increasing $\\lambda$ directly impacts the security: the hash power of the adversary that can be tolerated decreases as $\\lambda \\Delta$ increases (see Figure~\\ref{fig:threshold}, reproduced here from Lecture 6). While $\\lambda$ can be increased somewhat, e.g., say by a factor of 40 (as in Ethereum, a blockchain that also uses the longest chain protocol) without impacting safety seriously, there is still an inherent limitation on the mining rate due to the impact on security. \n\\item Increasing $B$ proportionally increases the network delay $\\Delta$: after all, it takes longer to transmit a bigger packet. This basic relationship is captured by a common networking model:\n$$\\Delta = \\frac{B}{C} + D, $$\nwhere $C$ is the network {\\em capacity} (measured in bits/s) and $D$ is the propagation delay (essentially the ratio of distance to the speed of light). Empirical measurements on the Bitcoin main network has borne out this observation (see Figure~\\ref{fig:empricalnetworkdata}). Thus increasing $B$\n has the same effect as increasing the mining rate $\\lambda$:\n this increases the product $\\lambda \\Delta$, undermining the security. \n \\end{itemize} \n We conclude that the throughput of Bitcoin is {\\em security limited}. \nIn this lecture, we see three separate attempts to increase the throughput of Bitcoin while maintaining its security; the first two are successful only to limited degrees while the third resolves the issue entirely. \n\n\\begin{figure}\n     \\centering\n     \\includegraphics[width=10cm]{figures/threshold.png}\n   \\caption{Minimum hash power needed by the adversary to succeed in any safety attack.  }\n   \\label{fig:threshold}\n \\end{figure}\n \n \\begin{figure}\n     \\centering\n     \\includegraphics[width=10cm]{figures/empiricalnetworkdata.png}\n   \\caption{Plot of network delay as a function of the size of the block being communicated based on empirical measurements on the Bitcoin network. }\n   \\label{fig:empricalnetworkdata}\n \\end{figure}\n \n \n \n\\section*{{\\sf GHOST} fork choice rule}\nIncreasing the mining rate and/or the block size has the direct effect of increasing the product $\\lambda \\Delta$ which is directly proportional to the {\\em forking rate}: the fraction of blocks not on the longest chain. The forking rate, in turn, directly impacts the security of the longest chain protocol. Perhaps one should deviate from the longest chain protocol to a new mining rule  that {\\em embraces} forking (the longest chain protocol fights forking) -- this is the spirit of the {\\sf GHOST} (greedy heaviest observed subtree) fork choice rule: the key idea is to measure the ``quality\" of a chain not by its height but by how heavy the weight of the subtree that supports the chain is. The {\\sf GHOST} rule is best explained by an example. \n\nConsider the block tree in Figure~\\ref{fig:ghostillustration}, with substantial forking caused by a large mining rate. The adversary faces no forking (since its mining efforts are all synchronized) and thus finds it easier to overtake the longest chain via a private attack. The {\\sf GHOST} rule also dictates honest nodes to mine at the tip of a chain, but the chosen chain is potentially different from  the longest chain  as follows: for each block we calculate the {\\em weight} of the subtree rooted at that\nblock, i.e., the number of blocks in the subtree (including the block itself). Note that the weight of every leaf block is simply unity; the weights of the blocks are labeled inside each block in Figure~\\ref{fig:ghostillustration}. \nThe {\\sf GHOST} chain is constructed by starting at the genesis and following the heaviest subtree whenever a fork is encountered; the {\\sf GHOST} chain (red/green) and the longest chain (blue) could be different, as in Figure~\\ref{fig:ghostillustration}. \n\n\\begin{figure}\n \\centering\n \\includegraphics[width=12cm]{figures/GHOST.png}\n\\caption{{\\sf GHOST} rule dictates mining to be conducted at the tip of the red/green colored chain, different from the longest chain rule (blue colored).  }\n\\label{fig:ghostillustration}\n\\end{figure}\n\n\\noindent {\\bf Private attack on {\\sf GHOST}}. Consider the adversary launching a private attack, i.e., mining in private and not participating in the public mining process of the honest nodes. The weight of the honest subtree (rooted at the genesis) is proportional to the honest mining rate, $(1-\\beta)\\lambda$, irrespective of the forking rate of the honest subtree. The weight of the private adversary chain (or any subtree) is proportional to $\\beta \\lambda$. Thus the safety of the {\\sf GHOST} rule against a private attack is ensured as long as  $1-\\beta > \\frac{1}{2}$, i.e., a majority of the hash power is honest (follows protocol) -- note that this is true regardless of the mining rate $\\lambda$, so the throughput can be increased by increasing the mining rate, only limited by the network capacity. This security analysis is focused on a specific adversarial strategy: the private attack. In the  security analysis of the longest chain protocol (cf.\\ Lecture 6), we have seen that the private attack is exactly optimal for any confirmation depth $k$ (when $\\Delta = 0$) and  optimal for large confirmation depths (when $\\Delta > 0$). So it might seem that private attack analysis suffices in general for security of blockchain protocols; this was the premise on which {\\sf GHOST} was invented and its earlier security analysis was based. Unfortunately, this premise turns out to be false as we see next. \n\n\\noindent {\\bf Balance attack on {\\sf GHOST}}.  The goal of the adversary in the balance attack is to maintain {\\em two} growing chains that have equal weights (according to the {\\sf GHOST} rule).  When there are two or more  chains with equal weights, honest miners pick the earliest chain to mine on. By controlling the network enough so that half the honest nodes see one of the chains earlier than the other (and vice versa with the other half of honest nodes), the adversary ensures that half the honest nodes mine at the tip of one of the chains (red) and the other half mine at the tip of the other chain (green), {\\em splitting} the honest mining power. The adversarial miner simply privately mines on the two  blocks forking from the genesis itself (see Figure~\\ref{fig:ghostillustration}), making its blocks  public as needed (to balance the two subtree weights). \nIf the balance attack is kept up for longer than the confirmation depth $k$,  then the safety of the blockchain protocol is fatally threatened. The following analysis sheds light on how much hash power $\\beta$ the adversary needs to possess to successfully maintain the balance attack. \n\n\n\\noindent {\\bf Security analysis of balance attack on {\\sf GHOST}}.  Suppose at some steady state during the balance attack,  within the network delay $\\Delta$, the left (right)  subtree forked from genesis has grown $N_\\ell$ ($N_r$) {\\em honest} blocks, respectively. Due to the mining process and the split in honest power among the two subtrees, both $N_\\ell$ and $N_r$ are i.i.d.\\ Poisson random variables with mean  equal to  $\\frac{(1-\\beta)\\lambda \\Delta}{2}$. For the balance attack to be successful, the adversary needs to ensure that $N_\\ell$ and $N_r$ match with high probability, i.e., it needs to mine $|N_\\ell-N_r|$ blocks with high probability. Let $N_a$ be the number of adversarial blocks mined in private (totally on both the left and right subtrees) within the network delay $\\Delta$, which is a Poisson random variable with mean $\\beta\\lambda\\Delta$. \n% Therefore, a {\\color{red} necessary} condition for the balance attack to be able to continue indefinitely with non-zero probability is\n% \\begin{equation}\n%  \\beta\\lambda\\Delta > \\mathbb{E}[|N_\\ell-N_r|].\n% \\end{equation}\n% \\xw{To argue that the balance attack is successful if $\\lambda\\Delta$ get too large, we need a sufficient condition.}\n% A loose argument. \nWe note that $\\mathbb{E}[N_\\ell - N_r]$ is zero, and the second moment of $N_\\ell - N_r$ is \n$$\n  \\mathbb{E}[(N_\\ell - N_r)^2]  = {\\rm Var}(N_\\ell - N_r) = {\\rm Var}(N_\\ell) + {\\rm Var}(N_r)= (1-\\beta)\\lambda \\Delta. \n$$\nThen by Cauchy-Schwarz inequality, we have $\\mathbb{E}(|N_\\ell -N_r|) \\leq \\sqrt{\\mathbb{E}[(N_\\ell - N_r)^2]} = \\sqrt{(1-\\beta)\\lambda \\Delta}$.\nFor fixed $\\beta > 0$, if $\\lambda\\Delta \\gg 1$, then we have $\\beta \\lambda\\Delta \\gg \\sqrt{(1-\\beta)\\lambda \\Delta} \\geq \\mathbb{E}(|N_\\ell -N_r|)$, i.e., the expected number of blocks the adversary can mine within the network delay $\\Delta$ far exceeds the gap between the two subtrees. Hence, the adversary can easily balance the two subtrees and remain in the steady state of the balance attack. Once the balance attack is kept up for longer than the confirmation depth $k$,  the safety of the {\\sf GHOST} rule is broken. Just like in Bitcoin, {\\sf GHOST} is not secure when $\\lambda\\Delta \\gg 1$ for any $\\beta$. Therefore, we see that the throughput of {\\sf GHOST} is again limited by security, due to the balance attack.\n\n% \\pramod{Xuechao: can you please complete this proof? You can borrow the logic from Appendix A of the Prism theory paper, version 2, on arxiv. Please conclude that the balance attack is successful if $\\lambda\\Delta$ get too large. This limits the throughput and please compare with the Bitcoin performance. Argue they are the essentially the same. this was also done in an earlier version of Prism paper (both main text and Appendix).} \n \n\n\n\n\n\n\n\\section*{{\\sf Bitcoin-NG}}\n{\\sf GHOST} tried to speed up the mining process while using a different fork choice rule, but ran into the balance attack. {\\sf Bitcoin-NG} approaches the scaling problem from a different angle: separate the transactions (which make up all the throughput) from the headers (which provide the chaining and resultant security). The idea is similar in spirit to the {\\sf Fruitchains} protocol we saw in Lecture 7. There are two types of blocks: {\\em proposer } blocks and {\\em transaction} blocks. %The proposer blocks are just like regular Bitcoin blocks, with the exception that   \nThe  mining process is described below; see  Figure~\\ref{fig:bitcoin-ng}.  \n\\begin{itemize}\n    \\item Proposer blocks are mined as in Bitcoin, with the difference that the {\\em public key of the miner} is included in the block; this is a departure from  Bitcoin where the miners stay truly anonymous, which opens up security vulnerabilities as we will see shortly.\n    \\item The transaction blocks are not subject to proof of work and are simply signed (using the private key) by the miner whose public key is embedded in the immediately preceding proposer block. Since the transaction blocks are not inhibited by proof of work, they can be added to the blockchain as quickly as the underlying network can support their reliable broadcast. The transaction blocks continue to be mined until a new proposer block appears on the longest chain, after which only this new proposer can mine transaction blocks. \n    \\item Proposer blocks and transaction blocks are interspersed with each other: proposer blocks are mined at the tip of the longest chain: the length  is only defined via the number of proposer blocks in the chain.  \n\\end{itemize}\n\n\n \\begin{figure}\n     \\centering\n     \\includegraphics[width=6cm]{figures/bitcoin-ng.png}\n   \\caption{{\\sf Bitcoin-NG} protocol has two block types: proposer and transaction blocks, interspersed with each other. The proposer block is mined at the tip of the longest chain, as measured in terms of proposer blocks from the genesis. Transaction blocks are not subject to proof of work, but can only be signed using a private key associated with the  public key as that identified in the immediately preceding proposer block.}\n   \\label{fig:bitcoin-ng}\n \\end{figure}\n\n\n\\noindent {\\bf Security of {\\sf Bitcoin-NG}}. The longest chain mining rule is executed only with respect to the proposer blocks. Further, confirmation of a  proposer block (and all transaction blocks chain in between the proposer blocks on the chain up to the genesis block)  occurs only when there are at least $k$ {\\em proposer} blocks mined underneath. Therefore, transaction blocks are not involved in the mining and confirmation processes; thus the security of the longest chain is provided by the proposer blocks and  since the proposer blocks are mined infrequently, the same strong security guarantees as Bitcoin hold here. \n\n Consider an {\\em adaptive} adversary, i.e., one which chooses which participants to corrupt while the protocol is running.  An adaptive adversary is typically implemented by coordinating with the participants outside the blockchain (e.g., on a website where participants can upload their blockchain status). Bitcoin has a strong {\\em unpredictability} property which renders an adaptive adversary no more potent than a static one. The unpredictability property has  two components: (a) which miner will be successful in the PoW process is unknown to anyone, including the miner, until the success is seen; (b) once a miner succeeds in the PoW process, the mined block is ``sealed\", i.e., the contents cannot be changed without rendering the nonce useless and, hence, successful mining defeated. \n \n However, the presence of the public key of the miner in the proposer block identifies the miner of the following transaction blocks (until a new proposer block is mined), so property (a) above is violated. Further, the transaction blocks are no longer ``sealed\": their contents can be changed later by the owner of the private key associated with the immediately preceding proposer block; so property (b) above is also violated. An adaptive adversary can take advantage of the resulting predictability to  launch the following {\\em slow-down} attack. Whenever a proposer block is published, the adversary corrupts the miner and shuts down all following transaction blocks.  Security is not threatened in this attack, but  only the transactions inside of the proposer block get to the confirmed ledger and the resulting  throughput is the same as that of Bitcoin. \n \n {\\sf Bitcoin-NG} is an interesting design to scale throughput by separating payload (transactions) from security (longest chain rule of PoW mining and $k$-deep confirmation of proposer blocks). However, the order in which the two types of blocks, transaction and proposer, are linked leads to slow-down attacks by an adaptive adversary. A subtle change involving {\\em reversing} the order of linking between transaction and proposer blocks directly solves this problem. This architecture is the same as the {\\sf Fruitchains} protocol from Lecture 7, but was independently constructed and its throughput optimality proved in  \\href{https://arxiv.org/pdf/1810.08092v3.pdf}{{\\sf Prism 1.0}}; this architecture  completely solves the problem of throughput scaling in PoW longest chain protocols and is described next. \n\n\\section*{{\\sf Prism}: scaling throughput to physical limits }\nConsider the {\\sf Fruitchains} architecture from Lecture 7 (see Figure~\\ref{fig:prism10}). By setting the transaction  target  difficulty easy, the transactions are published on the blockchain at a high throughput (limited only by the underlying network capacity).  By setting the proposer target difficulty hard, the security is maintained. This optimal throughput property of {\\sf Fruitchains} architecture was observed in an independent work that constructed a PoW protocol called \\href{https://arxiv.org/pdf/1810.08092v3.pdf}{{\\sf Prism}}. It is interesting to compare and contrast with the {\\sf Bitcoin-NG} architecture (see Figure~\\ref{fig:bitcoin-ng}). The coupling between the transaction and proposer blocks is {\\em reversed}: in {\\sf Bitcoin-NG}, a proposer block is mined first and then transaction blocks spawned from it. In {\\sf Fruitchains}, the previously mined transaction blocks are referred to by a proposer block (by inserting their hashes inside the proposer block). Further, the mining process of the two types of blocks are coupled in different ways: in {\\sf Bitcoin-NG}, the proposer block publishes its public key inside the block, whose corresponding private key is then used to sign the following transaction blocks -- at the expense of allowing a slow-down attack by an adaptive adversary. In {\\sf Fruitchains}, the transaction and proposer blocks are mined {\\em together} via the ``two for one\" mining procedure and cryptographic sortition (discussed in detail in Lecture~7) -- this format of mining allows the overall architecture to have the same unpredictability properties as {\\sf Bitcoin}: until a superblock (containing both proposer and transaction blocks) is successfully mined, it is unclear whether the superblock will be identified as a proposer block or transaction block (property (a) above). Further, once the superblock is mined, the contents are sealed by the proof of work (property (b) above). Thus the security of {\\sf Fruitchains} is as high as that in {\\sf Bitcoin}. \n\n\n \\begin{figure}\n     \\centering\n     \\includegraphics[width=10cm]{figures/prism10.png}\n   \\caption{{\\sf Prism 1.0} and {\\sf Fruitchains} protocols have two block types: proposer and transaction blocks, interspersed with each other. The transaction and proposer blocks are mined in parallel, coupled through the sortition process. Transaction block   hashes are referred to by proposer blocks thus bringing the transactions into the confirmed ledger. Transaction block mining is kept easy (so throughput is high) and proposer block mining is kept difficult (so security is high).   }\n   \\label{fig:prism10}\n \\end{figure}\n\nDue to the decoupling of transaction blocks from the security of the protocol, the throughput is only restricted by the capacity of the underlying P2P network. A full-stack UTXO implementation of {\\sf Prism} achieves more than 70,000 transactions/second, as reported in \\href{https://arxiv.org/pdf/1909.11261.pdf}{this paper}. The full {\\sf Prism} protocol also resolves another important limitation of the longest chain protocol: latency of confirmation. This is the topic of the next lecture. \n\n\n\\section*{References}\n\nScaling throughput of blockchain protocols has been a major research focus in the past three years, arguably the most important issue studied in blockchains. One major direction has been to improve the throughput of PoW blockchains; this lecture has covered the  highlights of this research thrust, ending with the throughput optimality of {\\sf Fruitchains} and {\\sf Prism}. One major direction we have not covered in this lecture involves   embracing forking by embedding appropriate reference links among the blocks (other than the usual parent reference link) to create a directed acyclic graph (DAG) structured blockchain.   Each block in a DAG can reference multiple previous blocks instead of a unique ancestor (as in Bitcoin). The pertinent challenges are how to choose the reference links and how to obtain a total ordering of blocks from the observed DAG in a way that is secure. In a family of protocols, {\\sf Inclusive}, {\\sf Spectre}, and {\\sf Phantom}, every block references all previous orphan blocks. These reference links are interpreted in differing ways to give these different protocols. \n\nFor example, in \\href{https://fc15.ifca.ai/preproceedings/paper_101.pdf}{\\sf Inclusive}, the key observation is that the reference link structure provides enough information to emulate any main-chain protocol, such as the longest-chain or {\\sf GHOST} protocol, while in addition providing the ability to pull in stale blocks into a valid ledger. However, the security guarantee remains the same as that of {\\sf Bitcoin} (namely, tending to zero as the mining rate grows), and the throughput is security-limited. \n\\href{https://arxiv.org/pdf/1805.03870.pdf}{Conflux} is another DAG-based protocol whose goal is to increase throughput. However, {\\sf Conflux}s reference links are not used to determine where to mine blocks or how to confirm them; they are only used to include side-chain blocks into the main chain to improve throughput. The main chain itself is selected by the {\\sf GHOST} rule. Due to the vulnerability of {\\sf GHOST} to the balance attack, the secured throughput of {\\sf Conflux} is limited to {\\sf Bitcoin} levels. \n Although {\\sf Prism} uses a DAG to order transactions, it diverges from prior DAG schemes by separating block proposals from block ordering in the protocol. This helps because an adversarial party that misbehaves during block proposal does not affect the security of transaction ordering, and vice versa; it provides a degree of algorithmic sandboxing. \n\n \n\\input{Problem_sets/Lec8_PS}\n\n\n\n\\end{document}",
    "lecture_02.tex": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1.25in]{geometry}\n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{graphicx}\n\\hypersetup{\n    colorlinks=true,\n    linkcolor=blue,\n    filecolor=magenta,      \n    urlcolor=blue\n}\n\\usepackage{fancyhdr}\n\\pagestyle{fancy}\n\\fancyhf{}\n\\rhead{Principles of Blockchains}\n\\lhead{Lecture 2}\n\\cfoot{\\thepage}\n\n\\title{Lecture 2:  Blockchains as Cryptographic Data Structures}\n\\author{Principles of Blockchains, Princeton University,  \\\\ Professor:  Pramod Viswanath \\\\ Scribe: Suryanarayana Sankagiri}\n%\\date{January 28, 2021}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nThere are two main cryptographic tools used critically in blockchains: \\textbf{cryptographic hash functions} and \\textbf{digital signatures}. We first briefly review regular hash functions, and their use in hash tables. We then introduce cryptographic hash functions and state their additional security properties. The notion of a \\textbf{hash pointer} is then introduced, which is used to define the data structures \\textbf{blockchains} and \\textbf{Merkle trees}. We cover properties of Merkle trees as relevant to blockchains in detail leading to the creation of a tamper-resistant ledger. Finally, we present digital signatures (the public-key variant) used to authenticate messages (i.e., map a message to its sender) setting the stage for a decentralized ledger.  \n\\end{abstract}\n\n\\section*{Hash Functions}\nA hash function is a function that converts a binary string of arbitrary length to a binary string of fixed length. Since any data structure can be represented as a binary string, a hash function converts any data structure to a fixed-length binary string. For any piece of data $x$, the output of the hash function is denoted by $H(x)$ and is called the hash of $x$. Given a hash function, suppose its output is always a binary string of length $k$. Then the size of the output space is $2^k$. Call this output space $Y$. \n\nA good hash function has two properties. Firstly, it should be very fast to compute. Secondly, it must reduce the chance of collisions over the expected input space. A collision happens when there are two inputs, $x$ and $x'$, which get mapped to the same hash, i.e., $H(x) = H(x')$. To minimize collisions, a hash function must distribute its output uniformly over the output space $Y$. Let us elaborate on this. Suppose we restrict ourselves to some fixed set of inputs (denoted by $X$). Then, if we choose an input $x$ uniformly at random from this set, the probability that $H(x)$ is equal to a particular $y$ should be close to $2^{-k}$. Given such a hash function, and $m$ inputs that are sampled uniformly at random from $X$, what is the probability that there will be a collision? The \\href{https://en.wikipedia.org/wiki/Birthday_problem}{birthday paradox} comes into play here. The probability that there will be at least one collision among the $m$ hashes is approximately $1 - \\exp(-m^2 2^{-k})$. Thus, for $ m \\approx 2^{k/2} $, there is a reasonable chance for a hash collision.\n\nA classic use of hash functions is to create \\textbf{hash tables}. Hash tables are a form of a key-value store, just like dictionaries in standard programming languages. They are used to reduce the lookup time for values stored in it. In what follows, a value is a piece of data; it could be in the form of any data type (integer, string, tuple, or a custom type). The following example illustrates why hash tables are useful. Suppose we want to store $C$ (say, a million) values, e.g., (name, phone number, email address) tuples. We could store them as a list of length $C$, which would take $O(C)$ time to look up. Instead, we could first hash the values into a binary string of length $k$, and store each value that hashes to some particular $y \\in Y$ as a separate list. These lists would be of size $C/2^k$, because of the uniform spread of the hashes. These shorter lists would take much lesser time to look up. The additional overhead of computing the hash is minimal. \n\nThe \\href{https://en.wikipedia.org/wiki/Hash_function}{Wikipedia page on hash functions} describes the use of hash functions in hash tables in more detail and gives many examples of hash functions. For example, one can take the last 256 bits of a long bit string as its hash. More generally, one can take any subset of 256 (or $k$) bits as the hash. A potential drawback of such hashes is that there could be many collisions; this depends upon the input set. One can choose the hash to represent the subset of bits in a bitstring that are likely to change from one data point to another in the relevant application. One can also perform certain computations that mix-up the bits, such as computing the xor of the first and last bits, the second and second-last bits, and so on.\n\n\\section*{Cryptographic Hash Functions}\nIn cryptocurrencies, we require additional properties from a hash function, which are captured via a \\textbf{cryptographic hash function}. The key feature of a cryptographic hash function is that it is easy to compute, but difficult to invert. To elaborate, given a binary string $x$, it is easy to compute $y = H(x)$, but given an arbitrary $y'$, it is difficult to find any $x'$ for which $H(x') = y'$. By difficult, we mean that it would take a really long time to find such an $x'$. Essentially, the only way to do so is to exhaustively search over all possible values of $x'$. Another important property of cryptographic hash functions is \\textbf{collision resistance}: it is difficult to come up with two values $x, x'$ that are not equal such that $H(x) = H(x')$. The output space of cryptographic hash functions must be large, or else one could easily find a hash collision by iterating over the output space. Typically, they are 128-bit strings, 256-bit strings, or longer. A hash functions security is determined by how easy it is to find hash collisions (or partial hash collisions, defined in terms of equality of a prefix of the hash).\n\nNote that regular hash functions minimize the chance of collisions if the inputs are chosen at random. However, if one is specifically looking to find a hash collision, it is easy to do so (see if you can find collisions for the examples given above). In contrast, for a cryptographic hash function, finding collisions should be practically impossible, even for an adversary specifically trying to do so. In blockchains we will exclusively use cryptographic hash functions and we refer to cryptographic hashes as merely hashes. It is useful to think of a hash function as a random oracle, which generates an arbitrary random $k$-bit string for any input with a uniform distribution. Note that the oracle always returns a fixed output for a given input. In practice, for $k$ large enough, we assume that collisions never occur.\n\nConstructing a cryptographic hash function is not easy (in contrast to regular hash functions). In fact, they should not be created in an ad-hoc manner. The National Institute of Standards and Technology (NIST) sets a standard for these hash functions. One such function is \\textbf{SHA-256}, where SHA stands for Secure Hash Algorithm, and 256 is the length of the output. This function has been studied extensively and is currently believed to be secure enough for practical applications. The exact construction of this function, and the best-known attacks on it, are given on the \\href{https://en.wikipedia.org/wiki/SHA-2}{Wikipedia page for SHA}. This function is available as part of a cryptography library in most standard programming languages.\n\nA general principle used in the construction of many cryptographic hash functions is the \\textbf{Merkle-Damgard construction}. A rough description of this construction is as follows. Suppose we are given a function $F$ that compresses strings of a certain length $l$ (say 512) bits to strings of shorter length $k$ (say 256) bits. Further, suppose this function has adversarial collision resistance (i.e., it is a cryptographic hash function). Then this function can be used to create a cryptographic hash function $H$, which takes as input an arbitrarily long string $m$. Break $m$ into portions of length $l - k$ (256 in our example); call these portions $m_1, m_2, \\ldots$. We appropriately pad the message with some extra bits to ensure that all portions are of equal length. The compression function $F$ is applied recursively, with the output of the $i$\\textsuperscript{th} iteration padded to $m_{i+1}$ and fed into the $i+1$\\textsuperscript{th} iteration of $F$. The initial input is a fixed string of $l$ bits.\n\n\\section*{Uses of cryptographic hashes}\nA hash of a certain value acts as a \\textbf{commitment} for that value. Consider an auction, where each party would like to bid a certain price without openly revealing the value to all. One can broadcast the hash of the value instead of the value itself. Later, after all the bids have been placed, one can reveal the actual value and others can verify if it was the originally committed value. Due to the collision resistance property, one cannot generate an alternate value that matches the same hash value; one is committed to the original value. Thus, publishing the hash of a value is like writing it on a piece of paper and placing it in a sealed envelope.\n\nA hash function can also be used as a \\textit{pointer} to certain values when these are stored in a hash table. Due to the collision resistance property, each value in the hash table has a unique hash. Thus, the hash serves as a pointer to the value within the hash table. When used in this fashion, we call the hash a \\textbf{hash pointer}. Note that a hash pointer is nothing more than a hash; the term alludes to the fact that the hash is being used as a pointer.\n\nA third application of hashes is that we can use it to create \\textbf{hash puzzles}. The problem (or puzzle) is to find an input $x$ such that $H(x)$ is less than a certain threshold. The simplest form of the threshold is to require that the first $n$ bits of the hash are all zero. The best method of solving such a puzzle is simply to randomly choose different inputs. This variable input to a hash puzzle is called a \\textbf{nonce}. More generally, the input is a tuple (nonce, data), where data stands for any useful data. For any threshold $\\tau$, the probability that a certain nonce succeeds is $\\tau/|Y|$ (recall $Y$ is the output space of the hash). Thus, on average, one needs to try $|Y|/\\tau$ different nonces to succeed. If $|Y|/\\tau$ is set to be a very large number, say $10^{10}$, and a computer can compute 1 hash in 10 nanoseconds, then such a computer would be able to solve the hash puzzle in 100 seconds (on average). Note that it is very quick to verify that a certain (nonce, data) tuple solves the hash puzzle.  Hash puzzles have been used as a means of preventing spam. If a sender must solve a hash puzzle each time it sends an email, then it cannot do so very frequently. Here, the data field could be the email and recipients address, so it needs to recompute the puzzle every time it sends a new email.\n\n\\section*{Blockchains}\nThe blockchain data structure is a linked list that uses hash pointers instead of regular pointers. In the context of blockchains, a block is a data type that contains a particular header field, called the hash pointer, and some data. The hash pointer field is simply the hash of another block, which we call its parent. A sequence of such blocks forms a chain, with each block containing a hash pointer to its parent; we call this chain a blockchain. A blockchain system is much more complicated than the blockchain data structure. Since this data structure lies at the heart of digital trust systems, the same term is used for the whole system. See this \\href{https://medium.com/@zhaohuabing/hash-pointers-and-data-structures-f85d5fe91659}{blog post} for an explanation of blockchains as a data structure with a figure.\n\nBlockchains are tamper-proof data structures, making them particularly useful in digital trust systems. Generally speaking, each party in the system stores a local copy of this data structure in the form of a hash table. Using the hash pointers, a party can obtain the sequence of ancestors (parent, parents parent, and so on) of any given block. Suppose a particular block is missing from a partys local hash table. It can query its peers for the block using the blocks hash (obtained from its child). It can then verify that the block it receives from its peer is the correct one (i.e., it has not been tampered with) by checking that its hash matches with what it has; this is essentially using the hash as a commitment. Extending this principle, a party can check if any portion of the blockchain it receives has been tampered with or not.\n\nSometimes it is useful for a party to verify the membership of one particular data value in the blockchain. Having access to the full blockchain and all data internal to it, will naturally provide proof of such membership. But for a party that is only interested in verifying the membership of one particular data value, this is very onerous. In anticipation of this requirement in practical blockchain systems, we consider a Merkle tree data structure to organize the data inside each of the blocks. This is discussed next. \n\n\\section*{Merkle Trees}\nA Merkle tree is a directed tree formed using hash pointers. It is constructed from a set of data values as follows. The hash of each value forms the \\textit{leaf node} of the Merkle tree. An \\textit{internal (non-leaf) node} contains the hashes of its two (or more) children nodes. In other words, a parent node consists of the hash pointers to its children. These tree nodes converge to a single root node. See the \\href{https://en.wikipedia.org/wiki/Merkle_tree}{Wikipedia page on Merkle trees} for a more elaborate explanation with a figure.\n\nMerkle trees are also tamper-proof data structures. By storing only the hash of the root of the Merkle tree (root hash), one can detect any modifications to the tree. However, they have additional properties, namely that of an accumulator (in some places, the term authenticated data structure is used instead of accumulator). We will not formally define these terms but rather provide a simple explanation. An accumulator scheme provides a compact commitment for a set of values. In addition, it provides a means to prove whether a specific value is part of the committed set without revealing the other values. For Merkle trees, this compact commitment is the root hash. The trees branch from the root node to a leaf node acts as a proof/witness for the corresponding value being in the set. See \\href{https://nakamoto.com/merkle-trees/}{here} for a more detailed explanation of Merkle trees as an accumulator, with figures.\n\n\\section*{Blockchains as a Ledger}\nA \\textbf{ledger} is an ordered list of data values. The blockchain data structure provides a tamper-resistant ordered sequence of blocks. Storing the data in each block as a Merkle tree allows for a natural ordering (e.g., lexicographic) of the data values. Put together, the two data structures (blockchain and Merkle tree) lead to a tamper resistant ledger. We did not specify who is creating the ledger so far; presumably a single party has write permission with all others having read permissions. This describes a centralized ledger above, with one person writing and many persons reading. How do we enable many parties to write? We first need a way to distinguish different parties.  Digital signatures are a method to provide people an identity, using which they can write blocks to the blockchain. This basic cryptographic primitive is discussed next.\n\n%\\section*{A centralized, tamper-evident ledger}\n%A ledger is an ordered list of data-values (or entries). For now, we work with this definition; in Lecture 5, we shall give some semantic meaning to the entries in the ledger. (E.g., the entries could be transactions, which are statements that record the transfer of money from one user to another). A blockchain consists of a sequence of blocks, linked via hash pointers. In a centralized ledger, a single user creates these blocks and hosts them on a server. Other users can download these blocks for a local copy of the ledger. Each block contains some new data to be recorded in the ledger. This data is arranged in the form of a Merkle tree, which also provides a natural order (from left-to-right in the tree). Thus, a centralized ledger can be created using blockchains.\n\n%Typically, it is desirable that once entries in the ledger are written, they are not removed. In other words, the ledger should be `append-only'. %It is also desirable that the copies of the ledger stored by each user locally are consistent with one another. This means that the sequence of entries in one user's ledger is a sub-sequence of entries of a different user's ledger. Moreover, they should not be too different in lengths. \n%In the centralized ledger described above, if the central party behaves `correctly', the ledger will indeed be append-only. However, if it so chooses, it can tweak some data in already published blocks later on. For example, suppose blocks $B_1, B_2, B_3$ are three consecutive blocks published by the central party, each of which point to each other. Suppose $B_2$ is tweaked after it has been published. This would violate the append-only property of the ledger. The blockchain and Merkle tree data structures provide a `proof' that the ledger has been tampered with. Even a user that did not see the original copy of block $B_3$ on the server can be convinced that the ledger was tampered with, if another user provides both versions of $B_3$.\n\n%Since each block has a unique hash, the central party effectively published a new block $B'_3$ that points to $B_3$.  %For example, suppose blocks $B_1, B_2, B_3$ are three consecutive blocks published by the central party, each of which point to each other. It then publishes a block $B'_3$ that points to $B_2$. Further, $B'_3$ has different data compared to $B_3$. Whenever there are two conflicting blocks at the same height, it leads to an inconsistency in the ledger among different parties. Further, suppose that it now continues to extend block $B'_3$ with newer blocks. Effectively, it has erased block $B_3$ from the ledger. It can also simply `tweak' some data within $B_3$, after it has been published.\n\n\\section*{Digital Signatures}\nDigital signatures are the cryptographic analog of handwritten signatures. Broadly speaking, a signed message allows anyone to check who the messages sender is. To elaborate, a digital signature scheme gives a pair of keys to each user: a secret key, which is held privately by each user, and a public key, which is given to everybody. A message can be signed using ones secret key, and the signature is sent along with the message. A different user can verify that the message indeed came from its purported sender by matching the message and signature to its public key. Thus, a users public key becomes the users identity in the system. The scheme is secure if an adversary cannot forge signatures, i.e., it cannot generate a valid signature without knowing the corresponding partys secret key. \n\nAn important point to note is that the signature is different for each message. Otherwise, upon receiving one particular message from a user, an adversary can then simply append the signature to other messages, rendering the scheme pointless. Typically, users sign the hash of the message that they wish to send. Thus, the object being signed is a constant-length bit string, and so is the signature itself. Once again, for unforgeability, one must have that the signature is long enough.\n\nJust as in hash functions, there are standards for secure signature schemes, declared by NIST. The scheme used by Bitcoin is known as the Elliptic Curve Digital Signature Algorithm (ECDSA). Just as in the case of hashes, these signature schemes have been empirically tested for years, and there is good reason to believe they are secure. We will not specify what elliptic curves are, and how they are used for signatures here. You can learn more about them from \\href{https://en.wikipedia.org/wiki/Elliptic_Curve_Digital_Signature_Algorithm}{Wikipedia page on ECDSA} and associated links, as well as from the references given below.\n\nThe first application of digital signatures is to upgrade the centralized blockchain system we saw earlier to a decentralized version. We do this by adding a digital signature to each block; this allows different users to append blocks to the blockchain and identify themselves through the signature. \\textit{Figure forthcoming}. There are three questions in this decentralized architecture: \n\\begin{enumerate}\n    \\item Who are the set of users that can participate in and how are they chosen? \n    \\item When and which block does a user get to append and how do others verify this rule in a decentralized manner?\n    \\item Where does a user append the block? In principle, a block can be appended to any other block in the view of the user. \n\\end{enumerate}\nBlockchain designs and their properties vary in how they answer the questions to these three questions. In the next lecture we will see how Bitcoin resolves these three questions. \n\nThe second application of digital signatures is in providing user attribution to the data stored in the blocks. So far the data is considered to be an abstract digital entity, but in many applications it makes sense to have attribution to users. For instance, in  cryptocurrencies, the data refers to transactions which record change of ownership of coins. Now using signatures for users ownership of coins can be established (during creation stage) and during transfer of ownership).  \\textit{Figure forthcoming}.\n\n\\section*{Summary}\nA hash maps any value (piece of data) to a constant-sized bit string. For practical purposes, the hash of a value uniquely identifies it. Hashes are used to construct blockchains and Merkle trees, which are tamper-proof data structures. Hashes provide commitments to pieces of data. In addition, Merkle trees act as accumulators, enabling one to provide a proof of membership for individual elements in a committed set. Digital signatures parallel hand-written signatures and thereby provide authenticated communication. All messages that are exchanged in a blockchain system are signed.\n\nWe also described a ledger, which is an ordered list of data values. We saw how the blockchain (and Merkle tree) data structure are sufficient to create a centralized ledger, with a central authority writing to the ledger and multiple parties reading from it. We discussed how digital signatures help us move towards a decentralized ledger. Finally, we identified three important questions to answer in order to have a functional decentralized ledger.\n\n\n\\section*{References}\nA good reference for the material of this lecture is Chapter 1 of the book ``Bitcoin and Cryptocurrency Technologies\" by Narayanan et al. In particular, it elaborates on the use of Merkle trees as an authenticated data structure, and explains digital signature schemes in more detail. A free, pre-publication version is available at  \\href{https://d28rh4a8wq0iu5.cloudfront.net/bitcointech/readings/princeton_bitcoin_book.pdf}{this link}.\n\n\\href{https://www.youtube.com/watch?v=4M8_Oo7lpiA}{This public talk} by Dan Boneh describes elliptic curves and their usage in cryptography, among other things.\n\n\\href{https://patents.google.com/patent/US4309569A/en}{The original patent application} by R. Merkle is a superb place to learn about Merkle trees. It is not every patent application that is this lucid and clear. \n\\input{Problem_sets/Lec2_PS}\n\n\\end{document}"
}